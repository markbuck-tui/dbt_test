2019-09-30 16:57:24,844 (MainThread): Tracking: tracking
2019-09-30 16:57:24,887 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC608>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B508>]}
2019-09-30 16:57:25,238 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-09-30 16:57:25,238 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.61', 64360), raddr=('54.164.98.48', 443)>

2019-09-30 16:57:25,240 (MainThread): Error sending message, disabling tracking
2019-09-30 16:57:25,310 (MainThread): Parsing macros\core.sql
2019-09-30 16:57:25,358 (MainThread): Parsing macros\adapters\common.sql
2019-09-30 16:57:25,454 (MainThread): Parsing macros\etc\datetime.sql
2019-09-30 16:57:25,492 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-09-30 16:57:25,511 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-09-30 16:57:25,532 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-09-30 16:57:25,554 (MainThread): Parsing macros\etc\is_incremental.sql
2019-09-30 16:57:25,610 (MainThread): Parsing macros\etc\query.sql
2019-09-30 16:57:25,651 (MainThread): Parsing macros\materializations\helpers.sql
2019-09-30 16:57:25,679 (MainThread): Parsing macros\materializations\common\merge.sql
2019-09-30 16:57:25,702 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-09-30 16:57:25,733 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-09-30 16:57:25,770 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-09-30 16:57:25,827 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-09-30 16:57:25,844 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-09-30 16:57:25,874 (MainThread): Parsing macros\materializations\table\table.sql
2019-09-30 16:57:25,896 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-09-30 16:57:25,991 (MainThread): Parsing macros\materializations\view\view.sql
2019-09-30 16:57:26,018 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-09-30 16:57:26,037 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-09-30 16:57:26,058 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-09-30 16:57:26,075 (MainThread): Parsing macros\schema_tests\unique.sql
2019-09-30 16:57:26,091 (MainThread): Parsing macros\adapters.sql
2019-09-30 16:57:26,125 (MainThread): Parsing macros\catalog.sql
2019-09-30 16:57:26,145 (MainThread): Parsing macros\materializations\incremental.sql
2019-09-30 16:57:26,169 (MainThread): Parsing macros\materializations\merge.sql
2019-09-30 16:57:26,188 (MainThread): Parsing macros\materializations\table.sql
2019-09-30 16:57:26,202 (MainThread): Parsing macros\materializations\view.sql
2019-09-30 16:57:26,234 (MainThread): Parsing model.dbt_test.create_table_booking_fact_uk
2019-09-30 16:57:26,237 (MainThread): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-09-30 16:57:26,237 (MainThread): Opening a new connection, currently in state init
2019-09-30 16:57:26,239 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-09-30 16:57:27,486 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-09-30 16:57:27,526 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-09-30 16:57:28,135 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-09-30 16:57:28,137 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-09-30 16:57:28,137 (MainThread): Re-using an available connection from the pool (formerly create_table_booking_fact_uk).
2019-09-30 16:57:28,241 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-09-30 16:57:28,243 (MainThread): 
2019-09-30 16:57:28,245 (MainThread): 16:57:28 | Concurrency: 1 threads (target='dev')
2019-09-30 16:57:28,246 (MainThread): 16:57:28 | 
2019-09-30 16:57:28,255 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-09-30 16:57:28,256 (Thread-1): Opening a new connection, currently in state init
2019-09-30 16:57:28,811 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-09-30 16:57:28,854 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-09-30 16:57:28,878 (Thread-1): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-09-30 16:57:28,878 (Thread-1): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-09-30 16:57:28,879 (Thread-1): Compiling model.dbt_test.create_table_booking_fact_uk
2019-09-30 16:57:28,891 (Thread-1): Writing injected SQL for node "model.dbt_test.create_table_booking_fact_uk"
2019-09-30 16:57:28,972 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-09-30 16:57:28,973 (MainThread): On v_booking_fact_uk: Close
2019-09-30 16:57:29,048 (MainThread): Connection 'create_table_booking_fact_uk' was left open.
2019-09-30 16:57:29,049 (MainThread): On create_table_booking_fact_uk: Close
2019-09-30 16:57:29,157 (MainThread): 16:57:29 | Done.
2019-09-30 16:57:29,159 (MainThread): Flushing usage events
2019-10-01 11:52:28,542 (MainThread): Tracking: tracking
2019-10-01 11:52:28,557 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8D5C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C927C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6CD88>]}
2019-10-01 11:52:28,911 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 11:52:28,912 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 52588), raddr=('54.164.98.48', 443)>

2019-10-01 11:52:28,915 (MainThread): Error sending message, disabling tracking
2019-10-01 11:52:28,993 (MainThread): Parsing macros\core.sql
2019-10-01 11:52:29,023 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 11:52:29,084 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 11:52:29,106 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 11:52:29,111 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 11:52:29,115 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 11:52:29,119 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 11:52:29,123 (MainThread): Parsing macros\etc\query.sql
2019-10-01 11:52:29,139 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 11:52:29,175 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 11:52:29,188 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 11:52:29,207 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 11:52:29,238 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 11:52:29,270 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 11:52:29,274 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 11:52:29,289 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 11:52:29,297 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 11:52:29,304 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 11:52:29,313 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 11:52:29,316 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 11:52:29,319 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 11:52:29,322 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 11:52:29,339 (MainThread): Parsing macros\adapters.sql
2019-10-01 11:52:29,353 (MainThread): Parsing macros\catalog.sql
2019-10-01 11:52:29,357 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 11:52:29,366 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 11:52:29,381 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 11:52:29,398 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 11:52:29,417 (MainThread): Parsing model.dbt_test.create_table_booking_fact_uk
2019-10-01 11:52:29,418 (MainThread): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-10-01 11:52:29,418 (MainThread): Opening a new connection, currently in state init
2019-10-01 11:52:29,421 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 11:52:30,017 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 11:52:30,051 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 11:52:30,632 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 11:52:30,633 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 11:52:30,633 (MainThread): Re-using an available connection from the pool (formerly create_table_booking_fact_uk).
2019-10-01 11:52:30,703 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 11:52:30,704 (MainThread): 
2019-10-01 11:52:30,705 (MainThread): 11:52:30 | Concurrency: 1 threads (target='dev')
2019-10-01 11:52:30,706 (MainThread): 11:52:30 | 
2019-10-01 11:52:30,709 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 11:52:30,710 (Thread-1): Opening a new connection, currently in state init
2019-10-01 11:52:31,268 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 11:52:31,291 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 11:52:31,301 (Thread-1): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-10-01 11:52:31,301 (Thread-1): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 11:52:31,302 (Thread-1): Compiling model.dbt_test.create_table_booking_fact_uk
2019-10-01 11:52:31,313 (Thread-1): Writing injected SQL for node "model.dbt_test.create_table_booking_fact_uk"
2019-10-01 11:52:31,414 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 11:52:31,414 (MainThread): On v_booking_fact_uk: Close
2019-10-01 11:52:31,488 (MainThread): Connection 'create_table_booking_fact_uk' was left open.
2019-10-01 11:52:31,489 (MainThread): On create_table_booking_fact_uk: Close
2019-10-01 11:52:31,582 (MainThread): 11:52:31 | Done.
2019-10-01 11:52:31,583 (MainThread): Flushing usage events
2019-10-01 13:50:19,609 (MainThread): Tracking: tracking
2019-10-01 13:50:19,613 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91448>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C808>]}
2019-10-01 13:50:19,959 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:50:19,960 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57844), raddr=('54.164.98.48', 443)>

2019-10-01 13:50:19,961 (MainThread): Error sending message, disabling tracking
2019-10-01 13:50:19,991 (MainThread): Parsing macros\core.sql
2019-10-01 13:50:20,005 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:50:20,053 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:50:20,064 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:50:20,067 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:50:20,072 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:50:20,076 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:50:20,080 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:50:20,085 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:50:20,096 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:50:20,107 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:50:20,124 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:50:20,156 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:50:20,198 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:50:20,205 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:50:20,220 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:50:20,228 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:50:20,235 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:50:20,244 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:50:20,248 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:50:20,251 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:50:20,256 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:50:20,271 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:50:20,289 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:50:20,309 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:50:20,318 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:50:20,323 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:50:20,328 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:50:20,375 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:50:20,376 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:50:20,376 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:50:20,379 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:50:20,730 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:50:20,752 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:50:21,409 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:50:21,410 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:50:21,410 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:50:21,415 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:50:21,416 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:50:21,416 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:50:21,420 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:50:21,421 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:50:21,421 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:50:21,426 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:50:21,428 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:50:21,428 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:50:21,433 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:50:21,434 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:50:21,434 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:50:21,442 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:50:21,445 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:50:21,445 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:50:21,454 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:50:21,455 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:50:21,455 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:50:21,459 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:50:21,460 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:50:21,461 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:50:21,466 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:50:21,468 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:50:21,468 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:50:21,476 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:50:21,478 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:50:21,478 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:50:21,484 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:50:21,485 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:50:21,485 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:50:21,490 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:50:21,491 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:50:21,491 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:50:21,495 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:50:21,498 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:50:21,498 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:50:21,506 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:50:21,508 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:50:21,508 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:50:21,518 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:50:21,520 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:50:21,520 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:50:21,529 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:50:21,531 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:50:21,531 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:50:21,536 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:50:21,537 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:50:21,537 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:50:21,542 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:50:21,543 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:50:21,543 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:50:21,548 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:50:21,549 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:50:21,549 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:50:21,609 (MainThread): Found 20 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 13:50:21,612 (MainThread): 
2019-10-01 13:50:21,613 (MainThread): 13:50:21 | Concurrency: 1 threads (target='dev')
2019-10-01 13:50:21,613 (MainThread): 13:50:21 | 
2019-10-01 13:50:21,618 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:50:21,618 (Thread-1): Opening a new connection, currently in state init
2019-10-01 13:50:22,147 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 13:50:22,159 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:50:22,174 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:50:22,174 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:50:22,178 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 13:50:22,187 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:50:22,209 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:50:22,215 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:50:22,216 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 13:50:22,238 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:50:22,293 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:50:22,297 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:50:22,299 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 13:50:22,324 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:50:22,383 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:50:22,386 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:50:22,387 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 13:50:22,401 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:50:22,423 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:50:22,427 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:50:22,428 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 13:50:22,440 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:50:22,455 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:50:22,458 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:50:22,459 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 13:50:22,469 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:50:22,485 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:50:22,485 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:50:22,486 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 13:50:22,500 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:50:22,517 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:50:22,517 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:50:22,518 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 13:50:22,531 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:50:22,559 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:50:22,563 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:50:22,564 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 13:50:22,584 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:50:22,612 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:50:22,612 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:50:22,620 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:50:22,635 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:50:22,650 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:50:22,651 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:50:22,651 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 13:50:22,667 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:50:22,689 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:50:22,690 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:50:22,693 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 13:50:22,704 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:50:22,729 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:50:22,729 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:50:22,730 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 13:50:22,741 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:50:22,761 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:50:22,762 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:50:22,762 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 13:50:22,783 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:50:22,820 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 13:50:22,820 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:50:22,821 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 13:50:22,850 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 13:50:22,880 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:50:22,880 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:50:22,881 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 13:50:22,904 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:50:22,927 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:50:22,929 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:50:22,930 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:50:22,940 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:50:22,953 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:50:22,956 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:50:22,957 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 13:50:22,967 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:50:22,994 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:50:22,997 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:50:22,998 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 13:50:23,011 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:50:23,074 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:50:23,075 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:50:23,162 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:50:23,162 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:50:23,339 (MainThread): 13:50:23 | Done.
2019-10-01 13:50:23,339 (MainThread): Flushing usage events
2019-10-01 13:51:52,928 (MainThread): Tracking: tracking
2019-10-01 13:51:52,930 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBE388>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBE5C8>]}
2019-10-01 13:51:53,243 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:51:53,244 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57859), raddr=('54.174.31.151', 443)>

2019-10-01 13:51:53,246 (MainThread): Error sending message, disabling tracking
2019-10-01 13:51:53,272 (MainThread): Parsing macros\core.sql
2019-10-01 13:51:53,283 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:51:53,349 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:51:53,359 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:51:53,361 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:51:53,364 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:51:53,368 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:51:53,370 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:51:53,373 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:51:53,382 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:51:53,396 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:51:53,410 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:51:53,427 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:51:53,451 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:51:53,454 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:51:53,468 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:51:53,475 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:51:53,486 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:51:53,496 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:51:53,501 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:51:53,503 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:51:53,505 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:51:53,508 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:51:53,521 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:51:53,524 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:51:53,536 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:51:53,539 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:51:53,543 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:51:53,567 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:51:53,570 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:51:53,570 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:51:53,572 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:51:53,840 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:51:53,855 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:51:54,475 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:51:54,476 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:51:54,476 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:51:54,481 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:51:54,482 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:51:54,482 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:51:54,486 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:51:54,487 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:51:54,487 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:51:54,492 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:51:54,493 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:51:54,493 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:51:54,498 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:51:54,499 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:51:54,499 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:51:54,504 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:51:54,505 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:51:54,505 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:51:54,510 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:51:54,512 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:51:54,512 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:51:54,516 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:51:54,518 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:51:54,518 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:51:54,524 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:51:54,524 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:51:54,525 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:51:54,529 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:51:54,530 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:51:54,531 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:51:54,535 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:51:54,536 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:51:54,536 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:51:54,541 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:51:54,542 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:51:54,543 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:51:54,548 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:51:54,549 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:51:54,549 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:51:54,554 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:51:54,555 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:51:54,555 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:51:54,560 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:51:54,561 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:51:54,561 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:51:54,565 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:51:54,566 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:51:54,567 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:51:54,571 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:51:54,572 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:51:54,573 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:51:54,577 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:51:54,579 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:51:54,579 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:51:54,585 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:51:54,586 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:51:54,586 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:51:54,646 (MainThread): Found 20 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 13:51:54,649 (MainThread): 
2019-10-01 13:51:54,650 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 13:51:54,650 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 13:51:54,671 (MainThread): Parsing macros\core.sql
2019-10-01 13:51:54,676 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:51:54,749 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:51:54,759 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:51:54,761 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:51:54,767 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:51:54,771 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:51:54,774 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:51:54,776 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:51:54,784 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:51:54,793 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:51:54,801 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:51:54,819 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:51:54,840 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:51:54,843 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:51:54,862 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:51:54,869 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:51:54,875 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:51:54,881 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:51:54,884 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:51:54,886 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:51:54,889 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:51:54,892 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:51:54,904 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:51:54,907 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:51:54,924 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:51:54,928 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:51:54,934 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:51:55,113 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:55,113 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 13:51:55,796 (MainThread): SQL status: SUCCESS 29 in 0.68 seconds
2019-10-01 13:51:55,852 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:55,852 (MainThread): On master: BEGIN
2019-10-01 13:51:55,985 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:51:55,986 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:55,986 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 13:51:57,282 (MainThread): SQL status: SUCCESS 2 in 1.30 seconds
2019-10-01 13:51:57,284 (MainThread): On master: ROLLBACK
2019-10-01 13:51:57,661 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:57,661 (MainThread): On master: BEGIN
2019-10-01 13:51:57,810 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:51:57,811 (MainThread): On master: COMMIT
2019-10-01 13:51:57,811 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:57,811 (MainThread): On master: COMMIT
2019-10-01 13:51:57,971 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:51:57,972 (MainThread): 13:51:57 | Concurrency: 1 threads (target='dev')
2019-10-01 13:51:57,972 (MainThread): 13:51:57 | 
2019-10-01 13:51:57,975 (Thread-1): 13:51:57 | 1 of 20 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 13:51:57,976 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:51:57,976 (Thread-1): Opening a new connection, currently in state init
2019-10-01 13:51:58,449 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 13:51:58,454 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:51:58,487 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:51:58,511 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 13:51:58,511 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 13:51:58,668 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:51:58,668 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 13:51:58,669 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 13:51:58,950 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 13:51:58,952 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 13:51:58,952 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 13:51:58,952 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 13:51:59,046 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:51:59,051 (Thread-1): 13:51:59 | 1 of 20 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.07s]
2019-10-01 13:51:59,053 (Thread-1): 13:51:59 | 2 of 20 START view model DBT_TEST.with_ar_currency................... [RUN]
2019-10-01 13:51:59,056 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:51:59,056 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:51:59,057 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 13:51:59,065 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:51:59,076 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:51:59,084 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 13:51:59,084 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 13:51:59,207 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:51:59,207 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 13:51:59,208 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 13:51:59,557 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 13:51:59,558 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 13:51:59,559 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 13:51:59,559 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 13:51:59,654 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:51:59,658 (Thread-1): 13:51:59 | 2 of 20 OK created view model DBT_TEST.with_ar_currency.............. [SUCCESS 1 in 0.60s]
2019-10-01 13:51:59,659 (Thread-1): 13:51:59 | 3 of 20 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 13:51:59,662 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:51:59,662 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:51:59,663 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 13:51:59,670 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:51:59,679 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:51:59,685 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 13:51:59,685 (Thread-1): On with_ar_market: BEGIN
2019-10-01 13:51:59,794 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:51:59,794 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 13:51:59,795 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 13:52:00,049 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 13:52:00,051 (Thread-1): On with_ar_market: COMMIT
2019-10-01 13:52:00,051 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 13:52:00,051 (Thread-1): On with_ar_market: COMMIT
2019-10-01 13:52:00,144 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:00,148 (Thread-1): 13:52:00 | 3 of 20 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.49s]
2019-10-01 13:52:00,149 (Thread-1): 13:52:00 | 4 of 20 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 13:52:00,150 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:52:00,150 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:52:00,151 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 13:52:00,156 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:52:00,164 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:52:00,171 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 13:52:00,171 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 13:52:00,277 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:00,277 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 13:52:00,278 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 13:52:00,583 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 13:52:00,584 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 13:52:00,584 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 13:52:00,584 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 13:52:00,700 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:00,704 (Thread-1): 13:52:00 | 4 of 20 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.55s]
2019-10-01 13:52:00,705 (Thread-1): 13:52:00 | 5 of 20 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 13:52:00,707 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:52:00,707 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:52:00,707 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 13:52:00,715 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:52:00,725 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:52:00,733 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 13:52:00,733 (Thread-1): On with_ar_point: BEGIN
2019-10-01 13:52:00,858 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:00,858 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 13:52:00,859 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 13:52:01,217 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 13:52:01,218 (Thread-1): On with_ar_point: COMMIT
2019-10-01 13:52:01,218 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 13:52:01,218 (Thread-1): On with_ar_point: COMMIT
2019-10-01 13:52:01,311 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:01,314 (Thread-1): 13:52:01 | 5 of 20 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.61s]
2019-10-01 13:52:01,315 (Thread-1): 13:52:01 | 6 of 20 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 13:52:01,317 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,317 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:52:01,317 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 13:52:01,322 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:52:01,334 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:52:01,343 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,343 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 13:52:01,448 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:01,448 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,448 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 13:52:01,761 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 13:52:01,763 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 13:52:01,763 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,763 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 13:52:01,898 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:01,902 (Thread-1): 13:52:01 | 6 of 20 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.58s]
2019-10-01 13:52:01,904 (Thread-1): 13:52:01 | 7 of 20 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 13:52:01,905 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:52:01,906 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:52:01,906 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 13:52:01,912 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:52:01,920 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:52:01,928 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 13:52:01,928 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 13:52:02,093 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:52:02,094 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 13:52:02,094 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 13:52:02,495 (Thread-1): SQL status: SUCCESS 1 in 0.40 seconds
2019-10-01 13:52:02,497 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 13:52:02,497 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 13:52:02,498 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 13:52:02,606 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:02,610 (Thread-1): 13:52:02 | 7 of 20 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.70s]
2019-10-01 13:52:02,611 (Thread-1): 13:52:02 | 8 of 20 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 13:52:02,613 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:52:02,613 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:52:02,614 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 13:52:02,619 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:52:02,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:52:02,639 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 13:52:02,639 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 13:52:02,756 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:02,756 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 13:52:02,757 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 13:52:03,016 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 13:52:03,017 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 13:52:03,017 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 13:52:03,017 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 13:52:03,258 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 13:52:03,262 (Thread-1): 13:52:03 | 8 of 20 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.65s]
2019-10-01 13:52:03,263 (Thread-1): 13:52:03 | 9 of 20 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 13:52:03,264 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,264 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:52:03,265 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 13:52:03,270 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:52:03,277 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:52:03,282 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,282 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 13:52:03,421 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 13:52:03,422 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,422 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 13:52:03,771 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 13:52:03,772 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 13:52:03,772 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,772 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 13:52:03,895 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:03,899 (Thread-1): 13:52:03 | 9 of 20 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.63s]
2019-10-01 13:52:03,900 (Thread-1): 13:52:03 | 10 of 20 START view model DBT_TEST.with_ar_transinvroute............. [RUN]
2019-10-01 13:52:03,902 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:03,902 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:52:03,902 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 13:52:03,907 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:52:03,918 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:52:03,924 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:03,925 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 13:52:04,077 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:52:04,078 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:04,078 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 13:52:04,501 (Thread-1): SQL status: SUCCESS 1 in 0.42 seconds
2019-10-01 13:52:04,503 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 13:52:04,503 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:04,503 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 13:52:04,608 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:04,612 (Thread-1): 13:52:04 | 10 of 20 OK created view model DBT_TEST.with_ar_transinvroute........ [SUCCESS 1 in 0.71s]
2019-10-01 13:52:04,614 (Thread-1): 13:52:04 | 11 of 20 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 13:52:04,615 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:04,615 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:52:04,616 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:52:04,621 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:52:04,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:52:04,640 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:04,641 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 13:52:04,757 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:04,758 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:04,758 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 13:52:05,016 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 13:52:05,018 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 13:52:05,018 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:05,019 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 13:52:05,151 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:05,154 (Thread-1): 13:52:05 | 11 of 20 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.54s]
2019-10-01 13:52:05,155 (Thread-1): 13:52:05 | 12 of 20 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 13:52:05,157 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,157 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:52:05,157 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 13:52:05,162 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:52:05,171 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:52:05,181 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,181 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 13:52:05,415 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 13:52:05,416 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,416 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 13:52:05,799 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2019-10-01 13:52:05,800 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 13:52:05,801 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,801 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 13:52:05,909 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:05,913 (Thread-1): 13:52:05 | 12 of 20 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.76s]
2019-10-01 13:52:05,914 (Thread-1): 13:52:05 | 13 of 20 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 13:52:05,915 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:52:05,915 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:52:05,915 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 13:52:05,921 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:52:05,933 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:52:05,943 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 13:52:05,943 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 13:52:06,055 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:06,055 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 13:52:06,055 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 13:52:06,308 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 13:52:06,309 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 13:52:06,309 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 13:52:06,309 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 13:52:06,401 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:06,410 (Thread-1): 13:52:06 | 13 of 20 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.49s]
2019-10-01 13:52:06,412 (Thread-1): 13:52:06 | 14 of 20 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 13:52:06,418 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:52:06,419 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:52:06,420 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 13:52:06,430 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:52:06,446 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:52:06,467 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 13:52:06,468 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 13:52:06,642 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 13:52:06,643 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 13:52:06,643 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 13:52:07,029 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2019-10-01 13:52:07,030 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 13:52:07,030 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 13:52:07,031 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 13:52:07,126 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:07,132 (Thread-1): 13:52:07 | 14 of 20 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.71s]
2019-10-01 13:52:07,134 (Thread-1): 13:52:07 | 15 of 20 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 13:52:07,138 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,139 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:52:07,139 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 13:52:07,149 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:52:07,163 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:52:07,174 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,174 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 13:52:07,419 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 13:52:07,419 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,419 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 13:52:07,938 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2019-10-01 13:52:07,939 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 13:52:07,939 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,940 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 13:52:08,061 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:08,065 (Thread-1): 13:52:08 | 15 of 20 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.93s]
2019-10-01 13:52:08,067 (Thread-1): 13:52:08 | 16 of 20 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 13:52:08,071 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 13:52:08,071 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:52:08,072 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 13:52:08,079 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 13:52:08,092 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 13:52:08,099 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 13:52:08,099 (Thread-1): On with_dates: BEGIN
2019-10-01 13:52:08,227 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:08,228 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 13:52:08,228 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim
  );
2019-10-01 13:52:08,498 (Thread-1): Snowflake error: 000904 (42000): 018f4144-0006-fbe4-0000-0e29015fd5aa: SQL compilation error: error line 6 at position 1
invalid identifier 'DD.BK_DATE'
2019-10-01 13:52:08,498 (Thread-1): On with_dates: ROLLBACK
2019-10-01 13:52:08,635 (Thread-1): 13:52:08 | 16 of 20 ERROR creating view model DBT_TEST.with_dates............... [ERROR in 0.56s]
2019-10-01 13:52:08,637 (Thread-1): 13:52:08 | 17 of 20 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 13:52:08,641 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:08,641 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:52:08,642 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 13:52:08,649 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:52:08,661 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:52:08,669 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:08,669 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 13:52:08,833 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:52:08,833 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:08,833 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 13:52:09,146 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 13:52:09,147 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 13:52:09,147 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:09,147 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 13:52:09,250 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:09,254 (Thread-1): 13:52:09 | 17 of 20 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.61s]
2019-10-01 13:52:09,256 (Thread-1): 13:52:09 | 18 of 20 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 13:52:09,259 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,260 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:52:09,260 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:52:09,267 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:52:09,276 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:52:09,286 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,287 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 13:52:09,462 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 13:52:09,463 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,463 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 13:52:09,826 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 13:52:09,827 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 13:52:09,827 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,827 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 13:52:09,987 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:52:09,991 (Thread-1): 13:52:09 | 18 of 20 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.73s]
2019-10-01 13:52:09,993 (Thread-1): 13:52:09 | 19 of 20 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 13:52:09,997 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:52:09,997 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:52:09,998 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 13:52:10,007 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:52:10,020 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:52:10,031 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 13:52:10,031 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 13:52:10,161 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:10,161 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 13:52:10,161 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 13:52:10,556 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2019-10-01 13:52:10,558 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 13:52:10,558 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 13:52:10,558 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 13:52:10,656 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:10,663 (Thread-1): 13:52:10 | 19 of 20 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.66s]
2019-10-01 13:52:10,664 (Thread-1): 13:52:10 | 20 of 20 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 13:52:10,668 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:10,669 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:52:10,670 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 13:52:10,679 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:52:10,690 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:52:10,699 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:10,699 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 13:52:10,896 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 13:52:10,896 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:10,896 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 13:52:11,175 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 13:52:11,176 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 13:52:11,176 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:11,176 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 13:52:11,274 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:11,278 (Thread-1): 13:52:11 | 20 of 20 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.61s]
2019-10-01 13:52:11,370 (MainThread): Using snowflake connection "master".
2019-10-01 13:52:11,371 (MainThread): On master: BEGIN
2019-10-01 13:52:11,520 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:52:11,520 (MainThread): On master: COMMIT
2019-10-01 13:52:11,520 (MainThread): Using snowflake connection "master".
2019-10-01 13:52:11,520 (MainThread): On master: COMMIT
2019-10-01 13:52:11,674 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:52:11,675 (MainThread): 13:52:11 | 
2019-10-01 13:52:11,676 (MainThread): 13:52:11 | Finished running 20 view models in 17.03s.
2019-10-01 13:52:11,677 (MainThread): Connection 'master' was left open.
2019-10-01 13:52:11,677 (MainThread): On master: Close
2019-10-01 13:52:11,870 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:52:11,870 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:52:12,140 (MainThread): 
2019-10-01 13:52:12,141 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 13:52:12,143 (MainThread): 
2019-10-01 13:52:12,144 (MainThread): Database Error in model with_dates (models\with_dates.sql)
2019-10-01 13:52:12,150 (MainThread):   000904 (42000): 018f4144-0006-fbe4-0000-0e29015fd5aa: SQL compilation error: error line 6 at position 1
2019-10-01 13:52:12,155 (MainThread):   invalid identifier 'DD.BK_DATE'
2019-10-01 13:52:12,157 (MainThread):   compiled SQL at target\compiled\dbt_test\with_dates.sql
2019-10-01 13:52:12,161 (MainThread): 
Done. PASS=19 WARN=0 ERROR=1 SKIP=0 TOTAL=20
2019-10-01 13:52:12,166 (MainThread): Flushing usage events
2019-10-01 13:57:15,082 (MainThread): Tracking: tracking
2019-10-01 13:57:15,084 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C96408>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DF88>]}
2019-10-01 13:57:15,415 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:57:15,416 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57927), raddr=('54.174.31.151', 443)>

2019-10-01 13:57:15,418 (MainThread): Error sending message, disabling tracking
2019-10-01 13:57:15,439 (MainThread): Parsing macros\core.sql
2019-10-01 13:57:15,447 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:57:15,502 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:57:15,523 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:57:15,526 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:57:15,532 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:57:15,539 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:57:15,543 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:57:15,548 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:57:15,560 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:57:15,569 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:57:15,581 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:57:15,599 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:57:15,620 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:57:15,623 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:57:15,640 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:57:15,652 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:57:15,658 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:57:15,665 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:57:15,670 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:57:15,672 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:57:15,674 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:57:15,677 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:57:15,690 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:57:15,694 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:57:15,702 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:57:15,705 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:57:15,710 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:57:15,750 (MainThread): Parsing model.dbt_test.create_table_booking_fact_uk
2019-10-01 13:57:15,752 (MainThread): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-10-01 13:57:15,752 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:57:15,755 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:57:16,051 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:57:16,078 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:57:16,742 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 13:57:16,745 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:57:16,745 (MainThread): Re-using an available connection from the pool (formerly create_table_booking_fact_uk).
2019-10-01 13:57:16,800 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:57:16,801 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:57:16,801 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 13:57:16,807 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:57:16,809 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:57:16,809 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:57:16,816 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:57:16,818 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:57:16,818 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:57:16,829 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:57:16,833 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:57:16,833 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:57:16,842 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:57:16,843 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:57:16,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:57:16,851 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:57:16,853 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:57:16,853 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:57:16,861 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:57:16,863 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:57:16,864 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:57:16,875 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:57:16,877 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:57:16,878 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:57:16,888 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:57:16,891 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:57:16,891 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:57:16,900 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:57:16,901 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:57:16,901 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:57:16,907 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:57:16,909 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:57:16,910 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:57:16,919 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:57:16,921 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:57:16,921 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:57:16,927 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:57:16,929 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:57:16,929 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:57:16,935 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:57:16,936 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:57:16,936 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:57:16,942 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:57:16,944 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:57:16,944 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:57:16,951 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:57:16,953 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:57:16,953 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:57:16,964 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:57:16,966 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:57:16,966 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:57:16,976 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:57:16,978 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:57:16,978 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:57:16,985 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:57:16,986 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:57:16,987 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:57:16,996 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:57:16,998 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:57:16,999 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:57:17,064 (MainThread): Flushing usage events
2019-10-01 13:57:17,064 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:57:17,064 (MainThread): Encountered an error:
2019-10-01 13:57:17,065 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:57:17,065 (MainThread): Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled
2019-10-01 13:57:17,166 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 164, in _load_from_projects
    return loader.create_manifest()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 153, in create_manifest
    self.root_project.project_name)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 217, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 204, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 399, in invalid_ref_fail_unless_test
    target_model_package)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 402, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled

2019-10-01 13:58:39,441 (MainThread): Tracking: tracking
2019-10-01 13:58:39,443 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91A08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91A48>]}
2019-10-01 13:58:39,767 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:58:39,768 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57975), raddr=('54.164.98.48', 443)>

2019-10-01 13:58:39,770 (MainThread): Error sending message, disabling tracking
2019-10-01 13:58:39,810 (MainThread): Parsing macros\core.sql
2019-10-01 13:58:39,825 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:58:39,906 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:58:39,927 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:58:39,931 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:58:39,938 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:58:39,945 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:58:39,951 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:58:39,956 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:58:39,977 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:58:39,994 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:58:40,010 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:58:40,048 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:58:40,093 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:58:40,100 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:58:40,132 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:58:40,151 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:58:40,164 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:58:40,181 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:58:40,186 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:58:40,190 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:58:40,194 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:58:40,200 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:58:40,228 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:58:40,234 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:58:40,251 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:58:40,256 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:58:40,266 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:58:40,314 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 13:58:40,316 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:58:40,317 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:58:40,319 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:58:40,627 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:58:40,651 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:58:41,302 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:58:41,304 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:58:41,304 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 13:58:41,313 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:58:41,315 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:58:41,315 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:58:41,324 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:58:41,326 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:58:41,326 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:58:41,333 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:58:41,334 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:58:41,335 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:58:41,340 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:58:41,341 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:58:41,341 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:58:41,345 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:58:41,346 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:58:41,346 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:58:41,351 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:58:41,353 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:58:41,353 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:58:41,361 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:58:41,363 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:58:41,363 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:58:41,370 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:58:41,371 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:58:41,371 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:58:41,380 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:58:41,382 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:58:41,382 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:58:41,390 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:58:41,392 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:58:41,393 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:58:41,400 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:58:41,401 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:58:41,401 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:58:41,409 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:58:41,411 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:58:41,411 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:58:41,419 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:58:41,421 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:58:41,421 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:58:41,428 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:58:41,430 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:58:41,430 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:58:41,436 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:58:41,438 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:58:41,438 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:58:41,444 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:58:41,446 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:58:41,446 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:58:41,456 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:58:41,458 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:58:41,458 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:58:41,468 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:58:41,470 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:58:41,470 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:58:41,478 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:58:41,480 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:58:41,480 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:58:41,542 (MainThread): Flushing usage events
2019-10-01 13:58:41,543 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:58:41,543 (MainThread): Encountered an error:
2019-10-01 13:58:41,544 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:58:41,544 (MainThread): Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled
2019-10-01 13:58:41,577 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 164, in _load_from_projects
    return loader.create_manifest()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 153, in create_manifest
    self.root_project.project_name)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 217, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 204, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 399, in invalid_ref_fail_unless_test
    target_model_package)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 402, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled

2019-10-01 13:59:30,890 (MainThread): Tracking: tracking
2019-10-01 13:59:30,893 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C938C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93DC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6CA48>]}
2019-10-01 13:59:31,188 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:59:31,189 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58000), raddr=('54.164.98.48', 443)>

2019-10-01 13:59:31,191 (MainThread): Error sending message, disabling tracking
2019-10-01 13:59:31,232 (MainThread): Parsing macros\core.sql
2019-10-01 13:59:31,246 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:59:31,322 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:59:31,342 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:59:31,346 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:59:31,351 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:59:31,358 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:59:31,363 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:59:31,367 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:59:31,382 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:59:31,399 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:59:31,411 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:59:31,437 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:59:31,475 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:59:31,480 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:59:31,494 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:59:31,506 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:59:31,518 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:59:31,529 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:59:31,533 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:59:31,536 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:59:31,542 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:59:31,547 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:59:31,569 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:59:31,575 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:59:31,591 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:59:31,598 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:59:31,605 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:59:31,679 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 13:59:31,685 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:59:31,685 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:59:31,688 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:59:32,084 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:59:32,111 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:59:32,829 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:59:32,831 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:59:32,832 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 13:59:32,841 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:59:32,844 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:59:32,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:59:32,854 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:59:32,857 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:59:32,857 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:59:32,869 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:59:32,871 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:59:32,871 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:59:32,881 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:59:32,884 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:59:32,884 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:59:32,894 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:59:32,896 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:59:32,896 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:59:32,907 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:59:32,910 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:59:32,910 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:59:32,922 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:59:32,924 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:59:32,924 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:59:32,934 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:59:32,937 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:59:32,937 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:59:32,947 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:59:32,948 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:59:32,949 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:59:32,958 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:59:32,960 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:59:32,961 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:59:32,971 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:59:32,974 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:59:32,974 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:59:32,984 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:59:32,987 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:59:32,988 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:59:32,998 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:59:33,000 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:59:33,000 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:59:33,009 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:59:33,012 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:59:33,012 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:59:33,028 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:59:33,032 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:59:33,033 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:59:33,047 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:59:33,050 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:59:33,050 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:59:33,063 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:59:33,066 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:59:33,066 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:59:33,078 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:59:33,081 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:59:33,081 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:59:33,092 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:59:33,095 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:59:33,095 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:59:33,254 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 13:59:33,263 (MainThread): 
2019-10-01 13:59:33,270 (MainThread): 13:59:33 | Concurrency: 1 threads (target='dev')
2019-10-01 13:59:33,273 (MainThread): 13:59:33 | 
2019-10-01 13:59:33,305 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:59:33,307 (Thread-1): Opening a new connection, currently in state init
2019-10-01 13:59:33,900 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 13:59:33,916 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:59:33,940 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:59:33,943 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:59:33,945 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 13:59:33,957 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:59:33,980 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:59:33,984 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:59:33,985 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 13:59:33,995 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:59:34,017 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:59:34,017 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:59:34,019 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 13:59:34,035 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:59:34,050 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:59:34,054 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:59:34,064 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 13:59:34,084 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:59:34,098 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:59:34,102 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:59:34,103 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 13:59:34,113 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:59:34,130 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:59:34,133 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:59:34,134 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 13:59:34,144 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:59:34,158 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:59:34,161 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:59:34,162 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 13:59:34,173 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:59:34,203 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:59:34,204 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:59:34,205 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 13:59:34,228 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:59:34,244 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:59:34,248 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:59:34,250 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:59:34,262 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:59:34,279 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:59:34,279 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:59:34,280 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 13:59:34,290 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:59:34,313 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:59:34,314 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:59:34,321 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 13:59:34,337 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:59:34,377 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:59:34,381 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:59:34,382 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 13:59:34,394 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:59:34,409 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:59:34,409 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:59:34,410 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 13:59:34,423 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:59:34,463 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 13:59:34,466 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:59:34,467 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 13:59:34,477 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 13:59:34,496 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:59:34,498 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:59:34,499 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 13:59:34,510 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:59:34,544 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:59:34,547 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:59:34,548 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:59:34,558 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:59:34,576 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:59:34,576 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:59:34,577 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 13:59:34,587 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:59:34,608 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:59:34,611 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:59:34,612 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 13:59:34,621 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:59:34,637 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:59:34,638 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 13:59:34,639 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 13:59:34,652 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:59:34,670 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:59:34,674 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:59:34,675 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 13:59:34,773 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 13:59:34,846 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:59:34,847 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:59:34,981 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 13:59:34,982 (MainThread): On v_booking_fact_uk: Close
2019-10-01 13:59:35,143 (MainThread): 13:59:35 | Done.
2019-10-01 13:59:35,144 (MainThread): Flushing usage events
2019-10-01 14:00:45,846 (MainThread): Tracking: tracking
2019-10-01 14:00:45,849 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000070CB748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93B08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6E588>]}
2019-10-01 14:00:46,163 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:00:46,163 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58028), raddr=('54.174.31.151', 443)>

2019-10-01 14:00:46,164 (MainThread): Error sending message, disabling tracking
2019-10-01 14:00:46,190 (MainThread): Parsing macros\core.sql
2019-10-01 14:00:46,202 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:00:46,277 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:00:46,293 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:00:46,296 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:00:46,299 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:00:46,303 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:00:46,306 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:00:46,309 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:00:46,321 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:00:46,332 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:00:46,344 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:00:46,372 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:00:46,414 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:00:46,420 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:00:46,444 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:00:46,458 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:00:46,470 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:00:46,484 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:00:46,489 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:00:46,493 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:00:46,497 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:00:46,502 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:00:46,530 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:00:46,540 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:00:46,568 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:00:46,575 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:00:46,586 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:00:46,630 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:00:46,633 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:00:46,633 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:00:46,636 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:00:46,919 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:00:46,947 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:00:47,635 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:00:47,636 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:00:47,636 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:00:47,640 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:00:47,641 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:00:47,641 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:00:47,645 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:00:47,646 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:00:47,646 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:00:47,653 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:00:47,655 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:00:47,656 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:00:47,664 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:00:47,667 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:00:47,667 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:00:47,676 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:00:47,676 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:47,677 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:00:47,681 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:00:47,682 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:00:47,682 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:00:47,686 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:00:47,687 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:00:47,687 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:00:47,693 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:00:47,694 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:00:47,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:00:47,698 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:00:47,699 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:00:47,699 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:00:47,703 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:00:47,704 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:00:47,705 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:00:47,709 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:00:47,710 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:00:47,710 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:00:47,714 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:00:47,715 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:00:47,715 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:00:47,720 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:00:47,721 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:00:47,721 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:00:47,725 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:00:47,726 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:00:47,726 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:00:47,731 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:00:47,732 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:00:47,732 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:00:47,737 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:00:47,738 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:00:47,738 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:00:47,742 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:00:47,743 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:00:47,744 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:00:47,748 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:00:47,749 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:00:47,749 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:00:47,753 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:00:47,754 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:00:47,754 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:00:47,820 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:00:47,825 (MainThread): 
2019-10-01 14:00:47,825 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:00:47,826 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:00:47,865 (MainThread): Parsing macros\core.sql
2019-10-01 14:00:47,876 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:00:47,975 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:00:47,997 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:00:48,001 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:00:48,008 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:00:48,015 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:00:48,021 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:00:48,026 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:00:48,042 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:00:48,051 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:00:48,065 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:00:48,093 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:00:48,123 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:00:48,126 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:00:48,146 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:00:48,158 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:00:48,168 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:00:48,186 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:00:48,194 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:00:48,199 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:00:48,204 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:00:48,211 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:00:48,238 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:00:48,244 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:00:48,260 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:00:48,265 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:00:48,272 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:00:48,411 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:48,412 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:00:49,621 (MainThread): SQL status: SUCCESS 29 in 1.21 seconds
2019-10-01 14:00:49,700 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:49,701 (MainThread): On master: BEGIN
2019-10-01 14:00:49,872 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:00:49,873 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:49,873 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:00:52,615 (MainThread): SQL status: SUCCESS 19 in 2.74 seconds
2019-10-01 14:00:52,634 (MainThread): On master: ROLLBACK
2019-10-01 14:00:52,837 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:52,837 (MainThread): On master: BEGIN
2019-10-01 14:00:52,947 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:00:52,947 (MainThread): On master: COMMIT
2019-10-01 14:00:52,947 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:52,947 (MainThread): On master: COMMIT
2019-10-01 14:00:53,111 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:00:53,112 (MainThread): 14:00:53 | Concurrency: 1 threads (target='dev')
2019-10-01 14:00:53,112 (MainThread): 14:00:53 | 
2019-10-01 14:00:53,121 (Thread-1): 14:00:53 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:00:53,122 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:00:53,122 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:00:53,692 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:00:53,698 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:00:53,732 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:00:53,741 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:00:53,742 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:00:53,863 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:53,863 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:00:53,864 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:00:54,812 (Thread-1): SQL status: SUCCESS 1 in 0.95 seconds
2019-10-01 14:00:54,814 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:00:54,814 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:00:54,814 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:00:54,914 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:00:54,924 (Thread-1): 14:00:54 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.80s]
2019-10-01 14:00:54,927 (Thread-1): 14:00:54 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:00:54,931 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:00:54,931 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:00:54,933 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:00:54,945 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:00:54,963 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:00:54,971 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:00:54,971 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:00:55,092 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:55,093 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:00:55,093 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:00:56,051 (Thread-1): SQL status: SUCCESS 1 in 0.96 seconds
2019-10-01 14:00:56,052 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:00:56,052 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:00:56,052 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:00:56,226 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:00:56,232 (Thread-1): 14:00:56 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 1.30s]
2019-10-01 14:00:56,233 (Thread-1): 14:00:56 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:00:56,237 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:00:56,238 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:00:56,239 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:00:56,250 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:00:56,263 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:00:56,272 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:00:56,272 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:00:56,436 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:00:56,437 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:00:56,437 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:00:56,720 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:00:56,722 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:00:56,722 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:00:56,722 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:00:56,811 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:00:56,822 (Thread-1): 14:00:56 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.58s]
2019-10-01 14:00:56,826 (Thread-1): 14:00:56 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:00:56,831 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:00:56,832 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:00:56,833 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:00:56,848 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:00:56,866 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:00:56,876 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:00:56,876 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:00:56,996 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:56,997 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:00:56,997 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:00:57,273 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:00:57,276 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:00:57,276 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:00:57,276 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:00:57,886 (Thread-1): SQL status: SUCCESS 1 in 0.61 seconds
2019-10-01 14:00:57,893 (Thread-1): 14:00:57 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 1.06s]
2019-10-01 14:00:57,894 (Thread-1): 14:00:57 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:00:57,899 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:57,899 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:00:57,901 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:00:57,907 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:00:57,917 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:00:57,924 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:57,924 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:00:58,109 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-01 14:00:58,109 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:58,109 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:00:59,095 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2019-10-01 14:00:59,097 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:00:59,097 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:59,097 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:00:59,234 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:00:59,241 (Thread-1): 14:00:59 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 1.34s]
2019-10-01 14:00:59,244 (Thread-1): 14:00:59 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:00:59,250 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,250 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:00:59,251 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:00:59,260 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:00:59,273 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:00:59,282 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,283 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:00:59,390 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:00:59,391 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,391 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:00:59,682 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:00:59,683 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:00:59,683 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,683 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:00:59,777 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:00:59,782 (Thread-1): 14:00:59 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.53s]
2019-10-01 14:00:59,784 (Thread-1): 14:00:59 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:00:59,788 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:00:59,788 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:00:59,789 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:00:59,796 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:00:59,808 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:00:59,815 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:00:59,815 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:00:59,933 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:59,933 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:00:59,933 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:01:00,267 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2019-10-01 14:01:00,269 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:01:00,269 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:01:00,270 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:01:00,361 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:00,370 (Thread-1): 14:01:00 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.58s]
2019-10-01 14:01:00,372 (Thread-1): 14:01:00 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:01:00,376 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,376 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:01:00,378 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:01:00,391 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:01:00,406 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:01:00,416 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,416 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:01:00,532 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:00,533 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,533 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:01:00,898 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 14:01:00,900 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:01:00,901 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,901 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:01:00,999 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:01:01,008 (Thread-1): 14:01:01 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.63s]
2019-10-01 14:01:01,012 (Thread-1): 14:01:01 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:01:01,018 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,018 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:01:01,020 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:01:01,032 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:01:01,051 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:01:01,059 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,059 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:01:01,248 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:01:01,249 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,249 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:01:01,495 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:01:01,496 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:01:01,496 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,496 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:01:01,589 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:01,593 (Thread-1): 14:01:01 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.57s]
2019-10-01 14:01:01,594 (Thread-1): 14:01:01 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:01:01,598 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:01,598 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:01:01,599 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:01:01,609 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:01:01,622 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:01:01,629 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:01,630 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:01:01,750 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:01,751 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:01,751 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:01:02,180 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2019-10-01 14:01:02,182 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:01:02,182 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:02,182 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:01:02,296 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:02,313 (Thread-1): 14:01:02 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.71s]
2019-10-01 14:01:02,319 (Thread-1): 14:01:02 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:01:02,323 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:02,324 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:01:02,325 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:01:02,331 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:01:02,350 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:01:02,359 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:02,359 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:01:02,880 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2019-10-01 14:01:02,881 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:02,881 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:01:03,330 (Thread-1): SQL status: SUCCESS 1 in 0.45 seconds
2019-10-01 14:01:03,332 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:01:03,332 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:03,332 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:01:03,455 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:03,459 (Thread-1): 14:01:03 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 1.13s]
2019-10-01 14:01:03,461 (Thread-1): 14:01:03 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:01:03,465 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,466 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:01:03,466 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:01:03,476 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:01:03,489 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:01:03,495 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,495 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:01:03,643 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:01:03,644 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,644 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:01:03,925 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:01:03,927 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:01:03,927 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,927 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:01:04,024 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:01:04,033 (Thread-1): 14:01:04 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.56s]
2019-10-01 14:01:04,035 (Thread-1): 14:01:04 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:01:04,040 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:01:04,040 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:01:04,042 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:01:04,054 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:01:04,067 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:01:04,074 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:01:04,074 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:01:04,186 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:04,187 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:01:04,187 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:01:05,238 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2019-10-01 14:01:05,240 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:01:05,240 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:01:05,240 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:01:05,371 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:05,379 (Thread-1): 14:01:05 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 1.34s]
2019-10-01 14:01:05,380 (Thread-1): 14:01:05 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:01:05,384 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:05,385 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:01:05,386 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:01:05,400 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:01:05,414 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:01:05,421 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:05,421 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:01:06,196 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2019-10-01 14:01:06,197 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:06,197 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:01:06,704 (Thread-1): SQL status: SUCCESS 1 in 0.51 seconds
2019-10-01 14:01:06,706 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:01:06,706 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:06,707 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:01:06,807 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:01:06,811 (Thread-1): 14:01:06 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 1.42s]
2019-10-01 14:01:06,813 (Thread-1): 14:01:06 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:01:06,816 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:01:06,817 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:01:06,817 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:01:06,824 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:01:06,832 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:01:06,838 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:01:06,838 (Thread-1): On with_dates: BEGIN
2019-10-01 14:01:06,964 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:06,964 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:01:06,965 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:01:07,229 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:01:07,231 (Thread-1): On with_dates: COMMIT
2019-10-01 14:01:07,232 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:01:07,232 (Thread-1): On with_dates: COMMIT
2019-10-01 14:01:07,353 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:07,362 (Thread-1): 14:01:07 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.54s]
2019-10-01 14:01:07,365 (Thread-1): 14:01:07 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:01:07,371 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:07,371 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:01:07,373 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:01:07,385 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:01:07,399 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:01:07,407 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:07,408 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:01:07,517 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:07,518 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:07,518 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:01:08,267 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2019-10-01 14:01:08,268 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:01:08,269 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:08,269 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:01:08,363 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:08,367 (Thread-1): 14:01:08 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.99s]
2019-10-01 14:01:08,368 (Thread-1): 14:01:08 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:01:08,372 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,373 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:01:08,373 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:01:08,381 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:01:08,394 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:01:08,403 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,403 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:01:08,524 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:08,525 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,525 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:01:08,762 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:01:08,764 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:01:08,764 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,764 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:01:09,005 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:01:09,016 (Thread-1): 14:01:09 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.64s]
2019-10-01 14:01:09,018 (Thread-1): 14:01:09 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:01:09,024 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,024 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:01:09,026 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:01:09,039 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:01:09,054 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:01:09,061 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,062 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:01:09,170 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:09,170 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,170 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:01:09,585 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2019-10-01 14:01:09,586 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:01:09,587 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,587 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:01:09,680 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:09,684 (Thread-1): 14:01:09 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.66s]
2019-10-01 14:01:09,686 (Thread-1): 14:01:09 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:01:09,690 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:09,690 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:01:09,691 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:01:09,699 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:01:09,707 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:01:09,714 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:09,714 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:01:09,919 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:01:09,919 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:09,920 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:01:10,235 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:01:10,237 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:01:10,238 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:10,238 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:01:10,352 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:10,358 (Thread-1): 14:01:10 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.67s]
2019-10-01 14:01:10,360 (Thread-1): 14:01:10 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:01:10,366 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:01:10,366 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:01:10,368 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:01:10,378 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:01:10,391 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:01:10,397 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:01:10,397 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:01:10,504 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:10,505 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:01:10,506 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:01:10,948 (Thread-1): SQL status: SUCCESS 1 in 0.44 seconds
2019-10-01 14:01:10,950 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:01:10,950 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:01:10,950 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:01:11,075 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:11,079 (Thread-1): 14:01:11 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.71s]
2019-10-01 14:01:11,081 (Thread-1): 14:01:11 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:01:11,085 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:01:11,085 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:01:11,086 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:01:11,144 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:01:11,191 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:01:11,322 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:01:11,322 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:01:11,435 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:11,436 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:01:11,436 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m   ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
);
2019-10-01 14:01:12,475 (Thread-1): Snowflake error: 000904 (42000): 018f414d-005d-aaf4-0000-0e29015fd91e: SQL compilation error: error line 502 at position 22
invalid identifier 'BS.SERVICE_TYPE'
2019-10-01 14:01:12,475 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:01:12,616 (Thread-1): 14:01:12 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 1.53s]
2019-10-01 14:01:12,662 (MainThread): Using snowflake connection "master".
2019-10-01 14:01:12,662 (MainThread): On master: BEGIN
2019-10-01 14:01:12,791 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:12,791 (MainThread): On master: COMMIT
2019-10-01 14:01:12,791 (MainThread): Using snowflake connection "master".
2019-10-01 14:01:12,791 (MainThread): On master: COMMIT
2019-10-01 14:01:12,939 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:01:12,940 (MainThread): 14:01:12 | 
2019-10-01 14:01:12,940 (MainThread): 14:01:12 | Finished running 21 view models in 25.12s.
2019-10-01 14:01:12,941 (MainThread): Connection 'master' was left open.
2019-10-01 14:01:12,942 (MainThread): On master: Close
2019-10-01 14:01:13,121 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:01:13,122 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:01:13,354 (MainThread): 
2019-10-01 14:01:13,354 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:01:13,356 (MainThread): 
2019-10-01 14:01:13,357 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:01:13,364 (MainThread):   000904 (42000): 018f414d-005d-aaf4-0000-0e29015fd91e: SQL compilation error: error line 502 at position 22
2019-10-01 14:01:13,367 (MainThread):   invalid identifier 'BS.SERVICE_TYPE'
2019-10-01 14:01:13,370 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:01:13,375 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:01:13,379 (MainThread): Flushing usage events
2019-10-01 14:04:03,404 (MainThread): Tracking: tracking
2019-10-01 14:04:03,406 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93E48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C937C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6EE08>]}
2019-10-01 14:04:03,715 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:04:03,716 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58088), raddr=('54.164.98.48', 443)>

2019-10-01 14:04:03,717 (MainThread): Error sending message, disabling tracking
2019-10-01 14:04:03,745 (MainThread): Parsing macros\core.sql
2019-10-01 14:04:03,754 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:04:03,793 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:04:03,803 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:04:03,806 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:04:03,810 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:04:03,814 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:04:03,817 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:04:03,820 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:04:03,829 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:04:03,838 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:04:03,851 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:04:03,878 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:04:03,914 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:04:03,920 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:04:03,948 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:04:03,956 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:04:03,963 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:04:03,972 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:04:03,975 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:04:03,980 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:04:03,984 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:04:03,990 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:04:04,013 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:04:04,016 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:04:04,027 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:04:04,032 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:04:04,037 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:04:04,066 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:04:04,069 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:04,069 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:04:04,071 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:04:04,351 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:04:04,376 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:04:04,962 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:04:04,964 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:04:04,965 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:04:04,975 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:04:04,977 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:04:04,978 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:04:04,988 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:04:04,991 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:04:04,991 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:04:05,003 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:04:05,005 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:04:05,005 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:04:05,017 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:04:05,019 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:04:05,020 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:04:05,031 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:04:05,034 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:05,034 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:04:05,046 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:04:05,048 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:04:05,048 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:04:05,059 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:04:05,062 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:04:05,062 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:04:05,072 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:04:05,074 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:04:05,074 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:04:05,082 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:04:05,084 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:05,084 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:04:05,091 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:04:05,093 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:05,093 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:04:05,100 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:04:05,102 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:05,102 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:04:05,110 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:04:05,112 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:04:05,112 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:04:05,119 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:04:05,121 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:04:05,121 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:04:05,129 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:04:05,130 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:05,131 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:04:05,140 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:04:05,142 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:04:05,143 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:04:05,152 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:04:05,154 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:05,154 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:04:05,164 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:04:05,165 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:05,165 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:04:05,176 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:04:05,179 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:04:05,179 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:04:05,189 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:04:05,191 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:05,191 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:04:05,301 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:04:05,305 (MainThread): 
2019-10-01 14:04:05,306 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:04:05,307 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:04:05,334 (MainThread): Parsing macros\core.sql
2019-10-01 14:04:05,342 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:04:05,422 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:04:05,447 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:04:05,451 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:04:05,459 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:04:05,468 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:04:05,473 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:04:05,477 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:04:05,491 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:04:05,502 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:04:05,511 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:04:05,530 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:04:05,568 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:04:05,572 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:04:05,599 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:04:05,615 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:04:05,629 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:04:05,646 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:04:05,651 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:04:05,655 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:04:05,659 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:04:05,666 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:04:05,696 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:04:05,702 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:04:05,710 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:04:05,713 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:04:05,717 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:04:05,872 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:05,873 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:04:06,472 (MainThread): SQL status: SUCCESS 29 in 0.60 seconds
2019-10-01 14:04:06,524 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:06,525 (MainThread): On master: BEGIN
2019-10-01 14:04:06,642 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:06,643 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:06,643 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:04:07,873 (MainThread): SQL status: SUCCESS 21 in 1.23 seconds
2019-10-01 14:04:07,883 (MainThread): On master: ROLLBACK
2019-10-01 14:04:08,055 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:08,055 (MainThread): On master: BEGIN
2019-10-01 14:04:08,193 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:08,193 (MainThread): On master: COMMIT
2019-10-01 14:04:08,193 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:08,193 (MainThread): On master: COMMIT
2019-10-01 14:04:08,339 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:04:08,339 (MainThread): 14:04:08 | Concurrency: 1 threads (target='dev')
2019-10-01 14:04:08,340 (MainThread): 14:04:08 | 
2019-10-01 14:04:08,345 (Thread-1): 14:04:08 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:04:08,346 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:04:08,346 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:04:08,784 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:04:08,791 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:04:08,843 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:04:08,851 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:04:08,851 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:04:09,048 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 14:04:09,049 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:04:09,049 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:04:09,350 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:04:09,351 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:04:09,351 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:04:09,351 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:04:09,465 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:09,469 (Thread-1): 14:04:09 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.12s]
2019-10-01 14:04:09,470 (Thread-1): 14:04:09 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:04:09,473 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:04:09,473 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:04:09,474 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:04:09,481 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:04:09,495 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:04:09,500 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:04:09,500 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:04:09,790 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:09,791 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:04:09,791 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:04:10,065 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:04:10,067 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:04:10,067 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:04:10,067 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:04:10,205 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:10,209 (Thread-1): 14:04:10 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.74s]
2019-10-01 14:04:10,211 (Thread-1): 14:04:10 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:04:10,214 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:04:10,214 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:04:10,214 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:04:10,219 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:04:10,227 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:04:10,232 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:04:10,232 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:04:10,352 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:10,353 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:04:10,353 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:04:10,639 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:10,640 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:04:10,641 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:04:10,641 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:04:10,735 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:04:10,738 (Thread-1): 14:04:10 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.52s]
2019-10-01 14:04:10,739 (Thread-1): 14:04:10 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:04:10,741 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:04:10,741 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:04:10,742 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:04:10,747 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:04:10,761 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:04:10,767 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:04:10,767 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:04:10,884 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:10,885 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:04:10,885 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:04:11,115 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:04:11,116 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:04:11,116 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:04:11,116 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:04:11,237 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:11,244 (Thread-1): 14:04:11 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.50s]
2019-10-01 14:04:11,245 (Thread-1): 14:04:11 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:04:11,246 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,247 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:04:11,247 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:04:11,252 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:04:11,267 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:04:11,273 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,273 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:04:11,386 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:11,386 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,386 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:04:11,618 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:04:11,620 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:04:11,621 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,621 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:04:11,781 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:04:11,785 (Thread-1): 14:04:11 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.54s]
2019-10-01 14:04:11,786 (Thread-1): 14:04:11 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:04:11,789 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:04:11,789 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:04:11,790 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:04:11,801 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:04:11,815 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:04:11,820 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:04:11,820 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:04:11,939 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:11,940 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:04:11,940 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:04:12,224 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:04:12,225 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:04:12,225 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:04:12,225 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:04:12,320 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:12,324 (Thread-1): 14:04:12 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.53s]
2019-10-01 14:04:12,325 (Thread-1): 14:04:12 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:04:12,328 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,329 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:04:12,330 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:04:12,338 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:04:12,353 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:04:12,359 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,359 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:04:12,492 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:12,493 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,493 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:04:12,759 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:04:12,761 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:04:12,761 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,762 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:04:12,868 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:12,878 (Thread-1): 14:04:12 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.55s]
2019-10-01 14:04:12,879 (Thread-1): 14:04:12 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:04:12,882 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:04:12,882 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:04:12,883 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:04:12,894 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:04:12,908 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:04:12,915 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:04:12,915 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:04:13,055 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:13,056 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:04:13,056 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:04:13,397 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:04:13,398 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:04:13,398 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:04:13,398 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:04:13,507 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:13,515 (Thread-1): 14:04:13 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.63s]
2019-10-01 14:04:13,517 (Thread-1): 14:04:13 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:04:13,518 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:13,518 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:04:13,519 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:04:13,524 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:04:13,539 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:04:13,545 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:13,546 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:04:13,670 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:13,671 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:13,671 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:04:14,010 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:04:14,011 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:04:14,011 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:14,011 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:04:14,146 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:14,149 (Thread-1): 14:04:14 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.63s]
2019-10-01 14:04:14,151 (Thread-1): 14:04:14 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:04:14,154 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:14,154 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:04:14,155 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:04:14,160 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:04:14,169 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:04:14,174 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:14,174 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:04:14,293 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:14,294 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:14,294 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:04:15,052 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2019-10-01 14:04:15,054 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:04:15,054 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:15,054 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:04:15,155 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:15,164 (Thread-1): 14:04:15 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 1.01s]
2019-10-01 14:04:15,164 (Thread-1): 14:04:15 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:04:15,168 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,168 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:04:15,169 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:04:15,179 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:04:15,194 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:04:15,200 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,201 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:04:15,328 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:15,329 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,329 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:04:15,624 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:04:15,625 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:04:15,626 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,626 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:04:15,718 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:04:15,723 (Thread-1): 14:04:15 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.55s]
2019-10-01 14:04:15,724 (Thread-1): 14:04:15 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:04:15,726 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:04:15,726 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:04:15,726 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:04:15,732 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:04:15,746 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:04:15,754 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:04:15,754 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:04:15,866 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:15,867 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:04:15,867 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:04:16,103 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:04:16,105 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:04:16,105 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:04:16,106 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:04:16,212 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:16,221 (Thread-1): 14:04:16 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.49s]
2019-10-01 14:04:16,222 (Thread-1): 14:04:16 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:04:16,225 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,225 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:04:16,226 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:04:16,237 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:04:16,251 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:04:16,255 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,255 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:04:16,376 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:16,376 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,377 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:04:16,658 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:04:16,660 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:04:16,660 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,660 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:04:16,792 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:16,800 (Thread-1): 14:04:16 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.57s]
2019-10-01 14:04:16,801 (Thread-1): 14:04:16 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:04:16,805 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:16,805 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:04:16,806 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:04:16,818 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:04:16,832 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:04:16,841 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:16,841 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:04:16,972 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:16,972 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:16,972 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:04:17,493 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2019-10-01 14:04:17,494 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:04:17,494 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:17,495 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:04:17,596 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:17,605 (Thread-1): 14:04:17 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.80s]
2019-10-01 14:04:17,606 (Thread-1): 14:04:17 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:04:17,608 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:04:17,608 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:04:17,608 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:04:17,615 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:04:17,625 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:04:17,629 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:04:17,629 (Thread-1): On with_dates: BEGIN
2019-10-01 14:04:17,740 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:17,741 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:04:17,741 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:04:17,991 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:04:17,992 (Thread-1): On with_dates: COMMIT
2019-10-01 14:04:17,992 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:04:17,992 (Thread-1): On with_dates: COMMIT
2019-10-01 14:04:18,110 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:18,115 (Thread-1): 14:04:18 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.51s]
2019-10-01 14:04:18,116 (Thread-1): 14:04:18 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:04:18,118 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,118 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:04:18,118 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:04:18,124 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:04:18,138 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:04:18,147 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,147 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:04:18,266 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:18,266 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,267 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:04:18,505 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:04:18,506 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:04:18,506 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,506 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:04:18,602 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:18,607 (Thread-1): 14:04:18 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.49s]
2019-10-01 14:04:18,608 (Thread-1): 14:04:18 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:04:18,610 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:18,610 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:04:18,611 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:04:18,619 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:04:18,635 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:04:18,641 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:18,641 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:04:18,779 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:18,779 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:18,779 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:04:19,080 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:04:19,082 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:04:19,082 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:19,082 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:04:19,188 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:19,193 (Thread-1): 14:04:19 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.58s]
2019-10-01 14:04:19,194 (Thread-1): 14:04:19 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:04:19,194 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,194 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:04:19,195 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:04:19,203 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:04:19,222 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:04:19,228 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,229 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:04:19,363 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:19,364 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,364 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:04:19,657 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:19,659 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:04:19,659 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,660 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:04:19,789 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:19,793 (Thread-1): 14:04:19 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.60s]
2019-10-01 14:04:19,794 (Thread-1): 14:04:19 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:04:19,795 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:19,795 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:04:19,796 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:04:19,807 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:04:19,816 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:04:19,821 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:19,821 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:04:19,937 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:19,938 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:19,938 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:04:20,230 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:20,231 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:04:20,231 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:20,232 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:04:20,338 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:20,342 (Thread-1): 14:04:20 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.54s]
2019-10-01 14:04:20,343 (Thread-1): 14:04:20 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:04:20,343 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:04:20,343 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:04:20,343 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:04:20,348 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:04:20,364 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:04:20,368 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:04:20,368 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:04:20,490 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:20,491 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:04:20,491 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:04:20,908 (Thread-1): SQL status: SUCCESS 1 in 0.42 seconds
2019-10-01 14:04:20,909 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:04:20,909 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:04:20,909 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:04:21,005 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:21,015 (Thread-1): 14:04:21 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.67s]
2019-10-01 14:04:21,017 (Thread-1): 14:04:21 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:04:21,022 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:21,023 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:04:21,024 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:04:21,099 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:04:21,143 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:04:21,306 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:21,306 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:04:21,416 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:21,417 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:21,417 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m   ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
);
2019-10-01 14:04:22,343 (Thread-1): Snowflake error: 000904 (42000): 018f4150-00c8-b342-0000-0e29015fbcb2: SQL compilation error: error line 970 at position 14
invalid identifier 'BK.EFFECTIVE_FROM'
2019-10-01 14:04:22,343 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:04:22,523 (Thread-1): 14:04:22 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 1.50s]
2019-10-01 14:04:22,564 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:22,565 (MainThread): On master: BEGIN
2019-10-01 14:04:22,675 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:22,676 (MainThread): On master: COMMIT
2019-10-01 14:04:22,676 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:22,676 (MainThread): On master: COMMIT
2019-10-01 14:04:22,829 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:04:22,830 (MainThread): 14:04:22 | 
2019-10-01 14:04:22,831 (MainThread): 14:04:22 | Finished running 21 view models in 17.52s.
2019-10-01 14:04:22,831 (MainThread): Connection 'master' was left open.
2019-10-01 14:04:22,832 (MainThread): On master: Close
2019-10-01 14:04:23,001 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:04:23,001 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:04:23,186 (MainThread): 
2019-10-01 14:04:23,187 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:04:23,187 (MainThread): 
2019-10-01 14:04:23,187 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:04:23,188 (MainThread):   000904 (42000): 018f4150-00c8-b342-0000-0e29015fbcb2: SQL compilation error: error line 970 at position 14
2019-10-01 14:04:23,188 (MainThread):   invalid identifier 'BK.EFFECTIVE_FROM'
2019-10-01 14:04:23,188 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:04:23,188 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:04:23,189 (MainThread): Flushing usage events
2019-10-01 14:10:32,169 (MainThread): Tracking: tracking
2019-10-01 14:10:32,171 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004972FC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C108>]}
2019-10-01 14:10:32,509 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:10:32,510 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58148), raddr=('54.164.98.48', 443)>

2019-10-01 14:10:32,512 (MainThread): Error sending message, disabling tracking
2019-10-01 14:10:32,545 (MainThread): Parsing macros\core.sql
2019-10-01 14:10:32,555 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:10:32,592 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:10:32,605 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:10:32,608 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:10:32,611 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:10:32,615 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:10:32,618 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:10:32,620 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:10:32,629 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:10:32,638 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:10:32,647 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:10:32,665 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:10:32,685 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:10:32,688 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:10:32,704 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:10:32,710 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:10:32,717 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:10:32,723 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:10:32,726 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:10:32,728 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:10:32,731 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:10:32,734 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:10:32,748 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:10:32,753 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:10:32,762 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:10:32,764 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:10:32,769 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:10:32,796 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:10:32,798 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:32,798 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:10:32,800 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:10:33,112 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:10:33,128 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:10:33,696 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:10:33,697 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:10:33,698 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:10:33,702 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:10:33,703 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:10:33,703 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:10:33,708 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:10:33,709 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:10:33,709 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:10:33,714 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:10:33,715 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:10:33,715 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:10:33,720 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:10:33,721 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:10:33,722 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:10:33,726 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:10:33,727 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:33,727 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:10:33,732 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:10:33,733 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:10:33,733 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:10:33,738 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:10:33,738 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:10:33,739 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:10:33,744 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:10:33,745 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:10:33,745 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:10:33,750 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:10:33,750 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:33,751 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:10:33,755 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:10:33,756 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:33,757 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:10:33,761 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:10:33,762 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:33,762 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:10:33,769 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:10:33,770 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:10:33,770 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:10:33,775 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:10:33,776 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:10:33,776 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:10:33,781 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:10:33,783 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:33,783 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:10:33,788 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:10:33,789 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:10:33,789 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:10:33,794 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:10:33,795 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:33,795 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:10:33,800 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:10:33,801 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:33,801 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:10:33,806 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:10:33,807 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:10:33,807 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:10:33,812 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:10:33,813 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:33,813 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:10:33,873 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:10:33,875 (MainThread): 
2019-10-01 14:10:33,877 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:10:33,877 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:10:33,911 (MainThread): Parsing macros\core.sql
2019-10-01 14:10:33,922 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:10:34,024 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:10:34,051 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:10:34,060 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:10:34,073 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:10:34,086 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:10:34,093 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:10:34,100 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:10:34,126 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:10:34,151 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:10:34,163 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:10:34,198 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:10:34,233 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:10:34,239 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:10:34,280 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:10:34,292 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:10:34,299 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:10:34,312 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:10:34,315 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:10:34,321 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:10:34,326 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:10:34,332 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:10:34,359 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:10:34,365 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:10:34,387 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:10:34,395 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:10:34,406 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:10:34,591 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:34,591 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:10:35,366 (MainThread): SQL status: SUCCESS 28 in 0.77 seconds
2019-10-01 14:10:35,375 (MainThread): Creating schema "OPA_DEV"."DBT_TEST".
2019-10-01 14:10:35,377 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,378 (MainThread): On master: BEGIN
2019-10-01 14:10:35,503 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:35,504 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,505 (MainThread): On master: create schema if not exists OPA_DEV.DBT_TEST
2019-10-01 14:10:35,696 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:10:35,697 (MainThread): On master: COMMIT
2019-10-01 14:10:35,698 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,698 (MainThread): On master: COMMIT
2019-10-01 14:10:35,803 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:35,885 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,885 (MainThread): On master: BEGIN
2019-10-01 14:10:36,010 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:36,010 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:36,010 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:10:37,201 (MainThread): SQL status: SUCCESS 0 in 1.19 seconds
2019-10-01 14:10:37,203 (MainThread): On master: ROLLBACK
2019-10-01 14:10:37,493 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:37,494 (MainThread): On master: BEGIN
2019-10-01 14:10:37,626 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:37,627 (MainThread): On master: COMMIT
2019-10-01 14:10:37,627 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:37,627 (MainThread): On master: COMMIT
2019-10-01 14:10:37,789 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:37,791 (MainThread): 14:10:37 | Concurrency: 1 threads (target='dev')
2019-10-01 14:10:37,792 (MainThread): 14:10:37 | 
2019-10-01 14:10:37,806 (Thread-1): 14:10:37 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:10:37,808 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:10:37,809 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:10:38,396 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:10:38,421 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:10:38,481 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:10:38,485 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:10:38,485 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:10:38,617 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:38,617 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:10:38,617 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:10:38,998 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2019-10-01 14:10:38,999 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:10:38,999 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:10:38,999 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:10:39,106 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:39,111 (Thread-1): 14:10:39 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.30s]
2019-10-01 14:10:39,112 (Thread-1): 14:10:39 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:10:39,114 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:10:39,115 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:10:39,115 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:10:39,122 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:10:39,130 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:10:39,134 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:10:39,135 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:10:39,244 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:39,245 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:10:39,245 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:10:39,503 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:10:39,505 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:10:39,505 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:10:39,506 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:10:39,596 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:10:39,600 (Thread-1): 14:10:39 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.49s]
2019-10-01 14:10:39,601 (Thread-1): 14:10:39 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:10:39,604 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:10:39,604 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:10:39,605 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:10:39,610 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:10:39,620 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:10:39,624 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:10:39,624 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:10:39,746 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:39,746 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:10:39,747 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:10:40,024 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:10:40,026 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:10:40,027 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:10:40,027 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:10:40,126 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:40,132 (Thread-1): 14:10:40 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.53s]
2019-10-01 14:10:40,133 (Thread-1): 14:10:40 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:10:40,135 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:10:40,135 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:10:40,135 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:10:40,141 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:10:40,149 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:10:40,154 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:10:40,155 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:10:40,259 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:40,260 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:10:40,260 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:10:40,546 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:10:40,548 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:10:40,549 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:10:40,549 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:10:40,654 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:40,661 (Thread-1): 14:10:40 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.52s]
2019-10-01 14:10:40,663 (Thread-1): 14:10:40 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:10:40,663 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:40,663 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:10:40,664 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:10:40,675 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:10:40,732 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:10:40,737 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:40,737 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:10:40,845 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:40,845 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:40,846 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:10:41,305 (Thread-1): SQL status: SUCCESS 1 in 0.46 seconds
2019-10-01 14:10:41,306 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:10:41,307 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:41,307 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:10:41,402 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:10:41,408 (Thread-1): 14:10:41 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.74s]
2019-10-01 14:10:41,409 (Thread-1): 14:10:41 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:10:41,412 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,412 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:10:41,412 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:10:41,417 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:10:41,427 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:10:41,431 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,431 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:10:41,598 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:10:41,599 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,599 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:10:41,958 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 14:10:41,960 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:10:41,960 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,960 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:10:42,065 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:42,077 (Thread-1): 14:10:42 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.66s]
2019-10-01 14:10:42,079 (Thread-1): 14:10:42 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:10:42,089 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,089 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:10:42,091 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:10:42,103 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:10:42,113 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:10:42,117 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,118 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:10:42,245 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:42,245 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,245 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:10:42,518 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:10:42,521 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:10:42,522 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,522 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:10:42,618 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:42,628 (Thread-1): 14:10:42 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.53s]
2019-10-01 14:10:42,630 (Thread-1): 14:10:42 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:10:42,635 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:10:42,635 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:10:42,637 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:10:42,645 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:10:42,656 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:10:42,661 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:10:42,661 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:10:42,778 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:42,778 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:10:42,778 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:10:43,317 (Thread-1): SQL status: SUCCESS 1 in 0.54 seconds
2019-10-01 14:10:43,320 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:10:43,320 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:10:43,321 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:10:43,427 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:43,433 (Thread-1): 14:10:43 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.80s]
2019-10-01 14:10:43,435 (Thread-1): 14:10:43 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:10:43,438 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,439 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:10:43,440 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:10:43,447 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:10:43,459 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:10:43,463 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,464 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:10:43,650 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:10:43,650 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,650 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:10:43,972 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:10:43,973 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:10:43,974 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,974 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:10:44,091 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:44,095 (Thread-1): 14:10:44 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.66s]
2019-10-01 14:10:44,096 (Thread-1): 14:10:44 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:10:44,098 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,098 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:10:44,099 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:10:44,105 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:10:44,116 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:10:44,121 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,121 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:10:44,233 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:44,233 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,234 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:10:44,480 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:10:44,482 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:10:44,482 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,483 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:10:44,590 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:44,601 (Thread-1): 14:10:44 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.50s]
2019-10-01 14:10:44,602 (Thread-1): 14:10:44 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:10:44,605 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:44,605 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:10:44,607 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:10:44,615 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:10:44,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:10:44,638 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:44,638 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:10:44,750 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:44,751 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:44,751 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:10:45,038 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:10:45,039 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:10:45,039 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:45,039 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:10:45,132 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:10:45,137 (Thread-1): 14:10:45 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.53s]
2019-10-01 14:10:45,138 (Thread-1): 14:10:45 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:10:45,139 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,139 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:10:45,139 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:10:45,149 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:10:45,163 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:10:45,168 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,169 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:10:45,325 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:45,325 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,325 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:10:45,652 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2019-10-01 14:10:45,654 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:10:45,655 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,655 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:10:45,753 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:45,757 (Thread-1): 14:10:45 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.62s]
2019-10-01 14:10:45,759 (Thread-1): 14:10:45 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:10:45,761 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:10:45,761 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:10:45,761 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:10:45,768 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:10:45,781 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:10:45,786 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:10:45,786 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:10:45,891 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:45,892 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:10:45,892 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:10:46,106 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:10:46,109 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:10:46,109 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:10:46,109 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:10:46,204 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:46,212 (Thread-1): 14:10:46 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.45s]
2019-10-01 14:10:46,215 (Thread-1): 14:10:46 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:10:46,218 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,218 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:10:46,219 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:10:46,228 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:10:46,242 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:10:46,250 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,250 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:10:46,370 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:46,371 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,371 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:10:46,675 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:10:46,678 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:10:46,678 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,678 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:10:46,835 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:46,842 (Thread-1): 14:10:46 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.62s]
2019-10-01 14:10:46,845 (Thread-1): 14:10:46 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:10:46,847 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:10:46,847 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:10:46,848 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:10:46,856 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:10:46,869 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:10:46,875 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:10:46,875 (Thread-1): On with_dates: BEGIN
2019-10-01 14:10:47,088 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:10:47,089 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:10:47,089 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:10:47,363 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:10:47,365 (Thread-1): On with_dates: COMMIT
2019-10-01 14:10:47,365 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:10:47,365 (Thread-1): On with_dates: COMMIT
2019-10-01 14:10:47,538 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:10:47,548 (Thread-1): 14:10:47 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.70s]
2019-10-01 14:10:47,558 (Thread-1): 14:10:47 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:10:47,558 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:47,558 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:10:47,568 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:10:47,578 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:10:47,593 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:10:47,601 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:47,601 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:10:47,826 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:10:47,827 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:47,827 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:10:48,149 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:10:48,150 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:10:48,151 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:48,151 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:10:48,499 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:10:48,517 (Thread-1): 14:10:48 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.95s]
2019-10-01 14:10:48,521 (Thread-1): 14:10:48 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:10:48,527 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:48,528 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:10:48,530 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:10:48,550 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:10:48,565 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:10:48,574 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:48,576 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:10:48,692 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:48,693 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:48,693 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:10:49,280 (Thread-1): SQL status: SUCCESS 1 in 0.59 seconds
2019-10-01 14:10:49,280 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:10:49,280 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:49,280 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:10:49,421 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:10:49,441 (Thread-1): 14:10:49 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.90s]
2019-10-01 14:10:49,441 (Thread-1): 14:10:49 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:10:49,442 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,442 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:10:49,442 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:10:49,448 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:10:49,457 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:10:49,462 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,462 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:10:49,610 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:10:49,610 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,610 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:10:49,958 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:10:49,958 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:10:49,958 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,958 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:10:50,071 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:50,081 (Thread-1): 14:10:50 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.64s]
2019-10-01 14:10:50,091 (Thread-1): 14:10:50 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:10:50,091 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,091 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:10:50,091 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:10:50,101 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:10:50,105 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:10:50,111 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,111 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:10:50,273 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:50,273 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,273 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:10:50,523 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:10:50,525 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:10:50,526 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,526 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:10:50,682 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:50,698 (Thread-1): 14:10:50 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.60s]
2019-10-01 14:10:50,708 (Thread-1): 14:10:50 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:10:50,708 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:10:50,708 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:10:50,708 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:10:50,718 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:10:50,728 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:10:50,738 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:10:50,738 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:10:50,850 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:50,850 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:10:50,850 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:10:51,199 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:10:51,199 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:10:51,199 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:10:51,199 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:10:51,298 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:51,306 (Thread-1): 14:10:51 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.59s]
2019-10-01 14:10:51,307 (Thread-1): 14:10:51 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:10:51,310 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:51,310 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:10:51,311 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:10:51,366 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:10:51,401 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:10:51,498 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:51,498 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:10:51,627 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:51,627 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:51,627 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
);
2019-10-01 14:10:54,467 (Thread-1): SQL status: SUCCESS 1 in 2.84 seconds
2019-10-01 14:10:54,467 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:54,467 (Thread-1): On v_booking_fact_uk: );
2019-10-01 14:10:54,768 (Thread-1): Snowflake error: 001003 (42000): 018f4156-0031-3e69-0000-0e29015fbfea: SQL compilation error:
syntax error line 1 at position 0 unexpected ')'.
2019-10-01 14:10:54,768 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:10:54,935 (Thread-1): 14:10:54 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 3.62s]
2019-10-01 14:10:55,012 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:55,012 (MainThread): On master: BEGIN
2019-10-01 14:10:55,138 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:55,138 (MainThread): On master: COMMIT
2019-10-01 14:10:55,138 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:55,138 (MainThread): On master: COMMIT
2019-10-01 14:10:55,301 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:55,301 (MainThread): 14:10:55 | 
2019-10-01 14:10:55,301 (MainThread): 14:10:55 | Finished running 21 view models in 21.42s.
2019-10-01 14:10:55,301 (MainThread): Connection 'master' was left open.
2019-10-01 14:10:55,301 (MainThread): On master: Close
2019-10-01 14:10:55,462 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:10:55,464 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:10:55,690 (MainThread): 
2019-10-01 14:10:55,690 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:10:55,690 (MainThread): 
2019-10-01 14:10:55,690 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:10:55,690 (MainThread):   001003 (42000): 018f4156-0031-3e69-0000-0e29015fbfea: SQL compilation error:
2019-10-01 14:10:55,690 (MainThread):   syntax error line 1 at position 0 unexpected ')'.
2019-10-01 14:10:55,690 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:10:55,690 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:10:55,690 (MainThread): Flushing usage events
2019-10-01 14:28:20,946 (MainThread): Tracking: tracking
2019-10-01 14:28:20,948 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBD188>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBD1C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8C588>]}
2019-10-01 14:28:21,289 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:28:21,292 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57927), raddr=('54.174.31.151', 443)>

2019-10-01 14:28:21,297 (MainThread): Error sending message, disabling tracking
2019-10-01 14:28:21,364 (MainThread): Parsing macros\core.sql
2019-10-01 14:28:21,377 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:28:21,416 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:28:21,428 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:28:21,431 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:28:21,434 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:28:21,438 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:28:21,441 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:28:21,443 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:28:21,452 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:28:21,460 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:28:21,470 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:28:21,486 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:28:21,507 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:28:21,510 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:28:21,523 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:28:21,530 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:28:21,536 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:28:21,543 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:28:21,546 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:28:21,548 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:28:21,550 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:28:21,553 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:28:21,566 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:28:21,570 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:28:21,578 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:28:21,581 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:28:21,586 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:28:21,614 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:28:21,616 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:21,616 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:28:21,618 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:28:21,974 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:28:21,990 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:28:22,626 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:28:22,627 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:28:22,627 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:28:22,632 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:28:22,633 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:28:22,633 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:28:22,637 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:28:22,638 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:28:22,639 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:28:22,643 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:28:22,644 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:28:22,644 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:28:22,651 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:28:22,654 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:28:22,654 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:28:22,663 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:28:22,665 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:22,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:28:22,674 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:28:22,676 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:28:22,676 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:28:22,683 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:28:22,684 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:28:22,684 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:28:22,690 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:28:22,691 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:28:22,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:28:22,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:28:22,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:22,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:28:22,701 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:28:22,702 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:22,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:28:22,707 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:28:22,708 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:22,708 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:28:22,713 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:28:22,714 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:28:22,714 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:28:22,718 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:28:22,719 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:28:22,719 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:28:22,724 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:28:22,725 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:22,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:28:22,730 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:28:22,731 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:28:22,731 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:28:22,736 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:28:22,737 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:22,737 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:28:22,741 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:28:22,742 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:22,742 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:28:22,747 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:28:22,748 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:28:22,749 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:28:22,754 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:28:22,755 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:22,755 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:28:22,817 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:28:22,820 (MainThread): 
2019-10-01 14:28:22,820 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:28:22,821 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:28:22,857 (MainThread): Parsing macros\core.sql
2019-10-01 14:28:22,869 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:28:22,941 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:28:22,954 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:28:22,956 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:28:22,959 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:28:22,963 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:28:22,966 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:28:22,968 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:28:22,977 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:28:22,986 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:28:22,995 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:28:23,017 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:28:23,037 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:28:23,042 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:28:23,068 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:28:23,082 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:28:23,090 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:28:23,098 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:28:23,102 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:28:23,104 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:28:23,107 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:28:23,110 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:28:23,125 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:28:23,131 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:28:23,143 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:28:23,148 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:28:23,153 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:28:23,267 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:23,267 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:28:23,771 (MainThread): SQL status: SUCCESS 29 in 0.50 seconds
2019-10-01 14:28:23,858 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:23,858 (MainThread): On master: BEGIN
2019-10-01 14:28:23,989 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:28:23,991 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:23,991 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:28:25,064 (MainThread): SQL status: SUCCESS 21 in 1.07 seconds
2019-10-01 14:28:25,117 (MainThread): On master: ROLLBACK
2019-10-01 14:28:25,288 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:25,289 (MainThread): On master: BEGIN
2019-10-01 14:28:25,432 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:28:25,434 (MainThread): On master: COMMIT
2019-10-01 14:28:25,435 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:25,435 (MainThread): On master: COMMIT
2019-10-01 14:28:25,590 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:28:25,592 (MainThread): 14:28:25 | Concurrency: 1 threads (target='dev')
2019-10-01 14:28:25,594 (MainThread): 14:28:25 | 
2019-10-01 14:28:25,607 (Thread-1): 14:28:25 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:28:25,609 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:28:25,610 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:28:25,922 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:28:25,938 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:28:25,987 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:28:25,991 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:28:25,991 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:28:26,096 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:26,097 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:28:26,097 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:28:26,330 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:28:26,332 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:28:26,333 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:28:26,333 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:28:26,432 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:26,439 (Thread-1): 14:28:26 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 0.83s]
2019-10-01 14:28:26,440 (Thread-1): 14:28:26 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:28:26,442 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:28:26,442 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:28:26,442 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:28:26,447 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:28:26,462 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:28:26,467 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:28:26,467 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:28:26,567 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:26,567 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:28:26,568 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:28:26,825 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:26,828 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:28:26,828 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:28:26,828 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:28:26,912 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-01 14:28:26,917 (Thread-1): 14:28:26 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.47s]
2019-10-01 14:28:26,918 (Thread-1): 14:28:26 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:28:26,920 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:28:26,920 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:28:26,921 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:28:26,925 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:28:26,939 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:28:26,945 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:28:26,945 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:28:27,055 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:27,055 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:28:27,055 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:28:27,275 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:27,277 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:28:27,278 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:28:27,278 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:28:27,379 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:27,386 (Thread-1): 14:28:27 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.46s]
2019-10-01 14:28:27,387 (Thread-1): 14:28:27 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:28:27,390 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:28:27,390 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:28:27,391 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:28:27,396 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:28:27,407 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:28:27,411 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:28:27,411 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:28:27,528 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:27,528 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:28:27,528 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:28:27,786 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:27,788 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:28:27,788 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:28:27,789 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:28:27,905 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:27,911 (Thread-1): 14:28:27 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.52s]
2019-10-01 14:28:27,912 (Thread-1): 14:28:27 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:28:27,912 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:27,912 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:28:27,913 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:28:27,921 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:28:27,930 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:28:27,934 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:27,935 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:28:28,042 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:28,043 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:28,043 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:28:28,306 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:28,310 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:28:28,310 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:28,311 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:28:28,448 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:28:28,464 (Thread-1): 14:28:28 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.55s]
2019-10-01 14:28:28,466 (Thread-1): 14:28:28 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:28:28,473 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,473 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:28:28,474 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:28:28,483 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:28:28,497 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:28:28,502 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,502 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:28:28,607 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:28,608 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,608 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:28:28,862 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:28,864 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:28:28,864 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,864 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:28:28,951 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:28:28,966 (Thread-1): 14:28:28 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.49s]
2019-10-01 14:28:28,970 (Thread-1): 14:28:28 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:28:28,976 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:28:28,976 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:28:28,978 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:28:28,993 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:28:29,009 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:28:29,014 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:28:29,015 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:28:29,121 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:29,122 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:28:29,122 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:28:29,356 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:28:29,360 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:28:29,361 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:28:29,361 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:28:29,454 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:28:29,473 (Thread-1): 14:28:29 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.49s]
2019-10-01 14:28:29,476 (Thread-1): 14:28:29 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:28:29,482 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,482 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:28:29,484 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:28:29,501 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:28:29,518 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:28:29,524 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,525 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:28:29,631 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:29,632 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,632 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:28:29,898 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:28:29,903 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:28:29,903 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,904 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:28:30,013 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:30,025 (Thread-1): 14:28:30 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.54s]
2019-10-01 14:28:30,026 (Thread-1): 14:28:30 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:28:30,027 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,028 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:28:30,029 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:28:30,044 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:28:30,057 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:28:30,061 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,061 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:28:30,166 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:30,167 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,168 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:28:30,382 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:28:30,384 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:28:30,384 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,384 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:28:30,493 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:30,508 (Thread-1): 14:28:30 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.48s]
2019-10-01 14:28:30,512 (Thread-1): 14:28:30 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:28:30,518 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,519 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:28:30,520 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:28:30,528 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:28:30,539 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:28:30,544 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,545 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:28:30,659 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:30,659 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,659 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:28:30,934 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:28:30,935 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:28:30,935 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,935 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:28:31,054 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:31,058 (Thread-1): 14:28:31 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.54s]
2019-10-01 14:28:31,059 (Thread-1): 14:28:31 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:28:31,060 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,060 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:28:31,060 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:28:31,070 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:28:31,083 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:28:31,088 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,088 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:28:31,197 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:31,197 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,198 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:28:31,415 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:31,417 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:28:31,417 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,417 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:28:31,527 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:31,532 (Thread-1): 14:28:31 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.47s]
2019-10-01 14:28:31,533 (Thread-1): 14:28:31 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:28:31,535 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,535 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:28:31,535 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:28:31,542 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:28:31,551 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:28:31,557 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,557 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:28:31,694 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:28:31,695 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,695 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:28:31,944 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:31,948 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:28:31,948 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,949 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:28:32,044 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:32,053 (Thread-1): 14:28:32 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.51s]
2019-10-01 14:28:32,054 (Thread-1): 14:28:32 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:28:32,056 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,056 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:28:32,057 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:28:32,070 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:28:32,083 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:28:32,088 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,088 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:28:32,195 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:32,195 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,195 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:28:32,420 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:32,424 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:28:32,424 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,425 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:28:32,536 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:32,543 (Thread-1): 14:28:32 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.48s]
2019-10-01 14:28:32,545 (Thread-1): 14:28:32 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:28:32,548 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:32,548 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:28:32,549 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:28:32,560 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:28:32,568 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:28:32,574 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:32,574 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:28:32,691 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:32,692 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:32,692 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:28:33,181 (Thread-1): SQL status: SUCCESS 1 in 0.49 seconds
2019-10-01 14:28:33,187 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:28:33,188 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:33,188 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:28:33,339 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:28:33,348 (Thread-1): 14:28:33 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.80s]
2019-10-01 14:28:33,350 (Thread-1): 14:28:33 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:28:33,352 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:28:33,353 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:28:33,354 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:28:33,366 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:28:33,380 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:28:33,385 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:28:33,385 (Thread-1): On with_dates: BEGIN
2019-10-01 14:28:33,508 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:33,509 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:28:33,509 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:28:33,874 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2019-10-01 14:28:33,875 (Thread-1): On with_dates: COMMIT
2019-10-01 14:28:33,876 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:28:33,876 (Thread-1): On with_dates: COMMIT
2019-10-01 14:28:33,958 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-01 14:28:33,963 (Thread-1): 14:28:33 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.61s]
2019-10-01 14:28:33,964 (Thread-1): 14:28:33 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:28:33,965 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:33,966 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:28:33,966 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:28:33,973 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:28:33,985 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:28:33,992 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:33,992 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:28:34,112 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:34,113 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:34,113 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:28:34,366 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:34,369 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:28:34,370 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:34,370 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:28:34,520 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:28:34,530 (Thread-1): 14:28:34 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.56s]
2019-10-01 14:28:34,533 (Thread-1): 14:28:34 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:28:34,536 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,536 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:28:34,537 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:28:34,545 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:28:34,553 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:28:34,558 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,559 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:28:34,678 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:34,678 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,678 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:28:34,939 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:34,946 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:28:34,948 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,948 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:28:35,052 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:35,075 (Thread-1): 14:28:35 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.53s]
2019-10-01 14:28:35,078 (Thread-1): 14:28:35 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:28:35,082 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,083 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:28:35,084 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:28:35,095 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:28:35,113 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:28:35,117 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,118 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:28:35,228 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:35,229 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,229 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:28:35,483 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:35,486 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:28:35,487 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,487 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:28:35,602 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:35,610 (Thread-1): 14:28:35 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.53s]
2019-10-01 14:28:35,611 (Thread-1): 14:28:35 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:28:35,614 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:35,615 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:28:35,615 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:28:35,622 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:28:35,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:28:35,635 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:35,635 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:28:35,796 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:28:35,796 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:35,796 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:28:36,052 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:36,054 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:28:36,055 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:36,055 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:28:36,150 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:28:36,159 (Thread-1): 14:28:36 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.54s]
2019-10-01 14:28:36,160 (Thread-1): 14:28:36 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:28:36,162 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:28:36,162 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:28:36,162 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:28:36,169 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:28:36,179 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:28:36,182 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:28:36,183 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:28:36,295 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:36,296 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:28:36,296 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:28:36,506 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:28:36,508 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:28:36,508 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:28:36,508 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:28:36,615 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:36,619 (Thread-1): 14:28:36 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.46s]
2019-10-01 14:28:36,620 (Thread-1): 14:28:36 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:28:36,623 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:36,623 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:28:36,624 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:28:36,668 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:28:36,703 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:28:36,830 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:36,830 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:28:36,939 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:36,939 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:36,940 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
;
2019-10-01 14:28:37,169 (Thread-1): Snowflake error: 001003 (42000): 018f4168-00fb-6626-0000-0e29015fe866: SQL compilation error:
syntax error line 1,093 at position 0 unexpected ';'.
2019-10-01 14:28:37,169 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:28:37,306 (Thread-1): 14:28:37 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 0.68s]
2019-10-01 14:28:37,314 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:37,314 (MainThread): On master: BEGIN
2019-10-01 14:28:37,427 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:37,428 (MainThread): On master: COMMIT
2019-10-01 14:28:37,428 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:37,428 (MainThread): On master: COMMIT
2019-10-01 14:28:37,652 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:37,652 (MainThread): 14:28:37 | 
2019-10-01 14:28:37,653 (MainThread): 14:28:37 | Finished running 21 view models in 14.83s.
2019-10-01 14:28:37,653 (MainThread): Connection 'master' was left open.
2019-10-01 14:28:37,653 (MainThread): On master: Close
2019-10-01 14:28:37,782 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:28:37,782 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:28:38,025 (MainThread): 
2019-10-01 14:28:38,026 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:28:38,027 (MainThread): 
2019-10-01 14:28:38,027 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:28:38,029 (MainThread):   001003 (42000): 018f4168-00fb-6626-0000-0e29015fe866: SQL compilation error:
2019-10-01 14:28:38,030 (MainThread):   syntax error line 1,093 at position 0 unexpected ';'.
2019-10-01 14:28:38,030 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:28:38,031 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:28:38,032 (MainThread): Flushing usage events
2019-10-01 14:29:03,111 (MainThread): Tracking: tracking
2019-10-01 14:29:03,113 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005B85708>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92888>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C7C8>]}
2019-10-01 14:29:03,378 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:29:03,379 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57939), raddr=('54.174.31.151', 443)>

2019-10-01 14:29:03,381 (MainThread): Error sending message, disabling tracking
2019-10-01 14:29:03,420 (MainThread): Parsing macros\core.sql
2019-10-01 14:29:03,433 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:29:03,496 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:29:03,506 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:29:03,508 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:29:03,512 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:29:03,515 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:29:03,518 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:29:03,521 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:29:03,530 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:29:03,539 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:29:03,556 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:29:03,576 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:29:03,598 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:29:03,602 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:29:03,616 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:29:03,624 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:29:03,632 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:29:03,639 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:29:03,642 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:29:03,645 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:29:03,647 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:29:03,650 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:29:03,665 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:29:03,669 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:29:03,685 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:29:03,690 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:29:03,699 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:29:03,743 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:29:03,745 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:03,745 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:29:03,747 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:29:04,003 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:29:04,023 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:29:04,577 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:29:04,578 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:29:04,578 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:29:04,582 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:29:04,583 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:29:04,583 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:29:04,588 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:29:04,589 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:29:04,589 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:29:04,593 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:29:04,594 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:29:04,595 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:29:04,599 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:29:04,600 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:29:04,600 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:29:04,607 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:29:04,609 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:04,609 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:29:04,613 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:29:04,614 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:29:04,615 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:29:04,619 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:29:04,620 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:29:04,620 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:29:04,628 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:29:04,629 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:29:04,629 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:29:04,634 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:29:04,635 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:04,635 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:29:04,640 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:29:04,641 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:04,641 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:29:04,645 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:29:04,646 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:04,646 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:29:04,651 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:29:04,652 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:29:04,652 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:29:04,660 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:29:04,662 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:29:04,662 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:29:04,667 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:29:04,668 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:04,668 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:29:04,673 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:29:04,674 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:29:04,674 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:29:04,680 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:29:04,682 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:04,682 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:29:04,689 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:29:04,691 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:04,691 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:29:04,700 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:29:04,702 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:29:04,702 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:29:04,710 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:29:04,711 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:04,711 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:29:04,805 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:29:04,808 (MainThread): 
2019-10-01 14:29:04,809 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:29:04,809 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:29:04,848 (MainThread): Parsing macros\core.sql
2019-10-01 14:29:04,861 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:29:04,966 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:29:04,982 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:29:04,986 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:29:04,992 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:29:04,997 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:29:05,001 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:29:05,006 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:29:05,020 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:29:05,035 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:29:05,050 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:29:05,077 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:29:05,129 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:29:05,135 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:29:05,164 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:29:05,179 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:29:05,193 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:29:05,215 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:29:05,222 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:29:05,227 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:29:05,232 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:29:05,239 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:29:05,272 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:29:05,279 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:29:05,298 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:29:05,303 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:29:05,313 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:29:05,540 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:05,540 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:29:06,060 (MainThread): SQL status: SUCCESS 29 in 0.52 seconds
2019-10-01 14:29:06,118 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:06,118 (MainThread): On master: BEGIN
2019-10-01 14:29:06,226 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:06,227 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:06,227 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:29:07,298 (MainThread): SQL status: SUCCESS 21 in 1.07 seconds
2019-10-01 14:29:07,311 (MainThread): On master: ROLLBACK
2019-10-01 14:29:07,467 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:07,467 (MainThread): On master: BEGIN
2019-10-01 14:29:07,572 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:07,572 (MainThread): On master: COMMIT
2019-10-01 14:29:07,573 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:07,573 (MainThread): On master: COMMIT
2019-10-01 14:29:07,713 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:29:07,714 (MainThread): 14:29:07 | Concurrency: 1 threads (target='dev')
2019-10-01 14:29:07,714 (MainThread): 14:29:07 | 
2019-10-01 14:29:07,718 (Thread-1): 14:29:07 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:29:07,719 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:29:07,720 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:29:08,038 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:29:08,046 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:29:08,110 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:29:08,119 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:29:08,121 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:29:08,234 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:08,235 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:29:08,235 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:29:08,459 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:29:08,461 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:29:08,461 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:29:08,462 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:29:08,626 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:29:08,633 (Thread-1): 14:29:08 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 0.91s]
2019-10-01 14:29:08,634 (Thread-1): 14:29:08 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:29:08,636 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:29:08,636 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:29:08,636 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:29:08,645 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:29:08,661 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:29:08,667 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:29:08,667 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:29:08,794 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:08,794 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:29:08,795 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:29:09,016 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:29:09,018 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:29:09,019 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:29:09,019 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:29:09,128 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:09,136 (Thread-1): 14:29:09 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.50s]
2019-10-01 14:29:09,137 (Thread-1): 14:29:09 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:29:09,140 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:29:09,140 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:29:09,141 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:29:09,151 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:29:09,166 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:29:09,172 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:29:09,172 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:29:09,477 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:29:09,477 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:29:09,478 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:29:09,717 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:09,718 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:29:09,718 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:29:09,718 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:29:09,930 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:09,934 (Thread-1): 14:29:09 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.79s]
2019-10-01 14:29:09,934 (Thread-1): 14:29:09 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:29:09,935 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:29:09,935 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:29:09,935 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:29:09,941 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:29:09,951 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:29:09,954 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:29:09,954 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:29:10,113 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:29:10,113 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:29:10,113 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:29:10,355 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:10,356 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:29:10,356 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:29:10,356 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:29:10,449 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:10,456 (Thread-1): 14:29:10 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.52s]
2019-10-01 14:29:10,457 (Thread-1): 14:29:10 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:29:10,458 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,458 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:29:10,459 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:29:10,469 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:29:10,480 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:29:10,484 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,485 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:29:10,590 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:10,591 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,591 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:29:10,831 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:10,832 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:29:10,832 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,832 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:29:10,952 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:10,961 (Thread-1): 14:29:10 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.50s]
2019-10-01 14:29:10,962 (Thread-1): 14:29:10 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:29:10,966 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:29:10,966 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:29:10,967 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:29:10,980 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:29:11,001 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:29:11,005 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:29:11,006 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:29:11,138 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:29:11,139 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:29:11,139 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:29:11,376 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:11,378 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:29:11,378 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:29:11,378 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:29:11,462 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-01 14:29:11,470 (Thread-1): 14:29:11 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.50s]
2019-10-01 14:29:11,471 (Thread-1): 14:29:11 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:29:11,474 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,474 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:29:11,476 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:29:11,489 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:29:11,507 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:29:11,515 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,516 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:29:11,664 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:29:11,665 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,665 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:29:11,964 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:29:11,965 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:29:11,965 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,965 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:29:12,060 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:12,065 (Thread-1): 14:29:12 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.59s]
2019-10-01 14:29:12,066 (Thread-1): 14:29:12 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:29:12,068 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,068 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:29:12,068 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:29:12,074 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:29:12,087 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:29:12,091 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,091 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:29:12,213 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:12,214 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,214 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:29:12,454 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:12,455 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:29:12,455 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,455 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:29:12,550 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:12,554 (Thread-1): 14:29:12 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.48s]
2019-10-01 14:29:12,555 (Thread-1): 14:29:12 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:29:12,556 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,556 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:29:12,557 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:29:12,563 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:29:12,574 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:29:12,578 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,578 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:29:12,687 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:12,688 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,688 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:29:12,904 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:29:12,905 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:29:12,905 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,905 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:29:13,009 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:13,019 (Thread-1): 14:29:13 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.46s]
2019-10-01 14:29:13,021 (Thread-1): 14:29:13 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:29:13,025 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,025 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:29:13,026 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:29:13,038 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:29:13,053 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:29:13,059 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,059 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:29:13,207 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:29:13,208 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,208 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:29:13,435 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:29:13,438 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:29:13,438 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,438 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:29:13,543 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:13,547 (Thread-1): 14:29:13 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.52s]
2019-10-01 14:29:13,548 (Thread-1): 14:29:13 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:29:13,548 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:13,548 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:29:13,549 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:29:13,554 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:29:13,564 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:29:13,568 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:13,568 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:29:13,708 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:29:13,708 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:13,709 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:29:14,017 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 14:29:14,019 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:29:14,020 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:14,020 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:29:14,121 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:14,126 (Thread-1): 14:29:14 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.58s]
2019-10-01 14:29:14,127 (Thread-1): 14:29:14 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:29:14,129 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,130 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:29:14,130 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:29:14,141 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:29:14,152 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:29:14,156 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,156 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:29:14,271 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:14,272 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,272 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:29:14,480 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:14,482 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:29:14,482 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,483 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:29:14,620 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:29:14,625 (Thread-1): 14:29:14 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.49s]
2019-10-01 14:29:14,626 (Thread-1): 14:29:14 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:29:14,628 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:29:14,628 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:29:14,629 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:29:14,638 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:29:14,652 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:29:14,658 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:29:14,658 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:29:14,791 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:29:14,792 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:29:14,792 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:29:15,376 (Thread-1): SQL status: SUCCESS 1 in 0.58 seconds
2019-10-01 14:29:15,378 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:29:15,379 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:29:15,379 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:29:15,483 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:15,493 (Thread-1): 14:29:15 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.86s]
2019-10-01 14:29:15,495 (Thread-1): 14:29:15 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:29:15,499 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,500 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:29:15,501 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:29:15,510 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:29:15,528 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:29:15,534 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,535 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:29:15,646 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:15,647 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,647 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:29:15,987 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:29:15,988 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:29:15,988 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,988 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:29:16,080 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:16,087 (Thread-1): 14:29:16 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.59s]
2019-10-01 14:29:16,088 (Thread-1): 14:29:16 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:29:16,090 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:29:16,090 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:29:16,091 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:29:16,099 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:29:16,116 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:29:16,123 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:29:16,123 (Thread-1): On with_dates: BEGIN
2019-10-01 14:29:16,238 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:16,239 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:29:16,239 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:29:16,446 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:16,448 (Thread-1): On with_dates: COMMIT
2019-10-01 14:29:16,448 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:29:16,448 (Thread-1): On with_dates: COMMIT
2019-10-01 14:29:16,544 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:16,551 (Thread-1): 14:29:16 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.46s]
2019-10-01 14:29:16,552 (Thread-1): 14:29:16 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:29:16,554 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:16,554 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:29:16,555 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:29:16,565 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:29:16,580 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:29:16,590 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:16,590 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:29:16,703 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:16,704 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:16,704 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:29:17,050 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:29:17,052 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:29:17,052 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:17,052 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:29:17,146 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:17,155 (Thread-1): 14:29:17 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.60s]
2019-10-01 14:29:17,156 (Thread-1): 14:29:17 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:29:17,159 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,159 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:29:17,160 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:29:17,171 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:29:17,186 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:29:17,193 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,193 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:29:17,306 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:17,307 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,307 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:29:17,536 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:29:17,538 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:29:17,539 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,539 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:29:17,658 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:17,664 (Thread-1): 14:29:17 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.50s]
2019-10-01 14:29:17,665 (Thread-1): 14:29:17 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:29:17,669 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:29:17,669 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:29:17,670 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:29:17,679 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:29:17,711 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:29:17,717 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:29:17,717 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:29:17,835 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:17,835 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:29:17,836 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:29:18,120 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:29:18,122 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:29:18,122 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:29:18,122 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:29:18,244 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:18,255 (Thread-1): 14:29:18 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.58s]
2019-10-01 14:29:18,257 (Thread-1): 14:29:18 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:29:18,260 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,260 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:29:18,261 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:29:18,273 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:29:18,291 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:29:18,296 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,296 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:29:18,402 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:18,403 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,403 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:29:18,694 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:29:18,695 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:29:18,695 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,695 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:29:18,790 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:18,797 (Thread-1): 14:29:18 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.54s]
2019-10-01 14:29:18,798 (Thread-1): 14:29:18 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:29:18,801 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:29:18,801 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:29:18,802 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:29:18,811 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:29:18,826 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:29:18,831 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:29:18,831 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:29:18,948 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:18,948 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:29:18,949 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:29:19,162 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:19,165 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:29:19,165 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:29:19,165 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:29:19,256 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:19,262 (Thread-1): 14:29:19 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.46s]
2019-10-01 14:29:19,263 (Thread-1): 14:29:19 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:29:19,265 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:19,265 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:29:19,265 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:29:19,319 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:29:19,363 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:29:19,511 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:19,511 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:29:19,628 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:19,629 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:19,629 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
  );
2019-10-01 14:29:21,718 (Thread-1): SQL status: SUCCESS 1 in 2.09 seconds
2019-10-01 14:29:21,720 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:29:21,721 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:21,721 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:29:21,819 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:21,828 (Thread-1): 14:29:21 | 21 of 21 OK created view model DBT_TEST.v_booking_fact_uk............ [SUCCESS 1 in 2.56s]
2019-10-01 14:29:21,840 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:21,840 (MainThread): On master: BEGIN
2019-10-01 14:29:21,954 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:21,954 (MainThread): On master: COMMIT
2019-10-01 14:29:21,954 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:21,954 (MainThread): On master: COMMIT
2019-10-01 14:29:22,115 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:29:22,116 (MainThread): 14:29:22 | 
2019-10-01 14:29:22,117 (MainThread): 14:29:22 | Finished running 21 view models in 17.31s.
2019-10-01 14:29:22,117 (MainThread): Connection 'master' was left open.
2019-10-01 14:29:22,118 (MainThread): On master: Close
2019-10-01 14:29:22,265 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:29:22,265 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:29:22,437 (MainThread): 
2019-10-01 14:29:22,437 (MainThread): Completed successfully
2019-10-01 14:29:22,438 (MainThread): 
Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
2019-10-01 14:29:22,439 (MainThread): Flushing usage events
2019-10-01 14:46:33,726 (MainThread): Tracking: tracking
2019-10-01 14:46:33,728 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92A88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92448>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92648>]}
2019-10-01 14:46:34,040 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:46:34,041 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58066), raddr=('54.174.31.151', 443)>

2019-10-01 14:46:34,042 (MainThread): Error sending message, disabling tracking
2019-10-01 14:46:34,063 (MainThread): Parsing macros\core.sql
2019-10-01 14:46:34,073 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:46:34,107 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:46:34,117 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:46:34,119 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:46:34,122 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:46:34,125 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:46:34,128 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:46:34,131 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:46:34,139 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:46:34,147 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:46:34,155 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:46:34,173 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:46:34,194 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:46:34,198 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:46:34,211 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:46:34,218 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:46:34,225 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:46:34,232 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:46:34,234 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:46:34,236 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:46:34,239 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:46:34,242 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:46:34,259 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:46:34,262 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:46:34,271 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:46:34,274 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:46:34,278 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:46:34,322 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:46:34,325 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:34,325 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:46:34,327 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:46:34,571 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:46:34,590 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:46:35,179 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:46:35,180 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:46:35,181 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:46:35,185 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:46:35,186 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:46:35,186 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:46:35,191 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:46:35,192 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:46:35,192 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:46:35,196 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:46:35,197 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:46:35,197 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:46:35,204 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:46:35,206 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:46:35,206 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:46:35,211 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:46:35,212 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:35,212 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:46:35,217 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:46:35,219 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:46:35,219 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:46:35,224 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:46:35,225 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:46:35,225 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:46:35,230 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:46:35,231 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:46:35,231 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:46:35,236 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:46:35,237 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:35,237 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:46:35,242 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:46:35,243 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:35,243 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:46:35,247 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:46:35,248 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:35,249 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:46:35,254 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:46:35,255 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:46:35,255 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:46:35,263 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:46:35,265 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:46:35,265 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:46:35,275 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:46:35,277 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:35,277 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:46:35,285 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:46:35,287 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:46:35,287 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:46:35,296 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:46:35,298 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:35,299 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:46:35,304 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:46:35,305 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:35,305 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:46:35,311 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:46:35,312 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:46:35,312 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:46:35,316 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:46:35,317 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:35,317 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:46:35,408 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:46:35,412 (MainThread): 
2019-10-01 14:46:35,413 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:46:35,413 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:46:35,460 (MainThread): Parsing macros\core.sql
2019-10-01 14:46:35,473 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:46:35,565 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:46:35,580 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:46:35,582 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:46:35,586 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:46:35,593 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:46:35,598 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:46:35,601 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:46:35,618 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:46:35,634 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:46:35,644 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:46:35,679 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:46:35,721 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:46:35,728 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:46:35,753 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:46:35,761 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:46:35,769 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:46:35,781 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:46:35,786 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:46:35,788 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:46:35,791 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:46:35,796 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:46:35,820 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:46:35,825 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:46:35,840 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:46:35,844 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:46:35,851 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:46:35,994 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:35,994 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:46:36,606 (MainThread): SQL status: SUCCESS 29 in 0.61 seconds
2019-10-01 14:46:36,672 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:36,672 (MainThread): On master: BEGIN
2019-10-01 14:46:36,792 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:36,793 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:36,793 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:46:37,858 (MainThread): SQL status: SUCCESS 21 in 1.07 seconds
2019-10-01 14:46:37,872 (MainThread): On master: ROLLBACK
2019-10-01 14:46:38,016 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:38,016 (MainThread): On master: BEGIN
2019-10-01 14:46:38,132 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:38,132 (MainThread): On master: COMMIT
2019-10-01 14:46:38,132 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:38,132 (MainThread): On master: COMMIT
2019-10-01 14:46:38,279 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:46:38,279 (MainThread): 14:46:38 | Concurrency: 1 threads (target='dev')
2019-10-01 14:46:38,280 (MainThread): 14:46:38 | 
2019-10-01 14:46:38,283 (Thread-1): 14:46:38 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:46:38,284 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:46:38,284 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:46:38,802 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:46:38,815 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:46:38,856 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:46:38,861 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:46:38,861 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:46:38,982 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:38,983 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:46:38,983 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:46:39,234 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:46:39,236 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:46:39,236 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:46:39,237 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:46:39,335 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:39,344 (Thread-1): 14:46:39 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.06s]
2019-10-01 14:46:39,345 (Thread-1): 14:46:39 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:46:39,352 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:46:39,352 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:46:39,353 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:46:39,364 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:46:39,381 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:46:39,387 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:46:39,387 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:46:39,578 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:46:39,578 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:46:39,579 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:46:39,819 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:39,820 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:46:39,821 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:46:39,821 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:46:39,912 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:39,923 (Thread-1): 14:46:39 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.57s]
2019-10-01 14:46:39,924 (Thread-1): 14:46:39 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:46:39,925 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:46:39,926 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:46:39,927 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:46:39,943 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:46:39,958 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:46:39,964 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:46:39,964 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:46:40,081 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:40,082 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:46:40,082 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:46:40,326 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:40,328 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:46:40,328 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:46:40,328 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:46:40,424 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:40,428 (Thread-1): 14:46:40 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.50s]
2019-10-01 14:46:40,428 (Thread-1): 14:46:40 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:46:40,431 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:46:40,431 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:46:40,431 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:46:40,436 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:46:40,445 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:46:40,449 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:46:40,449 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:46:40,567 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:40,567 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:46:40,567 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:46:40,833 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:46:40,834 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:46:40,834 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:46:40,834 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:46:40,927 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:40,931 (Thread-1): 14:46:40 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.50s]
2019-10-01 14:46:40,932 (Thread-1): 14:46:40 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:46:40,933 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:40,933 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:46:40,934 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:46:40,939 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:46:40,954 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:46:40,961 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:40,961 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:46:41,101 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:41,102 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:41,102 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:46:41,360 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:46:41,362 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:46:41,362 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:41,363 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:46:41,511 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:46:41,516 (Thread-1): 14:46:41 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.58s]
2019-10-01 14:46:41,517 (Thread-1): 14:46:41 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:46:41,520 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,520 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:46:41,521 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:46:41,526 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:46:41,542 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:46:41,548 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,548 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:46:41,676 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:41,677 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,677 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:46:41,933 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:46:41,935 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:46:41,936 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,936 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:46:42,041 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:42,044 (Thread-1): 14:46:42 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.52s]
2019-10-01 14:46:42,045 (Thread-1): 14:46:42 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:46:42,047 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,047 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:46:42,048 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:46:42,057 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:46:42,066 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:46:42,070 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,071 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:46:42,211 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:42,212 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,212 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:46:42,436 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:46:42,438 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:46:42,438 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,438 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:46:42,576 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:42,580 (Thread-1): 14:46:42 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.53s]
2019-10-01 14:46:42,581 (Thread-1): 14:46:42 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:46:42,584 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,584 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:46:42,585 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:46:42,589 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:46:42,599 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:46:42,603 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,603 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:46:42,721 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:42,722 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,723 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:46:42,945 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:46:42,946 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:46:42,946 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,946 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:46:43,047 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:43,051 (Thread-1): 14:46:43 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.46s]
2019-10-01 14:46:43,053 (Thread-1): 14:46:43 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:46:43,057 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,057 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:46:43,057 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:46:43,066 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:46:43,081 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:46:43,085 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,085 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:46:43,203 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:43,204 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,204 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:46:43,432 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:46:43,433 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:46:43,434 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,434 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:46:43,530 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:43,534 (Thread-1): 14:46:43 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.48s]
2019-10-01 14:46:43,535 (Thread-1): 14:46:43 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:46:43,537 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:43,537 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:46:43,537 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:46:43,542 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:46:43,551 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:46:43,555 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:43,555 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:46:43,750 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:46:43,751 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:43,751 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:46:44,030 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:46:44,033 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:46:44,033 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:44,033 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:46:44,123 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:44,131 (Thread-1): 14:46:44 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.59s]
2019-10-01 14:46:44,133 (Thread-1): 14:46:44 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:46:44,136 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,137 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:46:44,138 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:46:44,150 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:46:44,162 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:46:44,167 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,167 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:46:44,276 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:44,277 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,277 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:46:44,520 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:44,521 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:46:44,521 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,521 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:46:44,632 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:44,636 (Thread-1): 14:46:44 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.50s]
2019-10-01 14:46:44,637 (Thread-1): 14:46:44 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:46:44,640 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:46:44,640 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:46:44,641 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:46:44,648 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:46:44,657 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:46:44,662 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:46:44,662 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:46:44,775 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:44,776 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:46:44,776 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:46:45,025 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:46:45,027 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:46:45,027 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:46:45,027 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:46:45,144 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:45,154 (Thread-1): 14:46:45 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.51s]
2019-10-01 14:46:45,155 (Thread-1): 14:46:45 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:46:45,158 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,158 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:46:45,159 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:46:45,170 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:46:45,185 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:46:45,190 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,190 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:46:45,294 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:45,295 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,295 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:46:45,600 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:46:45,602 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:46:45,602 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,603 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:46:45,697 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:45,701 (Thread-1): 14:46:45 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.54s]
2019-10-01 14:46:45,702 (Thread-1): 14:46:45 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:46:45,704 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:45,704 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:46:45,705 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:46:45,713 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:46:45,727 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:46:45,732 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:45,732 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:46:45,865 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:45,866 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:45,866 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:46:46,196 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2019-10-01 14:46:46,198 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:46:46,198 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:46,199 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:46:46,294 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:46,297 (Thread-1): 14:46:46 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.59s]
2019-10-01 14:46:46,299 (Thread-1): 14:46:46 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:46:46,300 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:46:46,300 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:46:46,301 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:46:46,306 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:46:46,314 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:46:46,320 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:46:46,320 (Thread-1): On with_dates: BEGIN
2019-10-01 14:46:46,464 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:46,465 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:46:46,465 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:46:46,689 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:46:46,691 (Thread-1): On with_dates: COMMIT
2019-10-01 14:46:46,692 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:46:46,692 (Thread-1): On with_dates: COMMIT
2019-10-01 14:46:46,790 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:46,799 (Thread-1): 14:46:46 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.50s]
2019-10-01 14:46:46,800 (Thread-1): 14:46:46 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:46:46,801 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:46,802 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:46:46,802 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:46:46,811 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:46:46,826 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:46:46,835 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:46,835 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:46:46,973 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:46,974 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:46,974 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:46:47,212 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:47,215 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:46:47,215 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:47,215 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:46:47,316 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:47,324 (Thread-1): 14:46:47 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.52s]
2019-10-01 14:46:47,326 (Thread-1): 14:46:47 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:46:47,326 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,326 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:46:47,327 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:46:47,340 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:46:47,359 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:46:47,366 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,366 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:46:47,486 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:47,487 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,487 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:46:47,713 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:46:47,715 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:46:47,715 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,716 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:46:47,817 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:47,826 (Thread-1): 14:46:47 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.50s]
2019-10-01 14:46:47,827 (Thread-1): 14:46:47 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:46:47,830 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:46:47,830 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:46:47,831 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:46:47,839 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:46:47,855 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:46:47,861 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:46:47,861 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:46:47,976 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:47,977 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:46:47,977 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:46:48,216 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:48,218 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:46:48,218 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:46:48,218 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:46:48,313 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:48,317 (Thread-1): 14:46:48 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.49s]
2019-10-01 14:46:48,318 (Thread-1): 14:46:48 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:46:48,318 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,318 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:46:48,318 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:46:48,323 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:46:48,332 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:46:48,338 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,338 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:46:48,455 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:48,456 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,456 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:46:48,684 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:46:48,685 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:46:48,685 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,685 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:46:48,898 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:46:48,901 (Thread-1): 14:46:48 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.58s]
2019-10-01 14:46:48,902 (Thread-1): 14:46:48 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:46:48,905 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:46:48,905 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:46:48,906 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:46:48,913 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:46:48,926 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:46:48,930 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:46:48,930 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:46:49,062 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:49,063 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:46:49,063 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:46:49,303 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:49,304 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:46:49,304 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:46:49,304 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:46:49,447 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:49,455 (Thread-1): 14:46:49 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.55s]
2019-10-01 14:46:49,457 (Thread-1): 14:46:49 | 21 of 21 START table model DBT_TEST.v_booking_fact_uk................ [RUN]
2019-10-01 14:46:49,460 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:49,460 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:46:49,461 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:46:49,510 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:46:49,540 (Thread-1): Dropping relation "OPA_DEV"."DBT_TEST"."V_BOOKING_FACT_UK" because it is of type view
2019-10-01 14:46:49,549 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:49,550 (Thread-1): On v_booking_fact_uk: drop view if exists "OPA_DEV"."DBT_TEST"."V_BOOKING_FACT_UK" cascade
2019-10-01 14:46:49,753 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 14:46:49,783 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:46:49,951 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:49,952 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:46:50,084 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:50,085 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:50,085 (Thread-1): On v_booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.v_booking_fact_uk
      as (

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-01 14:48:02,740 (Thread-1): SQL status: SUCCESS 1 in 72.65 seconds
2019-10-01 14:48:02,742 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:48:02,742 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:48:02,743 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:48:02,842 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:48:02,853 (Thread-1): 14:48:02 | 21 of 21 OK created table model DBT_TEST.v_booking_fact_uk........... [SUCCESS 1 in 73.39s]
2019-10-01 14:51:53,354 (MainThread): Using snowflake connection "master".
2019-10-01 14:51:53,354 (MainThread): On master: BEGIN
2019-10-01 14:51:53,692 (MainThread): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:51:53,693 (MainThread): On master: COMMIT
2019-10-01 14:51:53,693 (MainThread): Using snowflake connection "master".
2019-10-01 14:51:53,694 (MainThread): On master: COMMIT
2019-10-01 14:51:53,846 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:51:53,847 (MainThread): 14:51:53 | 
2019-10-01 14:51:53,848 (MainThread): 14:51:53 | Finished running 20 view models, 1 table model in 318.43s.
2019-10-01 14:51:53,848 (MainThread): Connection 'master' was left open.
2019-10-01 14:51:53,849 (MainThread): On master: Close
2019-10-01 14:51:54,074 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:51:54,075 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:51:54,505 (MainThread): 
2019-10-01 14:51:54,506 (MainThread): Completed successfully
2019-10-01 14:51:54,507 (MainThread): 
Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
2019-10-01 14:51:54,507 (MainThread): Flushing usage events
2019-10-01 14:52:47,695 (MainThread): Tracking: tracking
2019-10-01 14:52:47,698 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93B08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93508>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8F6C8>]}
2019-10-01 14:52:47,972 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:52:47,973 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58279), raddr=('54.164.98.48', 443)>

2019-10-01 14:52:47,974 (MainThread): Error sending message, disabling tracking
2019-10-01 14:52:47,998 (MainThread): Parsing macros\core.sql
2019-10-01 14:52:48,007 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:52:48,045 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:52:48,055 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:52:48,057 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:52:48,060 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:52:48,064 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:52:48,067 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:52:48,070 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:52:48,078 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:52:48,086 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:52:48,096 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:52:48,113 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:52:48,134 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:52:48,137 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:52:48,151 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:52:48,157 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:52:48,164 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:52:48,172 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:52:48,175 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:52:48,177 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:52:48,180 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:52:48,185 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:52:48,204 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:52:48,208 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:52:48,217 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:52:48,220 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:52:48,224 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:52:48,269 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-01 14:52:48,271 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-01 14:52:48,271 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:52:48,272 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:52:48,612 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:52:48,642 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:52:49,669 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:52:49,670 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:52:49,670 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-01 14:52:49,674 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:52:49,675 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:52:49,676 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:52:49,680 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:52:49,681 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:52:49,681 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:52:49,686 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:52:49,687 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:52:49,687 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:52:49,693 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:52:49,694 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:52:49,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:52:49,699 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:52:49,700 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:49,700 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:52:49,705 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:52:49,706 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:52:49,706 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:52:49,711 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:52:49,712 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:52:49,712 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:52:49,718 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:52:49,719 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:52:49,720 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:52:49,724 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:52:49,725 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:49,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:52:49,730 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:52:49,731 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:49,731 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:52:49,737 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:52:49,739 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:49,739 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:52:49,744 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:52:49,745 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:52:49,745 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:52:49,751 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:52:49,752 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:52:49,752 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:52:49,758 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:52:49,759 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:52:49,759 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:52:49,764 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:52:49,765 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:52:49,765 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:52:49,769 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:52:49,770 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:52:49,770 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:52:49,775 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:52:49,776 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:52:49,776 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:52:49,781 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:52:49,784 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:52:49,784 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:52:49,793 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:52:49,794 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:52:49,794 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:52:49,858 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:52:49,863 (MainThread): 
2019-10-01 14:52:49,865 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:52:49,866 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:52:49,912 (MainThread): Parsing macros\core.sql
2019-10-01 14:52:49,923 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:52:50,009 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:52:50,029 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:52:50,032 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:52:50,041 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:52:50,047 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:52:50,052 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:52:50,056 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:52:50,071 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:52:50,080 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:52:50,088 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:52:50,123 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:52:50,150 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:52:50,155 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:52:50,183 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:52:50,192 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:52:50,208 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:52:50,224 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:52:50,230 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:52:50,235 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:52:50,240 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:52:50,246 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:52:50,270 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:52:50,276 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:52:50,290 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:52:50,295 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:52:50,303 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:52:50,552 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:50,552 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:52:51,080 (MainThread): SQL status: SUCCESS 29 in 0.53 seconds
2019-10-01 14:52:51,130 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:51,130 (MainThread): On master: BEGIN
2019-10-01 14:52:51,282 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:52:51,282 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:51,282 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:52:52,500 (MainThread): SQL status: SUCCESS 20 in 1.22 seconds
2019-10-01 14:52:52,522 (MainThread): On master: ROLLBACK
2019-10-01 14:52:52,680 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:52,680 (MainThread): On master: BEGIN
2019-10-01 14:52:52,789 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:52:52,789 (MainThread): On master: COMMIT
2019-10-01 14:52:52,789 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:52,789 (MainThread): On master: COMMIT
2019-10-01 14:52:52,956 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:52:52,957 (MainThread): 14:52:52 | Concurrency: 1 threads (target='dev')
2019-10-01 14:52:52,957 (MainThread): 14:52:52 | 
2019-10-01 14:52:52,963 (Thread-1): 14:52:52 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:52:52,964 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:52:52,964 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:52:53,467 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:52:53,477 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:52:53,533 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:52:53,538 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:52:53,538 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:52:53,657 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:53,658 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:52:53,658 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:52:53,946 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:52:53,948 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:52:53,948 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:52:53,948 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:52:54,047 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:54,056 (Thread-1): 14:52:54 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.09s]
2019-10-01 14:52:54,057 (Thread-1): 14:52:54 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:52:54,060 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:52:54,060 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:52:54,061 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:52:54,073 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:52:54,088 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:52:54,093 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:52:54,094 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:52:54,222 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:54,223 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:52:54,223 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:52:54,476 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:52:54,478 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:52:54,478 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:52:54,479 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:52:54,579 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:54,585 (Thread-1): 14:52:54 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.52s]
2019-10-01 14:52:54,586 (Thread-1): 14:52:54 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:52:54,588 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:52:54,588 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:52:54,589 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:52:54,599 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:52:54,612 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:52:54,618 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:52:54,618 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:52:54,738 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:54,739 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:52:54,739 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:52:54,991 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:52:54,993 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:52:54,994 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:52:54,994 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:52:55,090 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:55,103 (Thread-1): 14:52:55 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.51s]
2019-10-01 14:52:55,104 (Thread-1): 14:52:55 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:52:55,107 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:52:55,108 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:52:55,109 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:52:55,123 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:52:55,139 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:52:55,145 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:52:55,146 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:52:55,276 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:55,276 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:52:55,277 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:52:55,518 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:52:55,519 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:52:55,520 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:52:55,520 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:52:55,636 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:55,645 (Thread-1): 14:52:55 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.53s]
2019-10-01 14:52:55,646 (Thread-1): 14:52:55 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:52:55,649 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:55,650 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:52:55,651 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:52:55,662 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:52:55,682 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:52:55,693 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:55,693 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:52:55,829 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:52:55,830 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:55,830 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:52:56,056 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:52:56,058 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:52:56,059 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:56,059 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:52:56,216 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:52:56,224 (Thread-1): 14:52:56 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.57s]
2019-10-01 14:52:56,226 (Thread-1): 14:52:56 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:52:56,230 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,230 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:52:56,231 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:52:56,256 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:52:56,288 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:52:56,296 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,297 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:52:56,418 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:56,419 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,419 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:52:56,741 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:52:56,744 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:52:56,744 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,744 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:52:56,949 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 14:52:56,959 (Thread-1): 14:52:56 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.73s]
2019-10-01 14:52:56,961 (Thread-1): 14:52:56 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:52:56,964 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:52:56,964 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:52:56,965 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:52:56,977 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:52:56,994 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:52:56,999 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:52:56,999 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:52:57,120 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:57,121 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:52:57,122 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:52:57,344 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:52:57,346 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:52:57,347 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:52:57,347 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:52:57,441 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:52:57,450 (Thread-1): 14:52:57 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.48s]
2019-10-01 14:52:57,451 (Thread-1): 14:52:57 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:52:57,456 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,456 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:52:57,457 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:52:57,467 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:52:57,486 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:52:57,492 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,493 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:52:57,606 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:52:57,607 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,608 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:52:57,826 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:52:57,828 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:52:57,828 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,829 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:52:57,925 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:57,935 (Thread-1): 14:52:57 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.48s]
2019-10-01 14:52:57,936 (Thread-1): 14:52:57 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:52:57,942 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:57,942 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:52:57,945 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:52:57,957 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:52:57,980 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:52:57,987 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:57,988 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:52:58,115 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:58,116 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:58,116 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:52:58,361 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:52:58,363 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:52:58,363 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:58,364 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:52:58,497 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:58,503 (Thread-1): 14:52:58 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.56s]
2019-10-01 14:52:58,505 (Thread-1): 14:52:58 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:52:58,510 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,510 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:52:58,511 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:52:58,518 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:52:58,533 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:52:58,537 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,538 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:52:58,664 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:58,664 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,665 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:52:58,909 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:52:58,912 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:52:58,912 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,913 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:52:59,015 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:59,023 (Thread-1): 14:52:59 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.51s]
2019-10-01 14:52:59,024 (Thread-1): 14:52:59 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:52:59,027 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,028 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:52:59,028 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:52:59,040 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:52:59,057 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:52:59,064 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,065 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:52:59,227 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:52:59,228 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,228 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:52:59,451 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:52:59,453 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:52:59,453 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,454 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:52:59,579 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:59,588 (Thread-1): 14:52:59 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.56s]
2019-10-01 14:52:59,590 (Thread-1): 14:52:59 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:52:59,608 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:52:59,608 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:52:59,609 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:52:59,620 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:52:59,643 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:52:59,647 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:52:59,648 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:52:59,785 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:52:59,786 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:52:59,786 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:53:00,015 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:53:00,016 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:53:00,016 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:53:00,017 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:53:00,109 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:53:00,113 (Thread-1): 14:53:00 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.51s]
2019-10-01 14:53:00,114 (Thread-1): 14:53:00 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:53:00,115 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,116 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:53:00,116 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:53:00,121 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:53:00,131 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:53:00,135 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,135 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:53:00,309 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:53:00,310 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,310 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:53:00,541 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:53:00,542 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:53:00,542 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,542 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:53:00,709 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:53:00,716 (Thread-1): 14:53:00 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.60s]
2019-10-01 14:53:00,717 (Thread-1): 14:53:00 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:53:00,720 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:00,720 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:53:00,720 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:53:00,728 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:53:00,740 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:53:00,748 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:00,748 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:53:00,883 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:53:00,883 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:00,884 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:53:01,603 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2019-10-01 14:53:01,605 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:53:01,605 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:01,605 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:53:01,701 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:53:01,710 (Thread-1): 14:53:01 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.99s]
2019-10-01 14:53:01,711 (Thread-1): 14:53:01 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:53:01,714 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:53:01,714 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:53:01,715 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:53:01,720 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:53:01,732 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:53:01,736 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:53:01,737 (Thread-1): On with_dates: BEGIN
2019-10-01 14:53:01,863 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:53:01,864 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:53:01,864 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:53:02,096 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:53:02,098 (Thread-1): On with_dates: COMMIT
2019-10-01 14:53:02,099 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:53:02,099 (Thread-1): On with_dates: COMMIT
2019-10-01 14:53:02,205 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:53:02,215 (Thread-1): 14:53:02 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.50s]
2019-10-01 14:53:02,216 (Thread-1): 14:53:02 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:53:02,222 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,222 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:53:02,224 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:53:02,236 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:53:02,255 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:53:02,263 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,263 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:53:02,374 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:53:02,374 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,374 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:53:02,666 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:53:02,668 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:53:02,668 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,668 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:53:02,810 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:53:02,818 (Thread-1): 14:53:02 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.59s]
2019-10-01 14:53:02,820 (Thread-1): 14:53:02 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:53:02,826 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:02,827 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:53:02,828 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:53:02,839 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:53:02,872 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:53:02,889 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:02,889 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:53:03,029 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:53:03,030 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:03,030 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:53:03,268 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:53:03,270 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:53:03,270 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:03,271 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:53:03,368 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:53:03,376 (Thread-1): 14:53:03 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.55s]
2019-10-01 14:53:03,377 (Thread-1): 14:53:03 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:53:03,382 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,382 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:53:03,384 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:53:03,402 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:53:03,431 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:53:03,440 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,440 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:53:03,564 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:03,565 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,565 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:53:03,821 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:53:03,823 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:53:03,824 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,824 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:53:03,949 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:03,957 (Thread-1): 14:53:03 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.57s]
2019-10-01 14:53:03,958 (Thread-1): 14:53:03 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:53:03,968 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:03,969 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:53:03,971 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:53:04,006 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:53:04,040 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:53:04,050 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:04,054 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:53:04,182 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:04,185 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:04,186 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:53:04,507 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:53:04,511 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:53:04,512 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:04,513 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:53:04,654 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:53:04,667 (Thread-1): 14:53:04 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.69s]
2019-10-01 14:53:04,669 (Thread-1): 14:53:04 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:53:04,676 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:53:04,678 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:53:04,683 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:53:04,693 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:53:04,715 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:53:04,729 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:53:04,739 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:53:04,914 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:53:04,914 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:53:04,915 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:53:05,183 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:53:05,192 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:53:05,192 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:53:05,192 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:53:05,310 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:05,324 (Thread-1): 14:53:05 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.64s]
2019-10-01 14:53:05,327 (Thread-1): 14:53:05 | 21 of 21 START table model DBT_TEST.booking_fact_uk.................. [RUN]
2019-10-01 14:53:05,329 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-01 14:53:05,329 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:53:05,341 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-01 14:53:05,490 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-01 14:53:05,652 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-01 14:53:05,900 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-01 14:53:05,900 (Thread-1): On booking_fact_uk: BEGIN
2019-10-01 14:53:06,058 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:53:06,059 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-01 14:53:06,059 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-01 14:54:14,006 (Thread-1): SQL status: SUCCESS 1 in 67.95 seconds
2019-10-01 14:54:14,007 (Thread-1): On booking_fact_uk: COMMIT
2019-10-01 14:54:14,007 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-01 14:54:14,007 (Thread-1): On booking_fact_uk: COMMIT
2019-10-01 14:54:14,107 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:54:14,113 (Thread-1): 14:54:14 | 21 of 21 OK created table model DBT_TEST.booking_fact_uk............. [SUCCESS 1 in 68.78s]
2019-10-01 14:54:14,164 (MainThread): Using snowflake connection "master".
2019-10-01 14:54:14,164 (MainThread): On master: BEGIN
2019-10-01 14:54:14,277 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:54:14,277 (MainThread): On master: COMMIT
2019-10-01 14:54:14,277 (MainThread): Using snowflake connection "master".
2019-10-01 14:54:14,277 (MainThread): On master: COMMIT
2019-10-01 14:54:14,452 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:54:14,452 (MainThread): 14:54:14 | 
2019-10-01 14:54:14,453 (MainThread): 14:54:14 | Finished running 20 view models, 1 table model in 84.59s.
2019-10-01 14:54:14,453 (MainThread): Connection 'master' was left open.
2019-10-01 14:54:14,453 (MainThread): On master: Close
2019-10-01 14:54:14,628 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-01 14:54:14,629 (MainThread): On booking_fact_uk: Close
2019-10-01 14:54:14,893 (MainThread): 
2019-10-01 14:54:14,893 (MainThread): Completed successfully
2019-10-01 14:54:14,894 (MainThread): 
Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
2019-10-01 14:54:14,895 (MainThread): Flushing usage events
2019-10-02 10:02:04,320 (MainThread): Tracking: tracking
2019-10-02 10:02:04,324 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C95888>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92148>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C848>]}
2019-10-02 10:02:04,662 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 10:02:04,663 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60589), raddr=('54.174.31.151', 443)>

2019-10-02 10:02:04,664 (MainThread): Error sending message, disabling tracking
2019-10-02 10:02:04,710 (MainThread): Parsing macros\core.sql
2019-10-02 10:02:04,728 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 10:02:04,802 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 10:02:04,829 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 10:02:04,837 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 10:02:04,844 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 10:02:04,853 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 10:02:04,859 (MainThread): Parsing macros\etc\query.sql
2019-10-02 10:02:04,865 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 10:02:04,883 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 10:02:04,900 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 10:02:04,923 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 10:02:04,962 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 10:02:05,005 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 10:02:05,012 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 10:02:05,060 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 10:02:05,074 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 10:02:05,088 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 10:02:05,109 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 10:02:05,115 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 10:02:05,120 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 10:02:05,125 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 10:02:05,157 (MainThread): Parsing macros\adapters.sql
2019-10-02 10:02:05,185 (MainThread): Parsing macros\catalog.sql
2019-10-02 10:02:05,201 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 10:02:05,222 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 10:02:05,240 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 10:02:05,252 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 10:02:05,306 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 10:02:05,310 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:05,310 (MainThread): Opening a new connection, currently in state init
2019-10-02 10:02:05,316 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 10:02:05,763 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 10:02:05,793 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 10:02:06,509 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 10:02:06,511 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:06,512 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 10:02:06,522 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 10:02:06,524 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:06,524 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:06,535 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 10:02:06,537 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:06,537 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:06,547 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 10:02:06,549 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:06,549 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:06,561 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 10:02:06,563 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:06,563 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:06,573 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:06,575 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:06,576 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:06,585 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 10:02:06,588 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:06,588 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:06,598 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 10:02:06,601 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:06,601 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:06,613 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 10:02:06,615 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:06,615 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:06,625 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:06,628 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:06,628 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:06,638 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:06,640 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:06,641 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:06,650 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:06,653 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:06,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:06,664 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 10:02:06,666 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:06,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:06,676 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 10:02:06,678 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:06,678 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:06,688 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:06,690 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:06,690 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:06,702 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 10:02:06,704 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:06,705 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:06,714 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:06,717 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:06,717 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:06,729 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:06,731 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:06,731 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:06,742 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 10:02:06,744 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:06,745 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:06,757 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:06,759 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:06,759 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:06,943 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 10:02:06,948 (MainThread): 
2019-10-02 10:02:06,949 (MainThread): 10:02:06 | Concurrency: 1 threads (target='dev')
2019-10-02 10:02:06,950 (MainThread): 10:02:06 | 
2019-10-02 10:02:06,966 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:06,966 (Thread-1): Opening a new connection, currently in state init
2019-10-02 10:02:07,348 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 10:02:07,363 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 10:02:07,373 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:07,379 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:07,384 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 10:02:07,394 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 10:02:07,403 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:07,408 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:07,412 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 10:02:07,421 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 10:02:07,430 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:07,433 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:07,434 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 10:02:07,445 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 10:02:07,454 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:07,460 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:07,461 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:07,475 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 10:02:07,489 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:07,493 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:07,494 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 10:02:07,504 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 10:02:07,514 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:07,514 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:07,516 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 10:02:07,538 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 10:02:07,550 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:07,550 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:07,552 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 10:02:07,573 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 10:02:07,590 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:07,590 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:07,591 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:07,606 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 10:02:07,623 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:07,628 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:07,630 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:07,669 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 10:02:07,691 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:07,695 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:07,696 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:07,717 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 10:02:07,728 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:07,732 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:07,734 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 10:02:07,755 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 10:02:07,771 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:07,776 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:07,777 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 10:02:07,786 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 10:02:07,804 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:07,807 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:07,808 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:07,819 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 10:02:07,831 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:07,831 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:07,832 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 10:02:07,846 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 10:02:07,856 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:07,860 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:07,862 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:07,875 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 10:02:07,906 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:07,906 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:07,907 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:07,922 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 10:02:07,935 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:07,935 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:07,936 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 10:02:07,951 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 10:02:07,966 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:07,966 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:07,967 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:07,981 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 10:02:07,996 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:07,996 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 10:02:07,997 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 10:02:08,006 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 10:02:08,024 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:08,027 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:08,029 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 10:02:10,505 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 10:02:10,592 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 10:02:10,592 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 10:02:11,072 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 10:02:11,072 (MainThread): On booking_fact_uk: Close
2019-10-02 10:02:11,233 (MainThread): 10:02:11 | Done.
2019-10-02 10:02:11,234 (MainThread): Flushing usage events
2019-10-02 10:02:21,756 (MainThread): Tracking: tracking
2019-10-02 10:02:21,759 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004933D88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92DC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C148>]}
2019-10-02 10:02:22,034 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 10:02:22,035 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60594), raddr=('54.174.31.151', 443)>

2019-10-02 10:02:22,036 (MainThread): Error sending message, disabling tracking
2019-10-02 10:02:22,062 (MainThread): Parsing macros\core.sql
2019-10-02 10:02:22,071 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 10:02:22,119 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 10:02:22,135 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 10:02:22,138 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 10:02:22,143 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 10:02:22,148 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 10:02:22,152 (MainThread): Parsing macros\etc\query.sql
2019-10-02 10:02:22,156 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 10:02:22,169 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 10:02:22,180 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 10:02:22,188 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 10:02:22,205 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 10:02:22,227 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 10:02:22,230 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 10:02:22,243 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 10:02:22,249 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 10:02:22,258 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 10:02:22,269 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 10:02:22,272 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 10:02:22,276 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 10:02:22,279 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 10:02:22,282 (MainThread): Parsing macros\adapters.sql
2019-10-02 10:02:22,304 (MainThread): Parsing macros\catalog.sql
2019-10-02 10:02:22,313 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 10:02:22,326 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 10:02:22,330 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 10:02:22,336 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 10:02:22,379 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 10:02:22,382 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:22,383 (MainThread): Opening a new connection, currently in state init
2019-10-02 10:02:22,385 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 10:02:22,652 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 10:02:22,683 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 10:02:23,378 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 10:02:23,380 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:23,380 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 10:02:23,391 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 10:02:23,393 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:23,394 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:23,409 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 10:02:23,412 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:23,412 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:23,423 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 10:02:23,426 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:23,426 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:23,437 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 10:02:23,439 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:23,440 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:23,449 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:23,452 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:23,452 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:23,464 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 10:02:23,467 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:23,467 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:23,478 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 10:02:23,480 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:23,481 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:23,491 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 10:02:23,494 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:23,494 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:23,504 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:23,506 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:23,506 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:23,516 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:23,518 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:23,518 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:23,528 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:23,530 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:23,531 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:23,542 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 10:02:23,544 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:23,544 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:23,555 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 10:02:23,558 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:23,559 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:23,569 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:23,571 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:23,571 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:23,582 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 10:02:23,585 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:23,585 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:23,595 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:23,597 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:23,597 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:23,608 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:23,610 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:23,611 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:23,620 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 10:02:23,622 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:23,622 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:23,631 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:23,632 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:23,633 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:23,770 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 10:02:23,774 (MainThread): 
2019-10-02 10:02:23,774 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 10:02:23,774 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 10:02:23,836 (MainThread): Parsing macros\core.sql
2019-10-02 10:02:23,848 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 10:02:23,935 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 10:02:23,963 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 10:02:23,969 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 10:02:23,976 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 10:02:23,985 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 10:02:23,992 (MainThread): Parsing macros\etc\query.sql
2019-10-02 10:02:23,999 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 10:02:24,017 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 10:02:24,034 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 10:02:24,055 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 10:02:24,093 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 10:02:24,136 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 10:02:24,141 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 10:02:24,163 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 10:02:24,174 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 10:02:24,185 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 10:02:24,195 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 10:02:24,199 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 10:02:24,202 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 10:02:24,206 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 10:02:24,210 (MainThread): Parsing macros\adapters.sql
2019-10-02 10:02:24,237 (MainThread): Parsing macros\catalog.sql
2019-10-02 10:02:24,243 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 10:02:24,261 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 10:02:24,274 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 10:02:24,298 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 10:02:24,499 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:24,500 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 10:02:25,254 (MainThread): SQL status: SUCCESS 29 in 0.75 seconds
2019-10-02 10:02:25,344 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:25,344 (MainThread): On master: BEGIN
2019-10-02 10:02:25,461 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 10:02:25,462 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:25,462 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 10:02:27,122 (MainThread): SQL status: SUCCESS 0 in 1.66 seconds
2019-10-02 10:02:27,124 (MainThread): On master: ROLLBACK
2019-10-02 10:02:27,294 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:27,295 (MainThread): On master: BEGIN
2019-10-02 10:02:27,400 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 10:02:27,401 (MainThread): On master: COMMIT
2019-10-02 10:02:27,401 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:27,401 (MainThread): On master: COMMIT
2019-10-02 10:02:27,545 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 10:02:27,546 (MainThread): 10:02:27 | Concurrency: 1 threads (target='dev')
2019-10-02 10:02:27,547 (MainThread): 10:02:27 | 
2019-10-02 10:02:27,552 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:27,552 (Thread-1): Opening a new connection, currently in state init
2019-10-02 10:02:28,106 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 10:02:28,112 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 10:02:28,117 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:28,117 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:28,117 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 10:02:28,122 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 10:02:28,128 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:28,128 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:28,128 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 10:02:28,134 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 10:02:28,140 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:28,141 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:28,142 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 10:02:28,146 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 10:02:28,151 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:28,153 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:28,154 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:28,159 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 10:02:28,167 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:28,167 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:28,168 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 10:02:28,180 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 10:02:28,186 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:28,186 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:28,187 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 10:02:28,199 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 10:02:28,209 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:28,210 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:28,210 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 10:02:28,234 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 10:02:28,240 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:28,243 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:28,244 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:28,255 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 10:02:28,262 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:28,265 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:28,266 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:28,276 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 10:02:28,294 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:28,296 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:28,297 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:28,307 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 10:02:28,314 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:28,316 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:28,317 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 10:02:28,327 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 10:02:28,334 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:28,334 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:28,335 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 10:02:28,348 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 10:02:28,354 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:28,354 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:28,355 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:28,366 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 10:02:28,374 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:28,378 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:28,379 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 10:02:28,388 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 10:02:28,395 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:28,398 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:28,398 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:28,408 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 10:02:28,415 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:28,415 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:28,416 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:28,429 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 10:02:28,442 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:28,444 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:28,445 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 10:02:28,455 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 10:02:28,510 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:28,514 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:28,515 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:28,527 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 10:02:28,534 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:28,538 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 10:02:28,539 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 10:02:28,549 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 10:02:28,556 (Thread-1): 10:02:28 | 1 of 1 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 10:02:28,559 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:28,559 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:28,560 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 10:02:30,422 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 10:02:30,524 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 10:02:30,706 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 10:02:30,707 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 10:02:30,873 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 10:02:30,874 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 10:02:30,874 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_fl_acr_booking_service as (


SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
),  __dbt__CTE__with_fl_acr_service as (


SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
),  __dbt__CTE__with_fl_acr_service_element as (


SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
),  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_fl_acr_booking as (


SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM __dbt__CTE__with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN __dbt__CTE__with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN __dbt__CTE__with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM __dbt__CTE__with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 10:03:53,985 (Thread-1): SQL status: SUCCESS 1 in 83.11 seconds
2019-10-02 10:03:53,986 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 10:03:53,987 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 10:03:53,987 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 10:03:54,088 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 10:03:54,107 (Thread-1): 10:03:54 | 1 of 1 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 85.54s]
2019-10-02 10:03:54,197 (MainThread): Using snowflake connection "master".
2019-10-02 10:03:54,198 (MainThread): On master: BEGIN
2019-10-02 10:03:54,327 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 10:03:54,328 (MainThread): On master: COMMIT
2019-10-02 10:03:54,328 (MainThread): Using snowflake connection "master".
2019-10-02 10:03:54,328 (MainThread): On master: COMMIT
2019-10-02 10:03:54,489 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 10:03:54,489 (MainThread): 10:03:54 | 
2019-10-02 10:03:54,489 (MainThread): 10:03:54 | Finished running 1 table model in 90.72s.
2019-10-02 10:03:54,490 (MainThread): Connection 'master' was left open.
2019-10-02 10:03:54,490 (MainThread): On master: Close
2019-10-02 10:03:54,692 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 10:03:54,692 (MainThread): On booking_fact_uk: Close
2019-10-02 10:03:54,867 (MainThread): 
2019-10-02 10:03:54,867 (MainThread): Completed successfully
2019-10-02 10:03:54,868 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2019-10-02 10:03:54,868 (MainThread): Flushing usage events
2019-10-02 12:55:39,742 (MainThread): Tracking: tracking
2019-10-02 12:55:39,745 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004932F08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C808>]}
2019-10-02 12:55:40,043 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:55:40,044 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60637), raddr=('54.164.98.48', 443)>

2019-10-02 12:55:40,045 (MainThread): Error sending message, disabling tracking
2019-10-02 12:55:40,078 (MainThread): Parsing macros\core.sql
2019-10-02 12:55:40,091 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:55:40,161 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:55:40,174 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:55:40,177 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:55:40,181 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:55:40,189 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:55:40,195 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:55:40,199 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:55:40,215 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:55:40,229 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:55:40,244 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:55:40,263 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:55:40,294 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:55:40,300 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:55:40,318 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:55:40,326 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:55:40,333 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:55:40,344 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:55:40,348 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:55:40,351 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:55:40,354 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:55:40,359 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:55:40,376 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:55:40,383 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:55:40,395 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:55:40,399 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:55:40,405 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:55:40,449 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:55:40,451 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:55:40,451 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:55:40,455 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:55:40,937 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:55:40,963 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:55:41,680 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:55:41,681 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:55:41,681 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:55:41,686 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:55:41,687 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:55:41,687 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:55:41,692 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:55:41,693 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:55:41,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:55:41,699 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:55:41,700 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:55:41,700 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:55:41,709 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:55:41,710 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:55:41,710 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:55:41,719 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:55:41,722 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:55:41,722 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:55:41,730 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:55:41,732 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:55:41,732 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:55:41,741 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:55:41,743 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:55:41,743 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:55:41,750 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:55:41,751 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:55:41,751 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:55:41,757 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:55:41,758 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:55:41,758 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:55:41,766 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:55:41,767 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:55:41,767 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:55:41,774 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:55:41,776 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:55:41,776 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:55:41,781 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:55:41,783 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:55:41,783 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:55:41,790 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:55:41,791 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:55:41,791 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:55:41,796 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:55:41,798 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:55:41,798 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:55:41,805 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:55:41,806 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:55:41,806 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:55:41,811 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:55:41,813 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:55:41,813 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:55:41,832 (MainThread): Flushing usage events
2019-10-02 12:55:41,832 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:55:41,832 (MainThread): Encountered an error:
2019-10-02 12:55:41,833 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:55:41,833 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got 'unique_key'
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table
2019-10-02 12:55:42,003 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got 'unique_key'
  line 3
    unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got 'unique_key'
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

2019-10-02 12:56:29,386 (MainThread): Tracking: tracking
2019-10-02 12:56:29,388 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004935D08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBD288>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DA48>]}
2019-10-02 12:56:29,653 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:56:29,656 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60646), raddr=('54.164.98.48', 443)>

2019-10-02 12:56:29,661 (MainThread): Error sending message, disabling tracking
2019-10-02 12:56:29,724 (MainThread): Parsing macros\core.sql
2019-10-02 12:56:29,735 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:56:29,772 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:56:29,782 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:56:29,784 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:56:29,787 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:56:29,791 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:56:29,794 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:56:29,796 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:56:29,804 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:56:29,812 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:56:29,820 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:56:29,837 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:56:29,857 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:56:29,860 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:56:29,873 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:56:29,879 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:56:29,885 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:56:29,893 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:56:29,896 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:56:29,898 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:56:29,901 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:56:29,904 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:56:29,930 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:56:29,937 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:56:29,953 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:56:29,956 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:56:29,961 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:56:29,988 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:56:29,990 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:56:29,990 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:56:29,992 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:56:30,279 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:56:30,298 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:56:30,777 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:56:30,779 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:56:30,779 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:56:30,784 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:56:30,785 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:56:30,785 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:56:30,793 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:56:30,795 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:56:30,795 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:56:30,804 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:56:30,806 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:56:30,806 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:56:30,816 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:56:30,817 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:56:30,817 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:56:30,823 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:56:30,825 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:56:30,825 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:56:30,831 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:56:30,833 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:56:30,833 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:56:30,839 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:56:30,840 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:56:30,841 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:56:30,848 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:56:30,849 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:56:30,849 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:56:30,855 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:56:30,857 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:56:30,857 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:56:30,863 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:56:30,865 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:56:30,865 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:56:30,872 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:56:30,874 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:56:30,874 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:56:30,884 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:56:30,887 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:56:30,887 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:56:30,898 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:56:30,900 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:56:30,900 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:56:30,910 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:56:30,912 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:56:30,912 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:56:30,921 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:56:30,922 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:56:30,922 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:56:30,929 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:56:30,931 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:56:30,931 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:56:30,937 (MainThread): Flushing usage events
2019-10-02 12:56:30,937 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:56:30,937 (MainThread): Encountered an error:
2019-10-02 12:56:30,938 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:56:30,938 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table
2019-10-02 12:56:30,948 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

2019-10-02 12:57:48,308 (MainThread): Tracking: tracking
2019-10-02 12:57:48,310 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C959C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92808>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6B488>]}
2019-10-02 12:57:48,633 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:57:48,634 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60667), raddr=('54.174.31.151', 443)>

2019-10-02 12:57:48,637 (MainThread): Error sending message, disabling tracking
2019-10-02 12:57:48,677 (MainThread): Parsing macros\core.sql
2019-10-02 12:57:48,686 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:57:48,726 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:57:48,736 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:57:48,738 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:57:48,741 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:57:48,745 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:57:48,747 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:57:48,756 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:57:48,764 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:57:48,776 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:57:48,793 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:57:48,818 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:57:48,845 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:57:48,849 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:57:48,867 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:57:48,876 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:57:48,887 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:57:48,897 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:57:48,900 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:57:48,903 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:57:48,906 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:57:48,910 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:57:48,925 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:57:48,929 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:57:48,939 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:57:48,941 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:57:48,946 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:57:48,973 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:57:48,975 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:57:48,975 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:57:48,977 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:57:49,202 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:57:49,219 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:57:49,760 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:57:49,761 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:57:49,761 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:57:49,765 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:57:49,766 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:57:49,766 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:57:49,771 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:57:49,772 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:57:49,772 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:57:49,777 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:57:49,778 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:57:49,778 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:57:49,782 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:57:49,783 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:57:49,784 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:57:49,789 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:57:49,790 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:57:49,790 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:57:49,795 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:57:49,796 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:57:49,796 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:57:49,801 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:57:49,802 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:57:49,802 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:57:49,808 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:57:49,809 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:57:49,809 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:57:49,813 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:57:49,814 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:57:49,814 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:57:49,819 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:57:49,820 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:57:49,821 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:57:49,825 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:57:49,826 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:57:49,826 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:57:49,830 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:57:49,831 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:57:49,832 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:57:49,837 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:57:49,838 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:57:49,838 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:57:49,842 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:57:49,843 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:57:49,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:57:49,848 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:57:49,849 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:57:49,849 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:57:49,854 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:57:49,855 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:57:49,856 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:57:49,861 (MainThread): Flushing usage events
2019-10-02 12:57:49,861 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:57:49,861 (MainThread): Encountered an error:
2019-10-02 12:57:49,862 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:57:49,862 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, |, booking_version) -- bk in the target table
2019-10-02 12:57:49,874 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=concat(sk_booking_id, |, booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, |, booking_version) -- bk in the target table

2019-10-02 12:58:49,021 (MainThread): Tracking: tracking
2019-10-02 12:58:49,023 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004937308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E8C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B648>]}
2019-10-02 12:58:49,347 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:58:49,349 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60682), raddr=('54.164.98.48', 443)>

2019-10-02 12:58:49,354 (MainThread): Error sending message, disabling tracking
2019-10-02 12:58:49,410 (MainThread): Parsing macros\core.sql
2019-10-02 12:58:49,422 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:58:49,473 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:58:49,483 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:58:49,486 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:58:49,489 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:58:49,492 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:58:49,495 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:58:49,498 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:58:49,506 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:58:49,514 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:58:49,523 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:58:49,543 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:58:49,588 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:58:49,591 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:58:49,603 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:58:49,610 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:58:49,616 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:58:49,623 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:58:49,625 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:58:49,627 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:58:49,630 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:58:49,633 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:58:49,652 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:58:49,655 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:58:49,663 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:58:49,666 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:58:49,670 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:58:49,697 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:58:49,699 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:58:49,699 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:58:49,701 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:58:49,966 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:58:49,983 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:58:50,550 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:58:50,551 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:58:50,551 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:58:50,555 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:58:50,556 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:58:50,556 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:58:50,561 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:58:50,562 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:58:50,562 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:58:50,566 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:58:50,567 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:58:50,567 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:58:50,572 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:58:50,574 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:58:50,574 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:58:50,579 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:58:50,580 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:58:50,580 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:58:50,585 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:58:50,586 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:58:50,586 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:58:50,592 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:58:50,593 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:58:50,593 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:58:50,598 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:58:50,599 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:58:50,599 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:58:50,604 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:58:50,605 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:58:50,605 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:58:50,610 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:58:50,611 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:58:50,611 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:58:50,615 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:58:50,616 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:58:50,616 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:58:50,621 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:58:50,622 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:58:50,622 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:58:50,627 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:58:50,628 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:58:50,628 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:58:50,633 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:58:50,634 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:58:50,634 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:58:50,639 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:58:50,641 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:58:50,641 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:58:50,646 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:58:50,647 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:58:50,647 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:58:50,652 (MainThread): Flushing usage events
2019-10-02 12:58:50,652 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:58:50,652 (MainThread): Encountered an error:
2019-10-02 12:58:50,653 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:58:50,653 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table
2019-10-02 12:58:50,665 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

2019-10-02 12:59:06,375 (MainThread): Tracking: tracking
2019-10-02 12:59:06,377 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92708>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92AC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C088>]}
2019-10-02 12:59:06,662 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:59:06,665 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60686), raddr=('54.164.98.48', 443)>

2019-10-02 12:59:06,670 (MainThread): Error sending message, disabling tracking
2019-10-02 12:59:06,717 (MainThread): Parsing macros\core.sql
2019-10-02 12:59:06,727 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:59:06,779 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:59:06,788 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:59:06,790 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:59:06,794 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:59:06,798 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:59:06,800 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:59:06,803 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:59:06,812 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:59:06,819 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:59:06,831 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:59:06,865 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:59:06,915 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:59:06,923 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:59:06,956 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:59:06,972 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:59:06,982 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:59:06,989 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:59:06,993 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:59:06,995 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:59:06,998 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:59:07,002 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:59:07,015 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:59:07,020 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:59:07,028 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:59:07,031 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:59:07,036 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:59:07,069 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:59:07,072 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:59:07,073 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:59:07,076 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:59:07,313 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:59:07,329 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:59:07,945 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:59:07,946 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:59:07,946 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:59:07,950 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:59:07,951 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:59:07,951 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:59:07,955 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:59:07,956 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:59:07,956 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:59:07,961 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:59:07,962 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:59:07,962 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:59:07,967 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:59:07,968 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:59:07,968 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:59:07,972 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:59:07,973 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:59:07,973 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:59:07,978 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:59:07,978 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:59:07,979 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:59:07,983 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:59:07,984 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:59:07,984 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:59:07,989 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:59:07,990 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:59:07,990 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:59:07,995 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:59:07,996 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:59:07,996 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:59:08,001 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:59:08,002 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:59:08,002 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:59:08,006 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:59:08,008 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:59:08,008 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:59:08,013 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:59:08,014 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:59:08,014 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:59:08,018 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:59:08,019 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:59:08,019 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:59:08,023 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:59:08,024 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:59:08,025 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:59:08,029 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:59:08,030 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:59:08,030 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:59:08,035 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:59:08,036 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:59:08,036 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:59:08,041 (MainThread): Flushing usage events
2019-10-02 12:59:08,041 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:59:08,041 (MainThread): Encountered an error:
2019-10-02 12:59:08,042 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:59:08,042 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=sk_booking_id -- bk in the target table
2019-10-02 12:59:08,056 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=sk_booking_id -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=sk_booking_id -- bk in the target table

2019-10-02 13:01:29,206 (MainThread): Tracking: tracking
2019-10-02 13:01:29,208 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C926C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92988>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6BC48>]}
2019-10-02 13:01:29,500 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:01:29,500 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60709), raddr=('54.174.31.151', 443)>

2019-10-02 13:01:29,502 (MainThread): Error sending message, disabling tracking
2019-10-02 13:01:29,527 (MainThread): Parsing macros\core.sql
2019-10-02 13:01:29,537 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:01:29,576 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:01:29,592 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:01:29,596 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:01:29,601 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:01:29,607 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:01:29,611 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:01:29,615 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:01:29,626 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:01:29,638 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:01:29,651 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:01:29,675 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:01:29,714 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:01:29,718 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:01:29,736 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:01:29,744 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:01:29,751 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:01:29,758 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:01:29,761 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:01:29,763 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:01:29,765 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:01:29,768 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:01:29,787 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:01:29,791 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:01:29,800 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:01:29,804 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:01:29,810 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:01:29,843 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:01:29,845 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:01:29,845 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:01:29,847 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:01:30,075 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:01:30,094 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:01:30,666 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:01:30,667 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:01:30,667 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:01:30,672 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:01:30,673 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:01:30,673 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:01:30,681 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:01:30,683 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:01:30,683 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:01:30,692 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:01:30,694 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:01:30,695 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:01:30,700 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:01:30,701 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:01:30,701 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:01:30,707 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:01:30,709 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:01:30,709 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:01:30,717 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:01:30,718 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:01:30,718 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:01:30,724 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:01:30,725 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:01:30,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:01:30,731 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:01:30,732 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:01:30,733 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:01:30,741 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:01:30,743 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:01:30,743 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:01:30,751 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:01:30,753 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:01:30,753 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:01:30,758 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:01:30,759 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:01:30,759 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:01:30,763 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:01:30,764 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:01:30,764 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:01:30,774 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:01:30,775 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:01:30,775 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:01:30,786 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:01:30,791 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:01:30,791 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:01:30,801 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:01:30,803 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:01:30,804 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:01:30,815 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:01:30,817 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:01:30,818 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:01:30,830 (MainThread): Flushing usage events
2019-10-02 13:01:30,830 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:01:30,831 (MainThread): Encountered an error:
2019-10-02 13:01:30,832 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:01:30,832 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table
2019-10-02 13:01:30,851 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

2019-10-02 13:02:15,763 (MainThread): Tracking: tracking
2019-10-02 13:02:15,765 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000497E8C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC4C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005737B08>]}
2019-10-02 13:02:16,051 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:16,053 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60726), raddr=('54.174.31.151', 443)>

2019-10-02 13:02:16,058 (MainThread): Error sending message, disabling tracking
2019-10-02 13:02:16,110 (MainThread): Parsing macros\core.sql
2019-10-02 13:02:16,118 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:02:16,152 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:02:16,162 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:02:16,165 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:02:16,168 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:02:16,172 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:02:16,175 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:02:16,177 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:02:16,186 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:02:16,194 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:02:16,202 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:02:16,219 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:02:16,239 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:02:16,242 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:02:16,255 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:02:16,262 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:02:16,268 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:02:16,275 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:02:16,278 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:02:16,280 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:02:16,282 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:02:16,285 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:02:16,298 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:02:16,301 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:02:16,310 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:02:16,313 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:02:16,317 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:02:16,347 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:02:16,349 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:02:16,349 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:02:16,351 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:02:16,589 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:02:16,607 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:02:17,755 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:02:17,756 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:02:17,756 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:02:17,761 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:02:17,762 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:02:17,762 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:02:17,766 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:02:17,767 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:02:17,767 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:02:17,773 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:02:17,774 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:02:17,774 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:02:17,778 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:02:17,779 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:02:17,780 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:02:17,784 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:02:17,785 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:02:17,786 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:02:17,790 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:02:17,791 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:02:17,791 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:02:17,796 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:02:17,797 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:02:17,797 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:02:17,803 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:02:17,804 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:02:17,804 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:02:17,809 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:02:17,810 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:02:17,810 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:02:17,814 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:02:17,815 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:02:17,816 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:02:17,821 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:02:17,822 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:02:17,822 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:02:17,826 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:02:17,827 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:02:17,827 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:02:17,832 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:02:17,833 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:02:17,833 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:02:17,838 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:02:17,839 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:02:17,839 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:02:17,843 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:02:17,844 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:02:17,844 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:02:17,849 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:02:17,850 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:02:17,850 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:02:17,856 (MainThread): Flushing usage events
2019-10-02 13:02:17,856 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:17,856 (MainThread): Encountered an error:
2019-10-02 13:02:17,856 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:17,857 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, '|', booking_version) -- bk in the target table
2019-10-02 13:02:17,869 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat(sk_booking_id, '|', booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, '|', booking_version) -- bk in the target table

2019-10-02 13:02:49,503 (MainThread): Tracking: tracking
2019-10-02 13:02:49,505 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C910C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6BE08>]}
2019-10-02 13:02:49,855 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:49,856 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60737), raddr=('54.164.98.48', 443)>

2019-10-02 13:02:49,857 (MainThread): Error sending message, disabling tracking
2019-10-02 13:02:49,891 (MainThread): Parsing macros\core.sql
2019-10-02 13:02:49,903 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:02:49,945 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:02:49,955 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:02:49,957 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:02:49,960 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:02:49,964 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:02:49,967 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:02:49,970 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:02:49,979 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:02:49,987 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:02:49,996 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:02:50,013 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:02:50,034 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:02:50,037 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:02:50,050 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:02:50,056 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:02:50,062 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:02:50,069 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:02:50,071 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:02:50,073 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:02:50,075 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:02:50,078 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:02:50,093 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:02:50,098 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:02:50,106 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:02:50,109 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:02:50,113 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:02:50,140 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:02:50,142 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:02:50,142 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:02:50,145 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:02:50,417 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:02:50,434 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:02:51,321 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:02:51,322 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:02:51,322 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:02:51,326 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:02:51,327 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:02:51,327 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:02:51,331 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:02:51,332 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:02:51,332 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:02:51,338 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:02:51,339 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:02:51,339 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:02:51,343 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:02:51,344 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:02:51,344 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:02:51,349 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:02:51,350 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:02:51,350 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:02:51,355 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:02:51,356 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:02:51,356 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:02:51,360 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:02:51,361 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:02:51,361 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:02:51,366 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:02:51,367 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:02:51,368 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:02:51,373 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:02:51,374 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:02:51,374 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:02:51,378 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:02:51,379 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:02:51,379 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:02:51,383 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:02:51,384 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:02:51,385 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:02:51,390 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:02:51,391 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:02:51,391 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:02:51,395 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:02:51,396 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:02:51,396 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:02:51,401 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:02:51,402 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:02:51,402 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:02:51,408 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:02:51,409 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:02:51,409 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:02:51,414 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:02:51,415 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:02:51,415 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:02:51,420 (MainThread): Flushing usage events
2019-10-02 13:02:51,421 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:51,421 (MainThread): Encountered an error:
2019-10-02 13:02:51,421 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:51,421 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table
2019-10-02 13:02:51,432 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

2019-10-02 13:04:04,077 (MainThread): Tracking: tracking
2019-10-02 13:04:04,083 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC648>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B908>]}
2019-10-02 13:04:04,408 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:04,409 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60804), raddr=('54.164.98.48', 443)>

2019-10-02 13:04:04,412 (MainThread): Error sending message, disabling tracking
2019-10-02 13:04:04,449 (MainThread): Parsing macros\core.sql
2019-10-02 13:04:04,458 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:04:04,494 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:04:04,504 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:04:04,506 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:04:04,509 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:04:04,512 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:04:04,515 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:04:04,518 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:04:04,526 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:04:04,535 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:04:04,544 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:04:04,560 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:04:04,581 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:04:04,584 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:04:04,598 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:04:04,606 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:04:04,612 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:04:04,619 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:04:04,622 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:04:04,624 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:04:04,626 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:04:04,629 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:04:04,642 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:04:04,645 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:04:04,654 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:04:04,657 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:04:04,662 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:04:04,690 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:04:04,692 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:04:04,692 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:04:04,694 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:04:04,948 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:04:04,963 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:04:05,636 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:04:05,637 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:04:05,637 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:04:05,641 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:04:05,642 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:04:05,642 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:04:05,647 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:04:05,648 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:04:05,648 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:04:05,652 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:04:05,653 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:04:05,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:04:05,658 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:04:05,660 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:04:05,660 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:04:05,666 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:04:05,667 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:04:05,667 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:04:05,671 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:04:05,672 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:04:05,672 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:04:05,677 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:04:05,678 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:04:05,678 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:04:05,683 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:04:05,684 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:04:05,684 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:04:05,689 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:04:05,690 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:04:05,690 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:04:05,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:04:05,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:04:05,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:04:05,701 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:04:05,702 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:04:05,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:04:05,707 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:04:05,708 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:04:05,708 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:04:05,713 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:04:05,714 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:04:05,714 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:04:05,718 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:04:05,720 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:04:05,720 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:04:05,724 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:04:05,725 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:04:05,726 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:04:05,730 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:04:05,731 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:04:05,731 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:04:05,737 (MainThread): Flushing usage events
2019-10-02 13:04:05,737 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:05,737 (MainThread): Encountered an error:
2019-10-02 13:04:05,738 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:05,738 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', 'booking_version') -- bk in the target table
2019-10-02 13:04:05,751 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat('sk_booking_id', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', 'booking_version') -- bk in the target table

2019-10-02 13:04:31,188 (MainThread): Tracking: tracking
2019-10-02 13:04:31,190 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92988>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B688>]}
2019-10-02 13:04:31,479 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:31,481 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60812), raddr=('54.164.98.48', 443)>

2019-10-02 13:04:31,487 (MainThread): Error sending message, disabling tracking
2019-10-02 13:04:31,534 (MainThread): Parsing macros\core.sql
2019-10-02 13:04:31,543 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:04:31,582 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:04:31,593 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:04:31,595 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:04:31,598 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:04:31,602 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:04:31,605 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:04:31,607 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:04:31,616 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:04:31,624 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:04:31,632 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:04:31,649 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:04:31,671 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:04:31,674 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:04:31,688 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:04:31,694 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:04:31,700 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:04:31,707 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:04:31,710 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:04:31,712 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:04:31,714 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:04:31,717 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:04:31,730 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:04:31,734 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:04:31,742 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:04:31,745 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:04:31,749 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:04:31,778 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:04:31,779 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:04:31,779 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:04:31,781 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:04:32,069 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:04:32,093 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:04:32,618 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:04:32,619 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:04:32,619 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:04:32,624 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:04:32,625 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:04:32,625 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:04:32,629 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:04:32,630 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:04:32,630 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:04:32,634 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:04:32,636 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:04:32,636 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:04:32,641 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:04:32,642 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:04:32,642 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:04:32,647 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:04:32,648 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:04:32,648 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:04:32,653 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:04:32,654 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:04:32,654 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:04:32,659 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:04:32,660 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:04:32,660 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:04:32,666 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:04:32,667 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:04:32,667 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:04:32,672 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:04:32,673 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:04:32,673 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:04:32,678 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:04:32,679 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:04:32,679 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:04:32,683 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:04:32,684 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:04:32,684 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:04:32,689 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:04:32,690 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:04:32,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:04:32,695 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:04:32,696 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:04:32,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:04:32,701 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:04:32,702 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:04:32,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:04:32,707 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:04:32,708 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:04:32,708 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:04:32,713 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:04:32,714 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:04:32,714 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:04:32,719 (MainThread): Flushing usage events
2019-10-02 13:04:32,719 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:32,719 (MainThread): Encountered an error:
2019-10-02 13:04:32,720 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:32,720 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_id' -- bk in the target table
2019-10-02 13:04:32,731 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_id' -- bk in the target table

2019-10-02 13:05:05,095 (MainThread): Tracking: tracking
2019-10-02 13:05:05,097 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004938248>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E248>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B6C8>]}
2019-10-02 13:05:05,384 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:05,386 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60820), raddr=('54.164.98.48', 443)>

2019-10-02 13:05:05,392 (MainThread): Error sending message, disabling tracking
2019-10-02 13:05:05,451 (MainThread): Parsing macros\core.sql
2019-10-02 13:05:05,462 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:05:05,503 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:05:05,513 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:05:05,515 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:05:05,519 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:05:05,523 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:05:05,525 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:05:05,528 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:05:05,537 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:05:05,545 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:05:05,554 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:05:05,572 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:05:05,593 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:05:05,596 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:05:05,609 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:05:05,616 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:05:05,623 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:05:05,629 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:05:05,632 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:05:05,634 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:05:05,637 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:05:05,640 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:05:05,654 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:05:05,657 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:05:05,666 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:05:05,669 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:05:05,674 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:05:05,701 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:05:05,703 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:05:05,703 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:05:05,705 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:05:05,946 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:05:05,962 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:05:06,640 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:05:06,641 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:05:06,641 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:05:06,646 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:05:06,647 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:05:06,647 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:05:06,652 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:05:06,653 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:05:06,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:05:06,658 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:05:06,659 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:05:06,659 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:05:06,664 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:05:06,665 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:05:06,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:05:06,670 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:05:06,671 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:05:06,671 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:05:06,676 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:05:06,677 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:05:06,677 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:05:06,681 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:05:06,682 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:05:06,682 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:05:06,687 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:05:06,688 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:05:06,688 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:05:06,693 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:05:06,694 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:05:06,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:05:06,698 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:05:06,699 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:05:06,699 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:05:06,705 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:05:06,706 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:05:06,706 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:05:06,711 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:05:06,712 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:05:06,712 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:05:06,717 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:05:06,718 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:05:06,718 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:05:06,723 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:05:06,723 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:05:06,724 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:05:06,728 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:05:06,729 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:05:06,729 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:05:06,734 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:05:06,735 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:05:06,735 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:05:06,745 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:05:06,746 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:05:06,746 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:05:06,751 (MainThread): Flushing usage events
2019-10-02 13:05:06,751 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:06,751 (MainThread): Encountered an error:
2019-10-02 13:05:06,752 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:06,752 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:05:06,764 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:05:32,509 (MainThread): Tracking: tracking
2019-10-02 13:05:32,511 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004933D88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92808>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C848>]}
2019-10-02 13:05:32,797 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:32,799 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60829), raddr=('54.164.98.48', 443)>

2019-10-02 13:05:32,803 (MainThread): Error sending message, disabling tracking
2019-10-02 13:05:32,852 (MainThread): Parsing macros\core.sql
2019-10-02 13:05:32,862 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:05:32,908 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:05:32,931 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:05:32,935 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:05:32,941 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:05:32,947 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:05:32,952 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:05:32,955 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:05:32,966 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:05:32,976 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:05:32,988 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:05:33,008 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:05:33,034 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:05:33,040 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:05:33,054 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:05:33,061 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:05:33,067 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:05:33,074 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:05:33,077 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:05:33,080 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:05:33,082 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:05:33,087 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:05:33,118 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:05:33,124 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:05:33,138 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:05:33,142 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:05:33,150 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:05:33,197 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:05:33,200 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:05:33,200 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:05:33,204 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:05:33,453 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:05:33,472 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:05:33,949 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:05:33,950 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:05:33,950 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:05:33,954 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:05:33,955 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:05:33,955 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:05:33,960 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:05:33,961 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:05:33,961 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:05:33,966 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:05:33,967 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:05:33,967 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:05:33,972 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:05:33,972 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:05:33,973 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:05:33,978 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:05:33,979 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:05:33,979 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:05:33,984 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:05:33,985 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:05:33,985 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:05:33,990 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:05:33,991 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:05:33,991 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:05:33,996 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:05:33,997 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:05:33,997 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:05:34,002 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:05:34,003 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:05:34,003 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:05:34,007 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:05:34,008 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:05:34,009 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:05:34,013 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:05:34,014 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:05:34,014 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:05:34,019 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:05:34,019 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:05:34,020 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:05:34,024 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:05:34,025 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:05:34,025 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:05:34,030 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:05:34,031 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:05:34,031 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:05:34,036 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:05:34,037 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:05:34,037 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:05:34,043 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:05:34,044 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:05:34,044 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:05:34,053 (MainThread): dbt encountered an undefined variable, "sk_booking_id" in node dbt_test.with_fl_acr_booking (source path: C:\Users\EXTMB2\github\dbt_test\models\with_fl_acr_booking.sql)
2019-10-02 13:05:34,053 (MainThread): Flushing usage events
2019-10-02 13:05:34,054 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:34,054 (MainThread): Encountered an error:
2019-10-02 13:05:34,055 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:34,055 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined
2019-10-02 13:05:34,103 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 278, in parse_node
    self._update_parsed_node_info(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 210, in _update_parsed_node_info
    model_tags = config.config.get('tags', [])
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 81, in config
    self.in_model_config)
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 44, in _merge
    merged_config.copy(), config.copy()
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 193, in deep_merge
    last = copy.deepcopy(lst.pop(len(lst) - 1))
  File "c:\python\python37\lib\copy.py", line 150, in deepcopy
    y = copier(x, memo)
  File "c:\python\python37\lib\copy.py", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "c:\python\python37\lib\copy.py", line 161, in deepcopy
    y = copier(memo)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 224, in __deepcopy__
    node=self.node
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined

2019-10-02 13:05:59,013 (MainThread): Tracking: tracking
2019-10-02 13:05:59,014 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C942C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91AC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DB88>]}
2019-10-02 13:05:59,279 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:59,280 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60835), raddr=('54.164.98.48', 443)>

2019-10-02 13:05:59,284 (MainThread): Error sending message, disabling tracking
2019-10-02 13:05:59,332 (MainThread): Parsing macros\core.sql
2019-10-02 13:05:59,341 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:05:59,378 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:05:59,389 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:05:59,391 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:05:59,394 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:05:59,398 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:05:59,400 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:05:59,404 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:05:59,412 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:05:59,421 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:05:59,429 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:05:59,446 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:05:59,468 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:05:59,472 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:05:59,487 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:05:59,496 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:05:59,503 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:05:59,512 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:05:59,514 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:05:59,516 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:05:59,519 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:05:59,522 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:05:59,539 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:05:59,543 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:05:59,552 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:05:59,557 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:05:59,561 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:05:59,598 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:05:59,601 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:05:59,602 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:05:59,606 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:05:59,855 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:05:59,877 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:00,384 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:00,385 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:00,385 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:00,390 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:00,391 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:00,391 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:00,395 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:00,396 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:00,397 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:00,402 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:00,404 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:00,404 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:00,414 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:00,415 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:00,415 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:00,421 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:00,422 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:00,422 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:00,427 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:00,428 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:00,428 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:00,433 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:00,434 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:00,434 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:00,440 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:00,441 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:00,441 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:00,446 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:00,447 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:00,447 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:00,452 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:00,453 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:00,453 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:00,461 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:00,463 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:00,463 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:00,470 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:00,471 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:00,471 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:00,476 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:00,477 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:00,477 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:00,482 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:00,483 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:00,483 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:00,488 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:00,489 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:00,489 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:00,494 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:00,495 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:00,496 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:00,505 (MainThread): dbt encountered an undefined variable, "sk_booking_id" in node dbt_test.with_fl_acr_booking (source path: C:\Users\EXTMB2\github\dbt_test\models\with_fl_acr_booking.sql)
2019-10-02 13:06:00,506 (MainThread): Flushing usage events
2019-10-02 13:06:00,506 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:00,506 (MainThread): Encountered an error:
2019-10-02 13:06:00,506 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:00,507 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined
2019-10-02 13:06:00,517 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 278, in parse_node
    self._update_parsed_node_info(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 210, in _update_parsed_node_info
    model_tags = config.config.get('tags', [])
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 81, in config
    self.in_model_config)
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 44, in _merge
    merged_config.copy(), config.copy()
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 193, in deep_merge
    last = copy.deepcopy(lst.pop(len(lst) - 1))
  File "c:\python\python37\lib\copy.py", line 150, in deepcopy
    y = copier(x, memo)
  File "c:\python\python37\lib\copy.py", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "c:\python\python37\lib\copy.py", line 161, in deepcopy
    y = copier(memo)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 224, in __deepcopy__
    node=self.node
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined

2019-10-02 13:06:23,364 (MainThread): Tracking: tracking
2019-10-02 13:06:23,366 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC148>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91408>]}
2019-10-02 13:06:23,665 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:23,666 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60840), raddr=('54.174.31.151', 443)>

2019-10-02 13:06:23,669 (MainThread): Error sending message, disabling tracking
2019-10-02 13:06:23,708 (MainThread): Parsing macros\core.sql
2019-10-02 13:06:23,720 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:06:23,759 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:06:23,769 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:06:23,771 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:06:23,775 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:06:23,778 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:06:23,781 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:06:23,783 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:06:23,792 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:06:23,800 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:06:23,810 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:06:23,827 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:06:23,850 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:06:23,854 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:06:23,867 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:06:23,874 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:06:23,880 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:06:23,887 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:06:23,890 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:06:23,892 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:06:23,895 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:06:23,898 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:06:23,911 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:06:23,914 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:06:23,923 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:06:23,926 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:06:23,930 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:06:23,961 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:06:23,962 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:06:23,962 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:06:23,964 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:06:24,247 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:06:24,263 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:24,824 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:24,825 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:24,825 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:24,831 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:24,832 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:24,832 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:24,844 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:24,847 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:24,847 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:24,862 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:24,864 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:24,865 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:24,875 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:24,877 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:24,877 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:24,889 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:24,892 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:24,892 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:24,903 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:24,905 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:24,905 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:24,914 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:24,916 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:24,916 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:24,924 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:24,926 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:24,926 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:24,930 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:24,931 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:24,932 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:24,938 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:24,939 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:24,939 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:24,944 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:24,945 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:24,945 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:24,950 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:24,951 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:24,951 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:24,959 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:24,960 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:24,960 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:24,964 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:24,966 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:24,966 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:24,972 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:24,974 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:24,974 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:24,979 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:24,980 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:24,980 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:24,992 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:06:24,993 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:06:24,993 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:06:24,998 (MainThread): Flushing usage events
2019-10-02 13:06:24,998 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:24,998 (MainThread): Encountered an error:
2019-10-02 13:06:24,999 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:24,999 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:06:25,010 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:06:47,165 (MainThread): Tracking: tracking
2019-10-02 13:06:47,169 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E508>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B348>]}
2019-10-02 13:06:47,435 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:47,436 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60846), raddr=('54.174.31.151', 443)>

2019-10-02 13:06:47,437 (MainThread): Error sending message, disabling tracking
2019-10-02 13:06:47,460 (MainThread): Parsing macros\core.sql
2019-10-02 13:06:47,468 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:06:47,517 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:06:47,537 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:06:47,541 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:06:47,553 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:06:47,560 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:06:47,563 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:06:47,566 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:06:47,583 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:06:47,592 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:06:47,601 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:06:47,618 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:06:47,639 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:06:47,642 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:06:47,657 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:06:47,665 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:06:47,674 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:06:47,680 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:06:47,683 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:06:47,685 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:06:47,689 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:06:47,693 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:06:47,713 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:06:47,717 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:06:47,728 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:06:47,731 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:06:47,736 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:06:47,781 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:06:47,782 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:06:47,782 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:06:47,785 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:06:48,024 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:06:48,044 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:48,634 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:48,636 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:48,637 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:48,641 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:48,642 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:48,642 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:48,647 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:48,648 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:48,648 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:48,654 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:48,655 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:48,655 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:48,660 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:48,662 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:48,662 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:48,667 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:48,669 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:48,669 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:48,675 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:48,676 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:48,676 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:48,681 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:48,682 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:48,682 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:48,689 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:48,690 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:48,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:48,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:48,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:48,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:48,701 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:48,703 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:48,703 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:48,708 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:48,710 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:48,710 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:48,715 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:48,716 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:48,717 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:48,722 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:48,723 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:48,723 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:48,727 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:48,728 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:48,728 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:48,733 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:48,734 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:48,734 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:48,739 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:48,740 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:48,740 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:48,750 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:06:48,751 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:06:48,751 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:06:48,757 (MainThread): Flushing usage events
2019-10-02 13:06:48,757 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:48,757 (MainThread): Encountered an error:
2019-10-02 13:06:48,758 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:48,758 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:06:48,776 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:06:55,891 (MainThread): Tracking: tracking
2019-10-02 13:06:55,893 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004932BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C925C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DB08>]}
2019-10-02 13:06:56,177 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:56,179 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60850), raddr=('54.174.31.151', 443)>

2019-10-02 13:06:56,184 (MainThread): Error sending message, disabling tracking
2019-10-02 13:06:56,249 (MainThread): Parsing macros\core.sql
2019-10-02 13:06:56,257 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:06:56,295 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:06:56,305 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:06:56,307 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:06:56,311 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:06:56,315 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:06:56,318 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:06:56,320 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:06:56,328 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:06:56,337 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:06:56,345 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:06:56,362 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:06:56,382 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:06:56,385 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:06:56,399 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:06:56,405 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:06:56,412 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:06:56,418 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:06:56,421 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:06:56,423 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:06:56,426 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:06:56,429 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:06:56,442 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:06:56,445 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:06:56,453 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:06:56,456 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:06:56,460 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:06:56,489 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:06:56,490 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:06:56,490 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:06:56,493 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:06:56,743 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:06:56,761 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:57,343 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:57,344 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:57,344 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:57,349 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:57,350 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:57,350 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:57,355 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:57,356 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:57,356 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:57,361 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:57,361 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:57,362 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:57,366 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:57,367 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:57,367 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:57,372 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:57,373 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:57,373 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:57,378 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:57,379 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:57,379 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:57,383 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:57,384 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:57,384 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:57,390 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:57,391 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:57,391 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:57,396 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:57,397 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:57,397 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:57,402 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:57,403 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:57,403 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:57,407 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:57,408 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:57,408 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:57,413 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:57,414 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:57,414 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:57,418 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:57,420 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:57,420 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:57,424 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:57,425 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:57,425 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:57,430 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:57,431 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:57,431 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:57,436 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:57,437 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:57,438 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:57,446 (MainThread): dbt encountered an undefined variable, "sk_booking_id" in node dbt_test.with_fl_acr_booking (source path: C:\Users\EXTMB2\github\dbt_test\models\with_fl_acr_booking.sql)
2019-10-02 13:06:57,447 (MainThread): Flushing usage events
2019-10-02 13:06:57,447 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:57,447 (MainThread): Encountered an error:
2019-10-02 13:06:57,448 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:57,448 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined
2019-10-02 13:06:57,460 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 278, in parse_node
    self._update_parsed_node_info(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 210, in _update_parsed_node_info
    model_tags = config.config.get('tags', [])
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 81, in config
    self.in_model_config)
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 44, in _merge
    merged_config.copy(), config.copy()
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 193, in deep_merge
    last = copy.deepcopy(lst.pop(len(lst) - 1))
  File "c:\python\python37\lib\copy.py", line 150, in deepcopy
    y = copier(x, memo)
  File "c:\python\python37\lib\copy.py", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "c:\python\python37\lib\copy.py", line 161, in deepcopy
    y = copier(memo)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 224, in __deepcopy__
    node=self.node
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined

2019-10-02 13:09:23,769 (MainThread): Tracking: tracking
2019-10-02 13:09:23,771 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C90308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C90288>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6CEC8>]}
2019-10-02 13:09:24,087 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:09:24,088 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60896), raddr=('54.174.31.151', 443)>

2019-10-02 13:09:24,090 (MainThread): Error sending message, disabling tracking
2019-10-02 13:09:24,132 (MainThread): Parsing macros\core.sql
2019-10-02 13:09:24,148 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:09:24,229 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:09:24,239 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:09:24,241 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:09:24,245 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:09:24,248 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:09:24,251 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:09:24,254 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:09:24,262 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:09:24,272 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:09:24,281 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:09:24,298 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:09:24,319 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:09:24,323 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:09:24,336 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:09:24,343 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:09:24,349 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:09:24,356 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:09:24,358 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:09:24,360 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:09:24,363 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:09:24,366 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:09:24,379 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:09:24,382 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:09:24,392 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:09:24,394 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:09:24,399 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:09:24,426 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:09:24,428 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:09:24,428 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:09:24,431 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:09:24,671 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:09:24,689 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:09:25,196 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:09:25,197 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:09:25,198 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:09:25,202 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:09:25,203 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:09:25,203 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:09:25,207 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:09:25,208 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:09:25,209 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:09:25,213 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:09:25,214 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:09:25,214 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:09:25,219 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:09:25,220 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:09:25,220 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:09:25,224 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:09:25,225 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:09:25,225 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:09:25,230 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:09:25,231 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:09:25,231 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:09:25,235 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:09:25,236 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:09:25,237 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:09:25,242 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:09:25,243 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:09:25,243 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:09:25,247 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:09:25,248 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:09:25,248 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:09:25,253 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:09:25,254 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:09:25,254 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:09:25,258 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:09:25,259 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:09:25,259 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:09:25,264 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:09:25,265 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:09:25,265 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:09:25,269 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:09:25,270 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:09:25,270 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:09:25,275 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:09:25,276 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:09:25,276 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:09:25,281 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:09:25,282 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:09:25,282 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:09:25,287 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:09:25,288 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:09:25,288 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:09:25,298 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:09:25,299 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:09:25,299 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:09:25,304 (MainThread): Flushing usage events
2019-10-02 13:09:25,304 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:09:25,304 (MainThread): Encountered an error:
2019-10-02 13:09:25,305 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:09:25,305 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:09:25,318 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:10:17,497 (MainThread): Tracking: tracking
2019-10-02 13:10:17,499 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93288>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8F548>]}
2019-10-02 13:10:17,783 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:17,786 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60903), raddr=('54.174.31.151', 443)>

2019-10-02 13:10:17,789 (MainThread): Error sending message, disabling tracking
2019-10-02 13:10:17,832 (MainThread): Parsing macros\core.sql
2019-10-02 13:10:17,844 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:10:17,881 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:10:17,890 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:10:17,893 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:10:17,896 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:10:17,899 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:10:17,902 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:10:17,904 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:10:17,912 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:10:17,921 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:10:17,929 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:10:17,946 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:10:17,968 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:10:17,971 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:10:17,985 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:10:17,992 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:10:17,998 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:10:18,006 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:10:18,008 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:10:18,011 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:10:18,013 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:10:18,016 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:10:18,029 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:10:18,032 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:10:18,041 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:10:18,044 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:10:18,048 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:10:18,077 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:10:18,079 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:10:18,079 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:10:18,081 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:10:18,319 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:10:18,337 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:10:18,993 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:10:18,994 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:10:18,994 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:10:18,998 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:10:18,999 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:10:18,999 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:10:19,005 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:10:19,006 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:10:19,006 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:10:19,011 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:10:19,012 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:10:19,012 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:10:19,016 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:10:19,017 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:10:19,018 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:10:19,023 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:10:19,024 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:10:19,024 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:10:19,033 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:10:19,036 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:10:19,037 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:10:19,048 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:10:19,051 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:10:19,051 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:10:19,061 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:10:19,063 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:10:19,063 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:10:19,072 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:10:19,074 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:10:19,075 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:10:19,083 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:10:19,084 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:10:19,085 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:10:19,093 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:10:19,095 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:10:19,095 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:10:19,101 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:10:19,102 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:10:19,102 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:10:19,111 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:10:19,112 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:10:19,112 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:10:19,117 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:10:19,118 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:10:19,118 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:10:19,127 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:10:19,128 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:10:19,129 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:10:19,138 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:10:19,140 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:10:19,140 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:10:19,148 (MainThread): Flushing usage events
2019-10-02 13:10:19,148 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:19,148 (MainThread): Encountered an error:
2019-10-02 13:10:19,149 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:19,149 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id
2019-10-02 13:10:19,163 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 500, in parse_math1
    right = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 541, in parse_unary
    node = nodes.Neg(self.parse_unary(False), lineno=lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 583, in parse_primary
    self.fail("unexpected '%s'" % describe_token(token), token.lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 59, in fail
    raise exc(msg, lineno, self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 4
    --,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id

2019-10-02 13:10:58,711 (MainThread): Tracking: tracking
2019-10-02 13:10:58,713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004972BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C933C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8F088>]}
2019-10-02 13:10:59,004 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:59,005 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60908), raddr=('54.174.31.151', 443)>

2019-10-02 13:10:59,006 (MainThread): Error sending message, disabling tracking
2019-10-02 13:10:59,030 (MainThread): Parsing macros\core.sql
2019-10-02 13:10:59,041 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:10:59,103 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:10:59,115 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:10:59,119 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:10:59,123 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:10:59,127 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:10:59,130 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:10:59,133 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:10:59,143 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:10:59,156 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:10:59,170 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:10:59,188 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:10:59,208 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:10:59,211 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:10:59,225 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:10:59,231 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:10:59,239 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:10:59,245 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:10:59,248 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:10:59,250 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:10:59,254 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:10:59,257 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:10:59,270 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:10:59,274 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:10:59,282 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:10:59,284 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:10:59,289 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:10:59,317 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:10:59,319 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:10:59,320 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:10:59,322 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:10:59,555 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:10:59,571 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:11:00,082 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:11:00,084 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:11:00,084 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:11:00,088 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:11:00,089 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:11:00,089 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:11:00,095 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:11:00,097 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:11:00,097 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:11:00,107 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:11:00,109 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:11:00,110 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:11:00,118 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:11:00,119 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:11:00,119 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:11:00,127 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:11:00,128 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:11:00,128 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:11:00,135 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:11:00,137 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:11:00,137 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:11:00,144 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:11:00,146 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:11:00,146 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:11:00,152 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:11:00,153 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:11:00,153 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:11:00,158 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:11:00,160 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:11:00,160 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:11:00,165 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:11:00,168 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:11:00,168 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:11:00,176 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:11:00,177 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:11:00,177 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:11:00,182 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:11:00,183 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:11:00,183 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:11:00,191 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:11:00,192 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:11:00,192 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:11:00,198 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:11:00,199 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:11:00,200 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:11:00,204 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:11:00,205 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:11:00,206 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:11:00,210 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:11:00,211 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:11:00,211 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:11:00,216 (MainThread): Flushing usage events
2019-10-02 13:11:00,217 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:00,217 (MainThread): Encountered an error:
2019-10-02 13:11:00,217 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:00,217 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id
2019-10-02 13:11:00,231 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 500, in parse_math1
    right = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 541, in parse_unary
    node = nodes.Neg(self.parse_unary(False), lineno=lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 583, in parse_primary
    self.fail("unexpected '%s'" % describe_token(token), token.lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 59, in fail
    raise exc(msg, lineno, self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 4
    --,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id

2019-10-02 13:11:28,222 (MainThread): Tracking: tracking
2019-10-02 13:11:28,223 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92088>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92788>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C9C8>]}
2019-10-02 13:11:28,503 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:28,505 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60912), raddr=('54.174.31.151', 443)>

2019-10-02 13:11:28,510 (MainThread): Error sending message, disabling tracking
2019-10-02 13:11:28,576 (MainThread): Parsing macros\core.sql
2019-10-02 13:11:28,591 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:11:28,639 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:11:28,648 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:11:28,650 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:11:28,655 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:11:28,658 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:11:28,661 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:11:28,664 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:11:28,673 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:11:28,682 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:11:28,691 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:11:28,709 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:11:28,729 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:11:28,732 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:11:28,746 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:11:28,753 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:11:28,759 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:11:28,772 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:11:28,775 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:11:28,777 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:11:28,779 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:11:28,782 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:11:28,796 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:11:28,801 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:11:28,815 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:11:28,820 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:11:28,827 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:11:28,897 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:11:28,900 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:11:28,901 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:11:28,906 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:11:29,180 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:11:29,199 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:11:30,260 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:11:30,261 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:11:30,261 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:11:30,266 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:11:30,267 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:11:30,267 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:11:30,271 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:11:30,272 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:11:30,272 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:11:30,276 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:11:30,277 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:11:30,278 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:11:30,283 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:11:30,284 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:11:30,284 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:11:30,288 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:11:30,289 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:11:30,289 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:11:30,293 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:11:30,295 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:11:30,295 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:11:30,299 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:11:30,300 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:11:30,300 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:11:30,305 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:11:30,306 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:11:30,306 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:11:30,311 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:11:30,312 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:11:30,312 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:11:30,316 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:11:30,317 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:11:30,318 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:11:30,322 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:11:30,323 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:11:30,323 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:11:30,327 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:11:30,328 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:11:30,328 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:11:30,333 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:11:30,334 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:11:30,334 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:11:30,338 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:11:30,339 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:11:30,339 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:11:30,344 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:11:30,345 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:11:30,345 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:11:30,349 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:11:30,350 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:11:30,351 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:11:30,355 (MainThread): Flushing usage events
2019-10-02 13:11:30,356 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:30,356 (MainThread): Encountered an error:
2019-10-02 13:11:30,356 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:30,356 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id
2019-10-02 13:11:30,369 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 500, in parse_math1
    right = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 541, in parse_unary
    node = nodes.Neg(self.parse_unary(False), lineno=lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 583, in parse_primary
    self.fail("unexpected '%s'" % describe_token(token), token.lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 59, in fail
    raise exc(msg, lineno, self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 4
    --,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id

2019-10-02 13:13:52,101 (MainThread): Tracking: tracking
2019-10-02 13:13:52,104 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C94348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C94188>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C86A88>]}
2019-10-02 13:13:52,419 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:13:52,421 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60958), raddr=('54.164.98.48', 443)>

2019-10-02 13:13:52,426 (MainThread): Error sending message, disabling tracking
2019-10-02 13:13:52,476 (MainThread): Parsing macros\core.sql
2019-10-02 13:13:52,484 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:13:52,523 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:13:52,533 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:13:52,535 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:13:52,539 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:13:52,542 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:13:52,545 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:13:52,548 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:13:52,557 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:13:52,565 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:13:52,574 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:13:52,591 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:13:52,614 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:13:52,617 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:13:52,632 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:13:52,640 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:13:52,647 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:13:52,662 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:13:52,667 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:13:52,672 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:13:52,677 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:13:52,683 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:13:52,717 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:13:52,722 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:13:52,730 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:13:52,732 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:13:52,737 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:13:52,765 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:13:52,774 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:13:52,774 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:13:52,776 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:13:53,025 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:13:53,048 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:13:53,587 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:13:53,588 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:13:53,588 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:13:53,593 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:13:53,594 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:13:53,594 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:13:53,599 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:13:53,600 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:13:53,600 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:13:53,605 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:13:53,606 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:13:53,606 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:13:53,610 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:13:53,611 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:13:53,612 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:13:53,616 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:13:53,617 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:13:53,618 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:13:53,622 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:13:53,623 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:13:53,623 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:13:53,628 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:13:53,629 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:13:53,629 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:13:53,634 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:13:53,635 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:13:53,635 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:13:53,639 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:13:53,640 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:13:53,640 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:13:53,645 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:13:53,646 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:13:53,646 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:13:53,651 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:13:53,652 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:13:53,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:13:53,657 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:13:53,658 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:13:53,658 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:13:53,663 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:13:53,664 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:13:53,664 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:13:53,669 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:13:53,670 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:13:53,670 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:13:53,675 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:13:53,676 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:13:53,676 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:13:53,681 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:13:53,682 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:13:53,682 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:13:53,687 (MainThread): Flushing usage events
2019-10-02 13:13:53,688 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:13:53,688 (MainThread): Encountered an error:
2019-10-02 13:13:53,688 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:13:53,688 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      # ,unique_key=sk_booking_id#
2019-10-02 13:13:53,704 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 564, in parse_primary
    next(self.stream)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 359, in __next__
    self.current = next(self._iter)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 562, in wrap
    for lineno, token, value in stream:
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 739, in tokeniter
    name, filename)
jinja2.exceptions.TemplateSyntaxError: unexpected char '#' at 48
  line 4
    # ,unique_key=sk_booking_id#

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      # ,unique_key=sk_booking_id#

2019-10-02 13:14:18,787 (MainThread): Tracking: tracking
2019-10-02 13:14:18,789 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C927C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C922C8>]}
2019-10-02 13:14:19,075 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:14:19,077 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60964), raddr=('54.164.98.48', 443)>

2019-10-02 13:14:19,080 (MainThread): Error sending message, disabling tracking
2019-10-02 13:14:19,128 (MainThread): Parsing macros\core.sql
2019-10-02 13:14:19,139 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:14:19,178 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:14:19,189 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:14:19,191 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:14:19,194 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:14:19,198 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:14:19,201 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:14:19,204 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:14:19,212 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:14:19,221 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:14:19,229 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:14:19,246 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:14:19,268 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:14:19,271 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:14:19,283 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:14:19,290 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:14:19,296 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:14:19,303 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:14:19,306 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:14:19,308 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:14:19,310 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:14:19,313 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:14:19,326 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:14:19,329 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:14:19,338 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:14:19,340 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:14:19,345 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:14:19,375 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:14:19,377 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:14:19,377 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:14:19,379 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:14:19,630 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:14:19,651 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:14:20,176 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:14:20,177 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:14:20,177 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:14:20,182 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:14:20,183 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:14:20,183 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:14:20,189 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:14:20,189 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:14:20,190 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:14:20,194 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:14:20,195 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:14:20,195 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:14:20,200 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:14:20,201 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:14:20,201 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:14:20,206 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:14:20,207 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:14:20,207 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:14:20,211 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:14:20,212 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:14:20,212 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:14:20,217 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:14:20,219 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:14:20,219 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:14:20,224 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:14:20,226 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:14:20,226 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:14:20,230 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:14:20,231 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:14:20,231 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:14:20,236 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:14:20,237 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:14:20,237 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:14:20,241 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:14:20,242 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:14:20,242 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:14:20,246 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:14:20,247 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:14:20,248 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:14:20,252 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:14:20,253 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:14:20,253 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:14:20,257 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:14:20,258 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:14:20,259 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:14:20,263 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:14:20,264 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:14:20,264 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:14:20,269 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:14:20,270 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:14:20,270 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:14:20,275 (MainThread): Flushing usage events
2019-10-02 13:14:20,275 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:14:20,275 (MainThread): Encountered an error:
2019-10-02 13:14:20,276 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:14:20,276 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got '{'
    line 4
      {# ,unique_key=sk_booking_id #}
2019-10-02 13:14:20,290 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 4
    {# ,unique_key=sk_booking_id #}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got '{'
    line 4
      {# ,unique_key=sk_booking_id #}

2019-10-02 13:15:11,327 (MainThread): Tracking: tracking
2019-10-02 13:15:11,329 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C938C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DD48>]}
2019-10-02 13:15:11,653 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:11,654 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61012), raddr=('54.164.98.48', 443)>

2019-10-02 13:15:11,656 (MainThread): Error sending message, disabling tracking
2019-10-02 13:15:11,688 (MainThread): Parsing macros\core.sql
2019-10-02 13:15:11,698 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:15:11,739 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:15:11,749 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:15:11,752 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:15:11,755 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:15:11,759 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:15:11,762 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:15:11,764 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:15:11,773 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:15:11,781 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:15:11,790 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:15:11,807 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:15:11,828 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:15:11,831 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:15:11,845 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:15:11,852 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:15:11,858 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:15:11,865 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:15:11,868 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:15:11,870 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:15:11,873 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:15:11,876 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:15:11,889 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:15:11,892 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:15:11,900 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:15:11,904 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:15:11,909 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:15:11,937 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:15:11,939 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:15:11,939 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:15:11,941 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:15:12,173 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:15:12,191 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:15:12,758 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:15:12,759 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:15:12,759 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:15:12,763 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:15:12,764 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:15:12,764 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:15:12,769 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:15:12,770 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:15:12,770 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:15:12,774 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:15:12,775 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:15:12,775 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:15:12,787 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:15:12,788 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:15:12,788 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:15:12,796 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:15:12,798 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:15:12,798 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:15:12,808 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:15:12,811 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:15:12,811 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:15:12,819 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:15:12,822 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:15:12,822 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:15:12,829 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:15:12,830 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:15:12,830 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:15:12,835 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:15:12,837 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:15:12,837 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:15:12,843 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:15:12,844 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:15:12,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:15:12,848 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:15:12,849 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:15:12,850 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:15:12,855 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:15:12,856 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:15:12,856 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:15:12,861 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:15:12,862 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:15:12,862 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:15:12,873 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:15:12,875 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:15:12,875 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:15:12,889 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:15:12,891 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:15:12,892 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:15:12,902 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:15:12,905 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:12,905 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:15:12,914 (MainThread): Flushing usage events
2019-10-02 13:15:12,914 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:12,915 (MainThread): Encountered an error:
2019-10-02 13:15:12,915 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:12,915 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      ## ,unique_key=sk_booking_id
2019-10-02 13:15:12,934 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 564, in parse_primary
    next(self.stream)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 359, in __next__
    self.current = next(self._iter)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 562, in wrap
    for lineno, token, value in stream:
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 739, in tokeniter
    name, filename)
jinja2.exceptions.TemplateSyntaxError: unexpected char '#' at 48
  line 4
    ## ,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      ## ,unique_key=sk_booking_id

2019-10-02 13:15:52,083 (MainThread): Tracking: tracking
2019-10-02 13:15:52,085 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004938748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91948>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DA48>]}
2019-10-02 13:15:52,349 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:52,352 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61016), raddr=('54.164.98.48', 443)>

2019-10-02 13:15:52,357 (MainThread): Error sending message, disabling tracking
2019-10-02 13:15:52,411 (MainThread): Parsing macros\core.sql
2019-10-02 13:15:52,419 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:15:52,458 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:15:52,467 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:15:52,470 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:15:52,473 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:15:52,477 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:15:52,480 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:15:52,482 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:15:52,492 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:15:52,500 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:15:52,510 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:15:52,527 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:15:52,548 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:15:52,551 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:15:52,564 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:15:52,572 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:15:52,578 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:15:52,585 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:15:52,588 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:15:52,590 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:15:52,593 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:15:52,596 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:15:52,610 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:15:52,613 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:15:52,622 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:15:52,625 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:15:52,629 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:15:52,659 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:15:52,660 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:15:52,660 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:15:52,662 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:15:52,938 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:15:52,961 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:15:53,562 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:15:53,563 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:15:53,563 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:15:53,568 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:15:53,569 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:15:53,570 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:15:53,574 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:15:53,575 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:15:53,575 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:15:53,580 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:15:53,581 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:15:53,581 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:15:53,587 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:15:53,588 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:15:53,588 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:15:53,593 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:15:53,593 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:15:53,594 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:15:53,598 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:15:53,599 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:15:53,599 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:15:53,605 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:15:53,606 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:15:53,606 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:15:53,611 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:15:53,612 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:15:53,612 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:15:53,617 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:15:53,618 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:15:53,619 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:15:53,624 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:15:53,625 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:15:53,625 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:15:53,630 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:15:53,631 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:15:53,631 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:15:53,636 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:15:53,637 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:15:53,637 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:15:53,642 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:15:53,643 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:15:53,643 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:15:53,648 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:15:53,649 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:15:53,649 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:15:53,654 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:15:53,655 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:15:53,655 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:15:53,660 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:15:53,661 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:53,661 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:15:53,672 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:15:53,673 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:53,674 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:15:53,679 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:15:53,680 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:15:53,680 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:15:53,685 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:15:53,686 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:15:53,687 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:15:53,755 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:15:53,758 (MainThread): 
2019-10-02 13:15:53,759 (MainThread): 13:15:53 | Concurrency: 1 threads (target='dev')
2019-10-02 13:15:53,760 (MainThread): 13:15:53 | 
2019-10-02 13:15:53,773 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:15:53,774 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:15:54,287 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:15:54,304 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:15:54,310 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:15:54,313 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:15:54,314 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:15:54,322 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:15:54,328 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:15:54,330 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:15:54,330 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:15:54,335 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:15:54,340 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:15:54,342 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:15:54,342 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:15:54,349 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:15:54,355 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:15:54,357 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:15:54,358 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:15:54,366 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:15:54,376 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:15:54,380 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:15:54,381 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:15:54,392 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:15:54,400 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:15:54,400 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:15:54,405 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:15:54,417 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:15:54,427 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:15:54,427 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:15:54,432 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:15:54,445 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:15:54,454 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:15:54,457 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:15:54,458 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:15:54,466 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:15:54,474 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:15:54,474 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:15:54,477 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:15:54,488 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:15:54,496 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:15:54,496 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:15:54,497 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:15:54,510 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:15:54,517 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:15:54,520 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:15:54,521 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:15:54,530 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:15:54,537 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:15:54,540 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:15:54,540 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:15:54,548 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:15:54,555 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:15:54,557 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:15:54,558 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:15:54,568 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:15:54,575 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:15:54,578 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:15:54,579 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:15:54,588 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:15:54,594 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:54,597 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:15:54,598 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:15:54,607 (Thread-1): On "with_fl_acr_booking": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:15:54,649 (Thread-1): Parsing macros\core.sql
2019-10-02 13:15:54,664 (Thread-1): Parsing macros\adapters\common.sql
2019-10-02 13:15:54,742 (Thread-1): Parsing macros\etc\datetime.sql
2019-10-02 13:15:54,760 (Thread-1): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:15:54,763 (Thread-1): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:15:54,770 (Thread-1): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:15:54,776 (Thread-1): Parsing macros\etc\is_incremental.sql
2019-10-02 13:15:54,783 (Thread-1): Parsing macros\etc\query.sql
2019-10-02 13:15:54,788 (Thread-1): Parsing macros\materializations\helpers.sql
2019-10-02 13:15:54,809 (Thread-1): Parsing macros\materializations\common\merge.sql
2019-10-02 13:15:54,833 (Thread-1): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:15:54,858 (Thread-1): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:15:54,889 (Thread-1): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:15:54,925 (Thread-1): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:15:54,927 (Thread-1): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:15:54,950 (Thread-1): Parsing macros\materializations\table\table.sql
2019-10-02 13:15:54,961 (Thread-1): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:15:54,970 (Thread-1): Parsing macros\materializations\view\view.sql
2019-10-02 13:15:54,977 (Thread-1): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:15:54,983 (Thread-1): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:15:54,988 (Thread-1): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:15:54,992 (Thread-1): Parsing macros\schema_tests\unique.sql
2019-10-02 13:15:54,996 (Thread-1): Parsing macros\adapters.sql
2019-10-02 13:15:55,010 (Thread-1): Parsing macros\catalog.sql
2019-10-02 13:15:55,013 (Thread-1): Parsing macros\materializations\incremental.sql
2019-10-02 13:15:55,025 (Thread-1): Parsing macros\materializations\merge.sql
2019-10-02 13:15:55,030 (Thread-1): Parsing macros\materializations\table.sql
2019-10-02 13:15:55,043 (Thread-1): Parsing macros\materializations\view.sql
2019-10-02 13:15:55,270 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:55,270 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:15:55,383 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:15:55,383 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:55,383 (Thread-1): On with_fl_acr_booking: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:15:56,770 (Thread-1): SQL status: SUCCESS 1 in 1.39 seconds
2019-10-02 13:15:56,798 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:15:56,800 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:15:56,808 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:15:56,955 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:56,958 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:15:56,959 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:15:56,967 (Thread-1): On "with_fl_acr_booking_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:15:56,977 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:56,977 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:15:57,101 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:15:57,102 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:57,102 (Thread-1): On with_fl_acr_booking_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:15:58,412 (Thread-1): SQL status: SUCCESS 1 in 1.31 seconds
2019-10-02 13:15:58,419 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:15:58,425 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:15:58,440 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:15:58,583 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:15:58,583 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:15:58,584 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:15:58,596 (Thread-1): On "with_fl_acr_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:15:58,643 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:15:58,643 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:15:58,756 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:15:58,756 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:15:58,756 (Thread-1): On with_fl_acr_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:00,752 (Thread-1): SQL status: SUCCESS 1 in 2.00 seconds
2019-10-02 13:16:00,759 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:00,765 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:16:00,788 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:16:00,980 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:00,984 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:16:00,986 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:16:01,001 (Thread-1): On "with_fl_acr_service_element": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:01,010 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:01,010 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:16:01,137 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:16:01,137 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:01,138 (Thread-1): On with_fl_acr_service_element: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:02,432 (Thread-1): SQL status: SUCCESS 1 in 1.29 seconds
2019-10-02 13:16:02,439 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:02,446 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:16:02,461 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:16:02,621 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:16:02,624 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:16:02,625 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:16:02,635 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:16:02,642 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:16:02,643 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:16:02,643 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:16:03,925 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:16:04,026 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 13:16:04,027 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 13:16:04,106 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:16:04,107 (MainThread): On booking_fact_uk: Close
2019-10-02 13:16:04,298 (MainThread): 13:16:04 | Done.
2019-10-02 13:16:04,299 (MainThread): Flushing usage events
2019-10-02 13:16:21,259 (MainThread): Tracking: tracking
2019-10-02 13:16:21,261 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91F88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91A48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E108>]}
2019-10-02 13:16:21,549 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:16:21,550 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61021), raddr=('54.164.98.48', 443)>

2019-10-02 13:16:21,553 (MainThread): Error sending message, disabling tracking
2019-10-02 13:16:21,591 (MainThread): Parsing macros\core.sql
2019-10-02 13:16:21,600 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:16:21,638 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:16:21,648 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:16:21,650 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:16:21,654 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:16:21,657 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:16:21,660 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:16:21,663 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:16:21,672 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:16:21,680 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:16:21,689 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:16:21,706 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:16:21,727 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:16:21,730 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:16:21,743 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:16:21,749 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:16:21,756 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:16:21,762 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:16:21,765 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:16:21,769 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:16:21,771 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:16:21,774 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:16:21,787 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:16:21,790 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:16:21,799 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:16:21,802 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:16:21,807 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:16:21,836 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:16:21,837 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:16:21,837 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:16:21,840 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:16:22,084 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:16:22,102 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:16:22,644 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:16:22,645 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:16:22,645 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:16:22,650 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:16:22,651 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:16:22,651 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:16:22,655 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:16:22,656 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:16:22,656 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:16:22,661 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:16:22,662 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:16:22,663 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:16:22,667 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:16:22,668 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:16:22,668 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:16:22,673 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:16:22,674 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:16:22,674 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:16:22,678 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:16:22,679 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:16:22,679 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:16:22,684 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:16:22,685 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:16:22,685 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:16:22,690 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:16:22,691 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:16:22,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:16:22,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:16:22,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:16:22,697 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:16:22,701 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:16:22,702 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:16:22,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:16:22,706 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:16:22,707 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:16:22,707 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:16:22,712 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:16:22,713 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:16:22,713 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:16:22,718 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:16:22,719 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:16:22,719 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:16:22,724 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:16:22,725 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:16:22,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:16:22,730 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:16:22,731 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:16:22,731 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:16:22,735 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:16:22,736 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:22,736 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:16:22,746 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:16:22,747 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:22,747 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:16:22,753 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:16:22,754 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:16:22,754 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:16:22,759 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:16:22,760 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:22,760 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:16:22,835 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:16:22,840 (MainThread): 
2019-10-02 13:16:22,841 (MainThread): 13:16:22 | Concurrency: 1 threads (target='dev')
2019-10-02 13:16:22,842 (MainThread): 13:16:22 | 
2019-10-02 13:16:22,851 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:16:22,852 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:16:23,293 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:16:23,299 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:16:23,304 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:16:23,306 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:16:23,307 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:16:23,311 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:16:23,316 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:16:23,319 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:16:23,319 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:16:23,324 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:16:23,330 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:16:23,330 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:16:23,330 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:16:23,335 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:16:23,341 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:16:23,342 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:16:23,342 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:16:23,347 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:16:23,354 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:16:23,354 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:16:23,355 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:16:23,363 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:16:23,370 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:16:23,370 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:16:23,371 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:16:23,382 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:16:23,386 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:16:23,386 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:16:23,387 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:16:23,395 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:16:23,400 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:16:23,400 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:16:23,400 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:16:23,409 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:16:23,413 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:16:23,416 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:16:23,416 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:16:23,427 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:16:23,437 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:16:23,438 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:16:23,443 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:16:23,450 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:16:23,457 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:16:23,457 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:16:23,458 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:16:23,475 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:16:23,482 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:16:23,483 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:16:23,486 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:16:23,494 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:16:23,501 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:16:23,501 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:16:23,502 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:16:23,516 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:16:23,527 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:16:23,531 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:16:23,533 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:16:23,546 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:16:23,554 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:23,554 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:16:23,558 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:16:23,568 (Thread-1): On "with_fl_acr_booking": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:23,616 (Thread-1): Parsing macros\core.sql
2019-10-02 13:16:23,624 (Thread-1): Parsing macros\adapters\common.sql
2019-10-02 13:16:23,689 (Thread-1): Parsing macros\etc\datetime.sql
2019-10-02 13:16:23,698 (Thread-1): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:16:23,701 (Thread-1): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:16:23,704 (Thread-1): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:16:23,708 (Thread-1): Parsing macros\etc\is_incremental.sql
2019-10-02 13:16:23,711 (Thread-1): Parsing macros\etc\query.sql
2019-10-02 13:16:23,713 (Thread-1): Parsing macros\materializations\helpers.sql
2019-10-02 13:16:23,731 (Thread-1): Parsing macros\materializations\common\merge.sql
2019-10-02 13:16:23,754 (Thread-1): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:16:23,765 (Thread-1): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:16:23,786 (Thread-1): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:16:23,819 (Thread-1): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:16:23,825 (Thread-1): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:16:23,861 (Thread-1): Parsing macros\materializations\table\table.sql
2019-10-02 13:16:23,878 (Thread-1): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:16:23,895 (Thread-1): Parsing macros\materializations\view\view.sql
2019-10-02 13:16:23,913 (Thread-1): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:16:23,917 (Thread-1): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:16:23,921 (Thread-1): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:16:23,925 (Thread-1): Parsing macros\schema_tests\unique.sql
2019-10-02 13:16:23,929 (Thread-1): Parsing macros\adapters.sql
2019-10-02 13:16:23,954 (Thread-1): Parsing macros\catalog.sql
2019-10-02 13:16:23,960 (Thread-1): Parsing macros\materializations\incremental.sql
2019-10-02 13:16:23,975 (Thread-1): Parsing macros\materializations\merge.sql
2019-10-02 13:16:23,980 (Thread-1): Parsing macros\materializations\table.sql
2019-10-02 13:16:23,987 (Thread-1): Parsing macros\materializations\view.sql
2019-10-02 13:16:24,188 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:24,188 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:16:24,288 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:16:24,290 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:24,290 (Thread-1): On with_fl_acr_booking: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:25,666 (Thread-1): SQL status: SUCCESS 1 in 1.37 seconds
2019-10-02 13:16:25,693 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:25,696 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:16:25,704 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:16:25,884 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:25,886 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:16:25,886 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:16:25,891 (Thread-1): On "with_fl_acr_booking_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:25,895 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:25,896 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:16:26,020 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:16:26,020 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:26,020 (Thread-1): On with_fl_acr_booking_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:27,355 (Thread-1): SQL status: SUCCESS 1 in 1.34 seconds
2019-10-02 13:16:27,357 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:27,359 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:16:27,366 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:16:27,675 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:16:27,678 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:16:27,679 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:16:27,694 (Thread-1): On "with_fl_acr_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:27,749 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:16:27,749 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:16:27,851 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:16:27,853 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:16:27,854 (Thread-1): On with_fl_acr_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:29,426 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2019-10-02 13:16:29,428 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:29,429 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:16:29,433 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:16:29,571 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:29,575 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:16:29,576 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:16:29,583 (Thread-1): On "with_fl_acr_service_element": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:29,589 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:29,590 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:16:29,681 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 13:16:29,682 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:29,682 (Thread-1): On with_fl_acr_service_element: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:31,489 (Thread-1): SQL status: SUCCESS 1 in 1.81 seconds
2019-10-02 13:16:31,492 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:31,495 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:16:31,501 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:16:31,632 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:16:31,633 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:16:31,634 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:16:31,639 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:16:31,645 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:16:31,648 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:16:31,649 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:16:33,172 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:16:33,261 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 13:16:33,262 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 13:16:33,336 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:16:33,337 (MainThread): On booking_fact_uk: Close
2019-10-02 13:16:33,494 (MainThread): 13:16:33 | Done.
2019-10-02 13:16:33,495 (MainThread): Flushing usage events
2019-10-02 13:17:06,889 (MainThread): Tracking: tracking
2019-10-02 13:17:06,891 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C90D08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C80908>]}
2019-10-02 13:17:07,182 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:17:07,183 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61032), raddr=('54.164.98.48', 443)>

2019-10-02 13:17:07,186 (MainThread): Error sending message, disabling tracking
2019-10-02 13:17:07,233 (MainThread): Parsing macros\core.sql
2019-10-02 13:17:07,242 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:17:07,281 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:17:07,291 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:07,293 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:07,296 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:07,300 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:07,303 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:17:07,305 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:07,314 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:07,323 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:07,332 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:07,349 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:07,371 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:07,374 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:07,387 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:07,394 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:07,400 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:07,408 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:07,411 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:07,413 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:07,415 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:07,419 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:17:07,433 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:17:07,437 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:07,445 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:17:07,449 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:17:07,454 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:17:07,484 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:17:07,486 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:17:07,486 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:17:07,488 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:17:07,705 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:17:07,721 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:17:08,270 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:17:08,271 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:08,272 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:17:08,278 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:17:08,279 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:08,279 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:08,283 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:17:08,284 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:08,284 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:17:08,289 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:17:08,290 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:08,290 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:08,295 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:17:08,296 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:08,296 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:08,300 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:08,301 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:08,302 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:08,307 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:17:08,308 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:08,308 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:08,313 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:17:08,313 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:08,314 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:08,319 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:17:08,320 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:08,320 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:08,324 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:08,325 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:08,325 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:08,330 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:08,331 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:08,331 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:08,335 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:08,336 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:08,337 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:08,341 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:17:08,342 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:08,342 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:08,347 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:17:08,348 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:08,348 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:08,352 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:08,353 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:08,353 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:08,358 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:17:08,359 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:08,359 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:08,364 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:08,365 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:08,365 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:08,375 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:08,376 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:08,377 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:08,382 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:17:08,383 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:08,383 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:08,388 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:08,389 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:08,389 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:08,459 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:17:08,464 (MainThread): 
2019-10-02 13:17:08,465 (MainThread): 13:17:08 | Concurrency: 1 threads (target='dev')
2019-10-02 13:17:08,465 (MainThread): 13:17:08 | 
2019-10-02 13:17:08,475 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:08,476 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:17:08,968 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:17:08,975 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:17:08,980 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:08,982 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:08,983 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:17:08,988 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:17:08,992 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:08,994 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:08,994 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:17:08,999 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:17:09,005 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:09,005 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:09,007 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:17:09,013 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:17:09,017 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:09,017 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:09,018 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:09,024 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:17:09,034 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:09,034 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:09,035 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:17:09,047 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:17:09,054 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:09,056 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:09,057 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:17:09,068 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:17:09,075 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:09,075 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:09,080 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:17:09,094 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:17:09,101 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:09,102 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:09,103 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:09,113 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:17:09,123 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:09,124 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:09,125 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:09,137 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:17:09,144 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:09,146 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:09,146 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:09,156 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:17:09,166 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:09,171 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:09,172 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:17:09,185 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:17:09,194 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:09,194 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:09,195 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:17:09,209 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:17:09,218 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:09,219 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:09,223 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:09,235 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:17:09,244 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:09,244 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:09,245 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:17:09,258 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:17:09,265 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:09,267 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:09,267 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:09,275 (Thread-1): On "with_fl_acr_booking": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:09,299 (Thread-1): Parsing macros\core.sql
2019-10-02 13:17:09,308 (Thread-1): Parsing macros\adapters\common.sql
2019-10-02 13:17:09,391 (Thread-1): Parsing macros\etc\datetime.sql
2019-10-02 13:17:09,429 (Thread-1): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:09,437 (Thread-1): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:09,445 (Thread-1): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:09,454 (Thread-1): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:09,462 (Thread-1): Parsing macros\etc\query.sql
2019-10-02 13:17:09,467 (Thread-1): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:09,487 (Thread-1): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:09,505 (Thread-1): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:09,527 (Thread-1): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:09,573 (Thread-1): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:09,621 (Thread-1): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:09,625 (Thread-1): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:09,656 (Thread-1): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:09,671 (Thread-1): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:09,682 (Thread-1): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:09,699 (Thread-1): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:09,704 (Thread-1): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:09,709 (Thread-1): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:09,714 (Thread-1): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:09,718 (Thread-1): Parsing macros\adapters.sql
2019-10-02 13:17:09,743 (Thread-1): Parsing macros\catalog.sql
2019-10-02 13:17:09,749 (Thread-1): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:09,760 (Thread-1): Parsing macros\materializations\merge.sql
2019-10-02 13:17:09,765 (Thread-1): Parsing macros\materializations\table.sql
2019-10-02 13:17:09,771 (Thread-1): Parsing macros\materializations\view.sql
2019-10-02 13:17:09,951 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:09,951 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:17:10,080 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:17:10,081 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:10,082 (Thread-1): On with_fl_acr_booking: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:11,323 (Thread-1): SQL status: SUCCESS 1 in 1.24 seconds
2019-10-02 13:17:11,365 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:11,367 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:17:11,375 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:17:11,530 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:11,532 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:11,532 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:11,537 (Thread-1): On "with_fl_acr_booking_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:11,541 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:11,542 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:17:11,645 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:17:11,645 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:11,645 (Thread-1): On with_fl_acr_booking_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:13,215 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2019-10-02 13:17:13,219 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:13,224 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:17:13,239 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:17:13,371 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:13,372 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:13,372 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:17:13,378 (Thread-1): On "with_fl_acr_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:13,412 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:13,412 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:17:13,514 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:17:13,515 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:13,515 (Thread-1): On with_fl_acr_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:14,734 (Thread-1): SQL status: SUCCESS 1 in 1.22 seconds
2019-10-02 13:17:14,737 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:14,741 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:17:14,755 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:17:14,949 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:14,949 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:14,954 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:14,964 (Thread-1): On "with_fl_acr_service_element": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:14,974 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:14,975 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:17:15,127 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:17:15,128 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:15,128 (Thread-1): On with_fl_acr_service_element: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:16,397 (Thread-1): SQL status: SUCCESS 1 in 1.27 seconds
2019-10-02 13:17:16,398 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:16,401 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:17:16,410 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:17:16,558 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:16,560 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:17:16,561 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:17:16,565 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:17:16,573 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:17:16,577 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:17:16,578 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:17:18,178 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:17:18,237 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 13:17:18,238 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 13:17:18,318 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:17:18,319 (MainThread): On booking_fact_uk: Close
2019-10-02 13:17:18,642 (MainThread): 13:17:18 | Done.
2019-10-02 13:17:18,642 (MainThread): Flushing usage events
2019-10-02 13:17:47,703 (MainThread): Tracking: tracking
2019-10-02 13:17:47,706 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC648>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B5C8>]}
2019-10-02 13:17:48,011 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:17:48,012 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61046), raddr=('54.164.98.48', 443)>

2019-10-02 13:17:48,014 (MainThread): Error sending message, disabling tracking
2019-10-02 13:17:48,054 (MainThread): Parsing macros\core.sql
2019-10-02 13:17:48,063 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:17:48,100 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:17:48,111 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:48,113 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:48,116 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:48,120 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:48,123 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:17:48,126 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:48,134 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:48,143 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:48,152 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:48,170 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:48,191 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:48,194 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:48,208 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:48,214 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:48,221 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:48,228 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:48,231 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:48,233 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:48,237 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:48,240 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:17:48,253 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:17:48,256 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:48,264 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:17:48,267 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:17:48,273 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:17:48,300 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:17:48,301 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:17:48,301 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:17:48,304 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:17:48,600 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:17:48,616 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:17:49,179 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:17:49,180 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:49,181 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:17:49,185 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:17:49,186 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:49,186 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:49,191 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:17:49,192 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:49,192 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:17:49,197 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:17:49,198 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:49,198 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:49,203 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:17:49,204 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:49,205 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:49,209 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:49,210 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:49,210 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:49,215 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:17:49,216 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:49,216 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:49,222 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:17:49,223 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:49,223 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:49,228 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:17:49,229 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:49,229 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:49,234 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:49,235 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:49,235 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:49,240 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:49,241 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:49,241 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:49,245 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:49,246 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:49,246 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:49,250 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:17:49,251 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:49,251 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:49,256 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:17:49,257 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:49,257 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:49,265 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:49,266 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:49,266 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:49,272 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:17:49,273 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:49,273 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:49,278 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:49,279 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:49,279 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:49,289 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:49,290 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:49,290 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:49,296 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:17:49,297 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:49,297 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:49,303 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:49,304 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:49,304 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:49,361 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:17:49,364 (MainThread): 
2019-10-02 13:17:49,365 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 13:17:49,365 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:17:49,421 (MainThread): Parsing macros\core.sql
2019-10-02 13:17:49,434 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:17:49,537 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:17:49,551 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:49,555 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:49,560 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:49,564 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:49,568 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:17:49,572 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:49,588 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:49,605 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:49,620 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:49,637 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:49,683 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:49,687 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:49,714 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:49,724 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:49,733 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:49,742 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:49,745 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:49,747 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:49,749 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:49,753 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:17:49,765 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:17:49,769 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:49,777 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:17:49,780 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:17:49,784 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:17:49,896 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:49,897 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 13:17:50,463 (MainThread): SQL status: SUCCESS 29 in 0.57 seconds
2019-10-02 13:17:50,555 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:50,555 (MainThread): On master: BEGIN
2019-10-02 13:17:50,702 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:17:50,704 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:50,704 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:51,735 (MainThread): SQL status: SUCCESS 0 in 1.03 seconds
2019-10-02 13:17:51,740 (MainThread): On master: ROLLBACK
2019-10-02 13:17:51,887 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:51,888 (MainThread): On master: BEGIN
2019-10-02 13:17:52,003 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:17:52,005 (MainThread): On master: COMMIT
2019-10-02 13:17:52,006 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:52,006 (MainThread): On master: COMMIT
2019-10-02 13:17:52,172 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 13:17:52,174 (MainThread): 13:17:52 | Concurrency: 1 threads (target='dev')
2019-10-02 13:17:52,175 (MainThread): 13:17:52 | 
2019-10-02 13:17:52,193 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:52,194 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:17:52,647 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:17:52,659 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:17:52,669 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:52,669 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:52,673 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:17:52,680 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:17:52,687 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:52,687 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:52,688 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:17:52,700 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:17:52,708 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:52,708 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:52,709 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:17:52,720 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:17:52,725 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:52,728 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:52,729 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:52,740 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:17:52,749 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:52,749 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:52,755 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:17:52,764 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:17:52,772 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:52,775 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:52,776 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:17:52,787 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:17:52,796 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:52,801 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:52,802 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:17:52,813 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:17:52,821 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:52,825 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:52,826 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:52,836 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:17:52,842 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:52,845 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:52,846 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:52,853 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:17:52,860 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:52,863 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:52,864 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:52,873 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:17:52,888 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:52,888 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:52,890 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:17:52,900 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:17:52,912 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:52,913 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:52,915 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:17:52,932 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:17:52,943 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:52,947 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:52,947 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:52,957 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:17:52,964 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:52,966 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:52,967 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:17:52,972 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:17:52,979 (Thread-1): 13:17:52 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 13:17:52,983 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:52,983 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:52,983 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:52,992 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:17:53,119 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:17:53,130 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:53,130 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:17:53,247 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:17:53,248 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:53,248 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id
    
SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:53,487 (Thread-1): Snowflake error: 000979 (42601): 018f46c1-005b-6135-0000-0e290161d586: SQL compilation error:
[BK_1.EFFECTIVE_FROM] is not a valid group by expression
2019-10-02 13:17:53,487 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:17:53,624 (Thread-1): 13:17:53 | 1 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking. [ERROR in 0.64s]
2019-10-02 13:17:53,626 (Thread-1): 13:17:53 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 13:17:53,629 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:53,629 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:53,630 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:53,643 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:17:53,658 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:17:53,666 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:53,666 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:17:53,773 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:17:53,774 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:53,774 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table
    
SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:54,011 (Thread-1): Snowflake error: 001104 (42601): 018f46c1-00b8-9f3f-0000-0e290161a832: SQL compilation error: error line 8 at position 3
'BK_SER_1.SK_BOOKING_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:54,011 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:17:54,218 (Thread-1): 13:17:54 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.59s]
2019-10-02 13:17:54,219 (Thread-1): 13:17:54 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 13:17:54,221 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:54,221 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:54,221 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:17:54,227 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:17:54,241 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:17:54,250 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:54,250 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:17:54,446 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-02 13:17:54,446 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:54,446 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:54,671 (Thread-1): Snowflake error: 001104 (42601): 018f46c1-00d4-d908-0000-0e290161b6e6: SQL compilation error: error line 8 at position 3
'SER_1.ATCOM_SER_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:54,671 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:17:54,843 (Thread-1): 13:17:54 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.62s]
2019-10-02 13:17:54,844 (Thread-1): 13:17:54 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 13:17:54,849 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:54,849 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:54,850 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:54,864 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:17:54,881 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:17:54,891 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:54,891 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:17:55,044 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:17:55,044 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:55,045 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table
    
SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:55,423 (Thread-1): Snowflake error: 001104 (42601): 018f46c1-0044-fc5a-0000-0e290161a83a: SQL compilation error: error line 8 at position 3
'SER_E_1.SK_SERVICE_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:55,423 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:17:55,595 (Thread-1): 13:17:55 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.74s]
2019-10-02 13:17:55,599 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:55,599 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:17:55,602 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:17:55,625 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:17:55,633 (Thread-1): 13:17:55 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 13:17:55,698 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:55,698 (MainThread): On master: BEGIN
2019-10-02 13:17:56,054 (MainThread): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-02 13:17:56,055 (MainThread): On master: COMMIT
2019-10-02 13:17:56,055 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:56,055 (MainThread): On master: COMMIT
2019-10-02 13:17:56,219 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 13:17:56,220 (MainThread): 13:17:56 | 
2019-10-02 13:17:56,221 (MainThread): 13:17:56 | Finished running 4 incremental models, 1 table model in 6.86s.
2019-10-02 13:17:56,222 (MainThread): Connection 'master' was left open.
2019-10-02 13:17:56,223 (MainThread): On master: Close
2019-10-02 13:17:56,368 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 13:17:56,368 (MainThread): On with_ar_currency: Close
2019-10-02 13:17:56,594 (MainThread): 
2019-10-02 13:17:56,595 (MainThread): Completed with 4 errors and 0 warnings:
2019-10-02 13:17:56,597 (MainThread): 
2019-10-02 13:17:56,598 (MainThread): Database Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
2019-10-02 13:17:56,604 (MainThread):   000979 (42601): 018f46c1-005b-6135-0000-0e290161d586: SQL compilation error:
2019-10-02 13:17:56,606 (MainThread):   [BK_1.EFFECTIVE_FROM] is not a valid group by expression
2019-10-02 13:17:56,606 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking.sql
2019-10-02 13:17:56,606 (MainThread): 
2019-10-02 13:17:56,607 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 13:17:56,607 (MainThread):   001104 (42601): 018f46c1-00b8-9f3f-0000-0e290161a832: SQL compilation error: error line 8 at position 3
2019-10-02 13:17:56,608 (MainThread):   'BK_SER_1.SK_BOOKING_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:56,609 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 13:17:56,610 (MainThread): 
2019-10-02 13:17:56,610 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 13:17:56,611 (MainThread):   001104 (42601): 018f46c1-00d4-d908-0000-0e290161b6e6: SQL compilation error: error line 8 at position 3
2019-10-02 13:17:56,612 (MainThread):   'SER_1.ATCOM_SER_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:56,613 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 13:17:56,614 (MainThread): 
2019-10-02 13:17:56,616 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 13:17:56,631 (MainThread):   001104 (42601): 018f46c1-0044-fc5a-0000-0e290161a83a: SQL compilation error: error line 8 at position 3
2019-10-02 13:17:56,632 (MainThread):   'SER_E_1.SK_SERVICE_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:56,632 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 13:17:56,633 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
2019-10-02 13:17:56,633 (MainThread): Flushing usage events
2019-10-02 13:19:53,823 (MainThread): Tracking: tracking
2019-10-02 13:19:53,825 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000070CB7C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E0C8>]}
2019-10-02 13:19:54,130 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:19:54,130 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61057), raddr=('54.174.31.151', 443)>

2019-10-02 13:19:54,132 (MainThread): Error sending message, disabling tracking
2019-10-02 13:19:54,188 (MainThread): Parsing macros\core.sql
2019-10-02 13:19:54,196 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:19:54,236 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:19:54,246 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:19:54,248 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:19:54,253 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:19:54,261 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:19:54,267 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:19:54,273 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:19:54,295 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:19:54,308 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:19:54,317 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:19:54,334 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:19:54,356 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:19:54,359 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:19:54,373 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:19:54,380 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:19:54,387 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:19:54,393 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:19:54,396 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:19:54,398 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:19:54,400 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:19:54,404 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:19:54,417 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:19:54,420 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:19:54,429 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:19:54,431 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:19:54,436 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:19:54,464 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:19:54,466 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:19:54,466 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:19:54,468 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:19:54,706 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:19:54,723 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:19:55,300 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:19:55,301 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:19:55,302 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:19:55,307 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:19:55,308 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:19:55,308 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:19:55,314 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:19:55,315 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:19:55,315 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:19:55,322 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:19:55,323 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:19:55,323 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:19:55,329 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:19:55,330 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:19:55,330 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:19:55,338 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:19:55,339 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:19:55,339 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:19:55,345 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:19:55,346 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:19:55,346 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:19:55,353 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:19:55,354 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:19:55,354 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:19:55,361 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:19:55,362 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:19:55,362 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:19:55,368 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:19:55,369 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:19:55,369 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:19:55,377 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:19:55,379 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:19:55,379 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:19:55,385 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:19:55,387 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:19:55,387 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:19:55,392 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:19:55,394 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:19:55,394 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:19:55,398 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:19:55,399 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:19:55,400 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:19:55,404 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:19:55,405 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:19:55,405 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:19:55,411 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:19:55,412 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:19:55,412 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:19:55,417 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:19:55,418 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:55,418 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:19:55,428 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:19:55,429 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:19:55,429 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:19:55,434 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:19:55,435 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:19:55,435 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:19:55,440 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:19:55,442 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:19:55,442 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:19:55,499 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:19:55,501 (MainThread): 
2019-10-02 13:19:55,501 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 13:19:55,502 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:19:55,525 (MainThread): Parsing macros\core.sql
2019-10-02 13:19:55,534 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:19:55,628 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:19:55,642 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:19:55,645 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:19:55,648 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:19:55,652 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:19:55,655 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:19:55,657 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:19:55,666 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:19:55,674 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:19:55,682 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:19:55,703 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:19:55,743 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:19:55,748 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:19:55,777 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:19:55,789 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:19:55,800 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:19:55,811 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:19:55,814 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:19:55,818 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:19:55,821 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:19:55,826 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:19:55,852 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:19:55,859 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:19:55,875 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:19:55,878 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:19:55,883 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:19:55,999 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:56,000 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 13:19:56,513 (MainThread): SQL status: SUCCESS 29 in 0.51 seconds
2019-10-02 13:19:56,599 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:56,599 (MainThread): On master: BEGIN
2019-10-02 13:19:56,705 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:19:56,706 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:56,706 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:19:57,971 (MainThread): SQL status: SUCCESS 0 in 1.26 seconds
2019-10-02 13:19:57,974 (MainThread): On master: ROLLBACK
2019-10-02 13:19:58,108 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:58,108 (MainThread): On master: BEGIN
2019-10-02 13:19:58,284 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 13:19:58,286 (MainThread): On master: COMMIT
2019-10-02 13:19:58,287 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:58,288 (MainThread): On master: COMMIT
2019-10-02 13:19:58,431 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 13:19:58,434 (MainThread): 13:19:58 | Concurrency: 1 threads (target='dev')
2019-10-02 13:19:58,435 (MainThread): 13:19:58 | 
2019-10-02 13:19:58,454 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:19:58,455 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:19:58,852 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:19:58,868 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:19:58,874 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:19:58,874 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:19:58,875 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:19:58,884 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:19:58,892 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:19:58,895 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:19:58,895 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:19:58,907 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:19:58,915 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:19:58,919 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:19:58,920 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:19:58,929 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:19:58,936 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:19:58,939 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:19:58,939 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:19:58,948 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:19:58,955 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:19:58,958 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:19:58,960 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:19:58,967 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:19:58,974 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:19:58,977 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:19:58,978 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:19:58,988 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:19:58,995 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:19:58,998 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:19:58,999 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:19:59,008 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:19:59,015 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:19:59,015 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:19:59,020 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:19:59,029 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:19:59,036 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:19:59,039 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:19:59,040 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:19:59,049 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:19:59,055 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:19:59,057 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:19:59,058 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:19:59,063 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:19:59,070 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:19:59,072 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:19:59,073 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:19:59,086 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:19:59,095 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:19:59,100 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:19:59,103 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:19:59,114 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:19:59,123 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:19:59,126 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:19:59,128 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:19:59,140 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:19:59,148 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:19:59,150 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:19:59,151 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:19:59,159 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:19:59,167 (Thread-1): 13:19:59 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 13:19:59,170 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:59,170 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:19:59,171 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:19:59,187 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:19:59,329 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:19:59,337 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:59,337 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:19:59,463 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:19:59,463 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:59,463 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:01,224 (Thread-1): SQL status: SUCCESS 1 in 1.76 seconds
2019-10-02 13:20:01,226 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 13:20:01,226 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:20:01,226 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 13:20:01,312 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 13:20:01,316 (Thread-1): 13:20:01 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 2.14s]
2019-10-02 13:20:01,324 (Thread-1): 13:20:01 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 13:20:01,324 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:01,325 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:20:01,325 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:20:01,331 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:20:01,342 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:20:01,346 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:01,347 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:20:01,473 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:20:01,474 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:01,475 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:10,662 (Thread-1): SQL status: SUCCESS 1 in 9.19 seconds
2019-10-02 13:20:10,663 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 13:20:10,663 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:10,663 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 13:20:10,753 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 13:20:10,756 (Thread-1): 13:20:10 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 9.43s]
2019-10-02 13:20:10,757 (Thread-1): 13:20:10 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 13:20:10,758 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:20:10,759 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:20:10,759 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:20:10,765 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:20:10,781 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:20:10,787 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:20:10,787 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:20:10,886 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:20:10,887 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:20:10,887 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:32,163 (Thread-1): SQL status: SUCCESS 1 in 21.28 seconds
2019-10-02 13:20:32,167 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 13:20:32,168 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:20:32,168 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 13:20:32,291 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:20:32,308 (Thread-1): 13:20:32 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 21.54s]
2019-10-02 13:20:32,311 (Thread-1): 13:20:32 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 13:20:32,317 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:32,318 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:20:32,321 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:20:32,341 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:20:32,361 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:20:32,368 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:32,368 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:20:32,475 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:20:32,475 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:32,475 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:47,557 (Thread-1): SQL status: SUCCESS 1 in 15.08 seconds
2019-10-02 13:20:47,563 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 13:20:47,564 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:47,565 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 13:20:47,851 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-02 13:20:47,862 (Thread-1): 13:20:47 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 15.54s]
2019-10-02 13:20:47,864 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:20:47,864 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:20:47,869 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:20:47,880 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:20:47,887 (Thread-1): 13:20:47 | 5 of 5 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 13:20:47,890 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:20:47,890 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:20:47,891 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:20:49,199 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:20:49,233 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:20:49,308 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 13:20:49,308 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 13:20:49,436 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:20:49,437 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 13:20:49,437 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 13:21:37,208 (Thread-1): SQL status: SUCCESS 1 in 47.77 seconds
2019-10-02 13:21:37,211 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 13:21:37,212 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 13:21:37,212 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 13:21:37,297 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-02 13:21:37,319 (Thread-1): 13:21:37 | 5 of 5 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 49.42s]
2019-10-02 13:21:37,430 (MainThread): Using snowflake connection "master".
2019-10-02 13:21:37,432 (MainThread): On master: BEGIN
2019-10-02 13:21:37,629 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 13:21:37,632 (MainThread): On master: COMMIT
2019-10-02 13:21:37,632 (MainThread): Using snowflake connection "master".
2019-10-02 13:21:37,633 (MainThread): On master: COMMIT
2019-10-02 13:21:37,786 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:21:37,787 (MainThread): 13:21:37 | 
2019-10-02 13:21:37,787 (MainThread): 13:21:37 | Finished running 4 incremental models, 1 table model in 102.29s.
2019-10-02 13:21:37,788 (MainThread): Connection 'master' was left open.
2019-10-02 13:21:37,789 (MainThread): On master: Close
2019-10-02 13:21:37,917 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:21:37,920 (MainThread): On booking_fact_uk: Close
2019-10-02 13:21:38,140 (MainThread): 
2019-10-02 13:21:38,140 (MainThread): Completed successfully
2019-10-02 13:21:38,142 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 13:21:38,142 (MainThread): Flushing usage events
2019-10-02 13:56:35,307 (MainThread): Tracking: tracking
2019-10-02 13:56:35,321 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059738C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005973908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594D388>]}
2019-10-02 13:56:35,626 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:56:35,626 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 59875), raddr=('54.164.98.48', 443)>

2019-10-02 13:56:35,628 (MainThread): Error sending message, disabling tracking
2019-10-02 13:56:35,665 (MainThread): Parsing macros\core.sql
2019-10-02 13:56:35,689 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:56:35,760 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:56:35,777 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:56:35,782 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:56:35,789 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:56:35,796 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:56:35,802 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:56:35,807 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:56:35,840 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:56:35,854 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:56:35,870 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:56:35,898 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:56:35,933 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:56:35,941 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:56:35,958 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:56:35,969 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:56:35,980 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:56:35,992 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:56:35,997 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:56:36,011 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:56:36,014 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:56:36,019 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:56:36,038 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:56:36,044 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:56:36,060 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:56:36,066 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:56:36,075 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:56:36,155 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:56:36,158 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:56:36,158 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:56:36,161 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:56:36,606 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:56:36,642 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:56:37,690 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:56:37,691 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:56:37,691 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:56:37,695 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:56:37,697 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:56:37,697 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:56:37,701 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:56:37,702 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:56:37,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:56:37,708 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:56:37,709 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:56:37,709 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:56:37,717 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:56:37,719 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:56:37,720 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:56:37,727 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:56:37,728 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:56:37,728 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:56:37,734 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:56:37,735 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:56:37,735 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:56:37,740 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:56:37,741 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:56:37,741 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:56:37,747 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:56:37,748 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:56:37,748 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:56:37,752 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:56:37,753 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:56:37,754 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:56:37,758 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:56:37,760 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:56:37,760 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:56:37,764 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:56:37,765 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:56:37,765 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:56:37,772 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:56:37,774 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:56:37,774 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:56:37,783 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:56:37,785 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:56:37,785 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:56:37,794 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:56:37,796 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:56:37,796 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:56:37,805 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:56:37,807 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:56:37,807 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:56:37,816 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:56:37,817 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:56:37,817 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:56:37,840 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:56:37,842 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:56:37,842 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:56:37,848 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:56:37,850 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:56:37,851 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:56:37,860 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:56:37,862 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:56:37,862 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:56:37,952 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:56:37,955 (MainThread): 
2019-10-02 13:56:37,956 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 13:56:37,956 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:56:38,050 (MainThread): Parsing macros\core.sql
2019-10-02 13:56:38,076 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:56:38,168 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:56:38,195 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:56:38,199 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:56:38,205 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:56:38,212 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:56:38,225 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:56:38,239 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:56:38,261 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:56:38,293 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:56:38,313 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:56:38,355 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:56:38,404 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:56:38,415 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:56:38,446 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:56:38,468 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:56:38,482 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:56:38,495 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:56:38,500 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:56:38,503 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:56:38,509 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:56:38,517 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:56:38,550 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:56:38,556 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:56:38,574 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:56:38,580 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:56:38,589 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:56:38,921 (MainThread): Using snowflake connection "master".
2019-10-02 13:56:38,921 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 13:56:39,573 (MainThread): SQL status: SUCCESS 29 in 0.65 seconds
2019-10-02 13:56:39,655 (MainThread): Using snowflake connection "master".
2019-10-02 13:56:39,655 (MainThread): On master: BEGIN
2019-10-02 13:56:39,900 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 13:56:39,901 (MainThread): Using snowflake connection "master".
2019-10-02 13:56:39,901 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:56:41,211 (MainThread): SQL status: SUCCESS 5 in 1.31 seconds
2019-10-02 13:56:41,220 (MainThread): On master: ROLLBACK
2019-10-02 13:56:41,650 (MainThread): Using snowflake connection "master".
2019-10-02 13:56:41,650 (MainThread): On master: BEGIN
2019-10-02 13:56:41,806 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:56:41,807 (MainThread): On master: COMMIT
2019-10-02 13:56:41,807 (MainThread): Using snowflake connection "master".
2019-10-02 13:56:41,807 (MainThread): On master: COMMIT
2019-10-02 13:56:41,942 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:56:41,942 (MainThread): 13:56:41 | Concurrency: 1 threads (target='dev')
2019-10-02 13:56:41,943 (MainThread): 13:56:41 | 
2019-10-02 13:56:41,946 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:56:41,946 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:56:42,379 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:56:42,385 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:56:42,394 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:56:42,397 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:56:42,398 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:56:42,407 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:56:42,415 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:56:42,418 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:56:42,419 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:56:42,431 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:56:42,445 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:56:42,446 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:56:42,447 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:56:42,458 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:56:42,480 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:56:42,480 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:56:42,484 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:56:42,494 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:56:42,504 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:56:42,504 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:56:42,505 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:56:42,519 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:56:42,530 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:56:42,530 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:56:42,534 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:56:42,544 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:56:42,553 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:56:42,553 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:56:42,557 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:56:42,567 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:56:42,590 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:56:42,593 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:56:42,594 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:56:42,604 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:56:42,614 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:56:42,614 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:56:42,615 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:56:42,628 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:56:42,654 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:56:42,654 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:56:42,658 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:56:42,668 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:56:42,678 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:56:42,681 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:56:42,682 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:56:42,692 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:56:42,700 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:56:42,700 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:56:42,701 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:56:42,714 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:56:42,736 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:56:42,740 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:56:42,741 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:56:42,749 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:56:42,759 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:56:42,760 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:56:42,761 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:56:42,778 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:56:42,799 (Thread-1): 13:56:42 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 13:56:42,802 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:56:42,802 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:56:42,803 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:56:42,817 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:56:42,950 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:56:42,950 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:56:43,053 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:56:43,054 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:56:43,054 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking)

-- GROUP BY 1
      );
2019-10-02 13:56:43,247 (Thread-1): Snowflake error: 001003 (42000): 018f46e8-00ec-ec6f-0000-0e290161ad12: SQL compilation error:
syntax error line 40 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:43,247 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:56:43,381 (Thread-1): 13:56:43 | 1 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking. [ERROR in 0.58s]
2019-10-02 13:56:43,382 (Thread-1): 13:56:43 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 13:56:43,383 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:56:43,386 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:56:43,387 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:56:43,400 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:56:43,424 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:56:43,425 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:56:43,537 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:56:43,538 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:56:43,538 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 13:56:43,756 (Thread-1): Snowflake error: 001003 (42000): 018f46e8-00a4-7e5f-0000-0e290161ad1a: SQL compilation error:
syntax error line 21 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:43,756 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:56:43,882 (Thread-1): 13:56:43 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.49s]
2019-10-02 13:56:43,883 (Thread-1): 13:56:43 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 13:56:43,886 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:56:43,886 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:56:43,887 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:56:43,899 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:56:43,922 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:56:43,922 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:56:44,020 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:56:44,021 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:56:44,021 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 13:56:44,186 (Thread-1): Snowflake error: 001003 (42000): 018f46e8-0043-6eaf-0000-0e290161cb5e: SQL compilation error:
syntax error line 29 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:44,186 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:56:44,331 (Thread-1): 13:56:44 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.44s]
2019-10-02 13:56:44,332 (Thread-1): 13:56:44 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 13:56:44,336 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:56:44,336 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:56:44,337 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:56:44,354 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:56:44,380 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:56:44,381 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:56:44,480 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:56:44,481 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:56:44,481 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_stream_test ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 13:56:44,670 (Thread-1): Snowflake error: 001003 (42000): 018f46e8-006a-7a3e-0000-0e290161ad22: SQL compilation error:
syntax error line 18 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:44,670 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:56:44,801 (Thread-1): 13:56:44 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.46s]
2019-10-02 13:56:44,802 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:56:44,805 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:56:44,805 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:56:44,818 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:56:44,826 (Thread-1): 13:56:44 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 13:56:44,919 (MainThread): Using snowflake connection "master".
2019-10-02 13:56:44,920 (MainThread): On master: BEGIN
2019-10-02 13:56:45,053 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:56:45,053 (MainThread): On master: COMMIT
2019-10-02 13:56:45,054 (MainThread): Using snowflake connection "master".
2019-10-02 13:56:45,054 (MainThread): On master: COMMIT
2019-10-02 13:56:45,212 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 13:56:45,213 (MainThread): 13:56:45 | 
2019-10-02 13:56:45,213 (MainThread): 13:56:45 | Finished running 4 incremental models, 1 table model in 7.26s.
2019-10-02 13:56:45,213 (MainThread): Connection 'master' was left open.
2019-10-02 13:56:45,214 (MainThread): On master: Close
2019-10-02 13:56:45,325 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 13:56:45,326 (MainThread): On with_ar_currency: Close
2019-10-02 13:56:45,467 (MainThread): 
2019-10-02 13:56:45,468 (MainThread): Completed with 4 errors and 0 warnings:
2019-10-02 13:56:45,468 (MainThread): 
2019-10-02 13:56:45,468 (MainThread): Database Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
2019-10-02 13:56:45,469 (MainThread):   001003 (42000): 018f46e8-00ec-ec6f-0000-0e290161ad12: SQL compilation error:
2019-10-02 13:56:45,469 (MainThread):   syntax error line 40 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:45,469 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking.sql
2019-10-02 13:56:45,470 (MainThread): 
2019-10-02 13:56:45,470 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 13:56:45,470 (MainThread):   001003 (42000): 018f46e8-00a4-7e5f-0000-0e290161ad1a: SQL compilation error:
2019-10-02 13:56:45,471 (MainThread):   syntax error line 21 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:45,471 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 13:56:45,472 (MainThread): 
2019-10-02 13:56:45,472 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 13:56:45,472 (MainThread):   001003 (42000): 018f46e8-0043-6eaf-0000-0e290161cb5e: SQL compilation error:
2019-10-02 13:56:45,473 (MainThread):   syntax error line 29 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:45,473 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 13:56:45,473 (MainThread): 
2019-10-02 13:56:45,474 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 13:56:45,474 (MainThread):   001003 (42000): 018f46e8-006a-7a3e-0000-0e290161ad22: SQL compilation error:
2019-10-02 13:56:45,474 (MainThread):   syntax error line 18 at position 2 unexpected 'WHERE'.
2019-10-02 13:56:45,475 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 13:56:45,475 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
2019-10-02 13:56:45,475 (MainThread): Flushing usage events
2019-10-02 14:00:11,646 (MainThread): Tracking: tracking
2019-10-02 14:00:11,648 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C148>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C288>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C248>]}
2019-10-02 14:00:11,932 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:00:11,932 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 59919), raddr=('54.164.98.48', 443)>

2019-10-02 14:00:11,933 (MainThread): Error sending message, disabling tracking
2019-10-02 14:00:11,955 (MainThread): Parsing macros\core.sql
2019-10-02 14:00:11,963 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:00:12,000 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:00:12,010 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:00:12,012 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:00:12,016 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:00:12,020 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:00:12,023 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:00:12,026 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:00:12,034 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:00:12,043 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:00:12,051 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:00:12,069 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:00:12,091 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:00:12,094 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:00:12,111 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:00:12,124 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:00:12,131 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:00:12,143 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:00:12,148 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:00:12,152 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:00:12,156 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:00:12,159 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:00:12,175 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:00:12,178 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:00:12,191 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:00:12,194 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:00:12,199 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:00:12,229 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:00:12,231 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:00:12,231 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:00:12,233 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:00:12,446 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:00:12,463 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:00:13,067 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:00:13,069 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:00:13,070 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:00:13,079 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:00:13,081 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:00:13,081 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:00:13,090 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:00:13,092 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:00:13,092 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:00:13,101 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:00:13,103 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:00:13,103 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:00:13,112 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:00:13,114 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:00:13,115 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:00:13,123 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:00:13,125 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:00:13,126 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:00:13,135 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:00:13,136 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:00:13,137 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:00:13,143 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:00:13,144 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:00:13,144 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:00:13,151 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:00:13,152 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:00:13,152 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:00:13,158 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:00:13,159 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:00:13,159 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:00:13,165 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:00:13,166 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:00:13,166 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:00:13,171 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:00:13,173 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:00:13,173 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:00:13,177 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:00:13,178 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:00:13,178 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:00:13,183 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:00:13,185 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:00:13,186 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:00:13,191 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:00:13,192 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:00:13,192 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:00:13,197 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:00:13,199 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:00:13,199 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:00:13,207 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:00:13,209 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:00:13,209 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:00:13,220 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:00:13,221 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:00:13,222 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:00:13,227 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:00:13,228 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:00:13,228 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:00:13,233 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:00:13,234 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:00:13,234 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:00:13,321 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:00:13,324 (MainThread): 
2019-10-02 14:00:13,325 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:00:13,325 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:00:13,357 (MainThread): Parsing macros\core.sql
2019-10-02 14:00:13,368 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:00:13,457 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:00:13,478 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:00:13,480 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:00:13,484 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:00:13,490 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:00:13,494 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:00:13,497 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:00:13,511 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:00:13,525 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:00:13,540 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:00:13,568 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:00:13,592 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:00:13,598 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:00:13,629 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:00:13,645 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:00:13,656 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:00:13,665 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:00:13,668 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:00:13,670 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:00:13,674 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:00:13,679 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:00:13,706 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:00:13,712 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:00:13,730 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:00:13,733 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:00:13,738 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:00:13,900 (MainThread): Using snowflake connection "master".
2019-10-02 14:00:13,900 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:00:14,574 (MainThread): SQL status: SUCCESS 29 in 0.67 seconds
2019-10-02 14:00:14,627 (MainThread): Using snowflake connection "master".
2019-10-02 14:00:14,627 (MainThread): On master: BEGIN
2019-10-02 14:00:14,813 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-02 14:00:14,814 (MainThread): Using snowflake connection "master".
2019-10-02 14:00:14,814 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:00:16,360 (MainThread): SQL status: SUCCESS 5 in 1.55 seconds
2019-10-02 14:00:16,365 (MainThread): On master: ROLLBACK
2019-10-02 14:00:16,505 (MainThread): Using snowflake connection "master".
2019-10-02 14:00:16,505 (MainThread): On master: BEGIN
2019-10-02 14:00:16,656 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:00:16,656 (MainThread): On master: COMMIT
2019-10-02 14:00:16,656 (MainThread): Using snowflake connection "master".
2019-10-02 14:00:16,656 (MainThread): On master: COMMIT
2019-10-02 14:00:16,788 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:00:16,789 (MainThread): 14:00:16 | Concurrency: 1 threads (target='dev')
2019-10-02 14:00:16,789 (MainThread): 14:00:16 | 
2019-10-02 14:00:16,797 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:00:16,797 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:00:17,292 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:00:17,298 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:00:17,303 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:00:17,306 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:00:17,307 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:00:17,312 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:00:17,316 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:00:17,319 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:00:17,319 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:00:17,325 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:00:17,330 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:00:17,332 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:00:17,332 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:00:17,337 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:00:17,341 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:00:17,344 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:00:17,345 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:00:17,350 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:00:17,355 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:00:17,355 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:00:17,356 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:00:17,365 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:00:17,372 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:00:17,377 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:00:17,378 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:00:17,388 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:00:17,394 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:00:17,397 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:00:17,398 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:00:17,409 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:00:17,417 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:00:17,420 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:00:17,421 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:00:17,433 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:00:17,441 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:00:17,446 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:00:17,447 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:00:17,458 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:00:17,467 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:00:17,472 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:00:17,473 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:00:17,485 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:00:17,495 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:00:17,495 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:00:17,496 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:00:17,508 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:00:17,515 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:00:17,518 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:00:17,519 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:00:17,529 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:00:17,536 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:00:17,539 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:00:17,540 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:00:17,550 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:00:17,557 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:00:17,560 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:00:17,561 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:00:17,572 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:00:17,579 (Thread-1): 14:00:17 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:00:17,583 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:00:17,583 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:00:17,584 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:00:17,598 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:00:17,717 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:00:17,727 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:00:17,727 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:00:17,968 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 14:00:17,969 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:00:17,969 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:00:20,678 (Thread-1): SQL status: SUCCESS 1 in 2.71 seconds
2019-10-02 14:00:20,679 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:00:20,680 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:00:20,680 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:00:20,884 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 14:00:20,892 (Thread-1): 14:00:20 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 3.31s]
2019-10-02 14:00:20,894 (Thread-1): 14:00:20 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:00:20,901 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:00:20,901 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:00:20,903 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:00:20,916 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:00:20,932 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:00:20,940 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:00:20,941 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:00:21,183 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 14:00:21,184 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:00:21,184 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:00:26,875 (Thread-1): SQL status: SUCCESS 1 in 5.69 seconds
2019-10-02 14:00:26,876 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:00:26,876 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:00:26,876 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:00:27,109 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-02 14:00:27,113 (Thread-1): 14:00:27 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 6.21s]
2019-10-02 14:00:27,117 (Thread-1): 14:00:27 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:00:27,120 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:00:27,120 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:00:27,121 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:00:27,129 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:00:27,147 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:00:27,152 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:00:27,152 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:00:27,379 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-02 14:00:27,380 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:00:27,380 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:00:27,837 (Thread-1): Snowflake error: 000904 (42000): 018f46ec-0063-6937-0000-0e290161bcea: SQL compilation error: error line 11 at position 3
invalid identifier 'SER_1.SERVICE_STATUS'
2019-10-02 14:00:27,837 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:00:28,054 (Thread-1): 14:00:28 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.93s]
2019-10-02 14:00:28,057 (Thread-1): 14:00:28 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:00:28,060 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:00:28,060 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:00:28,061 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:00:28,070 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:00:28,085 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:00:28,090 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:00:28,090 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:00:28,209 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:00:28,210 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:00:28,210 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_stream_test ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:00:28,468 (Thread-1): Snowflake error: 000904 (42000): 018f46ec-00a5-d291-0000-0e290161dafe: SQL compilation error: error line 7 at position 2
invalid identifier 'SER_E_1.SK_SERVICE_ELEMENT_ID'
2019-10-02 14:00:28,468 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:00:28,656 (Thread-1): 14:00:28 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.59s]
2019-10-02 14:00:28,660 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:00:28,660 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:00:28,661 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:00:28,679 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:00:28,693 (Thread-1): 14:00:28 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:00:28,757 (MainThread): Using snowflake connection "master".
2019-10-02 14:00:28,757 (MainThread): On master: BEGIN
2019-10-02 14:00:28,880 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:00:28,881 (MainThread): On master: COMMIT
2019-10-02 14:00:28,881 (MainThread): Using snowflake connection "master".
2019-10-02 14:00:28,881 (MainThread): On master: COMMIT
2019-10-02 14:00:29,075 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-02 14:00:29,076 (MainThread): 14:00:29 | 
2019-10-02 14:00:29,076 (MainThread): 14:00:29 | Finished running 4 incremental models, 1 table model in 15.75s.
2019-10-02 14:00:29,079 (MainThread): Connection 'master' was left open.
2019-10-02 14:00:29,080 (MainThread): On master: Close
2019-10-02 14:00:29,274 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:00:29,275 (MainThread): On with_ar_currency: Close
2019-10-02 14:00:29,581 (MainThread): 
2019-10-02 14:00:29,582 (MainThread): Completed with 2 errors and 0 warnings:
2019-10-02 14:00:29,584 (MainThread): 
2019-10-02 14:00:29,585 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:00:29,591 (MainThread):   000904 (42000): 018f46ec-0063-6937-0000-0e290161bcea: SQL compilation error: error line 11 at position 3
2019-10-02 14:00:29,593 (MainThread):   invalid identifier 'SER_1.SERVICE_STATUS'
2019-10-02 14:00:29,597 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:00:29,601 (MainThread): 
2019-10-02 14:00:29,603 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:00:29,610 (MainThread):   000904 (42000): 018f46ec-00a5-d291-0000-0e290161dafe: SQL compilation error: error line 7 at position 2
2019-10-02 14:00:29,613 (MainThread):   invalid identifier 'SER_E_1.SK_SERVICE_ELEMENT_ID'
2019-10-02 14:00:29,616 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:00:29,620 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=1 TOTAL=5
2019-10-02 14:00:29,624 (MainThread): Flushing usage events
2019-10-02 14:04:31,677 (MainThread): Tracking: tracking
2019-10-02 14:04:31,679 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972A08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059720C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E5C8>]}
2019-10-02 14:04:31,983 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:04:31,985 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 59940), raddr=('54.164.98.48', 443)>

2019-10-02 14:04:31,991 (MainThread): Error sending message, disabling tracking
2019-10-02 14:04:32,034 (MainThread): Parsing macros\core.sql
2019-10-02 14:04:32,045 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:04:32,084 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:04:32,094 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:04:32,096 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:04:32,100 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:04:32,103 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:04:32,106 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:04:32,108 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:04:32,117 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:04:32,126 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:04:32,135 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:04:32,151 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:04:32,171 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:04:32,174 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:04:32,187 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:04:32,194 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:04:32,200 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:04:32,207 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:04:32,209 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:04:32,211 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:04:32,214 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:04:32,217 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:04:32,230 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:04:32,233 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:04:32,241 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:04:32,244 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:04:32,248 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:04:32,273 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:04:32,274 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:04:32,275 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:04:32,276 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:04:32,513 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:04:32,531 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:04:33,250 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:04:33,251 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:04:33,251 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:04:33,257 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:04:33,258 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:04:33,258 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:04:33,264 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:04:33,266 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:04:33,266 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:04:33,274 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:04:33,276 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:04:33,277 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:04:33,288 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:04:33,290 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:04:33,290 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:04:33,298 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:04:33,300 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:04:33,300 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:04:33,306 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:04:33,307 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:04:33,307 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:04:33,313 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:04:33,314 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:04:33,314 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:04:33,319 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:04:33,320 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:04:33,321 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:04:33,325 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:04:33,326 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:04:33,327 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:04:33,332 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:04:33,333 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:04:33,333 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:04:33,338 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:04:33,340 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:04:33,340 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:04:33,345 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:04:33,347 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:04:33,347 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:04:33,353 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:04:33,354 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:04:33,354 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:04:33,361 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:04:33,363 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:04:33,363 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:04:33,370 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:04:33,372 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:04:33,372 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:04:33,377 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:04:33,378 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:04:33,378 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:04:33,388 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:04:33,389 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:04:33,389 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:04:33,394 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:04:33,396 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:04:33,396 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:04:33,401 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:04:33,402 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:04:33,402 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:04:33,463 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:04:33,467 (MainThread): 
2019-10-02 14:04:33,468 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:04:33,468 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:04:33,490 (MainThread): Parsing macros\core.sql
2019-10-02 14:04:33,497 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:04:33,589 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:04:33,600 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:04:33,602 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:04:33,607 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:04:33,610 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:04:33,613 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:04:33,616 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:04:33,633 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:04:33,642 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:04:33,653 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:04:33,670 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:04:33,693 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:04:33,698 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:04:33,719 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:04:33,733 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:04:33,746 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:04:33,758 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:04:33,761 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:04:33,763 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:04:33,766 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:04:33,769 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:04:33,785 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:04:33,789 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:04:33,805 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:04:33,808 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:04:33,815 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:04:33,939 (MainThread): Using snowflake connection "master".
2019-10-02 14:04:33,939 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:04:34,592 (MainThread): SQL status: SUCCESS 29 in 0.65 seconds
2019-10-02 14:04:34,671 (MainThread): Using snowflake connection "master".
2019-10-02 14:04:34,671 (MainThread): On master: BEGIN
2019-10-02 14:04:34,797 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:04:34,798 (MainThread): Using snowflake connection "master".
2019-10-02 14:04:34,798 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:04:35,918 (MainThread): SQL status: SUCCESS 5 in 1.12 seconds
2019-10-02 14:04:35,926 (MainThread): On master: ROLLBACK
2019-10-02 14:04:36,059 (MainThread): Using snowflake connection "master".
2019-10-02 14:04:36,059 (MainThread): On master: BEGIN
2019-10-02 14:04:36,160 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:04:36,162 (MainThread): On master: COMMIT
2019-10-02 14:04:36,162 (MainThread): Using snowflake connection "master".
2019-10-02 14:04:36,163 (MainThread): On master: COMMIT
2019-10-02 14:04:36,327 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:04:36,329 (MainThread): 14:04:36 | Concurrency: 1 threads (target='dev')
2019-10-02 14:04:36,331 (MainThread): 14:04:36 | 
2019-10-02 14:04:36,351 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:04:36,351 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:04:36,782 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:04:36,795 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:04:36,802 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:04:36,804 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:04:36,805 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:04:36,814 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:04:36,821 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:04:36,824 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:04:36,825 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:04:36,836 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:04:36,843 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:04:36,846 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:04:36,847 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:04:36,856 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:04:36,863 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:04:36,865 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:04:36,866 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:04:36,871 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:04:36,875 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:04:36,878 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:04:36,879 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:04:36,884 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:04:36,890 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:04:36,893 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:04:36,893 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:04:36,903 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:04:36,909 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:04:36,911 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:04:36,911 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:04:36,920 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:04:36,928 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:04:36,929 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:04:36,930 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:04:36,939 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:04:36,945 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:04:36,948 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:04:36,949 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:04:36,957 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:04:36,967 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:04:36,970 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:04:36,972 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:04:36,982 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:04:36,992 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:04:36,996 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:04:36,997 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:04:37,007 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:04:37,014 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:04:37,016 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:04:37,017 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:04:37,027 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:04:37,033 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:04:37,036 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:04:37,036 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:04:37,046 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:04:37,054 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:04:37,057 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:04:37,064 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:04:37,078 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:04:37,087 (Thread-1): 14:04:37 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:04:37,092 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:04:37,093 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:04:37,095 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:04:37,116 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:04:37,279 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:04:37,287 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:04:37,287 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:04:37,403 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:04:37,404 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:04:37,404 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:04:38,536 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2019-10-02 14:04:38,545 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:04:38,546 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:04:38,547 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:04:38,643 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:04:38,658 (Thread-1): 14:04:38 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.56s]
2019-10-02 14:04:38,666 (Thread-1): 14:04:38 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:04:38,673 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:04:38,674 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:04:38,679 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:04:38,705 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:04:38,720 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:04:38,727 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:04:38,727 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:04:38,859 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:04:38,860 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:04:38,860 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:04:42,275 (Thread-1): SQL status: SUCCESS 1 in 3.41 seconds
2019-10-02 14:04:42,279 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:04:42,279 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:04:42,280 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:04:42,421 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:04:42,436 (Thread-1): 14:04:42 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 3.76s]
2019-10-02 14:04:42,445 (Thread-1): 14:04:42 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:04:42,454 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:04:42,455 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:04:42,457 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:04:42,471 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:04:42,486 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:04:42,492 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:04:42,493 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:04:42,615 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:04:42,616 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:04:42,616 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:04:46,871 (Thread-1): SQL status: SUCCESS 1 in 4.25 seconds
2019-10-02 14:04:46,875 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:04:46,875 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:04:46,876 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:04:46,968 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:04:46,984 (Thread-1): 14:04:46 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 4.52s]
2019-10-02 14:04:46,992 (Thread-1): 14:04:46 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:04:46,996 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:04:46,997 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:04:46,998 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:04:47,011 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:04:47,027 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:04:47,032 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:04:47,032 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:04:47,128 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:04:47,129 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:04:47,129 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:04:49,484 (Thread-1): SQL status: SUCCESS 1 in 2.36 seconds
2019-10-02 14:04:49,488 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:04:49,489 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:04:49,490 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:04:49,639 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:04:49,645 (Thread-1): 14:04:49 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 2.65s]
2019-10-02 14:04:49,648 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:04:49,652 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:04:49,653 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:04:49,664 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:04:49,671 (Thread-1): 14:04:49 | 5 of 5 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 14:04:49,675 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:04:49,676 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:04:49,678 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:04:51,168 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:04:51,238 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:04:51,346 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:04:51,347 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:04:51,473 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:04:51,473 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:04:51,473 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:05:03,451 (Thread-1): SQL status: SUCCESS 1 in 11.98 seconds
2019-10-02 14:05:03,455 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:05:03,456 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:05:03,456 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:05:03,544 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:05:03,574 (Thread-1): 14:05:03 | 5 of 5 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 13.89s]
2019-10-02 14:05:03,604 (MainThread): Using snowflake connection "master".
2019-10-02 14:05:03,604 (MainThread): On master: BEGIN
2019-10-02 14:05:03,746 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:05:03,748 (MainThread): On master: COMMIT
2019-10-02 14:05:03,748 (MainThread): Using snowflake connection "master".
2019-10-02 14:05:03,749 (MainThread): On master: COMMIT
2019-10-02 14:05:03,909 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:05:03,911 (MainThread): 14:05:03 | 
2019-10-02 14:05:03,913 (MainThread): 14:05:03 | Finished running 4 incremental models, 1 table model in 30.44s.
2019-10-02 14:05:03,919 (MainThread): Connection 'master' was left open.
2019-10-02 14:05:03,920 (MainThread): On master: Close
2019-10-02 14:05:04,061 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:05:04,063 (MainThread): On booking_fact_uk: Close
2019-10-02 14:05:04,294 (MainThread): 
2019-10-02 14:05:04,297 (MainThread): Completed successfully
2019-10-02 14:05:04,301 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:05:04,305 (MainThread): Flushing usage events
2019-10-02 14:11:50,093 (MainThread): Tracking: tracking
2019-10-02 14:11:50,095 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972788>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972088>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594B288>]}
2019-10-02 14:11:53,220 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:11:53,222 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 59975), raddr=('54.174.31.151', 443)>

2019-10-02 14:11:53,227 (MainThread): Error sending message, disabling tracking
2019-10-02 14:11:53,281 (MainThread): Parsing macros\core.sql
2019-10-02 14:11:53,294 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:11:53,356 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:11:53,366 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:11:53,368 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:11:53,371 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:11:53,374 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:11:53,377 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:11:53,380 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:11:53,388 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:11:53,396 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:11:53,405 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:11:53,421 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:11:53,441 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:11:53,444 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:11:53,458 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:11:53,465 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:11:53,471 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:11:53,478 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:11:53,481 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:11:53,483 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:11:53,485 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:11:53,488 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:11:53,501 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:11:53,504 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:11:53,512 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:11:53,515 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:11:53,519 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:11:53,545 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:11:53,547 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:11:53,547 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:11:53,549 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:11:53,837 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:11:53,854 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:11:54,495 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:11:54,497 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:11:54,497 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:11:54,505 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:11:54,506 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:11:54,507 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:11:54,514 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:11:54,516 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:11:54,516 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:11:54,525 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:11:54,527 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:11:54,527 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:11:54,535 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:11:54,537 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:11:54,537 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:11:54,545 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:11:54,547 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:11:54,548 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:11:54,556 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:11:54,557 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:11:54,558 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:11:54,566 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:11:54,568 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:11:54,568 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:11:54,577 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:11:54,579 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:11:54,579 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:11:54,587 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:11:54,589 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:11:54,589 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:11:54,597 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:11:54,598 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:11:54,598 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:11:54,606 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:11:54,608 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:11:54,608 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:11:54,617 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:11:54,619 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:11:54,620 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:11:54,627 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:11:54,628 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:11:54,629 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:11:54,637 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:11:54,639 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:11:54,639 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:11:54,647 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:11:54,649 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:11:54,650 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:11:54,658 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:11:54,659 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:11:54,660 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:11:54,679 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:11:54,681 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:11:54,682 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:11:54,691 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:11:54,693 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:11:54,694 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:11:54,703 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:11:54,706 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:11:54,706 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:11:54,863 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:11:54,868 (MainThread): 
2019-10-02 14:11:54,869 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:11:54,870 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:11:54,926 (MainThread): Parsing macros\core.sql
2019-10-02 14:11:54,936 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:11:55,050 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:11:55,071 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:11:55,075 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:11:55,082 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:11:55,086 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:11:55,089 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:11:55,091 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:11:55,110 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:11:55,129 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:11:55,139 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:11:55,158 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:11:55,182 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:11:55,188 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:11:55,207 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:11:55,219 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:11:55,232 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:11:55,246 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:11:55,251 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:11:55,256 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:11:55,261 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:11:55,265 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:11:55,288 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:11:55,292 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:11:55,305 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:11:55,308 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:11:55,312 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:11:55,470 (MainThread): Using snowflake connection "master".
2019-10-02 14:11:55,470 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:11:56,221 (MainThread): SQL status: SUCCESS 29 in 0.75 seconds
2019-10-02 14:11:56,330 (MainThread): Using snowflake connection "master".
2019-10-02 14:11:56,331 (MainThread): On master: BEGIN
2019-10-02 14:11:56,511 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 14:11:56,512 (MainThread): Using snowflake connection "master".
2019-10-02 14:11:56,512 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:11:58,131 (MainThread): SQL status: SUCCESS 5 in 1.62 seconds
2019-10-02 14:11:58,153 (MainThread): On master: ROLLBACK
2019-10-02 14:11:58,308 (MainThread): Using snowflake connection "master".
2019-10-02 14:11:58,309 (MainThread): On master: BEGIN
2019-10-02 14:11:58,420 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:11:58,422 (MainThread): On master: COMMIT
2019-10-02 14:11:58,423 (MainThread): Using snowflake connection "master".
2019-10-02 14:11:58,423 (MainThread): On master: COMMIT
2019-10-02 14:11:58,575 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:11:58,577 (MainThread): 14:11:58 | Concurrency: 1 threads (target='dev')
2019-10-02 14:11:58,578 (MainThread): 14:11:58 | 
2019-10-02 14:11:58,595 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:11:58,595 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:11:58,897 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:11:58,906 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:11:58,912 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:11:58,915 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:11:58,916 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:11:58,921 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:11:58,927 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:11:58,930 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:11:58,931 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:11:58,940 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:11:58,947 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:11:58,948 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:11:58,952 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:11:58,960 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:11:58,968 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:11:58,971 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:11:58,972 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:11:58,982 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:11:58,990 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:11:58,990 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:11:58,991 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:11:59,004 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:11:59,012 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:11:59,015 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:11:59,016 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:11:59,026 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:11:59,033 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:11:59,036 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:11:59,037 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:11:59,046 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:11:59,053 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:11:59,053 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:11:59,054 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:11:59,067 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:11:59,075 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:11:59,078 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:11:59,080 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:11:59,096 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:11:59,108 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:11:59,108 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:11:59,109 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:11:59,127 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:11:59,134 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:11:59,138 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:11:59,139 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:11:59,156 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:11:59,166 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:11:59,166 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:11:59,167 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:11:59,184 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:11:59,191 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:11:59,192 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:11:59,193 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:11:59,208 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:11:59,215 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:11:59,219 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:11:59,220 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:11:59,228 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:11:59,234 (Thread-1): 14:11:59 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:11:59,239 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:11:59,239 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:11:59,240 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:11:59,253 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:11:59,374 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:11:59,379 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:11:59,380 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:11:59,480 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:11:59,481 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:11:59,481 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:12:00,490 (Thread-1): SQL status: SUCCESS 1 in 1.01 seconds
2019-10-02 14:12:00,494 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:12:00,495 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:12:00,495 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:12:00,643 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:12:00,659 (Thread-1): 14:12:00 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.41s]
2019-10-02 14:12:00,665 (Thread-1): 14:12:00 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:12:00,673 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:12:00,673 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:12:00,675 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:12:00,696 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:12:00,708 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:12:00,714 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:12:00,714 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:12:00,919 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 14:12:00,920 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:12:00,920 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:12:01,486 (Thread-1): SQL status: SUCCESS 1 in 0.57 seconds
2019-10-02 14:12:01,490 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:12:01,491 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:12:01,491 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:12:01,655 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:12:01,669 (Thread-1): 14:12:01 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 0.99s]
2019-10-02 14:12:01,675 (Thread-1): 14:12:01 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:12:01,678 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:12:01,679 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:12:01,685 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:12:01,700 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:12:01,714 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:12:01,722 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:12:01,723 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:12:01,819 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:12:01,820 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:12:01,820 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:12:08,021 (Thread-1): SQL status: SUCCESS 1 in 6.20 seconds
2019-10-02 14:12:08,023 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:12:08,023 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:12:08,023 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:12:08,927 (Thread-1): SQL status: SUCCESS 1 in 0.90 seconds
2019-10-02 14:12:08,935 (Thread-1): 14:12:08 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 7.25s]
2019-10-02 14:12:08,937 (Thread-1): 14:12:08 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:12:08,941 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:12:08,942 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:12:08,942 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:12:08,952 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:12:08,968 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:12:08,972 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:12:08,972 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:12:09,072 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:12:09,073 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:12:09,073 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:12:09,839 (Thread-1): SQL status: SUCCESS 1 in 0.77 seconds
2019-10-02 14:12:09,843 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:12:09,844 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:12:09,844 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:12:09,932 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:12:09,947 (Thread-1): 14:12:09 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 1.00s]
2019-10-02 14:12:09,952 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:12:09,953 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:12:09,960 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:12:09,979 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:12:09,988 (Thread-1): 14:12:09 | 5 of 5 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 14:12:09,995 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:12:09,995 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:12:09,996 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:12:11,489 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:12:11,525 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:12:11,626 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:12:11,626 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:12:11,726 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:12:11,727 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:12:11,727 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:13:29,952 (Thread-1): SQL status: SUCCESS 1 in 78.22 seconds
2019-10-02 14:13:29,953 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:13:29,953 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:13:29,953 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:13:30,038 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-02 14:13:30,045 (Thread-1): 14:13:30 | 5 of 5 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 80.05s]
2019-10-02 14:13:30,106 (MainThread): Using snowflake connection "master".
2019-10-02 14:13:30,107 (MainThread): On master: BEGIN
2019-10-02 14:13:30,224 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:13:30,224 (MainThread): On master: COMMIT
2019-10-02 14:13:30,224 (MainThread): Using snowflake connection "master".
2019-10-02 14:13:30,225 (MainThread): On master: COMMIT
2019-10-02 14:13:30,367 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:13:30,368 (MainThread): 14:13:30 | 
2019-10-02 14:13:30,368 (MainThread): 14:13:30 | Finished running 4 incremental models, 1 table model in 95.50s.
2019-10-02 14:13:30,369 (MainThread): Connection 'master' was left open.
2019-10-02 14:13:30,370 (MainThread): On master: Close
2019-10-02 14:13:30,496 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:13:30,496 (MainThread): On booking_fact_uk: Close
2019-10-02 14:13:36,896 (MainThread): 
2019-10-02 14:13:36,901 (MainThread): Completed successfully
2019-10-02 14:13:36,902 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:13:36,903 (MainThread): Flushing usage events
2019-10-02 14:14:26,762 (MainThread): Tracking: tracking
2019-10-02 14:14:26,764 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005971A08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059711C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E0C8>]}
2019-10-02 14:14:27,085 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:14:27,088 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60035), raddr=('54.164.98.48', 443)>

2019-10-02 14:14:27,093 (MainThread): Error sending message, disabling tracking
2019-10-02 14:14:27,145 (MainThread): Parsing macros\core.sql
2019-10-02 14:14:27,159 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:14:27,199 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:14:27,209 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:14:27,211 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:14:27,214 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:14:27,218 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:14:27,221 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:14:27,223 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:14:27,232 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:14:27,240 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:14:27,249 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:14:27,266 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:14:27,286 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:14:27,289 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:14:27,303 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:14:27,309 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:14:27,316 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:14:27,322 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:14:27,325 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:14:27,327 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:14:27,330 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:14:27,332 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:14:27,345 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:14:27,349 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:14:27,357 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:14:27,361 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:14:27,366 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:14:27,429 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:14:27,433 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:14:27,434 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:14:27,436 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:14:27,747 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:14:27,766 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:14:28,430 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:14:28,431 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:14:28,431 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:14:28,435 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:14:28,436 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:14:28,437 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:14:28,443 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:14:28,444 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:14:28,444 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:14:28,448 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:14:28,449 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:14:28,449 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:14:28,454 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:14:28,455 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:14:28,455 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:14:28,460 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:14:28,461 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:14:28,461 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:14:28,465 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:14:28,466 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:14:28,466 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:14:28,470 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:14:28,471 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:14:28,471 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:14:28,477 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:14:28,478 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:14:28,478 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:14:28,482 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:14:28,483 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:14:28,483 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:14:28,488 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:14:28,489 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:14:28,489 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:14:28,493 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:14:28,494 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:14:28,494 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:14:28,499 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:14:28,500 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:14:28,500 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:14:28,504 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:14:28,505 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:14:28,505 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:14:28,510 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:14:28,511 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:14:28,511 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:14:28,516 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:14:28,517 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:14:28,517 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:14:28,522 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:14:28,523 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:14:28,523 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:14:28,534 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:14:28,535 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:14:28,535 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:14:28,540 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:14:28,541 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:14:28,541 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:14:28,546 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:14:28,547 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:14:28,547 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:14:28,675 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:14:28,727 (MainThread): 
2019-10-02 14:14:28,727 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:14:28,728 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:14:28,791 (MainThread): Parsing macros\core.sql
2019-10-02 14:14:28,806 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:14:28,929 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:14:28,949 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:14:28,952 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:14:28,958 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:14:28,965 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:14:28,969 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:14:28,973 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:14:28,991 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:14:29,002 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:14:29,013 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:14:29,039 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:14:29,082 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:14:29,088 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:14:29,103 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:14:29,113 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:14:29,120 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:14:29,128 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:14:29,133 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:14:29,136 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:14:29,139 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:14:29,143 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:14:29,168 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:14:29,176 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:14:29,195 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:14:29,200 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:14:29,208 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:14:29,354 (MainThread): Using snowflake connection "master".
2019-10-02 14:14:29,355 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:14:30,055 (MainThread): SQL status: SUCCESS 29 in 0.70 seconds
2019-10-02 14:14:30,146 (MainThread): Using snowflake connection "master".
2019-10-02 14:14:30,146 (MainThread): On master: BEGIN
2019-10-02 14:14:30,251 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:14:30,252 (MainThread): Using snowflake connection "master".
2019-10-02 14:14:30,253 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:14:31,828 (MainThread): SQL status: SUCCESS 5 in 1.58 seconds
2019-10-02 14:14:31,850 (MainThread): On master: ROLLBACK
2019-10-02 14:14:31,987 (MainThread): Using snowflake connection "master".
2019-10-02 14:14:31,987 (MainThread): On master: BEGIN
2019-10-02 14:14:32,131 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:14:32,131 (MainThread): On master: COMMIT
2019-10-02 14:14:32,132 (MainThread): Using snowflake connection "master".
2019-10-02 14:14:32,132 (MainThread): On master: COMMIT
2019-10-02 14:14:32,266 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:14:32,266 (MainThread): 14:14:32 | Concurrency: 1 threads (target='dev')
2019-10-02 14:14:32,267 (MainThread): 14:14:32 | 
2019-10-02 14:14:32,277 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:14:32,278 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:14:32,757 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:14:32,773 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:14:32,780 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:14:32,781 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:14:32,781 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:14:32,791 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:14:32,800 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:14:32,802 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:14:32,803 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:14:32,817 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:14:32,824 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:14:32,828 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:14:32,828 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:14:32,840 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:14:32,849 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:14:32,850 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:14:32,850 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:14:32,865 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:14:32,873 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:14:32,876 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:14:32,877 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:14:32,891 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:14:32,899 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:14:32,903 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:14:32,904 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:14:32,912 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:14:32,918 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:14:32,921 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:14:32,921 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:14:32,930 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:14:32,936 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:14:32,938 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:14:32,939 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:14:32,949 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:14:32,956 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:14:32,956 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:14:32,959 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:14:32,967 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:14:32,972 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:14:32,974 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:14:32,974 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:14:32,981 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:14:32,988 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:14:32,989 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:14:32,990 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:14:32,996 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:14:33,001 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:14:33,002 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:14:33,003 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:14:33,012 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:14:33,017 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:14:33,020 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:14:33,021 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:14:33,026 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:14:33,033 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:14:33,036 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:14:33,037 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:14:33,045 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:14:33,050 (Thread-1): 14:14:33 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:14:33,052 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:14:33,053 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:14:33,054 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:14:33,063 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:14:33,178 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:14:33,178 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:14:33,298 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:14:33,298 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:14:33,299 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  -- this filter will only be applied on an incremental run
-
-- GROUP BY 1
      );
2019-10-02 14:14:33,475 (Thread-1): Snowflake error: 001003 (42000): 018f46fa-00ed-e319-0000-0e29016210a2: SQL compilation error:
syntax error line 42 at position 6 unexpected ')'.
2019-10-02 14:14:33,475 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 14:14:33,605 (Thread-1): 14:14:33 | 1 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking. [ERROR in 0.55s]
2019-10-02 14:14:33,607 (Thread-1): 14:14:33 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:14:33,610 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:14:33,611 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:14:33,611 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:14:33,619 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:14:33,630 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:14:33,631 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:14:33,736 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:14:33,737 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:14:33,737 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 14:14:33,942 (Thread-1): Snowflake error: 002036 (42601): 018f46fa-009c-9dd9-0000-0e29016210a6: SQL compilation error:
Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:14:33,943 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:14:34,080 (Thread-1): 14:14:34 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.46s]
2019-10-02 14:14:34,086 (Thread-1): 14:14:34 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:14:34,092 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:14:34,096 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:14:34,097 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:14:34,111 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:14:34,126 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:14:34,126 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:14:34,241 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:14:34,242 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:14:34,242 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 14:14:34,438 (Thread-1): Snowflake error: 001003 (42000): 018f46fa-0017-750d-0000-0e2901620252: SQL compilation error:
syntax error line 29 at position 2 unexpected 'WHERE'.
2019-10-02 14:14:34,438 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:14:34,568 (Thread-1): 14:14:34 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.47s]
2019-10-02 14:14:34,573 (Thread-1): 14:14:34 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:14:34,582 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:14:34,583 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:14:34,584 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:14:34,605 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:14:34,625 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:14:34,626 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:14:34,734 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:14:34,735 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:14:34,736 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 14:14:35,038 (Thread-1): Snowflake error: 002036 (42601): 018f46fa-0079-3c83-0000-0e2901620256: SQL compilation error:
Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:14:35,038 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:14:35,217 (Thread-1): 14:14:35 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.63s]
2019-10-02 14:14:35,221 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:14:35,226 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:14:35,228 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:14:35,245 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:14:35,254 (Thread-1): 14:14:35 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:14:35,292 (MainThread): Using snowflake connection "master".
2019-10-02 14:14:35,293 (MainThread): On master: BEGIN
2019-10-02 14:14:35,387 (MainThread): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:14:35,388 (MainThread): On master: COMMIT
2019-10-02 14:14:35,388 (MainThread): Using snowflake connection "master".
2019-10-02 14:14:35,388 (MainThread): On master: COMMIT
2019-10-02 14:14:35,526 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:14:35,526 (MainThread): 14:14:35 | 
2019-10-02 14:14:35,527 (MainThread): 14:14:35 | Finished running 4 incremental models, 1 table model in 6.80s.
2019-10-02 14:14:35,528 (MainThread): Connection 'master' was left open.
2019-10-02 14:14:35,528 (MainThread): On master: Close
2019-10-02 14:14:35,694 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:14:35,695 (MainThread): On with_ar_currency: Close
2019-10-02 14:14:35,890 (MainThread): 
2019-10-02 14:14:35,891 (MainThread): Completed with 4 errors and 0 warnings:
2019-10-02 14:14:35,894 (MainThread): 
2019-10-02 14:14:35,896 (MainThread): Database Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
2019-10-02 14:14:35,900 (MainThread):   001003 (42000): 018f46fa-00ed-e319-0000-0e29016210a2: SQL compilation error:
2019-10-02 14:14:35,902 (MainThread):   syntax error line 42 at position 6 unexpected ')'.
2019-10-02 14:14:35,905 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking.sql
2019-10-02 14:14:35,908 (MainThread): 
2019-10-02 14:14:35,911 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:14:35,916 (MainThread):   002036 (42601): 018f46fa-009c-9dd9-0000-0e29016210a6: SQL compilation error:
2019-10-02 14:14:35,919 (MainThread):   Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:14:35,922 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:14:35,924 (MainThread): 
2019-10-02 14:14:35,927 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:14:35,932 (MainThread):   001003 (42000): 018f46fa-0017-750d-0000-0e2901620252: SQL compilation error:
2019-10-02 14:14:35,935 (MainThread):   syntax error line 29 at position 2 unexpected 'WHERE'.
2019-10-02 14:14:35,938 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:14:35,942 (MainThread): 
2019-10-02 14:14:35,945 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:14:35,952 (MainThread):   002036 (42601): 018f46fa-0079-3c83-0000-0e2901620256: SQL compilation error:
2019-10-02 14:14:35,955 (MainThread):   Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:14:35,959 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:14:35,962 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
2019-10-02 14:14:35,966 (MainThread): Flushing usage events
2019-10-02 14:18:14,856 (MainThread): Tracking: tracking
2019-10-02 14:18:14,859 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005974648>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059744C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596D748>]}
2019-10-02 14:18:15,166 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:18:15,168 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60053), raddr=('54.174.31.151', 443)>

2019-10-02 14:18:15,174 (MainThread): Error sending message, disabling tracking
2019-10-02 14:18:15,224 (MainThread): Parsing macros\core.sql
2019-10-02 14:18:15,232 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:18:15,268 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:18:15,278 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:18:15,281 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:18:15,284 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:18:15,287 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:18:15,291 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:18:15,294 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:18:15,302 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:18:15,310 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:18:15,319 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:18:15,335 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:18:15,355 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:18:15,358 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:18:15,371 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:18:15,378 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:18:15,384 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:18:15,391 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:18:15,394 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:18:15,397 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:18:15,401 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:18:15,404 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:18:15,417 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:18:15,420 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:18:15,428 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:18:15,431 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:18:15,435 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:18:15,464 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:18:15,465 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:18:15,465 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:18:15,467 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:18:15,768 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:18:15,786 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:18:16,321 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:18:16,322 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:18:16,322 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:18:16,327 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:18:16,328 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:18:16,328 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:18:16,332 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:18:16,333 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:18:16,333 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:18:16,338 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:18:16,339 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:18:16,339 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:18:16,344 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:18:16,345 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:18:16,345 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:18:16,350 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:18:16,351 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:18:16,351 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:18:16,356 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:18:16,357 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:18:16,357 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:18:16,362 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:18:16,363 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:18:16,363 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:18:16,369 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:18:16,371 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:18:16,371 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:18:16,375 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:18:16,376 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:18:16,376 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:18:16,381 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:18:16,382 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:18:16,382 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:18:16,386 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:18:16,387 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:18:16,387 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:18:16,392 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:18:16,393 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:18:16,393 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:18:16,398 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:18:16,399 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:18:16,399 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:18:16,403 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:18:16,404 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:18:16,404 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:18:16,409 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:18:16,410 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:18:16,410 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:18:16,415 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:18:16,416 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:16,416 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:18:16,427 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:18:16,428 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:18:16,429 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:18:16,434 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:18:16,435 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:18:16,435 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:18:16,440 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:18:16,441 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:18:16,441 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:18:16,500 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:18:16,503 (MainThread): 
2019-10-02 14:18:16,503 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:18:16,503 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:18:16,522 (MainThread): Parsing macros\core.sql
2019-10-02 14:18:16,529 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:18:16,573 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:18:16,600 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:18:16,605 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:18:16,613 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:18:16,621 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:18:16,627 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:18:16,632 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:18:16,652 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:18:16,663 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:18:16,682 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:18:16,706 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:18:16,748 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:18:16,753 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:18:16,769 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:18:16,776 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:18:16,782 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:18:16,793 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:18:16,798 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:18:16,802 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:18:16,806 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:18:16,813 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:18:16,832 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:18:16,836 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:18:16,845 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:18:16,849 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:18:16,856 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:18:17,045 (MainThread): Using snowflake connection "master".
2019-10-02 14:18:17,046 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:18:17,910 (MainThread): SQL status: SUCCESS 29 in 0.86 seconds
2019-10-02 14:18:17,979 (MainThread): Using snowflake connection "master".
2019-10-02 14:18:17,979 (MainThread): On master: BEGIN
2019-10-02 14:18:18,094 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:18:18,096 (MainThread): Using snowflake connection "master".
2019-10-02 14:18:18,096 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:18:19,680 (MainThread): SQL status: SUCCESS 5 in 1.58 seconds
2019-10-02 14:18:19,697 (MainThread): On master: ROLLBACK
2019-10-02 14:18:19,991 (MainThread): Using snowflake connection "master".
2019-10-02 14:18:19,992 (MainThread): On master: BEGIN
2019-10-02 14:18:20,286 (MainThread): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-02 14:18:20,288 (MainThread): On master: COMMIT
2019-10-02 14:18:20,288 (MainThread): Using snowflake connection "master".
2019-10-02 14:18:20,289 (MainThread): On master: COMMIT
2019-10-02 14:18:20,434 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:18:20,436 (MainThread): 14:18:20 | Concurrency: 1 threads (target='dev')
2019-10-02 14:18:20,437 (MainThread): 14:18:20 | 
2019-10-02 14:18:20,449 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:18:20,450 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:18:20,945 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:18:20,952 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:18:20,957 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:18:20,960 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:18:20,961 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:18:20,970 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:18:20,975 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:18:20,978 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:18:20,979 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:18:20,985 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:18:20,991 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:18:20,993 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:18:20,994 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:18:21,003 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:18:21,009 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:18:21,011 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:18:21,012 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:18:21,022 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:18:21,029 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:18:21,032 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:18:21,033 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:18:21,042 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:18:21,049 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:18:21,052 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:18:21,053 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:18:21,067 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:18:21,076 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:18:21,079 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:18:21,080 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:18:21,089 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:18:21,097 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:18:21,100 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:18:21,102 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:18:21,114 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:18:21,123 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:18:21,124 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:18:21,127 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:18:21,136 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:18:21,141 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:18:21,144 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:18:21,145 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:18:21,152 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:18:21,158 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:18:21,160 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:18:21,161 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:18:21,167 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:18:21,174 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:18:21,176 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:18:21,177 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:18:21,183 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:18:21,189 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:18:21,192 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:18:21,193 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:18:21,203 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:18:21,210 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:18:21,214 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:18:21,215 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:18:21,224 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:18:21,232 (Thread-1): 14:18:21 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:18:21,234 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:21,234 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:18:21,235 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:18:21,247 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:18:21,358 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:21,358 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:18:21,462 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:18:21,462 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:21,463 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  -- this filter will only be applied on an incremental run

-- GROUP BY 1
      );
2019-10-02 14:18:22,648 (Thread-1): SQL status: SUCCESS 1 in 1.19 seconds
2019-10-02 14:18:22,665 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:22,665 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:18:25,286 (Thread-1): SQL status: SUCCESS 23 in 2.62 seconds
2019-10-02 14:18:25,305 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:25,305 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:18:27,664 (Thread-1): SQL status: SUCCESS 23 in 2.36 seconds
2019-10-02 14:18:27,686 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:27,686 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:18:29,618 (Thread-1): SQL status: SUCCESS 23 in 1.93 seconds
2019-10-02 14:18:29,683 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:18:29,689 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:29,689 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 14:18:30,799 (Thread-1): SQL status: SUCCESS 4 in 1.11 seconds
2019-10-02 14:18:30,802 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:18:30,802 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:18:30,802 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:18:31,053 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-02 14:18:31,066 (Thread-1): 14:18:31 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 4 in 9.83s]
2019-10-02 14:18:31,069 (Thread-1): 14:18:31 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:18:31,075 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:18:31,077 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:18:31,078 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:18:31,093 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:18:31,107 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:18:31,107 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:18:31,251 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:18:31,251 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:18:31,252 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 14:18:31,491 (Thread-1): Snowflake error: 002036 (42601): 018f46fe-0016-66b1-0000-0e290161e556: SQL compilation error:
Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:18:31,491 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:18:31,624 (Thread-1): 14:18:31 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.54s]
2019-10-02 14:18:31,627 (Thread-1): 14:18:31 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:18:31,632 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:18:31,633 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:18:31,634 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:18:31,648 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:18:31,665 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:18:31,665 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:18:31,791 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:18:31,791 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:18:31,791 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 14:18:31,965 (Thread-1): Snowflake error: 001003 (42000): 018f46fe-00ee-6cc7-0000-0e290161f39a: SQL compilation error:
syntax error line 29 at position 2 unexpected 'WHERE'.
2019-10-02 14:18:31,966 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:18:32,199 (Thread-1): 14:18:32 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.56s]
2019-10-02 14:18:32,202 (Thread-1): 14:18:32 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:18:32,206 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:18:32,206 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:18:32,208 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:18:32,220 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:18:32,238 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:18:32,238 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:18:32,334 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:18:32,335 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:18:32,335 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 14:18:32,575 (Thread-1): Snowflake error: 002036 (42601): 018f46fe-0021-c786-0000-0e290162111e: SQL compilation error:
Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:18:32,576 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:18:32,721 (Thread-1): 14:18:32 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.51s]
2019-10-02 14:18:32,723 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:18:32,723 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:18:32,724 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:18:32,735 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:18:32,746 (Thread-1): 14:18:32 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:18:32,781 (MainThread): Using snowflake connection "master".
2019-10-02 14:18:32,782 (MainThread): On master: BEGIN
2019-10-02 14:18:32,920 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:18:32,920 (MainThread): On master: COMMIT
2019-10-02 14:18:32,920 (MainThread): Using snowflake connection "master".
2019-10-02 14:18:32,921 (MainThread): On master: COMMIT
2019-10-02 14:18:33,065 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:18:33,066 (MainThread): 14:18:33 | 
2019-10-02 14:18:33,066 (MainThread): 14:18:33 | Finished running 4 incremental models, 1 table model in 16.56s.
2019-10-02 14:18:33,067 (MainThread): Connection 'master' was left open.
2019-10-02 14:18:33,067 (MainThread): On master: Close
2019-10-02 14:18:33,190 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:18:33,190 (MainThread): On with_ar_currency: Close
2019-10-02 14:18:33,320 (MainThread): 
2019-10-02 14:18:33,321 (MainThread): Completed with 3 errors and 0 warnings:
2019-10-02 14:18:33,322 (MainThread): 
2019-10-02 14:18:33,322 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:18:33,323 (MainThread):   002036 (42601): 018f46fe-0016-66b1-0000-0e290161e556: SQL compilation error:
2019-10-02 14:18:33,323 (MainThread):   Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:18:33,324 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:18:33,324 (MainThread): 
2019-10-02 14:18:33,325 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:18:33,326 (MainThread):   001003 (42000): 018f46fe-00ee-6cc7-0000-0e290161f39a: SQL compilation error:
2019-10-02 14:18:33,326 (MainThread):   syntax error line 29 at position 2 unexpected 'WHERE'.
2019-10-02 14:18:33,327 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:18:33,328 (MainThread): 
2019-10-02 14:18:33,328 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:18:33,329 (MainThread):   002036 (42601): 018f46fe-0021-c786-0000-0e290162111e: SQL compilation error:
2019-10-02 14:18:33,330 (MainThread):   Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:18:33,331 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:18:33,332 (MainThread): 
Done. PASS=1 WARN=0 ERROR=3 SKIP=1 TOTAL=5
2019-10-02 14:18:33,333 (MainThread): Flushing usage events
2019-10-02 14:20:50,261 (MainThread): Tracking: tracking
2019-10-02 14:20:50,263 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005971BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C848>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E448>]}
2019-10-02 14:20:50,551 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:20:50,553 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60107), raddr=('54.174.31.151', 443)>

2019-10-02 14:20:50,555 (MainThread): Error sending message, disabling tracking
2019-10-02 14:20:50,599 (MainThread): Parsing macros\core.sql
2019-10-02 14:20:50,608 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:20:50,648 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:20:50,657 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:20:50,659 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:20:50,663 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:20:50,666 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:20:50,670 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:20:50,672 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:20:50,683 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:20:50,692 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:20:50,701 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:20:50,717 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:20:50,741 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:20:50,744 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:20:50,761 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:20:50,768 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:20:50,777 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:20:50,795 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:20:50,801 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:20:50,805 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:20:50,809 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:20:50,816 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:20:50,845 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:20:50,854 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:20:50,871 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:20:50,874 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:20:50,878 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:20:50,909 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:20:50,911 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:20:50,913 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:20:50,916 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:20:51,180 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:20:51,198 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:20:52,176 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:20:52,177 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:20:52,177 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:20:52,181 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:20:52,182 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:20:52,183 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:20:52,187 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:20:52,188 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:20:52,188 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:20:52,193 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:20:52,194 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:20:52,194 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:20:52,199 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:20:52,200 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:20:52,200 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:20:52,204 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:20:52,205 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:20:52,205 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:20:52,210 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:20:52,211 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:20:52,211 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:20:52,215 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:20:52,216 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:20:52,216 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:20:52,221 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:20:52,222 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:20:52,222 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:20:52,227 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:20:52,228 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:20:52,228 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:20:52,233 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:20:52,234 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:20:52,234 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:20:52,238 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:20:52,239 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:20:52,240 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:20:52,244 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:20:52,245 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:20:52,245 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:20:52,250 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:20:52,251 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:20:52,251 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:20:52,255 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:20:52,256 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:20:52,257 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:20:52,261 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:20:52,262 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:20:52,262 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:20:52,267 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:20:52,268 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:20:52,268 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:20:52,278 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:20:52,279 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:20:52,279 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:20:52,284 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:20:52,285 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:20:52,285 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:20:52,291 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:20:52,292 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:20:52,292 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:20:52,350 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:20:52,353 (MainThread): 
2019-10-02 14:20:52,353 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:20:52,353 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:20:52,374 (MainThread): Parsing macros\core.sql
2019-10-02 14:20:52,380 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:20:52,432 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:20:52,463 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:20:52,468 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:20:52,474 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:20:52,484 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:20:52,491 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:20:52,495 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:20:52,510 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:20:52,521 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:20:52,534 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:20:52,551 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:20:52,577 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:20:52,580 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:20:52,596 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:20:52,610 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:20:52,617 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:20:52,627 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:20:52,632 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:20:52,635 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:20:52,641 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:20:52,645 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:20:52,668 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:20:52,672 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:20:52,691 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:20:52,696 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:20:52,704 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:20:52,904 (MainThread): Using snowflake connection "master".
2019-10-02 14:20:52,904 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:20:53,599 (MainThread): SQL status: SUCCESS 29 in 0.69 seconds
2019-10-02 14:20:53,686 (MainThread): Using snowflake connection "master".
2019-10-02 14:20:53,686 (MainThread): On master: BEGIN
2019-10-02 14:20:53,907 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-02 14:20:53,908 (MainThread): Using snowflake connection "master".
2019-10-02 14:20:53,908 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:20:56,062 (MainThread): SQL status: SUCCESS 5 in 2.15 seconds
2019-10-02 14:20:56,083 (MainThread): On master: ROLLBACK
2019-10-02 14:20:56,256 (MainThread): Using snowflake connection "master".
2019-10-02 14:20:56,257 (MainThread): On master: BEGIN
2019-10-02 14:20:56,417 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:20:56,419 (MainThread): On master: COMMIT
2019-10-02 14:20:56,419 (MainThread): Using snowflake connection "master".
2019-10-02 14:20:56,420 (MainThread): On master: COMMIT
2019-10-02 14:20:56,617 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 14:20:56,619 (MainThread): 14:20:56 | Concurrency: 1 threads (target='dev')
2019-10-02 14:20:56,620 (MainThread): 14:20:56 | 
2019-10-02 14:20:56,633 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:20:56,634 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:20:57,146 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:20:57,155 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:20:57,161 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:20:57,164 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:20:57,165 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:20:57,171 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:20:57,176 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:20:57,177 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:20:57,178 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:20:57,184 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:20:57,192 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:20:57,192 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:20:57,193 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:20:57,208 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:20:57,217 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:20:57,217 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:20:57,218 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:20:57,232 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:20:57,239 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:20:57,243 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:20:57,244 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:20:57,253 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:20:57,261 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:20:57,263 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:20:57,264 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:20:57,273 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:20:57,279 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:20:57,282 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:20:57,283 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:20:57,290 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:20:57,296 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:20:57,299 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:20:57,300 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:20:57,314 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:20:57,323 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:20:57,323 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:20:57,324 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:20:57,342 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:20:57,354 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:20:57,354 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:20:57,358 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:20:57,390 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:20:57,403 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:20:57,406 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:20:57,407 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:20:57,421 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:20:57,430 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:20:57,434 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:20:57,435 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:20:57,447 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:20:57,454 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:20:57,454 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:20:57,457 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:20:57,467 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:20:57,473 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:20:57,476 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:20:57,477 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:20:57,487 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:20:57,492 (Thread-1): 14:20:57 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:20:57,495 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:20:57,495 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:20:57,496 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:20:57,505 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:20:57,620 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:20:57,621 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:20:57,753 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:20:57,754 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:20:57,754 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  -- this filter will only be applied on an incremental run

-- GROUP BY 1
      );
2019-10-02 14:20:58,474 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2019-10-02 14:20:58,492 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:20:58,493 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:21:00,825 (Thread-1): SQL status: SUCCESS 23 in 2.33 seconds
2019-10-02 14:21:00,832 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:21:00,832 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:21:03,006 (Thread-1): SQL status: SUCCESS 23 in 2.17 seconds
2019-10-02 14:21:03,012 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:21:03,012 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:21:04,963 (Thread-1): SQL status: SUCCESS 23 in 1.95 seconds
2019-10-02 14:21:04,992 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:21:04,998 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:21:04,998 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 14:21:05,779 (Thread-1): SQL status: SUCCESS 4 in 0.78 seconds
2019-10-02 14:21:05,783 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:21:05,784 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:21:05,784 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:21:05,998 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-02 14:21:06,013 (Thread-1): 14:21:06 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 4 in 8.51s]
2019-10-02 14:21:06,015 (Thread-1): 14:21:06 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:21:06,020 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:21:06,021 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:21:06,022 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:21:06,037 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:21:06,051 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:21:06,052 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:21:06,191 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:21:06,191 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:21:06,191 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 14:21:06,397 (Thread-1): Snowflake error: 002036 (42601): 018f4701-002e-9ecc-0000-0e290161f492: SQL compilation error:
Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:21:06,398 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:21:06,551 (Thread-1): 14:21:06 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.52s]
2019-10-02 14:21:06,554 (Thread-1): 14:21:06 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:21:06,562 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:21:06,563 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:21:06,566 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:21:06,589 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:21:06,606 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:21:06,607 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:21:06,701 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:21:06,702 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:21:06,702 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 14:21:06,911 (Thread-1): Snowflake error: 001003 (42000): 018f4701-00b8-bcdf-0000-0e290161f49a: SQL compilation error:
syntax error line 30 at position 2 unexpected 'WHERE'.
2019-10-02 14:21:06,911 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:21:07,041 (Thread-1): 14:21:07 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.48s]
2019-10-02 14:21:07,042 (Thread-1): 14:21:07 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:21:07,044 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:21:07,044 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:21:07,044 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:21:07,050 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:21:07,062 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:21:07,063 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:21:07,167 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:21:07,167 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:21:07,168 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 14:21:07,401 (Thread-1): Snowflake error: 002036 (42601): 018f4701-009f-4b6f-0000-0e290161e632: SQL compilation error:
Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:21:07,402 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:21:07,545 (Thread-1): 14:21:07 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.50s]
2019-10-02 14:21:07,547 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:21:07,547 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:21:07,548 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:21:07,557 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:21:07,567 (Thread-1): 14:21:07 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:21:07,674 (MainThread): Using snowflake connection "master".
2019-10-02 14:21:07,674 (MainThread): On master: BEGIN
2019-10-02 14:21:07,812 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:21:07,813 (MainThread): On master: COMMIT
2019-10-02 14:21:07,813 (MainThread): Using snowflake connection "master".
2019-10-02 14:21:07,814 (MainThread): On master: COMMIT
2019-10-02 14:21:07,981 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 14:21:07,982 (MainThread): 14:21:07 | 
2019-10-02 14:21:07,982 (MainThread): 14:21:07 | Finished running 4 incremental models, 1 table model in 15.63s.
2019-10-02 14:21:07,983 (MainThread): Connection 'master' was left open.
2019-10-02 14:21:07,983 (MainThread): On master: Close
2019-10-02 14:21:08,118 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:21:08,118 (MainThread): On with_ar_currency: Close
2019-10-02 14:21:08,259 (MainThread): 
2019-10-02 14:21:08,259 (MainThread): Completed with 3 errors and 0 warnings:
2019-10-02 14:21:08,260 (MainThread): 
2019-10-02 14:21:08,260 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:21:08,261 (MainThread):   002036 (42601): 018f4701-002e-9ecc-0000-0e290161f492: SQL compilation error:
2019-10-02 14:21:08,261 (MainThread):   Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:21:08,262 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:21:08,262 (MainThread): 
2019-10-02 14:21:08,263 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:21:08,264 (MainThread):   001003 (42000): 018f4701-00b8-bcdf-0000-0e290161f49a: SQL compilation error:
2019-10-02 14:21:08,265 (MainThread):   syntax error line 30 at position 2 unexpected 'WHERE'.
2019-10-02 14:21:08,266 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:21:08,266 (MainThread): 
2019-10-02 14:21:08,267 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:21:08,268 (MainThread):   002036 (42601): 018f4701-009f-4b6f-0000-0e290161e632: SQL compilation error:
2019-10-02 14:21:08,269 (MainThread):   Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:21:08,270 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:21:08,270 (MainThread): 
Done. PASS=1 WARN=0 ERROR=3 SKIP=1 TOTAL=5
2019-10-02 14:21:08,271 (MainThread): Flushing usage events
2019-10-02 14:24:08,646 (MainThread): Tracking: tracking
2019-10-02 14:24:08,648 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C0C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C608>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E688>]}
2019-10-02 14:24:08,941 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:24:08,942 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60127), raddr=('54.164.98.48', 443)>

2019-10-02 14:24:08,944 (MainThread): Error sending message, disabling tracking
2019-10-02 14:24:08,970 (MainThread): Parsing macros\core.sql
2019-10-02 14:24:08,983 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:24:09,041 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:24:09,051 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:24:09,053 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:24:09,056 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:24:09,060 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:24:09,063 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:24:09,065 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:24:09,073 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:24:09,081 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:24:09,089 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:24:09,106 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:24:09,127 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:24:09,130 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:24:09,143 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:24:09,150 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:24:09,155 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:24:09,162 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:24:09,165 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:24:09,167 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:24:09,169 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:24:09,172 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:24:09,188 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:24:09,191 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:24:09,199 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:24:09,202 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:24:09,206 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:24:09,232 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:24:09,234 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:24:09,234 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:24:09,236 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:24:09,467 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:24:09,483 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:24:10,051 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:24:10,052 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:24:10,052 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:24:10,056 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:24:10,057 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:24:10,057 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:24:10,062 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:24:10,063 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:24:10,063 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:24:10,068 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:24:10,069 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:24:10,069 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:24:10,073 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:24:10,074 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:24:10,074 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:24:10,079 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:24:10,080 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:24:10,080 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:24:10,084 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:24:10,085 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:24:10,086 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:24:10,090 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:24:10,091 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:24:10,091 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:24:10,097 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:24:10,098 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:24:10,098 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:24:10,102 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:24:10,103 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:24:10,103 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:24:10,108 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:24:10,109 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:24:10,109 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:24:10,114 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:24:10,115 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:24:10,115 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:24:10,120 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:24:10,121 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:24:10,121 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:24:10,128 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:24:10,129 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:24:10,129 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:24:10,135 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:24:10,136 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:24:10,136 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:24:10,142 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:24:10,143 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:24:10,143 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:24:10,148 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:24:10,149 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:10,149 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:24:10,159 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:24:10,160 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:10,160 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:24:10,166 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:24:10,168 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:24:10,168 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:24:10,177 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:24:10,178 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:10,178 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:24:10,241 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:24:10,246 (MainThread): 
2019-10-02 14:24:10,248 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:24:10,248 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:24:10,283 (MainThread): Parsing macros\core.sql
2019-10-02 14:24:10,299 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:24:10,368 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:24:10,384 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:24:10,388 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:24:10,393 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:24:10,398 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:24:10,402 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:24:10,406 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:24:10,418 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:24:10,429 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:24:10,439 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:24:10,456 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:24:10,479 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:24:10,482 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:24:10,509 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:24:10,522 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:24:10,530 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:24:10,536 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:24:10,539 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:24:10,541 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:24:10,544 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:24:10,548 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:24:10,569 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:24:10,574 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:24:10,587 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:24:10,592 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:24:10,599 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:24:10,711 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:10,712 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:24:11,328 (MainThread): SQL status: SUCCESS 29 in 0.62 seconds
2019-10-02 14:24:11,407 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:11,407 (MainThread): On master: BEGIN
2019-10-02 14:24:11,529 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:24:11,531 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:11,531 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:24:12,742 (MainThread): SQL status: SUCCESS 5 in 1.21 seconds
2019-10-02 14:24:12,754 (MainThread): On master: ROLLBACK
2019-10-02 14:24:12,883 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:12,883 (MainThread): On master: BEGIN
2019-10-02 14:24:12,986 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:24:12,987 (MainThread): On master: COMMIT
2019-10-02 14:24:12,987 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:12,987 (MainThread): On master: COMMIT
2019-10-02 14:24:13,128 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:24:13,129 (MainThread): 14:24:13 | Concurrency: 1 threads (target='dev')
2019-10-02 14:24:13,130 (MainThread): 14:24:13 | 
2019-10-02 14:24:13,141 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:24:13,141 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:24:13,591 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:24:13,611 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:24:13,621 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:24:13,626 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:24:13,628 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:24:13,638 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:24:13,643 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:24:13,644 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:24:13,644 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:24:13,652 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:24:13,656 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:24:13,658 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:24:13,659 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:24:13,667 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:24:13,674 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:24:13,675 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:24:13,675 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:24:13,681 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:24:13,688 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:24:13,690 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:24:13,690 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:24:13,698 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:24:13,702 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:24:13,703 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:24:13,703 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:24:13,716 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:24:13,724 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:24:13,724 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:24:13,725 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:24:13,737 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:24:13,748 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:24:13,750 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:24:13,751 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:24:13,759 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:24:13,769 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:24:13,769 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:24:13,770 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:24:13,786 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:24:13,794 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:24:13,798 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:24:13,799 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:24:13,809 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:24:13,817 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:24:13,817 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:24:13,820 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:24:13,829 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:24:13,835 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:24:13,838 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:24:13,839 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:24:13,845 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:24:13,852 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:24:13,855 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:24:13,856 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:24:13,866 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:24:13,872 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:24:13,875 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:24:13,876 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:24:13,885 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:24:13,892 (Thread-1): 14:24:13 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:24:13,895 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:13,895 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:24:13,896 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:24:13,909 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:24:14,018 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:14,019 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:24:14,176 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:24:14,177 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:14,178 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  where file_dt >= (select max(file_dt) from OPA_DEV.DBT_TEST.with_fl_acr_booking)

-- GROUP BY 1
      );
2019-10-02 14:24:14,404 (Thread-1): Snowflake error: 001003 (42000): 018f4704-0011-b20e-0000-0e290161f506: SQL compilation error:
syntax error line 40 at position 2 unexpected 'where'.
2019-10-02 14:24:14,405 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 14:24:14,545 (Thread-1): 14:24:14 | 1 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking. [ERROR in 0.64s]
2019-10-02 14:24:14,547 (Thread-1): 14:24:14 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:24:14,554 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:14,555 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:24:14,558 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:24:14,572 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:24:14,595 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:14,595 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:24:14,706 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:24:14,707 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:14,707 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 14:24:14,926 (Thread-1): Snowflake error: 002036 (42601): 018f4704-0018-9b1e-0000-0e290162129a: SQL compilation error:
Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:14,926 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:24:15,075 (Thread-1): 14:24:15 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.52s]
2019-10-02 14:24:15,076 (Thread-1): 14:24:15 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:24:15,079 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:24:15,079 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:24:15,080 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:24:15,092 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:24:15,105 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:24:15,105 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:24:15,870 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2019-10-02 14:24:15,872 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:24:15,873 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 14:24:16,077 (Thread-1): Snowflake error: 001003 (42000): 018f4704-0037-ef49-0000-0e290161f50e: SQL compilation error:
syntax error line 30 at position 2 unexpected 'WHERE'.
2019-10-02 14:24:16,077 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:24:16,532 (Thread-1): 14:24:16 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 1.45s]
2019-10-02 14:24:16,535 (Thread-1): 14:24:16 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:24:16,541 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:16,542 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:24:16,543 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:24:16,558 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:24:16,579 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:16,579 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:24:16,687 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:24:16,687 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:16,688 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 14:24:16,978 (Thread-1): Snowflake error: 002036 (42601): 018f4704-00e4-e99d-0000-0e290161f512: SQL compilation error:
Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:16,978 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:24:17,131 (Thread-1): 14:24:17 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.59s]
2019-10-02 14:24:17,132 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:24:17,135 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:24:17,136 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:24:17,143 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:24:17,149 (Thread-1): 14:24:17 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:24:17,193 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:17,194 (MainThread): On master: BEGIN
2019-10-02 14:24:17,294 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:24:17,295 (MainThread): On master: COMMIT
2019-10-02 14:24:17,295 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:17,295 (MainThread): On master: COMMIT
2019-10-02 14:24:17,902 (MainThread): SQL status: SUCCESS 1 in 0.61 seconds
2019-10-02 14:24:17,904 (MainThread): 14:24:17 | 
2019-10-02 14:24:17,906 (MainThread): 14:24:17 | Finished running 4 incremental models, 1 table model in 7.66s.
2019-10-02 14:24:17,908 (MainThread): Connection 'master' was left open.
2019-10-02 14:24:17,910 (MainThread): On master: Close
2019-10-02 14:24:18,055 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:24:18,057 (MainThread): On with_ar_currency: Close
2019-10-02 14:24:18,242 (MainThread): 
2019-10-02 14:24:18,243 (MainThread): Completed with 4 errors and 0 warnings:
2019-10-02 14:24:18,244 (MainThread): 
2019-10-02 14:24:18,245 (MainThread): Database Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
2019-10-02 14:24:18,246 (MainThread):   001003 (42000): 018f4704-0011-b20e-0000-0e290161f506: SQL compilation error:
2019-10-02 14:24:18,247 (MainThread):   syntax error line 40 at position 2 unexpected 'where'.
2019-10-02 14:24:18,247 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking.sql
2019-10-02 14:24:18,248 (MainThread): 
2019-10-02 14:24:18,249 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:24:18,250 (MainThread):   002036 (42601): 018f4704-0018-9b1e-0000-0e290162129a: SQL compilation error:
2019-10-02 14:24:18,251 (MainThread):   Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:18,253 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:24:18,253 (MainThread): 
2019-10-02 14:24:18,253 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:24:18,254 (MainThread):   001003 (42000): 018f4704-0037-ef49-0000-0e290161f50e: SQL compilation error:
2019-10-02 14:24:18,255 (MainThread):   syntax error line 30 at position 2 unexpected 'WHERE'.
2019-10-02 14:24:18,255 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:24:18,255 (MainThread): 
2019-10-02 14:24:18,256 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:24:18,258 (MainThread):   002036 (42601): 018f4704-00e4-e99d-0000-0e290161f512: SQL compilation error:
2019-10-02 14:24:18,259 (MainThread):   Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:18,260 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:24:18,261 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
2019-10-02 14:24:18,262 (MainThread): Flushing usage events
2019-10-02 14:24:51,442 (MainThread): Tracking: tracking
2019-10-02 14:24:51,445 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004617748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972CC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594E1C8>]}
2019-10-02 14:24:51,727 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:24:51,730 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60137), raddr=('54.164.98.48', 443)>

2019-10-02 14:24:51,735 (MainThread): Error sending message, disabling tracking
2019-10-02 14:24:51,796 (MainThread): Parsing macros\core.sql
2019-10-02 14:24:51,806 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:24:51,859 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:24:51,868 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:24:51,871 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:24:51,874 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:24:51,877 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:24:51,880 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:24:51,883 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:24:51,891 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:24:51,899 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:24:51,908 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:24:51,925 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:24:51,945 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:24:51,948 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:24:51,962 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:24:51,968 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:24:51,975 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:24:51,981 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:24:51,984 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:24:51,986 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:24:51,989 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:24:51,992 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:24:52,005 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:24:52,008 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:24:52,017 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:24:52,019 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:24:52,024 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:24:52,051 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:24:52,052 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:24:52,052 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:24:52,054 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:24:52,390 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:24:52,408 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:24:52,887 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:24:52,889 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:24:52,890 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:24:52,895 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:24:52,896 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:24:52,897 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:24:52,901 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:24:52,902 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:24:52,903 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:24:52,914 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:24:52,916 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:24:52,916 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:24:52,928 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:24:52,930 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:24:52,930 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:24:52,940 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:24:52,941 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:24:52,941 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:24:52,950 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:24:52,952 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:24:52,952 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:24:52,958 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:24:52,959 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:24:52,959 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:24:52,965 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:24:52,967 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:24:52,967 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:24:52,973 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:24:52,974 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:24:52,974 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:24:52,980 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:24:52,981 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:24:52,981 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:24:52,987 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:24:52,990 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:24:52,990 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:24:52,996 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:24:52,997 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:24:52,997 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:24:53,005 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:24:53,006 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:24:53,006 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:24:53,015 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:24:53,016 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:24:53,017 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:24:53,026 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:24:53,029 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:24:53,029 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:24:53,038 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:24:53,040 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:53,040 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:24:53,059 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:24:53,060 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:53,061 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:24:53,072 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:24:53,075 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:24:53,075 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:24:53,087 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:24:53,089 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:53,089 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:24:53,179 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:24:53,181 (MainThread): 
2019-10-02 14:24:53,181 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:24:53,182 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:24:53,203 (MainThread): Parsing macros\core.sql
2019-10-02 14:24:53,215 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:24:53,283 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:24:53,299 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:24:53,303 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:24:53,308 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:24:53,313 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:24:53,318 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:24:53,323 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:24:53,342 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:24:53,356 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:24:53,375 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:24:53,404 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:24:53,425 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:24:53,428 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:24:53,441 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:24:53,450 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:24:53,457 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:24:53,465 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:24:53,468 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:24:53,470 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:24:53,473 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:24:53,476 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:24:53,495 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:24:53,502 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:24:53,523 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:24:53,526 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:24:53,531 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:24:53,654 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:53,654 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:24:54,351 (MainThread): SQL status: SUCCESS 29 in 0.70 seconds
2019-10-02 14:24:54,433 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:54,434 (MainThread): On master: BEGIN
2019-10-02 14:24:54,539 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:24:54,541 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:54,541 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:24:55,593 (MainThread): SQL status: SUCCESS 5 in 1.05 seconds
2019-10-02 14:24:55,608 (MainThread): On master: ROLLBACK
2019-10-02 14:24:55,745 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:55,746 (MainThread): On master: BEGIN
2019-10-02 14:24:55,850 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:24:55,851 (MainThread): On master: COMMIT
2019-10-02 14:24:55,852 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:55,852 (MainThread): On master: COMMIT
2019-10-02 14:24:55,991 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:24:55,993 (MainThread): 14:24:55 | Concurrency: 1 threads (target='dev')
2019-10-02 14:24:55,994 (MainThread): 14:24:55 | 
2019-10-02 14:24:56,004 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:24:56,005 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:24:56,329 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:24:56,353 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:24:56,360 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:24:56,362 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:24:56,363 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:24:56,371 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:24:56,377 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:24:56,377 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:24:56,378 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:24:56,388 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:24:56,393 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:24:56,395 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:24:56,396 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:24:56,401 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:24:56,407 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:24:56,407 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:24:56,407 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:24:56,413 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:24:56,421 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:24:56,421 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:24:56,423 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:24:56,430 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:24:56,434 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:24:56,437 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:24:56,438 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:24:56,443 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:24:56,448 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:24:56,449 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:24:56,449 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:24:56,458 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:24:56,462 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:24:56,465 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:24:56,466 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:24:56,471 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:24:56,480 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:24:56,480 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:24:56,481 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:24:56,497 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:24:56,506 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:24:56,510 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:24:56,511 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:24:56,522 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:24:56,531 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:24:56,535 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:24:56,536 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:24:56,548 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:24:56,555 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:24:56,559 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:24:56,560 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:24:56,569 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:24:56,576 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:24:56,576 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:24:56,577 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:24:56,589 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:24:56,596 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:24:56,599 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:24:56,599 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:24:56,610 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:24:56,617 (Thread-1): 14:24:56 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:24:56,620 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:56,621 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:24:56,622 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:24:56,635 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:24:56,767 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:56,768 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:24:56,867 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:24:56,867 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:24:56,867 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  where file_dt >= (select max(file_dt) from OPA_DEV.DBT_TEST.with_fl_acr_booking)

-- GROUP BY 1
      );
2019-10-02 14:24:57,113 (Thread-1): Snowflake error: 001003 (42000): 018f4704-0091-4e14-0000-0e29016212fe: SQL compilation error:
syntax error line 39 at position 2 unexpected 'where'.
2019-10-02 14:24:57,113 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 14:24:57,295 (Thread-1): 14:24:57 | 1 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking. [ERROR in 0.67s]
2019-10-02 14:24:57,298 (Thread-1): 14:24:57 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:24:57,304 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:57,304 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:24:57,306 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:24:57,324 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:24:57,345 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:57,345 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:24:57,440 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:24:57,441 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:24:57,441 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 14:24:57,684 (Thread-1): Snowflake error: 002036 (42601): 018f4704-004f-7a8e-0000-0e2901621302: SQL compilation error:
Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:57,685 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:24:57,868 (Thread-1): 14:24:57 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.56s]
2019-10-02 14:24:57,872 (Thread-1): 14:24:57 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:24:57,878 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:24:57,879 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:24:57,880 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:24:57,894 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:24:57,916 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:24:57,916 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:24:58,093 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 14:24:58,094 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:24:58,094 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 14:24:58,288 (Thread-1): Snowflake error: 001003 (42000): 018f4704-00c2-22cd-0000-0e290161f546: SQL compilation error:
syntax error line 30 at position 2 unexpected 'WHERE'.
2019-10-02 14:24:58,289 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:24:58,441 (Thread-1): 14:24:58 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.56s]
2019-10-02 14:24:58,442 (Thread-1): 14:24:58 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:24:58,447 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:58,447 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:24:58,448 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:24:58,459 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:24:58,470 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:58,470 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:24:58,570 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:24:58,571 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:24:58,571 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 14:24:58,809 (Thread-1): Snowflake error: 002036 (42601): 018f4704-0050-6143-0000-0e290161f54e: SQL compilation error:
Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:58,809 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:24:58,949 (Thread-1): 14:24:58 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.50s]
2019-10-02 14:24:58,950 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:24:58,951 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:24:58,952 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:24:58,961 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:24:58,967 (Thread-1): 14:24:58 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:24:59,033 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:59,034 (MainThread): On master: BEGIN
2019-10-02 14:24:59,126 (MainThread): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:24:59,127 (MainThread): On master: COMMIT
2019-10-02 14:24:59,127 (MainThread): Using snowflake connection "master".
2019-10-02 14:24:59,127 (MainThread): On master: COMMIT
2019-10-02 14:24:59,276 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:24:59,276 (MainThread): 14:24:59 | 
2019-10-02 14:24:59,277 (MainThread): 14:24:59 | Finished running 4 incremental models, 1 table model in 6.10s.
2019-10-02 14:24:59,278 (MainThread): Connection 'master' was left open.
2019-10-02 14:24:59,278 (MainThread): On master: Close
2019-10-02 14:24:59,402 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:24:59,403 (MainThread): On with_ar_currency: Close
2019-10-02 14:24:59,602 (MainThread): 
2019-10-02 14:24:59,603 (MainThread): Completed with 4 errors and 0 warnings:
2019-10-02 14:24:59,604 (MainThread): 
2019-10-02 14:24:59,605 (MainThread): Database Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
2019-10-02 14:24:59,606 (MainThread):   001003 (42000): 018f4704-0091-4e14-0000-0e29016212fe: SQL compilation error:
2019-10-02 14:24:59,608 (MainThread):   syntax error line 39 at position 2 unexpected 'where'.
2019-10-02 14:24:59,609 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking.sql
2019-10-02 14:24:59,610 (MainThread): 
2019-10-02 14:24:59,610 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:24:59,612 (MainThread):   002036 (42601): 018f4704-004f-7a8e-0000-0e2901621302: SQL compilation error:
2019-10-02 14:24:59,612 (MainThread):   Subquery containing correlated aggregate function [MAX(BK_SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:59,613 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:24:59,615 (MainThread): 
2019-10-02 14:24:59,616 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:24:59,618 (MainThread):   001003 (42000): 018f4704-00c2-22cd-0000-0e290161f546: SQL compilation error:
2019-10-02 14:24:59,618 (MainThread):   syntax error line 30 at position 2 unexpected 'WHERE'.
2019-10-02 14:24:59,619 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:24:59,620 (MainThread): 
2019-10-02 14:24:59,622 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:24:59,624 (MainThread):   002036 (42601): 018f4704-0050-6143-0000-0e290161f54e: SQL compilation error:
2019-10-02 14:24:59,625 (MainThread):   Subquery containing correlated aggregate function [MAX(SER_E_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:24:59,626 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:24:59,628 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
2019-10-02 14:24:59,629 (MainThread): Flushing usage events
2019-10-02 14:28:07,793 (MainThread): Tracking: tracking
2019-10-02 14:28:07,795 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C5C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005971B88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005961E48>]}
2019-10-02 14:28:08,094 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:28:08,095 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60155), raddr=('54.164.98.48', 443)>

2019-10-02 14:28:08,096 (MainThread): Error sending message, disabling tracking
2019-10-02 14:28:08,117 (MainThread): Parsing macros\core.sql
2019-10-02 14:28:08,126 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:28:08,163 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:28:08,172 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:28:08,174 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:28:08,178 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:28:08,181 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:28:08,184 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:28:08,186 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:28:08,194 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:28:08,202 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:28:08,211 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:28:08,228 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:28:08,252 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:28:08,259 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:28:08,279 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:28:08,286 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:28:08,292 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:28:08,298 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:28:08,301 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:28:08,303 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:28:08,305 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:28:08,308 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:28:08,320 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:28:08,324 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:28:08,332 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:28:08,335 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:28:08,340 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:28:08,368 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:28:08,370 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:28:08,370 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:28:08,372 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:28:08,680 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:28:08,697 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:28:09,660 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:28:09,661 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:28:09,661 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:28:09,665 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:28:09,666 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:28:09,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:28:09,670 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:28:09,671 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:28:09,671 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:28:09,676 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:28:09,677 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:28:09,677 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:28:09,682 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:28:09,683 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:28:09,683 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:28:09,687 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:28:09,688 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:28:09,688 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:28:09,693 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:28:09,694 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:28:09,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:28:09,698 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:28:09,699 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:28:09,699 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:28:09,704 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:28:09,706 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:28:09,706 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:28:09,710 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:28:09,711 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:28:09,711 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:28:09,716 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:28:09,717 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:28:09,717 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:28:09,721 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:28:09,723 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:28:09,723 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:28:09,727 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:28:09,728 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:28:09,729 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:28:09,733 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:28:09,734 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:28:09,734 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:28:09,738 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:28:09,739 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:28:09,739 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:28:09,744 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:28:09,745 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:28:09,745 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:28:09,749 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:28:09,750 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:28:09,751 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:28:09,761 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:28:09,762 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:28:09,762 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:28:09,767 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:28:09,768 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:28:09,768 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:28:09,773 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:28:09,774 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:28:09,774 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:28:09,835 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:28:09,838 (MainThread): 
2019-10-02 14:28:09,838 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:28:09,838 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:28:09,869 (MainThread): Parsing macros\core.sql
2019-10-02 14:28:09,880 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:28:09,969 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:28:09,984 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:28:09,988 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:28:09,992 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:28:09,997 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:28:10,000 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:28:10,003 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:28:10,015 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:28:10,023 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:28:10,032 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:28:10,052 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:28:10,079 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:28:10,082 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:28:10,112 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:28:10,127 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:28:10,139 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:28:10,153 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:28:10,157 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:28:10,160 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:28:10,164 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:28:10,168 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:28:10,192 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:28:10,196 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:28:10,211 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:28:10,214 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:28:10,220 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:28:10,330 (MainThread): Using snowflake connection "master".
2019-10-02 14:28:10,330 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:28:10,966 (MainThread): SQL status: SUCCESS 29 in 0.64 seconds
2019-10-02 14:28:11,039 (MainThread): Using snowflake connection "master".
2019-10-02 14:28:11,040 (MainThread): On master: BEGIN
2019-10-02 14:28:11,233 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-02 14:28:11,235 (MainThread): Using snowflake connection "master".
2019-10-02 14:28:11,235 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:28:13,535 (MainThread): SQL status: SUCCESS 5 in 2.30 seconds
2019-10-02 14:28:13,556 (MainThread): On master: ROLLBACK
2019-10-02 14:28:13,811 (MainThread): Using snowflake connection "master".
2019-10-02 14:28:13,812 (MainThread): On master: BEGIN
2019-10-02 14:28:14,054 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 14:28:14,056 (MainThread): On master: COMMIT
2019-10-02 14:28:14,057 (MainThread): Using snowflake connection "master".
2019-10-02 14:28:14,057 (MainThread): On master: COMMIT
2019-10-02 14:28:14,256 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 14:28:14,258 (MainThread): 14:28:14 | Concurrency: 1 threads (target='dev')
2019-10-02 14:28:14,260 (MainThread): 14:28:14 | 
2019-10-02 14:28:14,271 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:28:14,272 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:28:14,620 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:28:14,645 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:28:14,656 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:28:14,660 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:28:14,661 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:28:14,672 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:28:14,683 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:28:14,684 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:28:14,685 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:28:14,696 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:28:14,702 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:28:14,702 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:28:14,703 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:28:14,716 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:28:14,722 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:28:14,726 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:28:14,727 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:28:14,737 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:28:14,745 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:28:14,748 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:28:14,749 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:28:14,757 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:28:14,765 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:28:14,765 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:28:14,766 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:28:14,779 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:28:14,787 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:28:14,791 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:28:14,792 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:28:14,803 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:28:14,811 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:28:14,812 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:28:14,815 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:28:14,827 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:28:14,835 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:28:14,838 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:28:14,839 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:28:14,849 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:28:14,857 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:28:14,857 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:28:14,861 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:28:14,868 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:28:14,875 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:28:14,878 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:28:14,879 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:28:14,886 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:28:14,893 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:28:14,896 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:28:14,896 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:28:14,902 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:28:14,909 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:28:14,911 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:28:14,912 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:28:14,919 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:28:14,925 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:28:14,928 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:28:14,929 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:28:14,938 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:28:14,945 (Thread-1): 14:28:14 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:28:14,948 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:28:14,948 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:28:14,949 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:28:14,962 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:28:15,123 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:28:15,124 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:28:15,235 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:28:15,236 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:28:15,236 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking)

-- GROUP BY 1
      );
2019-10-02 14:28:15,551 (Thread-1): Snowflake error: 002036 (42601): 018f4708-00f3-b269-0000-0e29016213d6: SQL compilation error:
Subquery containing correlated aggregate function [MAX(BK_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:28:15,551 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 14:28:15,835 (Thread-1): 14:28:15 | 1 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking. [ERROR in 0.89s]
2019-10-02 14:28:15,836 (Thread-1): 14:28:15 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:28:15,838 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:28:15,838 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:28:15,839 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:28:15,845 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:28:15,862 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:28:15,862 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:28:16,008 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:28:16,009 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:28:16,009 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 14:28:16,240 (Thread-1): Snowflake error: 001003 (42000): 018f4708-0024-a466-0000-0e290161f632: SQL compilation error:
syntax error line 22 at position 2 unexpected 'AND'.
syntax error line 22 at position 38 unexpected 'FROM'.
2019-10-02 14:28:16,241 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:28:16,445 (Thread-1): 14:28:16 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.60s]
2019-10-02 14:28:16,449 (Thread-1): 14:28:16 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:28:16,454 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:28:16,455 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:28:16,456 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:28:16,479 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:28:16,502 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:28:16,502 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:28:16,621 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:28:16,622 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:28:16,622 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 14:28:16,901 (Thread-1): Snowflake error: 002036 (42601): 018f4708-0060-b8bc-0000-0e290161f63e: SQL compilation error:
Subquery containing correlated aggregate function [MAX(SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:28:16,901 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:28:17,074 (Thread-1): 14:28:17 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.62s]
2019-10-02 14:28:17,074 (Thread-1): 14:28:17 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:28:17,076 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:28:17,076 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:28:17,076 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:28:17,082 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:28:17,092 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:28:17,092 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:28:17,216 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:28:17,217 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:28:17,217 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 14:28:17,412 (Thread-1): Snowflake error: 001003 (42000): 018f4708-0006-fdf2-0000-0e290161e826: SQL compilation error:
syntax error line 19 at position 2 unexpected 'AND'.
syntax error line 19 at position 38 unexpected 'FROM'.
2019-10-02 14:28:17,412 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:28:17,631 (Thread-1): 14:28:17 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.55s]
2019-10-02 14:28:17,634 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:28:17,637 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:28:17,638 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:28:17,650 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:28:17,656 (Thread-1): 14:28:17 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:28:17,745 (MainThread): Using snowflake connection "master".
2019-10-02 14:28:17,745 (MainThread): On master: BEGIN
2019-10-02 14:28:17,909 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:28:17,909 (MainThread): On master: COMMIT
2019-10-02 14:28:17,909 (MainThread): Using snowflake connection "master".
2019-10-02 14:28:17,909 (MainThread): On master: COMMIT
2019-10-02 14:28:18,119 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-02 14:28:18,120 (MainThread): 14:28:18 | 
2019-10-02 14:28:18,122 (MainThread): 14:28:18 | Finished running 4 incremental models, 1 table model in 8.28s.
2019-10-02 14:28:18,123 (MainThread): Connection 'master' was left open.
2019-10-02 14:28:18,125 (MainThread): On master: Close
2019-10-02 14:28:18,364 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:28:18,366 (MainThread): On with_ar_currency: Close
2019-10-02 14:28:18,618 (MainThread): 
2019-10-02 14:28:18,619 (MainThread): Completed with 4 errors and 0 warnings:
2019-10-02 14:28:18,620 (MainThread): 
2019-10-02 14:28:18,620 (MainThread): Database Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
2019-10-02 14:28:18,622 (MainThread):   002036 (42601): 018f4708-00f3-b269-0000-0e29016213d6: SQL compilation error:
2019-10-02 14:28:18,622 (MainThread):   Subquery containing correlated aggregate function [MAX(BK_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:28:18,623 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking.sql
2019-10-02 14:28:18,624 (MainThread): 
2019-10-02 14:28:18,625 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:28:18,626 (MainThread):   001003 (42000): 018f4708-0024-a466-0000-0e290161f632: SQL compilation error:
2019-10-02 14:28:18,627 (MainThread):   syntax error line 22 at position 2 unexpected 'AND'.
2019-10-02 14:28:18,628 (MainThread):   syntax error line 22 at position 38 unexpected 'FROM'.
2019-10-02 14:28:18,628 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:28:18,629 (MainThread): 
2019-10-02 14:28:18,630 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:28:18,631 (MainThread):   002036 (42601): 018f4708-0060-b8bc-0000-0e290161f63e: SQL compilation error:
2019-10-02 14:28:18,631 (MainThread):   Subquery containing correlated aggregate function [MAX(SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:28:18,632 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:28:18,633 (MainThread): 
2019-10-02 14:28:18,633 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:28:18,636 (MainThread):   001003 (42000): 018f4708-0006-fdf2-0000-0e290161e826: SQL compilation error:
2019-10-02 14:28:18,636 (MainThread):   syntax error line 19 at position 2 unexpected 'AND'.
2019-10-02 14:28:18,637 (MainThread):   syntax error line 19 at position 38 unexpected 'FROM'.
2019-10-02 14:28:18,638 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:28:18,639 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
2019-10-02 14:28:18,640 (MainThread): Flushing usage events
2019-10-02 14:29:53,420 (MainThread): Tracking: tracking
2019-10-02 14:29:53,422 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005975748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005975888>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E848>]}
2019-10-02 14:29:53,727 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:29:53,729 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60171), raddr=('54.174.31.151', 443)>

2019-10-02 14:29:53,734 (MainThread): Error sending message, disabling tracking
2019-10-02 14:29:53,791 (MainThread): Parsing macros\core.sql
2019-10-02 14:29:53,803 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:29:53,838 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:29:53,848 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:29:53,850 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:29:53,853 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:29:53,857 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:29:53,860 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:29:53,862 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:29:53,871 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:29:53,879 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:29:53,887 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:29:53,904 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:29:53,924 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:29:53,927 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:29:53,940 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:29:53,947 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:29:53,953 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:29:53,959 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:29:53,962 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:29:53,964 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:29:53,966 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:29:53,969 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:29:53,982 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:29:53,985 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:29:53,993 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:29:53,996 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:29:54,001 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:29:54,028 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:29:54,029 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:29:54,029 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:29:54,031 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:29:54,308 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:29:54,327 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:29:54,979 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:29:54,980 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:29:54,980 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:29:54,986 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:29:54,987 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:29:54,987 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:29:54,993 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:29:54,995 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:29:54,996 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:29:55,003 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:29:55,005 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:29:55,005 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:29:55,012 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:29:55,013 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:29:55,013 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:29:55,020 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:29:55,022 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:29:55,022 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:29:55,031 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:29:55,032 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:29:55,033 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:29:55,038 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:29:55,039 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:29:55,039 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:29:55,044 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:29:55,045 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:29:55,046 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:29:55,050 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:29:55,051 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:29:55,051 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:29:55,056 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:29:55,057 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:29:55,057 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:29:55,061 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:29:55,062 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:29:55,063 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:29:55,067 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:29:55,068 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:29:55,068 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:29:55,073 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:29:55,074 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:29:55,074 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:29:55,079 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:29:55,080 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:29:55,080 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:29:55,085 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:29:55,086 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:29:55,086 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:29:55,091 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:29:55,092 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:29:55,092 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:29:55,102 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:29:55,103 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:29:55,104 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:29:55,109 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:29:55,110 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:29:55,110 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:29:55,115 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:29:55,116 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:29:55,117 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:29:55,176 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:29:55,179 (MainThread): 
2019-10-02 14:29:55,179 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:29:55,179 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:29:55,200 (MainThread): Parsing macros\core.sql
2019-10-02 14:29:55,206 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:29:55,294 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:29:55,306 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:29:55,308 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:29:55,312 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:29:55,317 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:29:55,320 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:29:55,323 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:29:55,332 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:29:55,345 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:29:55,355 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:29:55,378 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:29:55,402 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:29:55,409 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:29:55,436 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:29:55,444 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:29:55,450 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:29:55,458 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:29:55,460 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:29:55,463 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:29:55,465 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:29:55,468 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:29:55,484 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:29:55,488 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:29:55,496 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:29:55,498 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:29:55,503 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:29:55,616 (MainThread): Using snowflake connection "master".
2019-10-02 14:29:55,616 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:29:56,149 (MainThread): SQL status: SUCCESS 29 in 0.53 seconds
2019-10-02 14:29:56,256 (MainThread): Using snowflake connection "master".
2019-10-02 14:29:56,256 (MainThread): On master: BEGIN
2019-10-02 14:29:56,352 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:29:56,354 (MainThread): Using snowflake connection "master".
2019-10-02 14:29:56,355 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:29:57,495 (MainThread): SQL status: SUCCESS 5 in 1.14 seconds
2019-10-02 14:29:57,516 (MainThread): On master: ROLLBACK
2019-10-02 14:29:57,666 (MainThread): Using snowflake connection "master".
2019-10-02 14:29:57,667 (MainThread): On master: BEGIN
2019-10-02 14:29:57,771 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:29:57,773 (MainThread): On master: COMMIT
2019-10-02 14:29:57,773 (MainThread): Using snowflake connection "master".
2019-10-02 14:29:57,774 (MainThread): On master: COMMIT
2019-10-02 14:29:57,916 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:29:57,918 (MainThread): 14:29:57 | Concurrency: 1 threads (target='dev')
2019-10-02 14:29:57,919 (MainThread): 14:29:57 | 
2019-10-02 14:29:57,932 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:29:57,933 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:29:58,465 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:29:58,488 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:29:58,497 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:29:58,501 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:29:58,502 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:29:58,514 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:29:58,518 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:29:58,520 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:29:58,521 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:29:58,529 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:29:58,534 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:29:58,534 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:29:58,535 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:29:58,544 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:29:58,549 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:29:58,552 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:29:58,553 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:29:58,565 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:29:58,570 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:29:58,574 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:29:58,575 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:29:58,587 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:29:58,596 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:29:58,599 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:29:58,600 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:29:58,609 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:29:58,616 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:29:58,620 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:29:58,621 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:29:58,632 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:29:58,640 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:29:58,643 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:29:58,644 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:29:58,655 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:29:58,662 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:29:58,667 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:29:58,668 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:29:58,690 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:29:58,698 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:29:58,699 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:29:58,702 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:29:58,713 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:29:58,721 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:29:58,723 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:29:58,724 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:29:58,732 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:29:58,739 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:29:58,740 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:29:58,741 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:29:58,753 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:29:58,760 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:29:58,763 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:29:58,764 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:29:58,772 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:29:58,778 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:29:58,779 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:29:58,780 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:29:58,791 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:29:58,797 (Thread-1): 14:29:58 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:29:58,799 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:29:58,800 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:29:58,800 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:29:58,809 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:29:58,915 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:29:58,915 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:29:59,029 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:29:59,030 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:29:59,030 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_stream_test bk_1)

-- GROUP BY 1
      );
2019-10-02 14:29:59,813 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2019-10-02 14:29:59,830 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:29:59,830 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:30:04,385 (Thread-1): SQL status: SUCCESS 24 in 4.55 seconds
2019-10-02 14:30:04,406 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:30:04,407 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:30:06,219 (Thread-1): SQL status: SUCCESS 23 in 1.81 seconds
2019-10-02 14:30:06,240 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:30:06,241 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:30:08,013 (Thread-1): SQL status: SUCCESS 23 in 1.77 seconds
2019-10-02 14:30:08,084 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:30:08,095 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:30:08,095 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 14:30:08,884 (Thread-1): SQL status: SUCCESS 2 in 0.79 seconds
2019-10-02 14:30:08,886 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:30:08,886 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:30:08,886 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:30:09,140 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-02 14:30:09,155 (Thread-1): 14:30:09 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 2 in 10.35s]
2019-10-02 14:30:09,157 (Thread-1): 14:30:09 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:30:09,163 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:30:09,164 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:30:09,165 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:30:09,178 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:30:09,199 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:30:09,199 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:30:09,330 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:30:09,331 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:30:09,331 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service)

-- GROUP BY 1
      );
2019-10-02 14:30:09,587 (Thread-1): Snowflake error: 001003 (42000): 018f470a-0063-53be-0000-0e2901621486: SQL compilation error:
syntax error line 22 at position 2 unexpected 'AND'.
syntax error line 22 at position 38 unexpected 'FROM'.
2019-10-02 14:30:09,588 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:30:09,725 (Thread-1): 14:30:09 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.56s]
2019-10-02 14:30:09,728 (Thread-1): 14:30:09 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:30:09,729 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:30:09,729 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:30:09,733 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:30:09,745 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:30:09,758 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:30:09,759 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:30:09,923 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:30:09,923 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:30:09,924 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service)

-- GROUP BY 1
      );
2019-10-02 14:30:10,128 (Thread-1): Snowflake error: 002036 (42601): 018f470a-0002-78d9-0000-0e290161e8ca: SQL compilation error:
Subquery containing correlated aggregate function [MAX(SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:30:10,129 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 14:30:10,320 (Thread-1): 14:30:10 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.59s]
2019-10-02 14:30:10,324 (Thread-1): 14:30:10 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:30:10,330 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:30:10,330 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:30:10,332 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:30:10,346 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:30:10,363 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:30:10,364 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:30:10,489 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:30:10,490 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:30:10,490 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_service_element)

-- GROUP BY 1
      );
2019-10-02 14:30:10,669 (Thread-1): Snowflake error: 001003 (42000): 018f470a-00e0-b30b-0000-0e290161f70e: SQL compilation error:
syntax error line 19 at position 2 unexpected 'AND'.
syntax error line 19 at position 38 unexpected 'FROM'.
2019-10-02 14:30:10,669 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:30:10,835 (Thread-1): 14:30:10 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.50s]
2019-10-02 14:30:10,836 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:30:10,838 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:30:10,839 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:30:10,845 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:30:10,851 (Thread-1): 14:30:10 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:30:10,921 (MainThread): Using snowflake connection "master".
2019-10-02 14:30:10,922 (MainThread): On master: BEGIN
2019-10-02 14:30:11,063 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:30:11,064 (MainThread): On master: COMMIT
2019-10-02 14:30:11,064 (MainThread): Using snowflake connection "master".
2019-10-02 14:30:11,065 (MainThread): On master: COMMIT
2019-10-02 14:30:11,229 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:30:11,230 (MainThread): 14:30:11 | 
2019-10-02 14:30:11,231 (MainThread): 14:30:11 | Finished running 4 incremental models, 1 table model in 16.05s.
2019-10-02 14:30:11,231 (MainThread): Connection 'master' was left open.
2019-10-02 14:30:11,231 (MainThread): On master: Close
2019-10-02 14:30:11,357 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:30:11,358 (MainThread): On with_ar_currency: Close
2019-10-02 14:30:11,570 (MainThread): 
2019-10-02 14:30:11,570 (MainThread): Completed with 3 errors and 0 warnings:
2019-10-02 14:30:11,572 (MainThread): 
2019-10-02 14:30:11,572 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:30:11,574 (MainThread):   001003 (42000): 018f470a-0063-53be-0000-0e2901621486: SQL compilation error:
2019-10-02 14:30:11,574 (MainThread):   syntax error line 22 at position 2 unexpected 'AND'.
2019-10-02 14:30:11,575 (MainThread):   syntax error line 22 at position 38 unexpected 'FROM'.
2019-10-02 14:30:11,576 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:30:11,576 (MainThread): 
2019-10-02 14:30:11,577 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 14:30:11,579 (MainThread):   002036 (42601): 018f470a-0002-78d9-0000-0e290161e8ca: SQL compilation error:
2019-10-02 14:30:11,580 (MainThread):   Subquery containing correlated aggregate function [MAX(SER_1.FILE_DT)] can only appear in having or select clause
2019-10-02 14:30:11,580 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 14:30:11,581 (MainThread): 
2019-10-02 14:30:11,581 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:30:11,583 (MainThread):   001003 (42000): 018f470a-00e0-b30b-0000-0e290161f70e: SQL compilation error:
2019-10-02 14:30:11,584 (MainThread):   syntax error line 19 at position 2 unexpected 'AND'.
2019-10-02 14:30:11,585 (MainThread):   syntax error line 19 at position 38 unexpected 'FROM'.
2019-10-02 14:30:11,585 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:30:11,586 (MainThread): 
Done. PASS=1 WARN=0 ERROR=3 SKIP=1 TOTAL=5
2019-10-02 14:30:11,587 (MainThread): Flushing usage events
2019-10-02 14:30:53,106 (MainThread): Tracking: tracking
2019-10-02 14:30:53,108 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005971208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005971248>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596D848>]}
2019-10-02 14:30:53,388 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:30:53,388 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60178), raddr=('54.164.98.48', 443)>

2019-10-02 14:30:53,390 (MainThread): Error sending message, disabling tracking
2019-10-02 14:30:53,413 (MainThread): Parsing macros\core.sql
2019-10-02 14:30:53,420 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:30:53,457 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:30:53,467 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:30:53,469 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:30:53,472 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:30:53,475 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:30:53,478 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:30:53,480 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:30:53,488 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:30:53,496 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:30:53,504 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:30:53,521 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:30:53,541 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:30:53,544 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:30:53,557 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:30:53,563 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:30:53,569 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:30:53,576 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:30:53,578 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:30:53,580 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:30:53,583 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:30:53,585 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:30:53,598 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:30:53,601 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:30:53,610 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:30:53,612 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:30:53,617 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:30:53,644 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:30:53,646 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:30:53,646 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:30:53,648 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:30:53,987 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:30:54,004 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:30:54,694 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:30:54,695 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:30:54,695 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:30:54,700 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:30:54,701 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:30:54,701 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:30:54,707 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:30:54,709 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:30:54,709 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:30:54,718 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:30:54,720 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:30:54,720 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:30:54,732 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:30:54,735 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:30:54,735 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:30:54,747 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:30:54,750 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:30:54,750 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:30:54,761 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:30:54,763 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:30:54,763 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:30:54,772 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:30:54,773 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:30:54,773 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:30:54,785 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:30:54,787 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:30:54,787 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:30:54,798 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:30:54,800 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:30:54,800 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:30:54,814 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:30:54,816 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:30:54,816 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:30:54,825 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:30:54,827 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:30:54,827 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:30:54,835 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:30:54,837 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:30:54,837 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:30:54,846 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:30:54,848 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:30:54,848 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:30:54,858 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:30:54,860 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:30:54,860 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:30:54,869 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:30:54,871 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:30:54,871 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:30:54,879 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:30:54,881 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:30:54,881 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:30:54,894 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:30:54,895 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:30:54,895 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:30:54,900 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:30:54,901 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:30:54,901 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:30:54,906 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:30:54,907 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:30:54,907 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:30:54,985 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:30:54,990 (MainThread): 
2019-10-02 14:30:54,992 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:30:54,993 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:30:55,021 (MainThread): Parsing macros\core.sql
2019-10-02 14:30:55,029 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:30:55,133 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:30:55,165 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:30:55,171 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:30:55,180 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:30:55,188 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:30:55,193 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:30:55,196 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:30:55,206 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:30:55,214 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:30:55,222 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:30:55,244 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:30:55,269 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:30:55,272 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:30:55,286 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:30:55,295 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:30:55,305 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:30:55,322 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:30:55,328 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:30:55,332 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:30:55,336 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:30:55,339 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:30:55,354 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:30:55,392 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:30:55,403 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:30:55,406 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:30:55,422 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:30:55,570 (MainThread): Using snowflake connection "master".
2019-10-02 14:30:55,571 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:30:56,516 (MainThread): SQL status: SUCCESS 29 in 0.95 seconds
2019-10-02 14:30:56,617 (MainThread): Using snowflake connection "master".
2019-10-02 14:30:56,617 (MainThread): On master: BEGIN
2019-10-02 14:30:56,722 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:30:56,724 (MainThread): Using snowflake connection "master".
2019-10-02 14:30:56,724 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:30:58,711 (MainThread): SQL status: SUCCESS 5 in 1.99 seconds
2019-10-02 14:30:58,722 (MainThread): On master: ROLLBACK
2019-10-02 14:30:58,877 (MainThread): Using snowflake connection "master".
2019-10-02 14:30:58,877 (MainThread): On master: BEGIN
2019-10-02 14:30:58,986 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:30:58,986 (MainThread): On master: COMMIT
2019-10-02 14:30:58,987 (MainThread): Using snowflake connection "master".
2019-10-02 14:30:58,987 (MainThread): On master: COMMIT
2019-10-02 14:30:59,192 (MainThread): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-02 14:30:59,194 (MainThread): 14:30:59 | Concurrency: 1 threads (target='dev')
2019-10-02 14:30:59,195 (MainThread): 14:30:59 | 
2019-10-02 14:30:59,208 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:30:59,209 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:30:59,763 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:30:59,784 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:30:59,795 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:30:59,799 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:30:59,800 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:30:59,808 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:30:59,814 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:30:59,816 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:30:59,817 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:30:59,824 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:30:59,831 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:30:59,834 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:30:59,835 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:30:59,845 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:30:59,850 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:30:59,853 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:30:59,854 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:30:59,861 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:30:59,866 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:30:59,869 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:30:59,870 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:30:59,876 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:30:59,881 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:30:59,881 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:30:59,882 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:30:59,892 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:30:59,899 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:30:59,903 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:30:59,904 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:30:59,917 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:30:59,925 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:30:59,926 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:30:59,927 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:30:59,942 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:30:59,950 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:30:59,950 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:30:59,954 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:30:59,964 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:30:59,971 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:30:59,975 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:30:59,976 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:30:59,986 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:30:59,993 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:30:59,995 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:30:59,996 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:31:00,007 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:31:00,014 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:31:00,014 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:31:00,015 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:31:00,029 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:31:00,036 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:31:00,036 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:31:00,037 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:31:00,050 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:31:00,057 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:31:00,061 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:31:00,062 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:31:00,072 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:31:00,079 (Thread-1): 14:31:00 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:31:00,082 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:00,082 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:31:00,083 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:31:00,098 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:31:00,215 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:00,216 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:31:00,366 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:31:00,366 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:00,366 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_stream_test bk_1)

-- GROUP BY 1
      );
2019-10-02 14:31:01,059 (Thread-1): SQL status: SUCCESS 1 in 0.69 seconds
2019-10-02 14:31:01,066 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:01,066 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:31:03,145 (Thread-1): SQL status: SUCCESS 24 in 2.08 seconds
2019-10-02 14:31:03,156 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:03,156 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:31:05,005 (Thread-1): SQL status: SUCCESS 23 in 1.85 seconds
2019-10-02 14:31:05,011 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:05,011 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:31:06,784 (Thread-1): SQL status: SUCCESS 23 in 1.77 seconds
2019-10-02 14:31:06,807 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:31:06,811 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:06,811 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 14:31:07,559 (Thread-1): SQL status: SUCCESS 2 in 0.75 seconds
2019-10-02 14:31:07,560 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:31:07,561 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:07,561 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:31:07,785 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-02 14:31:07,789 (Thread-1): 14:31:07 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 2 in 7.71s]
2019-10-02 14:31:07,790 (Thread-1): 14:31:07 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:31:07,792 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:31:07,792 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:31:07,792 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:31:07,798 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:31:07,814 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:31:07,814 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:31:07,921 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:31:07,922 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:31:07,922 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:31:08,090 (Thread-1): Snowflake error: 001003 (42000): 018f470b-0053-be9b-0000-0e290161f766: SQL compilation error:
syntax error line 22 at position 2 unexpected 'AND'.
syntax error line 22 at position 38 unexpected 'FROM'.
2019-10-02 14:31:08,090 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 14:31:08,337 (Thread-1): 14:31:08 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.54s]
2019-10-02 14:31:08,338 (Thread-1): 14:31:08 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:31:08,340 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:31:08,340 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:31:08,341 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:31:08,347 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:31:08,359 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:31:08,359 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:31:08,491 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:31:08,491 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:31:08,491 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:31:11,898 (Thread-1): SQL status: SUCCESS 1 in 3.41 seconds
2019-10-02 14:31:11,916 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:31:11,916 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:31:13,795 (Thread-1): SQL status: SUCCESS 15 in 1.88 seconds
2019-10-02 14:31:13,801 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:31:13,801 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:31:16,024 (Thread-1): SQL status: SUCCESS 14 in 2.22 seconds
2019-10-02 14:31:16,042 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:31:16,042 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:31:18,325 (Thread-1): SQL status: SUCCESS 14 in 2.28 seconds
2019-10-02 14:31:18,339 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:31:18,349 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:31:18,349 (Thread-1): On with_fl_acr_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_service (SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE)
        (
            select SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE
            from OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
        );
2019-10-02 14:31:19,107 (Thread-1): SQL status: SUCCESS 12 in 0.76 seconds
2019-10-02 14:31:19,109 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:31:19,109 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:31:19,110 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:31:19,350 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 14:31:19,355 (Thread-1): 14:31:19 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 12 in 11.01s]
2019-10-02 14:31:19,357 (Thread-1): 14:31:19 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:31:19,360 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:31:19,360 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:31:19,361 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:31:19,369 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:31:19,384 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:31:19,384 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:31:19,514 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:31:19,515 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:31:19,515 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_element_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:31:19,706 (Thread-1): Snowflake error: 001003 (42000): 018f470b-0078-d8cb-0000-0e290161f786: SQL compilation error:
syntax error line 19 at position 2 unexpected 'AND'.
syntax error line 19 at position 38 unexpected 'FROM'.
2019-10-02 14:31:19,706 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 14:31:19,854 (Thread-1): 14:31:19 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.49s]
2019-10-02 14:31:19,858 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:31:19,858 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:31:19,860 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:31:19,880 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:31:19,888 (Thread-1): 14:31:19 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 14:31:19,991 (MainThread): Using snowflake connection "master".
2019-10-02 14:31:19,991 (MainThread): On master: BEGIN
2019-10-02 14:31:20,150 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:31:20,150 (MainThread): On master: COMMIT
2019-10-02 14:31:20,150 (MainThread): Using snowflake connection "master".
2019-10-02 14:31:20,151 (MainThread): On master: COMMIT
2019-10-02 14:31:20,372 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-02 14:31:20,375 (MainThread): 14:31:20 | 
2019-10-02 14:31:20,376 (MainThread): 14:31:20 | Finished running 4 incremental models, 1 table model in 25.38s.
2019-10-02 14:31:20,377 (MainThread): Connection 'master' was left open.
2019-10-02 14:31:20,379 (MainThread): On master: Close
2019-10-02 14:31:20,502 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 14:31:20,503 (MainThread): On with_ar_currency: Close
2019-10-02 14:31:20,687 (MainThread): 
2019-10-02 14:31:20,687 (MainThread): Completed with 2 errors and 0 warnings:
2019-10-02 14:31:20,687 (MainThread): 
2019-10-02 14:31:20,688 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 14:31:20,688 (MainThread):   001003 (42000): 018f470b-0053-be9b-0000-0e290161f766: SQL compilation error:
2019-10-02 14:31:20,689 (MainThread):   syntax error line 22 at position 2 unexpected 'AND'.
2019-10-02 14:31:20,689 (MainThread):   syntax error line 22 at position 38 unexpected 'FROM'.
2019-10-02 14:31:20,689 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 14:31:20,690 (MainThread): 
2019-10-02 14:31:20,690 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 14:31:20,691 (MainThread):   001003 (42000): 018f470b-0078-d8cb-0000-0e290161f786: SQL compilation error:
2019-10-02 14:31:20,692 (MainThread):   syntax error line 19 at position 2 unexpected 'AND'.
2019-10-02 14:31:20,693 (MainThread):   syntax error line 19 at position 38 unexpected 'FROM'.
2019-10-02 14:31:20,693 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 14:31:20,694 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=1 TOTAL=5
2019-10-02 14:31:20,695 (MainThread): Flushing usage events
2019-10-02 14:31:49,278 (MainThread): Tracking: tracking
2019-10-02 14:31:49,280 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972188>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059722C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E308>]}
2019-10-02 14:31:49,591 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:31:49,593 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60194), raddr=('54.164.98.48', 443)>

2019-10-02 14:31:49,599 (MainThread): Error sending message, disabling tracking
2019-10-02 14:31:49,662 (MainThread): Parsing macros\core.sql
2019-10-02 14:31:49,670 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:31:49,708 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:31:49,718 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:31:49,720 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:31:49,723 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:31:49,727 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:31:49,730 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:31:49,732 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:31:49,740 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:31:49,748 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:31:49,756 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:31:49,773 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:31:49,794 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:31:49,796 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:31:49,810 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:31:49,816 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:31:49,822 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:31:49,829 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:31:49,831 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:31:49,833 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:31:49,836 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:31:49,838 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:31:49,851 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:31:49,854 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:31:49,863 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:31:49,865 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:31:49,870 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:31:49,898 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:31:49,900 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:31:49,900 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:31:49,902 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:31:50,247 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:31:50,266 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:31:50,855 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:31:50,856 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:31:50,856 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:31:50,863 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:31:50,865 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:31:50,865 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:31:50,870 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:31:50,871 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:31:50,871 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:31:50,877 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:31:50,878 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:31:50,878 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:31:50,883 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:31:50,884 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:31:50,884 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:31:50,889 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:31:50,890 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:31:50,890 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:31:50,894 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:31:50,895 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:31:50,896 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:31:50,900 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:31:50,901 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:31:50,901 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:31:50,906 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:31:50,907 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:31:50,908 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:31:50,917 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:31:50,919 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:31:50,919 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:31:50,926 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:31:50,928 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:31:50,929 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:31:50,934 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:31:50,935 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:31:50,935 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:31:50,939 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:31:50,940 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:31:50,940 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:31:50,949 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:31:50,952 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:31:50,952 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:31:50,963 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:31:50,965 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:31:50,966 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:31:50,977 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:31:50,979 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:31:50,979 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:31:50,985 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:31:50,986 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:50,987 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:31:51,002 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:31:51,004 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:31:51,005 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:31:51,013 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:31:51,015 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:31:51,015 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:31:51,021 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:31:51,022 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:31:51,023 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:31:51,115 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:31:51,120 (MainThread): 
2019-10-02 14:31:51,121 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:31:51,122 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:31:51,171 (MainThread): Parsing macros\core.sql
2019-10-02 14:31:51,184 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:31:51,271 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:31:51,287 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:31:51,290 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:31:51,294 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:31:51,301 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:31:51,306 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:31:51,310 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:31:51,324 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:31:51,340 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:31:51,357 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:31:51,398 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:31:51,420 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:31:51,425 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:31:51,447 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:31:51,460 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:31:51,468 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:31:51,477 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:31:51,482 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:31:51,487 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:31:51,492 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:31:51,497 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:31:51,522 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:31:51,528 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:31:51,546 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:31:51,551 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:31:51,557 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:31:51,713 (MainThread): Using snowflake connection "master".
2019-10-02 14:31:51,713 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:31:52,302 (MainThread): SQL status: SUCCESS 29 in 0.59 seconds
2019-10-02 14:31:52,388 (MainThread): Using snowflake connection "master".
2019-10-02 14:31:52,388 (MainThread): On master: BEGIN
2019-10-02 14:31:52,526 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:31:52,527 (MainThread): Using snowflake connection "master".
2019-10-02 14:31:52,527 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:31:53,894 (MainThread): SQL status: SUCCESS 5 in 1.37 seconds
2019-10-02 14:31:53,915 (MainThread): On master: ROLLBACK
2019-10-02 14:31:54,138 (MainThread): Using snowflake connection "master".
2019-10-02 14:31:54,139 (MainThread): On master: BEGIN
2019-10-02 14:31:54,256 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:31:54,258 (MainThread): On master: COMMIT
2019-10-02 14:31:54,259 (MainThread): Using snowflake connection "master".
2019-10-02 14:31:54,259 (MainThread): On master: COMMIT
2019-10-02 14:31:54,439 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 14:31:54,441 (MainThread): 14:31:54 | Concurrency: 1 threads (target='dev')
2019-10-02 14:31:54,442 (MainThread): 14:31:54 | 
2019-10-02 14:31:54,454 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:31:54,455 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:31:55,117 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:31:55,143 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:31:55,154 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:31:55,155 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:31:55,155 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:31:55,168 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:31:55,177 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:31:55,178 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:31:55,178 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:31:55,190 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:31:55,199 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:31:55,199 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:31:55,200 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:31:55,210 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:31:55,215 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:31:55,218 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:31:55,219 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:31:55,224 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:31:55,232 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:31:55,232 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:31:55,234 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:31:55,240 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:31:55,247 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:31:55,251 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:31:55,252 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:31:55,266 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:31:55,275 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:31:55,275 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:31:55,277 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:31:55,290 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:31:55,299 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:31:55,299 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:31:55,300 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:31:55,316 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:31:55,323 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:31:55,323 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:31:55,324 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:31:55,337 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:31:55,344 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:31:55,347 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:31:55,348 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:31:55,355 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:31:55,361 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:31:55,364 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:31:55,364 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:31:55,373 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:31:55,378 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:31:55,381 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:31:55,381 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:31:55,387 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:31:55,392 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:31:55,395 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:31:55,396 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:31:55,406 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:31:55,411 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:31:55,413 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:31:55,414 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:31:55,424 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:31:55,430 (Thread-1): 14:31:55 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:31:55,433 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:55,433 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:31:55,434 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:31:55,448 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:31:55,557 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:55,557 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:31:55,672 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:31:55,673 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:55,673 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_stream_test bk_1)

-- GROUP BY 1
      );
2019-10-02 14:31:56,329 (Thread-1): SQL status: SUCCESS 1 in 0.66 seconds
2019-10-02 14:31:56,345 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:56,345 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:31:58,563 (Thread-1): SQL status: SUCCESS 24 in 2.22 seconds
2019-10-02 14:31:58,585 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:31:58,585 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:00,669 (Thread-1): SQL status: SUCCESS 23 in 2.08 seconds
2019-10-02 14:32:00,703 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:32:00,703 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:02,618 (Thread-1): SQL status: SUCCESS 23 in 1.91 seconds
2019-10-02 14:32:02,671 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:32:02,681 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:32:02,681 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 14:32:03,566 (Thread-1): SQL status: SUCCESS 2 in 0.88 seconds
2019-10-02 14:32:03,568 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:32:03,568 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:32:03,569 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:32:03,794 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-02 14:32:03,808 (Thread-1): 14:32:03 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 2 in 8.37s]
2019-10-02 14:32:03,810 (Thread-1): 14:32:03 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:32:03,811 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:03,812 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:32:03,814 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:32:03,838 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:32:03,853 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:03,854 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:32:03,988 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:32:03,989 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:03,989 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:32:04,549 (Thread-1): SQL status: SUCCESS 1 in 0.56 seconds
2019-10-02 14:32:04,566 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:04,567 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:07,299 (Thread-1): SQL status: SUCCESS 6 in 2.73 seconds
2019-10-02 14:32:07,318 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:07,319 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:09,506 (Thread-1): SQL status: SUCCESS 5 in 2.19 seconds
2019-10-02 14:32:09,525 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:09,525 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:11,898 (Thread-1): SQL status: SUCCESS 5 in 2.37 seconds
2019-10-02 14:32:11,906 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:32:11,916 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:11,917 (Thread-1): On with_fl_acr_booking_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking_service (SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION)
        (
            select SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION
            from OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
        );
2019-10-02 14:32:12,449 (Thread-1): SQL status: SUCCESS 7 in 0.53 seconds
2019-10-02 14:32:12,455 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:32:12,456 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:32:12,456 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:32:12,926 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2019-10-02 14:32:12,935 (Thread-1): 14:32:12 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 7 in 9.12s]
2019-10-02 14:32:12,936 (Thread-1): 14:32:12 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:32:12,938 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:32:12,939 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:32:12,940 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:32:12,950 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:32:12,968 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:32:12,969 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:32:13,177 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-02 14:32:13,178 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:32:13,178 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:32:16,215 (Thread-1): SQL status: SUCCESS 1 in 3.04 seconds
2019-10-02 14:32:16,234 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:32:16,234 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:19,031 (Thread-1): SQL status: SUCCESS 15 in 2.80 seconds
2019-10-02 14:32:19,051 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:32:19,051 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:21,334 (Thread-1): SQL status: SUCCESS 14 in 2.28 seconds
2019-10-02 14:32:21,359 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:32:21,360 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:24,246 (Thread-1): SQL status: SUCCESS 14 in 2.89 seconds
2019-10-02 14:32:24,258 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:32:24,268 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:32:24,269 (Thread-1): On with_fl_acr_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_service (SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE)
        (
            select SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE
            from OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
        );
2019-10-02 14:32:25,209 (Thread-1): SQL status: SUCCESS 12 in 0.94 seconds
2019-10-02 14:32:25,210 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:32:25,211 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:32:25,211 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:32:25,513 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-02 14:32:25,528 (Thread-1): 14:32:25 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 12 in 12.58s]
2019-10-02 14:32:25,532 (Thread-1): 14:32:25 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:32:25,538 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:25,538 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:32:25,540 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:32:25,553 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:32:25,571 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:25,571 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:32:25,698 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:32:25,699 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:25,699 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_element_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:32:26,503 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2019-10-02 14:32:26,521 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:26,522 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:28,940 (Thread-1): SQL status: SUCCESS 5 in 2.42 seconds
2019-10-02 14:32:28,960 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:28,960 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:30,907 (Thread-1): SQL status: SUCCESS 4 in 1.95 seconds
2019-10-02 14:32:30,916 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:30,916 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:32:33,470 (Thread-1): SQL status: SUCCESS 4 in 2.55 seconds
2019-10-02 14:32:33,479 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:32:33,490 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:33,491 (Thread-1): On with_fl_acr_service_element: insert into OPA_DEV.DBT_TEST.with_fl_acr_service_element (SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID)
        (
            select SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID
            from OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
        );
2019-10-02 14:32:34,075 (Thread-1): SQL status: SUCCESS 6 in 0.58 seconds
2019-10-02 14:32:34,078 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:32:34,079 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:32:34,079 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:32:34,318 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 14:32:34,333 (Thread-1): 14:32:34 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 6 in 8.79s]
2019-10-02 14:32:34,336 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:32:34,341 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:32:34,344 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:32:34,364 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:32:34,372 (Thread-1): 14:32:34 | 5 of 5 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 14:32:34,375 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:32:34,376 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:32:34,377 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:32:35,628 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:32:35,666 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:32:35,783 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:32:35,783 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:32:35,946 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:32:35,946 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:32:35,946 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:33:20,572 (Thread-1): SQL status: SUCCESS 1 in 44.62 seconds
2019-10-02 14:33:20,576 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:33:20,577 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:33:20,577 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:33:20,693 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:33:20,719 (Thread-1): 14:33:20 | 5 of 5 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 46.34s]
2019-10-02 14:33:20,811 (MainThread): Using snowflake connection "master".
2019-10-02 14:33:20,811 (MainThread): On master: BEGIN
2019-10-02 14:33:21,013 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 14:33:21,014 (MainThread): On master: COMMIT
2019-10-02 14:33:21,014 (MainThread): Using snowflake connection "master".
2019-10-02 14:33:21,014 (MainThread): On master: COMMIT
2019-10-02 14:33:21,174 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:33:21,175 (MainThread): 14:33:21 | 
2019-10-02 14:33:21,175 (MainThread): 14:33:21 | Finished running 4 incremental models, 1 table model in 90.05s.
2019-10-02 14:33:21,176 (MainThread): Connection 'master' was left open.
2019-10-02 14:33:21,176 (MainThread): On master: Close
2019-10-02 14:33:21,336 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:33:21,336 (MainThread): On booking_fact_uk: Close
2019-10-02 14:33:21,539 (MainThread): 
2019-10-02 14:33:21,540 (MainThread): Completed successfully
2019-10-02 14:33:21,540 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:33:21,541 (MainThread): Flushing usage events
2019-10-02 14:35:48,536 (MainThread): Tracking: tracking
2019-10-02 14:35:48,538 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004614D88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972D08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594D248>]}
2019-10-02 14:35:48,825 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:35:48,825 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60221), raddr=('54.174.31.151', 443)>

2019-10-02 14:35:48,827 (MainThread): Error sending message, disabling tracking
2019-10-02 14:35:48,864 (MainThread): Parsing macros\core.sql
2019-10-02 14:35:48,874 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:35:48,937 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:35:48,952 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:35:48,955 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:35:48,961 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:35:48,970 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:35:48,977 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:35:48,982 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:35:49,003 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:35:49,019 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:35:49,036 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:35:49,073 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:35:49,107 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:35:49,111 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:35:49,141 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:35:49,156 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:35:49,172 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:35:49,189 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:35:49,194 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:35:49,197 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:35:49,201 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:35:49,205 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:35:49,225 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:35:49,229 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:35:49,242 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:35:49,247 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:35:49,255 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:35:49,306 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:35:49,308 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:35:49,308 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:35:49,310 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:35:49,562 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:35:49,588 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:35:50,066 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:35:50,067 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:35:50,067 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:35:50,073 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:35:50,074 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:35:50,074 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:35:50,080 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:35:50,081 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:35:50,081 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:35:50,086 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:35:50,087 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:35:50,087 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:35:50,091 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:35:50,092 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:35:50,093 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:35:50,097 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:35:50,098 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:35:50,098 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:35:50,103 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:35:50,104 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:35:50,105 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:35:50,110 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:35:50,111 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:35:50,111 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:35:50,118 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:35:50,120 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:35:50,120 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:35:50,125 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:35:50,126 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:35:50,126 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:35:50,131 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:35:50,132 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:35:50,132 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:35:50,137 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:35:50,138 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:35:50,138 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:35:50,143 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:35:50,144 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:35:50,144 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:35:50,150 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:35:50,151 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:35:50,152 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:35:50,156 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:35:50,157 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:35:50,157 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:35:50,162 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:35:50,163 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:35:50,163 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:35:50,168 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:35:50,169 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:35:50,169 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:35:50,179 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:35:50,180 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:35:50,180 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:35:50,186 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:35:50,188 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:35:50,188 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:35:50,194 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:35:50,195 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:35:50,195 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:35:50,256 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:35:50,260 (MainThread): 
2019-10-02 14:35:50,261 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:35:50,261 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:35:50,301 (MainThread): Parsing macros\core.sql
2019-10-02 14:35:50,311 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:35:50,388 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:35:50,411 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:35:50,415 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:35:50,422 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:35:50,430 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:35:50,439 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:35:50,444 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:35:50,463 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:35:50,479 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:35:50,498 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:35:50,527 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:35:50,563 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:35:50,567 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:35:50,590 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:35:50,598 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:35:50,605 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:35:50,619 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:35:50,624 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:35:50,627 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:35:50,631 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:35:50,635 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:35:50,659 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:35:50,666 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:35:50,689 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:35:50,695 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:35:50,706 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:35:50,949 (MainThread): Using snowflake connection "master".
2019-10-02 14:35:50,949 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:35:51,593 (MainThread): SQL status: SUCCESS 29 in 0.64 seconds
2019-10-02 14:35:51,645 (MainThread): Using snowflake connection "master".
2019-10-02 14:35:51,645 (MainThread): On master: BEGIN
2019-10-02 14:35:51,795 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:35:51,795 (MainThread): Using snowflake connection "master".
2019-10-02 14:35:51,795 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:35:52,774 (MainThread): SQL status: SUCCESS 5 in 0.98 seconds
2019-10-02 14:35:52,786 (MainThread): On master: ROLLBACK
2019-10-02 14:35:52,982 (MainThread): Using snowflake connection "master".
2019-10-02 14:35:52,983 (MainThread): On master: BEGIN
2019-10-02 14:35:53,084 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:35:53,085 (MainThread): On master: COMMIT
2019-10-02 14:35:53,085 (MainThread): Using snowflake connection "master".
2019-10-02 14:35:53,085 (MainThread): On master: COMMIT
2019-10-02 14:35:53,224 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:35:53,225 (MainThread): 14:35:53 | Concurrency: 1 threads (target='dev')
2019-10-02 14:35:53,225 (MainThread): 14:35:53 | 
2019-10-02 14:35:53,228 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:35:53,228 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:35:53,782 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:35:53,788 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:35:53,792 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:35:53,792 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:35:53,793 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:35:53,799 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:35:53,806 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:35:53,807 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:35:53,808 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:35:53,814 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:35:53,820 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:35:53,820 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:35:53,821 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:35:53,825 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:35:53,833 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:35:53,834 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:35:53,835 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:35:53,840 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:35:53,847 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:35:53,847 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:35:53,847 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:35:53,853 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:35:53,858 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:35:53,859 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:35:53,859 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:35:53,864 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:35:53,873 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:35:53,873 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:35:53,874 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:35:53,880 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:35:53,888 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:35:53,888 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:35:53,889 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:35:53,898 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:35:53,906 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:35:53,907 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:35:53,908 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:35:53,923 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:35:53,931 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:35:53,934 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:35:53,935 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:35:53,943 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:35:53,952 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:35:53,955 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:35:53,956 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:35:53,966 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:35:53,977 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:35:53,981 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:35:53,982 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:35:53,994 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:35:54,004 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:35:54,007 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:35:54,008 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:35:54,018 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:35:54,025 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:35:54,028 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:35:54,028 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:35:54,039 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:35:54,045 (Thread-1): 14:35:54 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:35:54,049 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:35:54,049 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:35:54,050 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:35:54,064 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:35:54,197 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:35:54,203 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:35:54,203 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:35:54,608 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2019-10-02 14:35:54,608 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:35:54,608 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:35:55,493 (Thread-1): SQL status: SUCCESS 1 in 0.88 seconds
2019-10-02 14:35:55,495 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:35:55,495 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:35:55,495 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:35:55,589 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:35:55,592 (Thread-1): 14:35:55 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.54s]
2019-10-02 14:35:55,593 (Thread-1): 14:35:55 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:35:55,595 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:35:55,595 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:35:55,595 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:35:55,602 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:35:55,617 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:35:55,626 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:35:55,626 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:35:55,775 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:35:55,775 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:35:55,775 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:35:56,595 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2019-10-02 14:35:56,596 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:35:56,596 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:35:56,596 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:35:56,679 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-02 14:35:56,683 (Thread-1): 14:35:56 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 1.09s]
2019-10-02 14:35:56,684 (Thread-1): 14:35:56 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:35:56,684 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:35:56,684 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:35:56,685 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:35:56,692 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:35:56,704 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:35:56,711 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:35:56,712 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:35:56,846 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:35:56,847 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:35:56,847 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:36:00,920 (Thread-1): SQL status: SUCCESS 1 in 4.07 seconds
2019-10-02 14:36:00,921 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:36:00,922 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:36:00,922 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:36:01,027 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:36:01,031 (Thread-1): 14:36:01 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 4.35s]
2019-10-02 14:36:01,032 (Thread-1): 14:36:01 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:36:01,034 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:36:01,034 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:36:01,035 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:36:01,041 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:36:01,053 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:36:01,056 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:36:01,057 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:36:01,253 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 14:36:01,254 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:36:01,254 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:36:01,990 (Thread-1): SQL status: SUCCESS 1 in 0.74 seconds
2019-10-02 14:36:01,991 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:36:01,991 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:36:01,991 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:36:02,093 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:36:02,097 (Thread-1): 14:36:02 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 1.06s]
2019-10-02 14:36:02,097 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:36:02,098 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:36:02,098 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:36:02,105 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:36:02,111 (Thread-1): 14:36:02 | 5 of 5 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 14:36:02,113 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:36:02,113 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:36:02,114 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:36:03,826 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:36:03,891 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:36:04,057 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:36:04,057 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:36:04,173 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:36:04,174 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:36:04,174 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:36:40,025 (Thread-1): SQL status: SUCCESS 1 in 35.85 seconds
2019-10-02 14:36:40,027 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:36:40,027 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:36:40,028 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:36:40,107 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-02 14:36:40,119 (Thread-1): 14:36:40 | 5 of 5 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 38.00s]
2019-10-02 14:36:40,162 (MainThread): Using snowflake connection "master".
2019-10-02 14:36:40,163 (MainThread): On master: BEGIN
2019-10-02 14:36:40,323 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:36:40,324 (MainThread): On master: COMMIT
2019-10-02 14:36:40,324 (MainThread): Using snowflake connection "master".
2019-10-02 14:36:40,324 (MainThread): On master: COMMIT
2019-10-02 14:36:40,543 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-02 14:36:40,544 (MainThread): 14:36:40 | 
2019-10-02 14:36:40,544 (MainThread): 14:36:40 | Finished running 4 incremental models, 1 table model in 50.28s.
2019-10-02 14:36:40,545 (MainThread): Connection 'master' was left open.
2019-10-02 14:36:40,545 (MainThread): On master: Close
2019-10-02 14:36:40,665 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:36:40,665 (MainThread): On booking_fact_uk: Close
2019-10-02 14:36:40,811 (MainThread): 
2019-10-02 14:36:40,813 (MainThread): Completed successfully
2019-10-02 14:36:40,813 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:36:40,814 (MainThread): Flushing usage events
2019-10-02 14:38:58,342 (MainThread): Tracking: tracking
2019-10-02 14:38:58,344 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599E688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972988>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596EB08>]}
2019-10-02 14:38:58,620 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:38:58,621 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60258), raddr=('54.164.98.48', 443)>

2019-10-02 14:38:58,622 (MainThread): Error sending message, disabling tracking
2019-10-02 14:38:58,648 (MainThread): Parsing macros\core.sql
2019-10-02 14:38:58,657 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:38:58,725 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:38:58,745 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:38:58,748 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:38:58,757 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:38:58,762 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:38:58,767 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:38:58,770 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:38:58,788 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:38:58,808 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:38:58,827 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:38:58,876 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:38:58,932 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:38:58,938 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:38:58,968 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:38:58,983 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:38:58,991 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:38:58,998 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:38:59,003 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:38:59,007 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:38:59,011 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:38:59,016 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:38:59,037 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:38:59,043 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:38:59,063 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:38:59,069 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:38:59,080 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:38:59,126 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:38:59,129 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:38:59,129 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:38:59,132 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:38:59,360 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:38:59,377 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:38:59,936 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:38:59,937 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:38:59,937 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:38:59,941 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:38:59,942 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:38:59,943 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:38:59,949 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:38:59,950 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:38:59,950 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:38:59,955 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:38:59,956 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:38:59,956 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:38:59,961 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:38:59,962 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:38:59,963 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:38:59,969 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:38:59,971 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:38:59,971 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:38:59,976 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:38:59,977 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:38:59,977 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:38:59,981 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:38:59,982 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:38:59,982 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:38:59,988 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:38:59,989 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:38:59,989 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:38:59,994 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:38:59,996 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:38:59,997 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:39:00,006 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:39:00,007 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:39:00,007 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:39:00,012 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:39:00,013 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:39:00,013 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:39:00,017 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:39:00,020 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:39:00,020 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:39:00,025 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:39:00,026 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:39:00,026 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:39:00,031 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:39:00,032 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:39:00,032 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:39:00,036 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:39:00,037 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:39:00,037 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:39:00,043 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:39:00,045 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:00,045 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:39:00,058 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:39:00,060 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:00,061 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:39:00,067 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:39:00,068 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:39:00,068 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:39:00,074 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:39:00,075 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:00,075 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:39:00,152 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:39:00,156 (MainThread): 
2019-10-02 14:39:00,157 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:39:00,158 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:39:00,199 (MainThread): Parsing macros\core.sql
2019-10-02 14:39:00,210 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:39:00,291 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:39:00,314 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:39:00,318 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:39:00,324 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:39:00,331 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:39:00,336 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:39:00,340 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:39:00,360 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:39:00,377 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:39:00,396 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:39:00,441 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:39:00,482 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:39:00,487 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:39:00,516 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:39:00,530 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:39:00,544 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:39:00,557 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:39:00,561 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:39:00,565 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:39:00,570 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:39:00,576 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:39:00,608 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:39:00,614 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:39:00,628 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:39:00,633 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:39:00,642 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:39:00,888 (MainThread): Using snowflake connection "master".
2019-10-02 14:39:00,888 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:39:01,510 (MainThread): SQL status: SUCCESS 29 in 0.62 seconds
2019-10-02 14:39:01,562 (MainThread): Using snowflake connection "master".
2019-10-02 14:39:01,562 (MainThread): On master: BEGIN
2019-10-02 14:39:01,683 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:39:01,684 (MainThread): Using snowflake connection "master".
2019-10-02 14:39:01,684 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:39:02,924 (MainThread): SQL status: SUCCESS 5 in 1.24 seconds
2019-10-02 14:39:02,938 (MainThread): On master: ROLLBACK
2019-10-02 14:39:03,118 (MainThread): Using snowflake connection "master".
2019-10-02 14:39:03,118 (MainThread): On master: BEGIN
2019-10-02 14:39:03,229 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:39:03,229 (MainThread): On master: COMMIT
2019-10-02 14:39:03,229 (MainThread): Using snowflake connection "master".
2019-10-02 14:39:03,230 (MainThread): On master: COMMIT
2019-10-02 14:39:03,394 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:39:03,395 (MainThread): 14:39:03 | Concurrency: 1 threads (target='dev')
2019-10-02 14:39:03,395 (MainThread): 14:39:03 | 
2019-10-02 14:39:03,398 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:39:03,398 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:39:03,806 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:39:03,817 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:39:03,824 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:39:03,825 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:39:03,826 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:39:03,834 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:39:03,839 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:39:03,842 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:39:03,843 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:39:03,853 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:39:03,860 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:39:03,860 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:39:03,861 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:39:03,873 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:39:03,879 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:39:03,879 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:39:03,880 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:39:03,886 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:39:03,894 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:39:03,897 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:39:03,898 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:39:03,908 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:39:03,920 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:39:03,924 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:39:03,925 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:39:03,934 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:39:03,942 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:39:03,942 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:39:03,943 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:39:03,955 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:39:03,964 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:39:03,967 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:39:03,968 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:39:03,979 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:39:03,988 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:39:03,991 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:39:03,992 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:39:04,004 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:39:04,013 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:39:04,014 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:39:04,015 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:39:04,025 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:39:04,032 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:39:04,036 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:39:04,038 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:39:04,048 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:39:04,055 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:39:04,058 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:39:04,059 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:39:04,069 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:39:04,109 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:39:04,112 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:39:04,113 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:39:04,121 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:39:04,128 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:39:04,131 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:39:04,132 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:39:04,142 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:39:04,153 (Thread-1): 14:39:04 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:39:04,156 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:04,156 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:39:04,157 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:39:04,170 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:39:04,289 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:04,289 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:39:04,434 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:39:04,435 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:04,435 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_stream_test bk_1)

-- GROUP BY 1
      );
2019-10-02 14:39:05,573 (Thread-1): SQL status: SUCCESS 1 in 1.14 seconds
2019-10-02 14:39:05,577 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:05,578 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:07,363 (Thread-1): SQL status: SUCCESS 24 in 1.78 seconds
2019-10-02 14:39:07,369 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:07,369 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:09,386 (Thread-1): SQL status: SUCCESS 24 in 2.02 seconds
2019-10-02 14:39:09,394 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:09,395 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:11,654 (Thread-1): SQL status: SUCCESS 24 in 2.26 seconds
2019-10-02 14:39:11,673 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:39:11,678 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:11,678 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 14:39:12,327 (Thread-1): SQL status: SUCCESS 2 in 0.65 seconds
2019-10-02 14:39:12,328 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:39:12,328 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:39:12,328 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:39:12,574 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-02 14:39:12,578 (Thread-1): 14:39:12 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 2 in 8.42s]
2019-10-02 14:39:12,578 (Thread-1): 14:39:12 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:39:12,580 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:12,580 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:39:12,581 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:39:12,587 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:39:12,598 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:12,598 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:39:12,705 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:39:12,706 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:12,706 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:39:13,437 (Thread-1): SQL status: SUCCESS 1 in 0.73 seconds
2019-10-02 14:39:13,450 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:13,451 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:15,735 (Thread-1): SQL status: SUCCESS 6 in 2.28 seconds
2019-10-02 14:39:15,740 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:15,740 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:17,460 (Thread-1): SQL status: SUCCESS 6 in 1.72 seconds
2019-10-02 14:39:17,465 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:17,465 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:19,331 (Thread-1): SQL status: SUCCESS 6 in 1.87 seconds
2019-10-02 14:39:19,333 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:39:19,338 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:19,338 (Thread-1): On with_fl_acr_booking_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking_service (SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT)
        (
            select SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
        );
2019-10-02 14:39:19,872 (Thread-1): SQL status: SUCCESS 7 in 0.53 seconds
2019-10-02 14:39:19,873 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:39:19,873 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:39:19,874 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:39:20,159 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-02 14:39:20,163 (Thread-1): 14:39:20 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 7 in 7.58s]
2019-10-02 14:39:20,164 (Thread-1): 14:39:20 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:39:20,166 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:39:20,166 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:39:20,166 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:39:20,172 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:39:20,184 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:39:20,184 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:39:20,294 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:39:20,295 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:39:20,296 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:39:23,395 (Thread-1): SQL status: SUCCESS 1 in 3.10 seconds
2019-10-02 14:39:23,402 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:39:23,402 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:25,430 (Thread-1): SQL status: SUCCESS 15 in 2.03 seconds
2019-10-02 14:39:25,440 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:39:25,440 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:27,256 (Thread-1): SQL status: SUCCESS 15 in 1.82 seconds
2019-10-02 14:39:27,263 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:39:27,263 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:28,908 (Thread-1): SQL status: SUCCESS 15 in 1.65 seconds
2019-10-02 14:39:28,912 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:39:28,917 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:39:28,917 (Thread-1): On with_fl_acr_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_service (SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT)
        (
            select SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
        );
2019-10-02 14:39:29,604 (Thread-1): SQL status: SUCCESS 12 in 0.69 seconds
2019-10-02 14:39:29,605 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:39:29,606 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:39:29,606 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:39:29,861 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-02 14:39:29,865 (Thread-1): 14:39:29 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 12 in 9.70s]
2019-10-02 14:39:29,865 (Thread-1): 14:39:29 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:39:29,867 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:29,867 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:39:29,867 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:39:29,873 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:39:29,883 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:29,883 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:39:29,995 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:39:29,997 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:29,997 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_element_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:39:30,760 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2019-10-02 14:39:30,770 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:30,770 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:32,519 (Thread-1): SQL status: SUCCESS 5 in 1.75 seconds
2019-10-02 14:39:32,525 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:32,525 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:34,531 (Thread-1): SQL status: SUCCESS 5 in 2.01 seconds
2019-10-02 14:39:34,541 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:34,541 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:39:36,709 (Thread-1): SQL status: SUCCESS 5 in 2.17 seconds
2019-10-02 14:39:36,713 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:39:36,717 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:36,717 (Thread-1): On with_fl_acr_service_element: insert into OPA_DEV.DBT_TEST.with_fl_acr_service_element (SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT)
        (
            select SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
        );
2019-10-02 14:39:37,191 (Thread-1): SQL status: SUCCESS 6 in 0.47 seconds
2019-10-02 14:39:37,192 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:39:37,192 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:39:37,192 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:39:37,483 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-02 14:39:37,487 (Thread-1): 14:39:37 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 6 in 7.62s]
2019-10-02 14:39:37,487 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:39:37,489 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:39:37,489 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:39:37,496 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:39:37,501 (Thread-1): 14:39:37 | 5 of 5 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 14:39:37,502 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:39:37,503 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:39:37,503 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:39:39,143 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:39:39,213 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:39:39,371 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:39:39,372 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:39:39,505 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:39:39,505 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:39:39,505 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:40:14,010 (Thread-1): SQL status: SUCCESS 1 in 34.50 seconds
2019-10-02 14:40:14,012 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:40:14,012 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:40:14,012 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:40:14,101 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:40:14,117 (Thread-1): 14:40:14 | 5 of 5 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 36.61s]
2019-10-02 14:40:14,174 (MainThread): Using snowflake connection "master".
2019-10-02 14:40:14,175 (MainThread): On master: BEGIN
2019-10-02 14:40:14,276 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:40:14,277 (MainThread): On master: COMMIT
2019-10-02 14:40:14,277 (MainThread): Using snowflake connection "master".
2019-10-02 14:40:14,277 (MainThread): On master: COMMIT
2019-10-02 14:40:14,532 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-02 14:40:14,533 (MainThread): 14:40:14 | 
2019-10-02 14:40:14,534 (MainThread): 14:40:14 | Finished running 4 incremental models, 1 table model in 74.38s.
2019-10-02 14:40:14,534 (MainThread): Connection 'master' was left open.
2019-10-02 14:40:14,535 (MainThread): On master: Close
2019-10-02 14:40:14,712 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:40:14,712 (MainThread): On booking_fact_uk: Close
2019-10-02 14:40:14,987 (MainThread): 
2019-10-02 14:40:14,987 (MainThread): Completed successfully
2019-10-02 14:40:14,988 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:40:14,989 (MainThread): Flushing usage events
2019-10-02 14:42:12,557 (MainThread): Tracking: tracking
2019-10-02 14:42:12,559 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972048>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972AC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594B8C8>]}
2019-10-02 14:42:12,845 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:42:12,846 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60279), raddr=('54.164.98.48', 443)>

2019-10-02 14:42:12,848 (MainThread): Error sending message, disabling tracking
2019-10-02 14:42:12,886 (MainThread): Parsing macros\core.sql
2019-10-02 14:42:12,899 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:42:12,964 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:42:12,985 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:42:12,988 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:42:13,007 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:42:13,016 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:42:13,022 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:42:13,027 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:42:13,047 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:42:13,066 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:42:13,085 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:42:13,117 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:42:13,164 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:42:13,171 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:42:13,202 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:42:13,213 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:42:13,224 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:42:13,236 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:42:13,241 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:42:13,244 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:42:13,249 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:42:13,254 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:42:13,272 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:42:13,276 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:42:13,288 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:42:13,293 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:42:13,301 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:42:13,350 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:42:13,352 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:42:13,352 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:42:13,354 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:42:13,603 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:42:13,621 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:42:14,204 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:42:14,205 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:42:14,205 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:42:14,210 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:42:14,211 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:42:14,211 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:42:14,217 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:42:14,218 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:42:14,218 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:42:14,223 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:42:14,224 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:42:14,224 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:42:14,228 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:42:14,229 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:42:14,229 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:42:14,234 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:42:14,235 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:42:14,235 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:42:14,240 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:42:14,241 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:42:14,241 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:42:14,246 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:42:14,247 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:42:14,247 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:42:14,252 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:42:14,253 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:42:14,253 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:42:14,258 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:42:14,259 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:42:14,259 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:42:14,263 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:42:14,265 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:42:14,265 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:42:14,270 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:42:14,272 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:42:14,272 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:42:14,277 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:42:14,278 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:42:14,278 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:42:14,283 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:42:14,284 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:42:14,284 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:42:14,289 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:42:14,290 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:42:14,290 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:42:14,294 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:42:14,295 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:42:14,296 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:42:14,301 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:42:14,302 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:42:14,302 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:42:14,312 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:42:14,313 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:42:14,313 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:42:14,318 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:42:14,320 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:42:14,321 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:42:14,329 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:42:14,330 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:42:14,330 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:42:14,402 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:42:14,405 (MainThread): 
2019-10-02 14:42:14,406 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:42:14,406 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:42:14,450 (MainThread): Parsing macros\core.sql
2019-10-02 14:42:14,460 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:42:14,558 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:42:14,573 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:42:14,575 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:42:14,578 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:42:14,582 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:42:14,587 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:42:14,591 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:42:14,609 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:42:14,626 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:42:14,644 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:42:14,690 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:42:14,754 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:42:14,760 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:42:14,792 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:42:14,809 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:42:14,824 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:42:14,838 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:42:14,843 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:42:14,848 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:42:14,852 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:42:14,858 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:42:14,882 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:42:14,888 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:42:14,902 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:42:14,906 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:42:14,914 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:42:15,143 (MainThread): Using snowflake connection "master".
2019-10-02 14:42:15,143 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:42:15,855 (MainThread): SQL status: SUCCESS 29 in 0.71 seconds
2019-10-02 14:42:15,973 (MainThread): Using snowflake connection "master".
2019-10-02 14:42:15,973 (MainThread): On master: BEGIN
2019-10-02 14:42:16,086 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:42:16,087 (MainThread): Using snowflake connection "master".
2019-10-02 14:42:16,087 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:42:17,329 (MainThread): SQL status: SUCCESS 5 in 1.24 seconds
2019-10-02 14:42:17,335 (MainThread): On master: ROLLBACK
2019-10-02 14:42:17,585 (MainThread): Using snowflake connection "master".
2019-10-02 14:42:17,585 (MainThread): On master: BEGIN
2019-10-02 14:42:17,691 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:42:17,692 (MainThread): On master: COMMIT
2019-10-02 14:42:17,692 (MainThread): Using snowflake connection "master".
2019-10-02 14:42:17,692 (MainThread): On master: COMMIT
2019-10-02 14:42:17,855 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:42:17,855 (MainThread): 14:42:17 | Concurrency: 1 threads (target='dev')
2019-10-02 14:42:17,856 (MainThread): 14:42:17 | 
2019-10-02 14:42:17,860 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:42:17,860 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:42:18,397 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:42:18,403 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:42:18,408 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:42:18,408 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:42:18,409 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:42:18,413 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:42:18,419 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:42:18,419 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:42:18,420 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:42:18,425 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:42:18,432 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:42:18,432 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:42:18,432 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:42:18,444 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:42:18,451 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:42:18,453 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:42:18,454 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:42:18,461 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:42:18,466 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:42:18,466 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:42:18,467 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:42:18,472 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:42:18,479 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:42:18,479 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:42:18,482 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:42:18,492 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:42:18,496 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:42:18,496 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:42:18,497 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:42:18,502 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:42:18,508 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:42:18,508 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:42:18,508 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:42:18,513 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:42:18,519 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:42:18,520 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:42:18,520 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:42:18,534 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:42:18,543 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:42:18,543 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:42:18,544 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:42:18,559 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:42:18,570 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:42:18,574 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:42:18,576 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:42:18,586 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:42:18,595 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:42:18,600 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:42:18,602 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:42:18,627 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:42:18,643 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:42:18,643 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:42:18,647 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:42:18,656 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:42:18,665 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:42:18,665 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:42:18,666 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:42:18,683 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:42:18,689 (Thread-1): 14:42:18 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:42:18,693 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:42:18,693 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:42:18,694 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:42:18,704 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:42:18,825 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:42:18,832 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:42:18,832 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:42:18,948 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:42:18,949 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:42:18,949 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:42:20,075 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2019-10-02 14:42:20,077 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:42:20,077 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:42:20,077 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:42:20,248 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 14:42:20,253 (Thread-1): 14:42:20 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.56s]
2019-10-02 14:42:20,254 (Thread-1): 14:42:20 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:42:20,256 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:42:20,256 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:42:20,256 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:42:20,263 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:42:20,276 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:42:20,283 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:42:20,283 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:42:20,397 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:42:20,397 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:42:20,398 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:42:21,332 (Thread-1): SQL status: SUCCESS 1 in 0.93 seconds
2019-10-02 14:42:21,334 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:42:21,334 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:42:21,334 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:42:21,423 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:42:21,428 (Thread-1): 14:42:21 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 1.17s]
2019-10-02 14:42:21,428 (Thread-1): 14:42:21 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:42:21,430 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:42:21,430 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:42:21,430 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:42:21,437 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:42:21,451 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:42:21,456 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:42:21,456 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:42:21,562 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:42:21,563 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:42:21,563 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:42:25,211 (Thread-1): SQL status: SUCCESS 1 in 3.65 seconds
2019-10-02 14:42:25,212 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:42:25,212 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:42:25,212 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:42:25,392 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 14:42:25,395 (Thread-1): 14:42:25 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 3.96s]
2019-10-02 14:42:25,396 (Thread-1): 14:42:25 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:42:25,398 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:42:25,398 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:42:25,398 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:42:25,406 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:42:25,422 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:42:25,426 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:42:25,426 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:42:25,531 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:42:25,532 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:42:25,532 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:42:26,305 (Thread-1): SQL status: SUCCESS 1 in 0.77 seconds
2019-10-02 14:42:26,306 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:42:26,306 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:42:26,307 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:42:26,405 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:42:26,409 (Thread-1): 14:42:26 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 1.01s]
2019-10-02 14:42:26,410 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:42:26,411 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:42:26,411 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:42:26,416 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:42:26,423 (Thread-1): 14:42:26 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 14:42:26,425 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:42:26,426 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:42:26,427 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:42:28,132 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:42:28,175 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:42:28,328 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:42:28,328 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:42:28,516 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-02 14:42:28,517 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:42:28,517 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:43:09,593 (Thread-1): SQL status: SUCCESS 1 in 41.08 seconds
2019-10-02 14:43:09,594 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:43:09,594 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:43:09,594 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:43:09,683 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:43:09,689 (Thread-1): 14:43:09 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 1 in 43.26s]
2019-10-02 14:43:09,792 (MainThread): Using snowflake connection "master".
2019-10-02 14:43:09,793 (MainThread): On master: BEGIN
2019-10-02 14:43:09,918 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:43:09,918 (MainThread): On master: COMMIT
2019-10-02 14:43:09,919 (MainThread): Using snowflake connection "master".
2019-10-02 14:43:09,919 (MainThread): On master: COMMIT
2019-10-02 14:43:10,081 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:43:10,081 (MainThread): 14:43:10 | 
2019-10-02 14:43:10,082 (MainThread): 14:43:10 | Finished running 5 incremental models in 55.67s.
2019-10-02 14:43:10,082 (MainThread): Connection 'master' was left open.
2019-10-02 14:43:10,082 (MainThread): On master: Close
2019-10-02 14:43:10,203 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:43:10,204 (MainThread): On booking_fact_uk: Close
2019-10-02 14:43:10,340 (MainThread): 
2019-10-02 14:43:10,340 (MainThread): Completed successfully
2019-10-02 14:43:10,341 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:43:10,341 (MainThread): Flushing usage events
2019-10-02 14:43:52,644 (MainThread): Tracking: tracking
2019-10-02 14:43:52,646 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059724C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059720C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596EF08>]}
2019-10-02 14:43:52,922 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:43:52,923 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60290), raddr=('54.164.98.48', 443)>

2019-10-02 14:43:52,925 (MainThread): Error sending message, disabling tracking
2019-10-02 14:43:52,967 (MainThread): Parsing macros\core.sql
2019-10-02 14:43:52,980 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:43:53,046 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:43:53,063 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:43:53,066 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:43:53,071 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:43:53,075 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:43:53,080 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:43:53,082 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:43:53,095 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:43:53,104 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:43:53,114 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:43:53,138 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:43:53,165 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:43:53,170 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:43:53,183 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:43:53,190 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:43:53,201 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:43:53,213 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:43:53,217 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:43:53,221 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:43:53,224 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:43:53,228 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:43:53,244 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:43:53,248 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:43:53,258 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:43:53,261 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:43:53,270 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:43:53,299 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:43:53,302 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:43:53,302 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:43:53,304 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:43:53,538 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:43:53,554 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:43:54,614 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:43:54,615 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:43:54,616 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:43:54,620 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:43:54,621 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:43:54,621 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:43:54,625 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:43:54,626 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:43:54,626 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:43:54,631 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:43:54,632 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:43:54,632 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:43:54,638 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:43:54,639 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:43:54,639 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:43:54,644 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:43:54,645 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:43:54,645 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:43:54,650 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:43:54,652 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:43:54,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:43:54,658 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:43:54,659 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:43:54,660 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:43:54,665 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:43:54,666 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:43:54,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:43:54,671 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:43:54,672 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:43:54,672 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:43:54,681 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:43:54,682 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:43:54,682 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:43:54,688 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:43:54,690 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:43:54,690 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:43:54,696 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:43:54,697 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:43:54,697 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:43:54,705 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:43:54,706 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:43:54,706 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:43:54,712 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:43:54,714 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:43:54,714 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:43:54,719 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:43:54,720 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:43:54,720 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:43:54,726 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:43:54,727 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:43:54,727 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:43:54,744 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:43:54,746 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:43:54,747 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:43:54,761 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:43:54,764 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:43:54,764 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:43:54,775 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:43:54,777 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:43:54,779 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:43:54,903 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:43:54,906 (MainThread): 
2019-10-02 14:43:54,908 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:43:54,908 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:43:54,951 (MainThread): Parsing macros\core.sql
2019-10-02 14:43:54,959 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:43:55,039 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:43:55,056 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:43:55,060 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:43:55,067 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:43:55,075 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:43:55,081 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:43:55,085 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:43:55,106 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:43:55,123 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:43:55,139 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:43:55,172 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:43:55,209 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:43:55,214 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:43:55,238 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:43:55,256 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:43:55,270 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:43:55,284 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:43:55,290 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:43:55,296 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:43:55,304 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:43:55,311 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:43:55,333 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:43:55,338 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:43:55,354 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:43:55,359 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:43:55,368 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:43:55,570 (MainThread): Using snowflake connection "master".
2019-10-02 14:43:55,570 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:43:56,305 (MainThread): SQL status: SUCCESS 29 in 0.73 seconds
2019-10-02 14:43:56,360 (MainThread): Using snowflake connection "master".
2019-10-02 14:43:56,360 (MainThread): On master: BEGIN
2019-10-02 14:43:56,589 (MainThread): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-02 14:43:56,590 (MainThread): Using snowflake connection "master".
2019-10-02 14:43:56,590 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:43:57,739 (MainThread): SQL status: SUCCESS 5 in 1.15 seconds
2019-10-02 14:43:57,744 (MainThread): On master: ROLLBACK
2019-10-02 14:43:57,934 (MainThread): Using snowflake connection "master".
2019-10-02 14:43:57,935 (MainThread): On master: BEGIN
2019-10-02 14:43:58,048 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:43:58,049 (MainThread): On master: COMMIT
2019-10-02 14:43:58,049 (MainThread): Using snowflake connection "master".
2019-10-02 14:43:58,049 (MainThread): On master: COMMIT
2019-10-02 14:43:58,198 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:43:58,198 (MainThread): 14:43:58 | Concurrency: 1 threads (target='dev')
2019-10-02 14:43:58,198 (MainThread): 14:43:58 | 
2019-10-02 14:43:58,202 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:43:58,202 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:43:59,017 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:43:59,024 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:43:59,031 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:43:59,034 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:43:59,035 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:43:59,046 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:43:59,054 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:43:59,054 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:43:59,055 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:43:59,066 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:43:59,073 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:43:59,076 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:43:59,077 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:43:59,088 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:43:59,097 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:43:59,099 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:43:59,100 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:43:59,112 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:43:59,121 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:43:59,124 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:43:59,125 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:43:59,137 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:43:59,145 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:43:59,149 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:43:59,150 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:43:59,162 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:43:59,170 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:43:59,173 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:43:59,174 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:43:59,186 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:43:59,192 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:43:59,195 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:43:59,195 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:43:59,205 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:43:59,212 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:43:59,216 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:43:59,217 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:43:59,227 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:43:59,235 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:43:59,239 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:43:59,239 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:43:59,251 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:43:59,258 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:43:59,261 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:43:59,262 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:43:59,272 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:43:59,279 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:43:59,282 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:43:59,283 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:43:59,293 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:43:59,300 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:43:59,303 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:43:59,304 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:43:59,314 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:43:59,322 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:43:59,325 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:43:59,326 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:43:59,335 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:43:59,342 (Thread-1): 14:43:59 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:43:59,345 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:43:59,345 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:43:59,346 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:43:59,358 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:43:59,490 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:43:59,496 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:43:59,496 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:43:59,668 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 14:43:59,669 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:43:59,669 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:44:00,323 (Thread-1): SQL status: SUCCESS 1 in 0.65 seconds
2019-10-02 14:44:00,325 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:44:00,325 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:44:00,325 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:44:00,407 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-02 14:44:00,411 (Thread-1): 14:44:00 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.06s]
2019-10-02 14:44:00,412 (Thread-1): 14:44:00 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:44:00,413 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:44:00,413 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:44:00,414 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:44:00,419 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:44:00,432 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:44:00,436 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:44:00,437 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:44:00,618 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 14:44:00,619 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:44:00,619 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:44:01,599 (Thread-1): SQL status: SUCCESS 1 in 0.98 seconds
2019-10-02 14:44:01,600 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:44:01,600 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:44:01,600 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:44:01,705 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:44:01,709 (Thread-1): 14:44:01 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 1.30s]
2019-10-02 14:44:01,710 (Thread-1): 14:44:01 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:44:01,711 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:44:01,711 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:44:01,712 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:44:01,718 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:44:01,729 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:44:01,732 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:44:01,733 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:44:01,844 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:44:01,845 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:44:01,845 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:44:04,907 (Thread-1): SQL status: SUCCESS 1 in 3.06 seconds
2019-10-02 14:44:04,908 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:44:04,908 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:44:04,908 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:44:05,022 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:44:05,026 (Thread-1): 14:44:05 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 3.31s]
2019-10-02 14:44:05,027 (Thread-1): 14:44:05 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:44:05,030 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:44:05,031 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:44:05,031 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:44:05,038 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:44:05,050 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:44:05,054 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:44:05,054 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:44:05,183 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:44:05,184 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:44:05,184 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:44:05,765 (Thread-1): SQL status: SUCCESS 1 in 0.58 seconds
2019-10-02 14:44:05,766 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:44:05,767 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:44:05,767 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:44:05,853 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:44:05,857 (Thread-1): 14:44:05 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 0.83s]
2019-10-02 14:44:05,858 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:44:05,861 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:44:05,862 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:44:05,867 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:44:05,872 (Thread-1): 14:44:05 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 14:44:05,877 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:44:05,878 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:44:05,878 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:44:07,611 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:44:07,662 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:44:07,828 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:44:07,828 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:44:07,931 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:44:07,932 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:44:07,932 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:44:46,826 (Thread-1): SQL status: SUCCESS 1 in 38.89 seconds
2019-10-02 14:44:46,828 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:44:46,828 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:44:46,828 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:44:46,914 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-02 14:44:46,922 (Thread-1): 14:44:46 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 1 in 41.04s]
2019-10-02 14:44:46,934 (MainThread): Using snowflake connection "master".
2019-10-02 14:44:46,935 (MainThread): On master: BEGIN
2019-10-02 14:44:47,069 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:44:47,069 (MainThread): On master: COMMIT
2019-10-02 14:44:47,070 (MainThread): Using snowflake connection "master".
2019-10-02 14:44:47,070 (MainThread): On master: COMMIT
2019-10-02 14:44:47,255 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 14:44:47,256 (MainThread): 14:44:47 | 
2019-10-02 14:44:47,256 (MainThread): 14:44:47 | Finished running 5 incremental models in 52.35s.
2019-10-02 14:44:47,256 (MainThread): Connection 'master' was left open.
2019-10-02 14:44:47,257 (MainThread): On master: Close
2019-10-02 14:44:47,376 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:44:47,376 (MainThread): On booking_fact_uk: Close
2019-10-02 14:44:47,498 (MainThread): 
2019-10-02 14:44:47,498 (MainThread): Completed successfully
2019-10-02 14:44:47,499 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:44:47,499 (MainThread): Flushing usage events
2019-10-02 14:45:54,326 (MainThread): Tracking: tracking
2019-10-02 14:45:54,328 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599C0C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972808>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594C6C8>]}
2019-10-02 14:45:54,650 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:45:54,651 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60305), raddr=('54.174.31.151', 443)>

2019-10-02 14:45:54,654 (MainThread): Error sending message, disabling tracking
2019-10-02 14:45:54,706 (MainThread): Parsing macros\core.sql
2019-10-02 14:45:54,717 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:45:54,783 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:45:54,806 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:45:54,810 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:45:54,815 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:45:54,821 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:45:54,825 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:45:54,828 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:45:54,839 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:45:54,848 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:45:54,856 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:45:54,873 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:45:54,898 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:45:54,901 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:45:54,914 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:45:54,921 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:45:54,928 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:45:54,936 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:45:54,942 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:45:54,946 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:45:54,951 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:45:54,956 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:45:54,977 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:45:54,980 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:45:54,989 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:45:54,993 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:45:54,998 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:45:55,032 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:45:55,033 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:45:55,033 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:45:55,035 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:45:55,365 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:45:55,386 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:45:56,464 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:45:56,465 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:45:56,465 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:45:56,470 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:45:56,471 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:45:56,471 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:45:56,476 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:45:56,477 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:45:56,477 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:45:56,482 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:45:56,483 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:45:56,483 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:45:56,488 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:45:56,489 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:45:56,489 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:45:56,493 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:45:56,494 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:45:56,495 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:45:56,499 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:45:56,500 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:45:56,500 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:45:56,504 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:45:56,505 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:45:56,506 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:45:56,511 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:45:56,512 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:45:56,512 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:45:56,516 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:45:56,517 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:45:56,517 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:45:56,522 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:45:56,523 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:45:56,523 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:45:56,528 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:45:56,529 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:45:56,529 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:45:56,534 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:45:56,535 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:45:56,535 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:45:56,539 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:45:56,540 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:45:56,541 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:45:56,545 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:45:56,546 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:45:56,546 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:45:56,550 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:45:56,551 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:45:56,552 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:45:56,556 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:45:56,557 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:45:56,557 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:45:56,568 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:45:56,569 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:45:56,570 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:45:56,575 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:45:56,576 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:45:56,576 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:45:56,581 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:45:56,582 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:45:56,582 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:45:56,638 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:45:56,641 (MainThread): 
2019-10-02 14:45:56,641 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:45:56,641 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:45:56,669 (MainThread): Parsing macros\core.sql
2019-10-02 14:45:56,697 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:45:56,764 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:45:56,784 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:45:56,787 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:45:56,792 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:45:56,799 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:45:56,804 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:45:56,807 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:45:56,819 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:45:56,829 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:45:56,876 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:45:56,971 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:45:57,046 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:45:57,053 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:45:57,087 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:45:57,105 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:45:57,128 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:45:57,145 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:45:57,151 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:45:57,156 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:45:57,163 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:45:57,170 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:45:57,201 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:45:57,244 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:45:57,281 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:45:57,289 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:45:57,297 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:45:57,476 (MainThread): Using snowflake connection "master".
2019-10-02 14:45:57,477 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:45:58,561 (MainThread): SQL status: SUCCESS 29 in 1.08 seconds
2019-10-02 14:45:58,650 (MainThread): Using snowflake connection "master".
2019-10-02 14:45:58,650 (MainThread): On master: BEGIN
2019-10-02 14:45:58,759 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:45:58,759 (MainThread): Using snowflake connection "master".
2019-10-02 14:45:58,760 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:45:59,971 (MainThread): SQL status: SUCCESS 5 in 1.21 seconds
2019-10-02 14:45:59,988 (MainThread): On master: ROLLBACK
2019-10-02 14:46:00,128 (MainThread): Using snowflake connection "master".
2019-10-02 14:46:00,128 (MainThread): On master: BEGIN
2019-10-02 14:46:00,244 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:46:00,246 (MainThread): On master: COMMIT
2019-10-02 14:46:00,247 (MainThread): Using snowflake connection "master".
2019-10-02 14:46:00,247 (MainThread): On master: COMMIT
2019-10-02 14:46:00,650 (MainThread): SQL status: SUCCESS 1 in 0.40 seconds
2019-10-02 14:46:00,651 (MainThread): 14:46:00 | Concurrency: 1 threads (target='dev')
2019-10-02 14:46:00,652 (MainThread): 14:46:00 | 
2019-10-02 14:46:00,665 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:46:00,666 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:46:00,918 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:46:00,933 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:46:00,940 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:46:00,944 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:46:00,945 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:46:00,955 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:46:00,961 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:46:00,963 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:46:00,964 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:46:00,972 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:46:00,978 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:46:00,981 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:46:00,982 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:46:00,991 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:46:00,998 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:46:01,000 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:46:01,001 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:46:01,010 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:46:01,016 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:46:01,018 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:46:01,019 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:46:01,025 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:46:01,030 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:46:01,033 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:46:01,034 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:46:01,045 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:46:01,054 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:46:01,058 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:46:01,059 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:46:01,070 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:46:01,078 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:46:01,081 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:46:01,083 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:46:01,095 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:46:01,103 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:46:01,106 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:46:01,108 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:46:01,117 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:46:01,124 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:46:01,126 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:46:01,126 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:46:01,132 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:46:01,137 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:46:01,138 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:46:01,139 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:46:01,149 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:46:01,156 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:46:01,157 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:46:01,158 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:46:01,166 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:46:01,173 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:46:01,175 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:46:01,176 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:46:01,184 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:46:01,191 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:46:01,192 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:46:01,193 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:46:01,199 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:46:01,205 (Thread-1): 14:46:01 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:46:01,207 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:46:01,207 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:46:01,207 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:46:01,216 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:46:01,317 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:46:01,322 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:46:01,322 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:46:01,463 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:46:01,463 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:46:01,464 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:46:02,533 (Thread-1): SQL status: SUCCESS 1 in 1.07 seconds
2019-10-02 14:46:02,536 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:46:02,536 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:46:02,536 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:46:02,628 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:46:02,642 (Thread-1): 14:46:02 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.43s]
2019-10-02 14:46:02,645 (Thread-1): 14:46:02 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:46:02,651 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:46:02,651 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:46:02,653 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:46:02,663 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:46:02,678 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:46:02,683 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:46:02,683 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:46:02,823 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:46:02,824 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:46:02,824 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:46:04,204 (Thread-1): SQL status: SUCCESS 1 in 1.38 seconds
2019-10-02 14:46:04,207 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:46:04,208 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:46:04,208 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:46:04,528 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-02 14:46:04,543 (Thread-1): 14:46:04 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 1.89s]
2019-10-02 14:46:04,546 (Thread-1): 14:46:04 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:46:04,552 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:46:04,552 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:46:04,554 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:46:04,574 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:46:04,590 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:46:04,596 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:46:04,596 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:46:04,727 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:46:04,728 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:46:04,728 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:46:08,246 (Thread-1): SQL status: SUCCESS 1 in 3.52 seconds
2019-10-02 14:46:08,250 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:46:08,250 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:46:08,250 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:46:08,337 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:46:08,347 (Thread-1): 14:46:08 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 3.79s]
2019-10-02 14:46:08,348 (Thread-1): 14:46:08 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:46:08,349 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:46:08,349 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:46:08,350 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:46:08,360 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:46:08,383 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:46:08,388 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:46:08,388 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:46:08,482 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 14:46:08,483 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:46:08,483 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 14:46:09,169 (Thread-1): SQL status: SUCCESS 1 in 0.69 seconds
2019-10-02 14:46:09,170 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:46:09,170 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:46:09,170 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:46:09,292 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:46:09,305 (Thread-1): 14:46:09 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 0.95s]
2019-10-02 14:46:09,308 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:46:09,313 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:46:09,314 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:46:09,323 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:46:09,331 (Thread-1): 14:46:09 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 14:46:09,334 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:46:09,334 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:46:09,335 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:46:10,478 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:46:10,516 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:46:10,666 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:46:10,667 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:46:10,937 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-02 14:46:10,937 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:46:10,937 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:46:45,868 (Thread-1): SQL status: SUCCESS 1 in 34.93 seconds
2019-10-02 14:46:45,871 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:46:45,872 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:46:45,872 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 14:46:45,979 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 14:46:46,004 (Thread-1): 14:46:46 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 1 in 36.66s]
2019-10-02 14:46:46,023 (MainThread): Using snowflake connection "master".
2019-10-02 14:46:46,023 (MainThread): On master: BEGIN
2019-10-02 14:46:46,178 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:46:46,180 (MainThread): On master: COMMIT
2019-10-02 14:46:46,180 (MainThread): Using snowflake connection "master".
2019-10-02 14:46:46,181 (MainThread): On master: COMMIT
2019-10-02 14:46:46,420 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 14:46:46,423 (MainThread): 14:46:46 | 
2019-10-02 14:46:46,424 (MainThread): 14:46:46 | Finished running 5 incremental models in 49.78s.
2019-10-02 14:46:46,425 (MainThread): Connection 'master' was left open.
2019-10-02 14:46:46,427 (MainThread): On master: Close
2019-10-02 14:46:46,600 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:46:46,602 (MainThread): On booking_fact_uk: Close
2019-10-02 14:46:46,792 (MainThread): 
2019-10-02 14:46:46,794 (MainThread): Completed successfully
2019-10-02 14:46:46,796 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 14:46:46,796 (MainThread): Flushing usage events
2019-10-02 14:47:34,857 (MainThread): Tracking: tracking
2019-10-02 14:47:34,860 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599E548>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599E108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596C508>]}
2019-10-02 14:47:35,154 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:47:35,155 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60324), raddr=('54.174.31.151', 443)>

2019-10-02 14:47:35,157 (MainThread): Error sending message, disabling tracking
2019-10-02 14:47:35,193 (MainThread): Parsing macros\core.sql
2019-10-02 14:47:35,205 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:47:35,274 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:47:35,292 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:47:35,296 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:47:35,301 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:47:35,307 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:47:35,312 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:47:35,316 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:47:35,331 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:47:35,346 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:47:35,364 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:47:35,419 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:47:35,465 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:47:35,470 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:47:35,498 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:47:35,510 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:47:35,521 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:47:35,532 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:47:35,536 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:47:35,540 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:47:35,543 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:47:35,548 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:47:35,571 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:47:35,577 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:47:35,592 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:47:35,597 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:47:35,604 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:47:35,655 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:47:35,657 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:47:35,658 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:47:35,661 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:47:35,919 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:47:35,943 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:47:36,606 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:47:36,609 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:47:36,609 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:47:36,619 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:47:36,621 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:47:36,621 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:47:36,630 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:47:36,632 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:47:36,632 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:47:36,640 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:47:36,642 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:47:36,643 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:47:36,651 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:47:36,653 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:47:36,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:47:36,662 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:47:36,664 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:47:36,664 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:47:36,672 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:47:36,676 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:47:36,676 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:47:36,687 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:47:36,689 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:47:36,689 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:47:36,701 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:47:36,704 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:47:36,705 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:47:36,722 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:47:36,725 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:47:36,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:47:36,739 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:47:36,744 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:47:36,744 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:47:36,754 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:47:36,756 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:47:36,756 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:47:36,766 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:47:36,768 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:47:36,768 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:47:36,776 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:47:36,778 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:47:36,778 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:47:36,785 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:47:36,787 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:47:36,787 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:47:36,796 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:47:36,798 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:47:36,798 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:47:36,805 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:47:36,807 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:36,807 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:47:36,823 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:47:36,825 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:36,825 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:47:36,833 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:47:36,835 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:47:36,835 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:47:36,844 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:47:36,846 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:47:36,846 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:47:36,950 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:47:36,954 (MainThread): 
2019-10-02 14:47:36,955 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:47:36,955 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:47:37,001 (MainThread): Parsing macros\core.sql
2019-10-02 14:47:37,014 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:47:37,122 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:47:37,150 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:47:37,155 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:47:37,163 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:47:37,172 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:47:37,181 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:47:37,187 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:47:37,213 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:47:37,233 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:47:37,261 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:47:37,310 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:47:37,374 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:47:37,388 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:47:37,424 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:47:37,441 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:47:37,460 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:47:37,476 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:47:37,480 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:47:37,484 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:47:37,489 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:47:37,494 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:47:37,522 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:47:37,528 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:47:37,549 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:47:37,555 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:47:37,562 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:47:37,764 (MainThread): Using snowflake connection "master".
2019-10-02 14:47:37,764 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:47:39,136 (MainThread): SQL status: SUCCESS 29 in 1.37 seconds
2019-10-02 14:47:39,233 (MainThread): Using snowflake connection "master".
2019-10-02 14:47:39,233 (MainThread): On master: BEGIN
2019-10-02 14:47:39,398 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:47:39,398 (MainThread): Using snowflake connection "master".
2019-10-02 14:47:39,399 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 14:47:40,438 (MainThread): SQL status: SUCCESS 5 in 1.04 seconds
2019-10-02 14:47:40,447 (MainThread): On master: ROLLBACK
2019-10-02 14:47:40,616 (MainThread): Using snowflake connection "master".
2019-10-02 14:47:40,617 (MainThread): On master: BEGIN
2019-10-02 14:47:40,897 (MainThread): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-02 14:47:40,898 (MainThread): On master: COMMIT
2019-10-02 14:47:40,898 (MainThread): Using snowflake connection "master".
2019-10-02 14:47:40,898 (MainThread): On master: COMMIT
2019-10-02 14:47:41,032 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 14:47:41,032 (MainThread): 14:47:41 | Concurrency: 1 threads (target='dev')
2019-10-02 14:47:41,033 (MainThread): 14:47:41 | 
2019-10-02 14:47:41,037 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:47:41,038 (Thread-1): Opening a new connection, currently in state init
2019-10-02 14:47:41,474 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 14:47:41,486 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 14:47:41,494 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:47:41,497 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:47:41,497 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 14:47:41,507 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 14:47:41,515 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:47:41,519 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:47:41,520 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 14:47:41,529 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 14:47:41,537 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:47:41,537 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:47:41,538 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 14:47:41,553 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 14:47:41,561 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:47:41,562 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:47:41,563 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 14:47:41,573 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 14:47:41,582 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:47:41,587 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:47:41,588 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 14:47:41,600 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 14:47:41,611 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:47:41,612 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:47:41,619 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 14:47:41,635 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 14:47:41,647 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:47:41,647 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:47:41,651 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 14:47:41,663 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 14:47:41,675 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:47:41,679 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:47:41,680 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 14:47:41,691 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 14:47:41,703 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:47:41,706 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:47:41,707 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:47:41,717 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 14:47:41,726 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:47:41,726 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:47:41,727 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 14:47:41,740 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 14:47:41,750 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:47:41,753 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:47:41,755 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 14:47:41,764 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 14:47:41,773 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:47:41,773 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:47:41,774 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 14:47:41,783 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 14:47:41,797 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:47:41,800 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:47:41,801 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 14:47:41,813 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 14:47:41,822 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 14:47:41,823 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:47:41,824 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 14:47:41,838 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 14:47:41,850 (Thread-1): 14:47:41 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 14:47:41,855 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:41,855 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:47:41,856 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 14:47:41,873 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:47:42,020 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:42,020 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 14:47:42,143 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:47:42,144 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:42,144 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_stream_test bk_1)

-- GROUP BY 1
      );
2019-10-02 14:47:43,099 (Thread-1): SQL status: SUCCESS 1 in 0.95 seconds
2019-10-02 14:47:43,106 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:43,106 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:47:46,013 (Thread-1): SQL status: SUCCESS 24 in 2.91 seconds
2019-10-02 14:47:46,023 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:46,023 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:47:48,181 (Thread-1): SQL status: SUCCESS 24 in 2.16 seconds
2019-10-02 14:47:48,194 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:48,195 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:47:50,396 (Thread-1): SQL status: SUCCESS 24 in 2.20 seconds
2019-10-02 14:47:50,464 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 14:47:50,476 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:50,476 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 14:47:51,208 (Thread-1): SQL status: SUCCESS 2 in 0.73 seconds
2019-10-02 14:47:51,211 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:47:51,212 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 14:47:51,212 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 14:47:51,447 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-02 14:47:51,457 (Thread-1): 14:47:51 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 2 in 9.60s]
2019-10-02 14:47:51,460 (Thread-1): 14:47:51 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 14:47:51,469 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:51,470 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:47:51,474 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:47:51,491 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:47:51,532 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:51,532 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 14:47:51,693 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 14:47:51,695 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:51,695 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:47:52,606 (Thread-1): SQL status: SUCCESS 1 in 0.91 seconds
2019-10-02 14:47:52,612 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:52,612 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:47:54,702 (Thread-1): SQL status: SUCCESS 6 in 2.09 seconds
2019-10-02 14:47:54,707 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:54,707 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:47:56,733 (Thread-1): SQL status: SUCCESS 6 in 2.03 seconds
2019-10-02 14:47:56,746 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:56,746 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:47:58,922 (Thread-1): SQL status: SUCCESS 6 in 2.18 seconds
2019-10-02 14:47:58,927 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 14:47:58,933 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:58,933 (Thread-1): On with_fl_acr_booking_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking_service (SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT)
        (
            select SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
        );
2019-10-02 14:47:59,441 (Thread-1): SQL status: SUCCESS 7 in 0.51 seconds
2019-10-02 14:47:59,446 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:47:59,446 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:47:59,446 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 14:47:59,964 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2019-10-02 14:47:59,972 (Thread-1): 14:47:59 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 7 in 8.50s]
2019-10-02 14:47:59,973 (Thread-1): 14:47:59 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 14:47:59,978 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:47:59,978 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:47:59,979 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 14:47:59,990 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:48:00,026 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:48:00,028 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 14:48:00,176 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 14:48:00,176 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:48:00,177 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:48:03,555 (Thread-1): SQL status: SUCCESS 1 in 3.38 seconds
2019-10-02 14:48:03,560 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:48:03,561 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:48:05,714 (Thread-1): SQL status: SUCCESS 15 in 2.15 seconds
2019-10-02 14:48:05,724 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:48:05,725 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:48:07,565 (Thread-1): SQL status: SUCCESS 15 in 1.84 seconds
2019-10-02 14:48:07,570 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:48:07,570 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:48:09,543 (Thread-1): SQL status: SUCCESS 15 in 1.97 seconds
2019-10-02 14:48:09,548 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 14:48:16,545 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:48:16,545 (Thread-1): On with_fl_acr_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_service (SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT)
        (
            select SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
        );
2019-10-02 14:48:17,233 (Thread-1): SQL status: SUCCESS 12 in 0.69 seconds
2019-10-02 14:48:17,236 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:48:17,237 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 14:48:17,237 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 14:48:17,437 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 14:48:17,447 (Thread-1): 14:48:17 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 12 in 17.46s]
2019-10-02 14:48:17,448 (Thread-1): 14:48:17 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 14:48:17,450 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:17,450 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:48:17,451 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 14:48:17,465 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:48:17,484 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:17,484 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 14:48:17,609 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:48:17,609 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:17,610 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_element_stream_test)

-- GROUP BY 1
      );
2019-10-02 14:48:18,290 (Thread-1): SQL status: SUCCESS 1 in 0.68 seconds
2019-10-02 14:48:18,300 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:18,301 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:48:20,252 (Thread-1): SQL status: SUCCESS 5 in 1.95 seconds
2019-10-02 14:48:20,259 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:20,259 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:48:22,126 (Thread-1): SQL status: SUCCESS 5 in 1.87 seconds
2019-10-02 14:48:22,144 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:22,145 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:48:24,028 (Thread-1): SQL status: SUCCESS 5 in 1.88 seconds
2019-10-02 14:48:24,036 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 14:48:24,047 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:24,047 (Thread-1): On with_fl_acr_service_element: insert into OPA_DEV.DBT_TEST.with_fl_acr_service_element (SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT)
        (
            select SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
        );
2019-10-02 14:48:24,622 (Thread-1): SQL status: SUCCESS 6 in 0.58 seconds
2019-10-02 14:48:24,626 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:48:24,627 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 14:48:24,627 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 14:48:24,886 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-02 14:48:24,893 (Thread-1): 14:48:24 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 6 in 7.44s]
2019-10-02 14:48:24,894 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:48:24,895 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:48:24,896 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 14:48:24,903 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 14:48:24,910 (Thread-1): 14:48:24 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 14:48:24,913 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:48:24,913 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:48:24,914 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 14:48:26,082 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:48:26,202 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:48:26,202 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 14:48:26,302 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:48:26,302 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:48:26,303 (Thread-1): On booking_fact_uk: create or replace temporary table OPA_DEV.DBT_TEST.booking_fact_uk__dbt_tmp
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 14:49:03,054 (Thread-1): SQL status: SUCCESS 1 in 36.75 seconds
2019-10-02 14:49:03,071 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:49:03,072 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:49:05,276 (Thread-1): SQL status: SUCCESS 77 in 2.20 seconds
2019-10-02 14:49:05,295 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:49:05,295 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:49:07,193 (Thread-1): SQL status: SUCCESS 77 in 1.90 seconds
2019-10-02 14:49:07,214 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:49:07,214 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 14:49:09,653 (Thread-1): SQL status: SUCCESS 77 in 2.44 seconds
2019-10-02 14:49:09,663 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 14:49:09,690 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 14:49:09,691 (Thread-1): On booking_fact_uk: merge into OPA_DEV.DBT_TEST.booking_fact_uk as DBT_INTERNAL_DEST
    using OPA_DEV.DBT_TEST.booking_fact_uk__dbt_tmp as DBT_INTERNAL_SOURCE

    
        on DBT_INTERNAL_SOURCE.bk_booking = DBT_INTERNAL_DEST.bk_booking
    

    
    when matched then update set
        BK_BOOKING = DBT_INTERNAL_SOURCE.BK_BOOKING,BK_PRIMARY_ACCOM = DBT_INTERNAL_SOURCE.BK_PRIMARY_ACCOM,BK_PRIMARY_ROOM = DBT_INTERNAL_SOURCE.BK_PRIMARY_ROOM,BK_FIRST_FLIGHT = DBT_INTERNAL_SOURCE.BK_FIRST_FLIGHT,BK_LAST_FLIGHT = DBT_INTERNAL_SOURCE.BK_LAST_FLIGHT,BK_SOURCE_MARKET = DBT_INTERNAL_SOURCE.BK_SOURCE_MARKET,BK_ORIGINATING_SYSTEM = DBT_INTERNAL_SOURCE.BK_ORIGINATING_SYSTEM,BK_BOOKING_TYPE = DBT_INTERNAL_SOURCE.BK_BOOKING_TYPE,BK_BOOKING_STATUS = DBT_INTERNAL_SOURCE.BK_BOOKING_STATUS,SOURCE_BOOKING_ID = DBT_INTERNAL_SOURCE.SOURCE_BOOKING_ID,SOURCE_BOOKING_VERSION = DBT_INTERNAL_SOURCE.SOURCE_BOOKING_VERSION,BOOKING_CREATED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CREATED_DATETIME,BOOKING_CONFIRMED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CONFIRMED_DATETIME,BOOKING_CANCELLED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CANCELLED_DATETIME,GROUP_SEASON = DBT_INTERNAL_SOURCE.GROUP_SEASON,SM_SEASON = DBT_INTERNAL_SOURCE.SM_SEASON,CHANNEL_CODE = DBT_INTERNAL_SOURCE.CHANNEL_CODE,CHANNEL_DESC = DBT_INTERNAL_SOURCE.CHANNEL_DESC,BOOKED_BOARD_CODE = DBT_INTERNAL_SOURCE.BOOKED_BOARD_CODE,BOOKED_BOARD_NAME = DBT_INTERNAL_SOURCE.BOOKED_BOARD_NAME,MULTI_ROOM_BOOKING = DBT_INTERNAL_SOURCE.MULTI_ROOM_BOOKING,NUMBER_OF_BOOKED_ROOMS = DBT_INTERNAL_SOURCE.NUMBER_OF_BOOKED_ROOMS,MULTI_CENTRE_BOOKING = DBT_INTERNAL_SOURCE.MULTI_CENTRE_BOOKING,DEPARTURE_DATE = DBT_INTERNAL_SOURCE.DEPARTURE_DATE,RETURN_DATE = DBT_INTERNAL_SOURCE.RETURN_DATE,DURATION = DBT_INTERNAL_SOURCE.DURATION,STD_NUMBER_OF_BOOKING_ADULT_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_ADULT_PAX,STD_NUMBER_OF_BOOKING_CHILD_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_CHILD_PAX,STD_NUMBER_OF_BOOKING_INFANT_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_INFANT_PAX,STD_NUMBER_OF_BOOKING_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_PAX,SM_NUMBER_OF_BOOKING_ADULT_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_ADULT_PAX,SM_NUMBER_OF_BOOKING_TEENAGER_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_TEENAGER_PAX,SM_NUMBER_OF_BOOKING_CHILD_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_CHILD_PAX,SM_NUMBER_OF_BOOKING_INFANT_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_INFANT_PAX,SM_NUMBER_OF_BOOKING_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_PAX,PRIMARY_GATEWAY = DBT_INTERNAL_SOURCE.PRIMARY_GATEWAY,SM_CURRENCY = DBT_INTERNAL_SOURCE.SM_CURRENCY,SM_REVENUE = DBT_INTERNAL_SOURCE.SM_REVENUE,SM_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.SM_CNX_AND_AMEND_REVENUE,SM_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.SM_ACCOMMODATION_COSTS,SM_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SM_EARLY_BOOKING_DISCOUNTS,SM_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SM_LATE_BOOKING_DISCOUNTS,SM_FLYING_COSTS = DBT_INTERNAL_SOURCE.SM_FLYING_COSTS,SM_OTHER_COSTS = DBT_INTERNAL_SOURCE.SM_OTHER_COSTS,SM_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.SM_DISTRIBUTION_COSTS,SM_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.SM_NON_MARGIN_ITEMS,SM_MARGIN = DBT_INTERNAL_SOURCE.SM_MARGIN,SMG_CURRENCY = DBT_INTERNAL_SOURCE.SMG_CURRENCY,SMG_REVENUE = DBT_INTERNAL_SOURCE.SMG_REVENUE,SMG_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.SMG_CNX_AND_AMEND_REVENUE,SMG_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.SMG_ACCOMMODATION_COSTS,SMG_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SMG_EARLY_BOOKING_DISCOUNTS,SMG_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SMG_LATE_BOOKING_DISCOUNTS,SMG_FLYING_COSTS = DBT_INTERNAL_SOURCE.SMG_FLYING_COSTS,SMG_OTHER_COSTS = DBT_INTERNAL_SOURCE.SMG_OTHER_COSTS,SMG_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.SMG_DISTRIBUTION_COSTS,SMG_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.SMG_NON_MARGIN_ITEMS,SMG_MARGIN = DBT_INTERNAL_SOURCE.SMG_MARGIN,REP_CURRENCY = DBT_INTERNAL_SOURCE.REP_CURRENCY,REP_REVENUE = DBT_INTERNAL_SOURCE.REP_REVENUE,REP_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.REP_CNX_AND_AMEND_REVENUE,REP_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.REP_ACCOMMODATION_COSTS,REP_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.REP_EARLY_BOOKING_DISCOUNTS,REP_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.REP_LATE_BOOKING_DISCOUNTS,REP_FLYING_COSTS = DBT_INTERNAL_SOURCE.REP_FLYING_COSTS,REP_OTHER_COSTS = DBT_INTERNAL_SOURCE.REP_OTHER_COSTS,REP_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.REP_DISTRIBUTION_COSTS,REP_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.REP_NON_MARGIN_ITEMS,REP_MARGIN = DBT_INTERNAL_SOURCE.REP_MARGIN,FFD_FLAG = DBT_INTERNAL_SOURCE.FFD_FLAG,RECORD_TYPE = DBT_INTERNAL_SOURCE.RECORD_TYPE,EFFECTIVE_FROM = DBT_INTERNAL_SOURCE.EFFECTIVE_FROM,EFFECTIVE_TO = DBT_INTERNAL_SOURCE.EFFECTIVE_TO,SM_CREATED_DATETIME = DBT_INTERNAL_SOURCE.SM_CREATED_DATETIME,SM_UPDATED_DATETIME = DBT_INTERNAL_SOURCE.SM_UPDATED_DATETIME,DM_CREATED_DATETIME = DBT_INTERNAL_SOURCE.DM_CREATED_DATETIME,LATEST_RECORD_INDICATOR = DBT_INTERNAL_SOURCE.LATEST_RECORD_INDICATOR
    

    when not matched then insert
        (BK_BOOKING, BK_PRIMARY_ACCOM, BK_PRIMARY_ROOM, BK_FIRST_FLIGHT, BK_LAST_FLIGHT, BK_SOURCE_MARKET, BK_ORIGINATING_SYSTEM, BK_BOOKING_TYPE, BK_BOOKING_STATUS, SOURCE_BOOKING_ID, SOURCE_BOOKING_VERSION, BOOKING_CREATED_DATETIME, BOOKING_CONFIRMED_DATETIME, BOOKING_CANCELLED_DATETIME, GROUP_SEASON, SM_SEASON, CHANNEL_CODE, CHANNEL_DESC, BOOKED_BOARD_CODE, BOOKED_BOARD_NAME, MULTI_ROOM_BOOKING, NUMBER_OF_BOOKED_ROOMS, MULTI_CENTRE_BOOKING, DEPARTURE_DATE, RETURN_DATE, DURATION, STD_NUMBER_OF_BOOKING_ADULT_PAX, STD_NUMBER_OF_BOOKING_CHILD_PAX, STD_NUMBER_OF_BOOKING_INFANT_PAX, STD_NUMBER_OF_BOOKING_PAX, SM_NUMBER_OF_BOOKING_ADULT_PAX, SM_NUMBER_OF_BOOKING_TEENAGER_PAX, SM_NUMBER_OF_BOOKING_CHILD_PAX, SM_NUMBER_OF_BOOKING_INFANT_PAX, SM_NUMBER_OF_BOOKING_PAX, PRIMARY_GATEWAY, SM_CURRENCY, SM_REVENUE, SM_CNX_AND_AMEND_REVENUE, SM_ACCOMMODATION_COSTS, SM_EARLY_BOOKING_DISCOUNTS, SM_LATE_BOOKING_DISCOUNTS, SM_FLYING_COSTS, SM_OTHER_COSTS, SM_DISTRIBUTION_COSTS, SM_NON_MARGIN_ITEMS, SM_MARGIN, SMG_CURRENCY, SMG_REVENUE, SMG_CNX_AND_AMEND_REVENUE, SMG_ACCOMMODATION_COSTS, SMG_EARLY_BOOKING_DISCOUNTS, SMG_LATE_BOOKING_DISCOUNTS, SMG_FLYING_COSTS, SMG_OTHER_COSTS, SMG_DISTRIBUTION_COSTS, SMG_NON_MARGIN_ITEMS, SMG_MARGIN, REP_CURRENCY, REP_REVENUE, REP_CNX_AND_AMEND_REVENUE, REP_ACCOMMODATION_COSTS, REP_EARLY_BOOKING_DISCOUNTS, REP_LATE_BOOKING_DISCOUNTS, REP_FLYING_COSTS, REP_OTHER_COSTS, REP_DISTRIBUTION_COSTS, REP_NON_MARGIN_ITEMS, REP_MARGIN, FFD_FLAG, RECORD_TYPE, EFFECTIVE_FROM, EFFECTIVE_TO, SM_CREATED_DATETIME, SM_UPDATED_DATETIME, DM_CREATED_DATETIME, LATEST_RECORD_INDICATOR)
    values
        (BK_BOOKING, BK_PRIMARY_ACCOM, BK_PRIMARY_ROOM, BK_FIRST_FLIGHT, BK_LAST_FLIGHT, BK_SOURCE_MARKET, BK_ORIGINATING_SYSTEM, BK_BOOKING_TYPE, BK_BOOKING_STATUS, SOURCE_BOOKING_ID, SOURCE_BOOKING_VERSION, BOOKING_CREATED_DATETIME, BOOKING_CONFIRMED_DATETIME, BOOKING_CANCELLED_DATETIME, GROUP_SEASON, SM_SEASON, CHANNEL_CODE, CHANNEL_DESC, BOOKED_BOARD_CODE, BOOKED_BOARD_NAME, MULTI_ROOM_BOOKING, NUMBER_OF_BOOKED_ROOMS, MULTI_CENTRE_BOOKING, DEPARTURE_DATE, RETURN_DATE, DURATION, STD_NUMBER_OF_BOOKING_ADULT_PAX, STD_NUMBER_OF_BOOKING_CHILD_PAX, STD_NUMBER_OF_BOOKING_INFANT_PAX, STD_NUMBER_OF_BOOKING_PAX, SM_NUMBER_OF_BOOKING_ADULT_PAX, SM_NUMBER_OF_BOOKING_TEENAGER_PAX, SM_NUMBER_OF_BOOKING_CHILD_PAX, SM_NUMBER_OF_BOOKING_INFANT_PAX, SM_NUMBER_OF_BOOKING_PAX, PRIMARY_GATEWAY, SM_CURRENCY, SM_REVENUE, SM_CNX_AND_AMEND_REVENUE, SM_ACCOMMODATION_COSTS, SM_EARLY_BOOKING_DISCOUNTS, SM_LATE_BOOKING_DISCOUNTS, SM_FLYING_COSTS, SM_OTHER_COSTS, SM_DISTRIBUTION_COSTS, SM_NON_MARGIN_ITEMS, SM_MARGIN, SMG_CURRENCY, SMG_REVENUE, SMG_CNX_AND_AMEND_REVENUE, SMG_ACCOMMODATION_COSTS, SMG_EARLY_BOOKING_DISCOUNTS, SMG_LATE_BOOKING_DISCOUNTS, SMG_FLYING_COSTS, SMG_OTHER_COSTS, SMG_DISTRIBUTION_COSTS, SMG_NON_MARGIN_ITEMS, SMG_MARGIN, REP_CURRENCY, REP_REVENUE, REP_CNX_AND_AMEND_REVENUE, REP_ACCOMMODATION_COSTS, REP_EARLY_BOOKING_DISCOUNTS, REP_LATE_BOOKING_DISCOUNTS, REP_FLYING_COSTS, REP_OTHER_COSTS, REP_DISTRIBUTION_COSTS, REP_NON_MARGIN_ITEMS, REP_MARGIN, FFD_FLAG, RECORD_TYPE, EFFECTIVE_FROM, EFFECTIVE_TO, SM_CREATED_DATETIME, SM_UPDATED_DATETIME, DM_CREATED_DATETIME, LATEST_RECORD_INDICATOR)
2019-10-02 14:49:12,070 (Thread-1): Snowflake error: 100090 (42P18): 018f471d-0092-4a2f-0000-0e2901621a66: Duplicate row detected during DML action
Row Values: ["UKATCOM|9128425|2", "UKATCOM|ESIB0073", "UKATCOM|1265812", "UKATCOM|IBZBHX3ABHXIBZ|20190821", "UKATCOM|IBZBHX3AIBZBHX|20190904", "UKATCOM|GB", "UKATCOM", "UKATCOM|PKG", "UKATCOM|BKG", 9128425, 2, 1550534400000000000, 1550591445000000000, 32503679999000000000, "S19", "S19", "UKATCOM|ECOM", "UKATCOM|E-Commerce", "UKATCOM|56663", "UKATCOM|Bed & Breakfast", "N", 1, "N", 1566345600000000000, 1567555200000000000, 14, 2, 0, 0, 2, 2, 0, 0, 0, 2, "IBZ", "GBP", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "GBP", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "EUR", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "N", "Insert", 1552553475000000000, 4102444799000000000, 1552521600000000000, 1552521600000000000, 1570027570926000000, "Y"]
2019-10-02 14:49:12,070 (Thread-1): On booking_fact_uk: ROLLBACK
2019-10-02 14:49:12,283 (Thread-1): 14:49:12 | 5 of 5 ERROR creating incremental model DBT_TEST.booking_fact_uk..... [ERROR in 47.37s]
2019-10-02 14:49:12,345 (MainThread): Using snowflake connection "master".
2019-10-02 14:49:12,345 (MainThread): On master: BEGIN
2019-10-02 14:49:12,451 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 14:49:12,451 (MainThread): On master: COMMIT
2019-10-02 14:49:12,452 (MainThread): Using snowflake connection "master".
2019-10-02 14:49:12,452 (MainThread): On master: COMMIT
2019-10-02 14:49:12,589 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 14:49:12,590 (MainThread): 14:49:12 | 
2019-10-02 14:49:12,590 (MainThread): 14:49:12 | Finished running 5 incremental models in 95.64s.
2019-10-02 14:49:12,590 (MainThread): Connection 'master' was left open.
2019-10-02 14:49:12,591 (MainThread): On master: Close
2019-10-02 14:49:12,743 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 14:49:12,744 (MainThread): On booking_fact_uk: Close
2019-10-02 14:49:12,941 (MainThread): 
2019-10-02 14:49:12,941 (MainThread): Completed with 1 error and 0 warnings:
2019-10-02 14:49:12,942 (MainThread): 
2019-10-02 14:49:12,943 (MainThread): Database Error in model booking_fact_uk (models\booking_fact_uk.sql)
2019-10-02 14:49:12,944 (MainThread):   100090 (42P18): 018f471d-0092-4a2f-0000-0e2901621a66: Duplicate row detected during DML action
2019-10-02 14:49:12,946 (MainThread):   Row Values: ["UKATCOM|9128425|2", "UKATCOM|ESIB0073", "UKATCOM|1265812", "UKATCOM|IBZBHX3ABHXIBZ|20190821", "UKATCOM|IBZBHX3AIBZBHX|20190904", "UKATCOM|GB", "UKATCOM", "UKATCOM|PKG", "UKATCOM|BKG", 9128425, 2, 1550534400000000000, 1550591445000000000, 32503679999000000000, "S19", "S19", "UKATCOM|ECOM", "UKATCOM|E-Commerce", "UKATCOM|56663", "UKATCOM|Bed & Breakfast", "N", 1, "N", 1566345600000000000, 1567555200000000000, 14, 2, 0, 0, 2, 2, 0, 0, 0, 2, "IBZ", "GBP", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "GBP", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "EUR", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "N", "Insert", 1552553475000000000, 4102444799000000000, 1552521600000000000, 1552521600000000000, 1570027570926000000, "Y"]
2019-10-02 14:49:12,948 (MainThread):   compiled SQL at target\compiled\dbt_test\booking_fact_uk.sql
2019-10-02 14:49:12,949 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2019-10-02 14:49:12,950 (MainThread): Flushing usage events
2019-10-02 14:59:55,788 (MainThread): Tracking: tracking
2019-10-02 14:59:55,790 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972F48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005972448>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E408>]}
2019-10-02 14:59:56,114 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 14:59:56,116 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60481), raddr=('54.174.31.151', 443)>

2019-10-02 14:59:56,119 (MainThread): Error sending message, disabling tracking
2019-10-02 14:59:56,165 (MainThread): Parsing macros\core.sql
2019-10-02 14:59:56,176 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:59:56,263 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:59:56,279 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:59:56,282 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:59:56,285 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:59:56,289 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:59:56,292 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:59:56,294 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:59:56,303 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:59:56,311 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:59:56,320 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:59:56,338 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:59:56,358 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:59:56,361 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:59:56,376 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:59:56,391 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:59:56,398 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:59:56,405 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:59:56,407 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:59:56,409 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:59:56,412 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:59:56,415 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:59:56,427 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:59:56,431 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:59:56,440 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:59:56,444 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:59:56,448 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:59:56,477 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 14:59:56,479 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 14:59:56,479 (MainThread): Opening a new connection, currently in state init
2019-10-02 14:59:56,482 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 14:59:56,799 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 14:59:56,824 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 14:59:57,465 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 14:59:57,466 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 14:59:57,466 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 14:59:57,471 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 14:59:57,473 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 14:59:57,473 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 14:59:57,478 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 14:59:57,479 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 14:59:57,480 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 14:59:57,485 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 14:59:57,487 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 14:59:57,487 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 14:59:57,493 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 14:59:57,494 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 14:59:57,494 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 14:59:57,499 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 14:59:57,500 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 14:59:57,500 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 14:59:57,504 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 14:59:57,505 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 14:59:57,505 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 14:59:57,509 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 14:59:57,510 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 14:59:57,511 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 14:59:57,516 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 14:59:57,517 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 14:59:57,517 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 14:59:57,521 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 14:59:57,522 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 14:59:57,523 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 14:59:57,527 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 14:59:57,528 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 14:59:57,528 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 14:59:57,533 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 14:59:57,534 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 14:59:57,534 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 14:59:57,538 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 14:59:57,539 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 14:59:57,539 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 14:59:57,544 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 14:59:57,545 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 14:59:57,545 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 14:59:57,549 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 14:59:57,550 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 14:59:57,550 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 14:59:57,555 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 14:59:57,556 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 14:59:57,556 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 14:59:57,560 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 14:59:57,561 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 14:59:57,562 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 14:59:57,571 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 14:59:57,572 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 14:59:57,572 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 14:59:57,578 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 14:59:57,579 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 14:59:57,580 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 14:59:57,585 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 14:59:57,586 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 14:59:57,586 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 14:59:57,644 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 14:59:57,646 (MainThread): 
2019-10-02 14:59:57,647 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 14:59:57,647 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 14:59:57,672 (MainThread): Parsing macros\core.sql
2019-10-02 14:59:57,680 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 14:59:57,732 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 14:59:57,751 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 14:59:57,755 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 14:59:57,762 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 14:59:57,770 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 14:59:57,777 (MainThread): Parsing macros\etc\query.sql
2019-10-02 14:59:57,782 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 14:59:57,796 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 14:59:57,805 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 14:59:57,816 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 14:59:57,835 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 14:59:57,855 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 14:59:57,858 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 14:59:57,871 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 14:59:57,878 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 14:59:57,884 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 14:59:57,896 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 14:59:57,901 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 14:59:57,903 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 14:59:57,905 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 14:59:57,909 (MainThread): Parsing macros\adapters.sql
2019-10-02 14:59:57,939 (MainThread): Parsing macros\catalog.sql
2019-10-02 14:59:57,945 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 14:59:57,956 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 14:59:57,961 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 14:59:57,967 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 14:59:58,093 (MainThread): Using snowflake connection "master".
2019-10-02 14:59:58,094 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 14:59:58,648 (MainThread): SQL status: SUCCESS 29 in 0.55 seconds
2019-10-02 14:59:58,768 (MainThread): Using snowflake connection "master".
2019-10-02 14:59:58,769 (MainThread): On master: BEGIN
2019-10-02 14:59:58,891 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 14:59:58,891 (MainThread): Using snowflake connection "master".
2019-10-02 14:59:58,892 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 15:00:00,183 (MainThread): SQL status: SUCCESS 5 in 1.29 seconds
2019-10-02 15:00:00,193 (MainThread): On master: ROLLBACK
2019-10-02 15:00:00,339 (MainThread): Using snowflake connection "master".
2019-10-02 15:00:00,340 (MainThread): On master: BEGIN
2019-10-02 15:00:00,467 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 15:00:00,468 (MainThread): On master: COMMIT
2019-10-02 15:00:00,469 (MainThread): Using snowflake connection "master".
2019-10-02 15:00:00,469 (MainThread): On master: COMMIT
2019-10-02 15:00:00,667 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 15:00:00,668 (MainThread): 15:00:00 | Concurrency: 1 threads (target='dev')
2019-10-02 15:00:00,669 (MainThread): 15:00:00 | 
2019-10-02 15:00:00,680 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:00:00,680 (Thread-1): Opening a new connection, currently in state init
2019-10-02 15:00:01,108 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 15:00:01,127 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 15:00:01,132 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:00:01,132 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:00:01,135 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 15:00:01,141 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 15:00:01,146 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:00:01,149 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:00:01,150 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 15:00:01,157 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 15:00:01,162 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:00:01,162 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:00:01,163 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 15:00:01,170 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 15:00:01,175 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:00:01,176 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:00:01,176 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 15:00:01,181 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 15:00:01,188 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:00:01,188 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:00:01,189 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 15:00:01,199 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 15:00:01,204 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:00:01,204 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:00:01,204 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 15:00:01,209 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 15:00:01,217 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:00:01,217 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:00:01,217 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 15:00:01,223 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 15:00:01,230 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:00:01,231 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:00:01,232 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 15:00:01,248 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 15:00:01,255 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:00:01,255 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:00:01,256 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:00:01,265 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 15:00:01,272 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:00:01,272 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:00:01,273 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 15:00:01,284 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 15:00:01,293 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:00:01,293 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:00:01,294 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 15:00:01,310 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 15:00:01,318 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:00:01,322 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:00:01,322 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 15:00:01,329 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 15:00:01,335 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:00:01,337 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:00:01,338 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 15:00:01,344 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 15:00:01,350 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 15:00:01,352 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:00:01,353 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 15:00:01,362 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 15:00:01,369 (Thread-1): 15:00:01 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 15:00:01,372 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:01,372 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:00:01,373 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 15:00:01,384 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:00:01,485 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:01,485 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 15:00:01,625 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 15:00:01,625 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:01,625 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_stream_test bk_1)

      );
2019-10-02 15:00:02,761 (Thread-1): SQL status: SUCCESS 1 in 1.13 seconds
2019-10-02 15:00:02,767 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:02,768 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:05,628 (Thread-1): SQL status: SUCCESS 24 in 2.86 seconds
2019-10-02 15:00:05,648 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:05,649 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:07,729 (Thread-1): SQL status: SUCCESS 24 in 2.08 seconds
2019-10-02 15:00:07,741 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:07,741 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:10,067 (Thread-1): SQL status: SUCCESS 24 in 2.33 seconds
2019-10-02 15:00:10,115 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:00:10,121 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:10,121 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 15:00:11,305 (Thread-1): SQL status: SUCCESS 2 in 1.18 seconds
2019-10-02 15:00:11,309 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:00:11,310 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:00:11,310 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:00:11,569 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-02 15:00:11,581 (Thread-1): 15:00:11 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 2 in 10.20s]
2019-10-02 15:00:11,585 (Thread-1): 15:00:11 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 15:00:11,591 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:11,591 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:00:11,593 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:00:11,605 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:00:11,623 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:11,624 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 15:00:11,817 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-02 15:00:11,817 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:11,818 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_service_stream_test)

      );
2019-10-02 15:00:12,603 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2019-10-02 15:00:12,622 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:12,622 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:14,968 (Thread-1): SQL status: SUCCESS 6 in 2.35 seconds
2019-10-02 15:00:14,985 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:14,986 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:16,818 (Thread-1): SQL status: SUCCESS 6 in 1.83 seconds
2019-10-02 15:00:16,829 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:16,829 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:19,888 (Thread-1): SQL status: SUCCESS 6 in 3.06 seconds
2019-10-02 15:00:19,897 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:00:19,905 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:19,905 (Thread-1): On with_fl_acr_booking_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking_service (SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT)
        (
            select SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
        );
2019-10-02 15:00:20,472 (Thread-1): SQL status: SUCCESS 7 in 0.57 seconds
2019-10-02 15:00:20,474 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:00:20,474 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:00:20,474 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:00:20,735 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-02 15:00:20,742 (Thread-1): 15:00:20 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 7 in 9.15s]
2019-10-02 15:00:20,743 (Thread-1): 15:00:20 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 15:00:20,746 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:00:20,746 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:00:20,747 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 15:00:20,761 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:00:20,782 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:00:20,782 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 15:00:20,886 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 15:00:20,886 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:00:20,887 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_stream_test)

      );
2019-10-02 15:00:25,568 (Thread-1): SQL status: SUCCESS 1 in 4.68 seconds
2019-10-02 15:00:25,585 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:00:25,586 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:28,070 (Thread-1): SQL status: SUCCESS 15 in 2.48 seconds
2019-10-02 15:00:28,084 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:00:28,085 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:30,746 (Thread-1): SQL status: SUCCESS 15 in 2.66 seconds
2019-10-02 15:00:30,759 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:00:30,759 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:33,099 (Thread-1): SQL status: SUCCESS 15 in 2.34 seconds
2019-10-02 15:00:33,108 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:00:33,118 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:00:33,119 (Thread-1): On with_fl_acr_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_service (SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT)
        (
            select SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
        );
2019-10-02 15:00:33,935 (Thread-1): SQL status: SUCCESS 12 in 0.82 seconds
2019-10-02 15:00:33,939 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:00:33,939 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:00:33,940 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:00:34,327 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2019-10-02 15:00:34,342 (Thread-1): 15:00:34 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 12 in 13.59s]
2019-10-02 15:00:34,345 (Thread-1): 15:00:34 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 15:00:34,351 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:34,352 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:00:34,354 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 15:00:34,368 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:00:34,382 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:34,383 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 15:00:34,615 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-02 15:00:34,617 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:34,617 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_element_stream_test)

      );
2019-10-02 15:00:35,341 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2019-10-02 15:00:35,358 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:35,358 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:37,912 (Thread-1): SQL status: SUCCESS 5 in 2.55 seconds
2019-10-02 15:00:37,931 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:37,932 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:40,583 (Thread-1): SQL status: SUCCESS 5 in 2.65 seconds
2019-10-02 15:00:40,602 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:40,603 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:00:42,621 (Thread-1): SQL status: SUCCESS 5 in 2.02 seconds
2019-10-02 15:00:42,628 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:00:42,637 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:42,638 (Thread-1): On with_fl_acr_service_element: insert into OPA_DEV.DBT_TEST.with_fl_acr_service_element (SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT)
        (
            select SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
        );
2019-10-02 15:00:43,359 (Thread-1): SQL status: SUCCESS 6 in 0.72 seconds
2019-10-02 15:00:43,364 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:00:43,365 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:00:43,365 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:00:43,631 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-02 15:00:43,644 (Thread-1): 15:00:43 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 6 in 9.29s]
2019-10-02 15:00:43,647 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:00:43,648 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:00:43,650 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 15:00:43,668 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 15:00:43,677 (Thread-1): 15:00:43 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 15:00:43,680 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:00:43,681 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:00:43,682 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 15:00:44,878 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:00:45,052 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:00:45,052 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 15:00:45,216 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 15:00:45,217 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:00:45,217 (Thread-1): On booking_fact_uk: create or replace temporary table OPA_DEV.DBT_TEST.booking_fact_uk__dbt_tmp
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
  AND bk.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk.sk_booking_id = bk_2.sk_booking_id AND bk.booking_version = bk_2.booking_version)
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 15:01:44,678 (Thread-1): SQL status: SUCCESS 1 in 59.46 seconds
2019-10-02 15:01:44,696 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:01:44,696 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:01:47,437 (Thread-1): SQL status: SUCCESS 77 in 2.74 seconds
2019-10-02 15:01:47,466 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:01:47,466 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:01:49,540 (Thread-1): SQL status: SUCCESS 77 in 2.07 seconds
2019-10-02 15:01:49,570 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:01:49,571 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:01:51,680 (Thread-1): SQL status: SUCCESS 77 in 2.11 seconds
2019-10-02 15:01:51,707 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:01:51,737 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:01:51,737 (Thread-1): On booking_fact_uk: merge into OPA_DEV.DBT_TEST.booking_fact_uk as DBT_INTERNAL_DEST
    using OPA_DEV.DBT_TEST.booking_fact_uk__dbt_tmp as DBT_INTERNAL_SOURCE

    
        on DBT_INTERNAL_SOURCE.bk_booking = DBT_INTERNAL_DEST.bk_booking
    

    
    when matched then update set
        BK_BOOKING = DBT_INTERNAL_SOURCE.BK_BOOKING,BK_PRIMARY_ACCOM = DBT_INTERNAL_SOURCE.BK_PRIMARY_ACCOM,BK_PRIMARY_ROOM = DBT_INTERNAL_SOURCE.BK_PRIMARY_ROOM,BK_FIRST_FLIGHT = DBT_INTERNAL_SOURCE.BK_FIRST_FLIGHT,BK_LAST_FLIGHT = DBT_INTERNAL_SOURCE.BK_LAST_FLIGHT,BK_SOURCE_MARKET = DBT_INTERNAL_SOURCE.BK_SOURCE_MARKET,BK_ORIGINATING_SYSTEM = DBT_INTERNAL_SOURCE.BK_ORIGINATING_SYSTEM,BK_BOOKING_TYPE = DBT_INTERNAL_SOURCE.BK_BOOKING_TYPE,BK_BOOKING_STATUS = DBT_INTERNAL_SOURCE.BK_BOOKING_STATUS,SOURCE_BOOKING_ID = DBT_INTERNAL_SOURCE.SOURCE_BOOKING_ID,SOURCE_BOOKING_VERSION = DBT_INTERNAL_SOURCE.SOURCE_BOOKING_VERSION,BOOKING_CREATED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CREATED_DATETIME,BOOKING_CONFIRMED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CONFIRMED_DATETIME,BOOKING_CANCELLED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CANCELLED_DATETIME,GROUP_SEASON = DBT_INTERNAL_SOURCE.GROUP_SEASON,SM_SEASON = DBT_INTERNAL_SOURCE.SM_SEASON,CHANNEL_CODE = DBT_INTERNAL_SOURCE.CHANNEL_CODE,CHANNEL_DESC = DBT_INTERNAL_SOURCE.CHANNEL_DESC,BOOKED_BOARD_CODE = DBT_INTERNAL_SOURCE.BOOKED_BOARD_CODE,BOOKED_BOARD_NAME = DBT_INTERNAL_SOURCE.BOOKED_BOARD_NAME,MULTI_ROOM_BOOKING = DBT_INTERNAL_SOURCE.MULTI_ROOM_BOOKING,NUMBER_OF_BOOKED_ROOMS = DBT_INTERNAL_SOURCE.NUMBER_OF_BOOKED_ROOMS,MULTI_CENTRE_BOOKING = DBT_INTERNAL_SOURCE.MULTI_CENTRE_BOOKING,DEPARTURE_DATE = DBT_INTERNAL_SOURCE.DEPARTURE_DATE,RETURN_DATE = DBT_INTERNAL_SOURCE.RETURN_DATE,DURATION = DBT_INTERNAL_SOURCE.DURATION,STD_NUMBER_OF_BOOKING_ADULT_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_ADULT_PAX,STD_NUMBER_OF_BOOKING_CHILD_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_CHILD_PAX,STD_NUMBER_OF_BOOKING_INFANT_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_INFANT_PAX,STD_NUMBER_OF_BOOKING_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_PAX,SM_NUMBER_OF_BOOKING_ADULT_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_ADULT_PAX,SM_NUMBER_OF_BOOKING_TEENAGER_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_TEENAGER_PAX,SM_NUMBER_OF_BOOKING_CHILD_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_CHILD_PAX,SM_NUMBER_OF_BOOKING_INFANT_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_INFANT_PAX,SM_NUMBER_OF_BOOKING_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_PAX,PRIMARY_GATEWAY = DBT_INTERNAL_SOURCE.PRIMARY_GATEWAY,SM_CURRENCY = DBT_INTERNAL_SOURCE.SM_CURRENCY,SM_REVENUE = DBT_INTERNAL_SOURCE.SM_REVENUE,SM_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.SM_CNX_AND_AMEND_REVENUE,SM_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.SM_ACCOMMODATION_COSTS,SM_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SM_EARLY_BOOKING_DISCOUNTS,SM_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SM_LATE_BOOKING_DISCOUNTS,SM_FLYING_COSTS = DBT_INTERNAL_SOURCE.SM_FLYING_COSTS,SM_OTHER_COSTS = DBT_INTERNAL_SOURCE.SM_OTHER_COSTS,SM_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.SM_DISTRIBUTION_COSTS,SM_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.SM_NON_MARGIN_ITEMS,SM_MARGIN = DBT_INTERNAL_SOURCE.SM_MARGIN,SMG_CURRENCY = DBT_INTERNAL_SOURCE.SMG_CURRENCY,SMG_REVENUE = DBT_INTERNAL_SOURCE.SMG_REVENUE,SMG_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.SMG_CNX_AND_AMEND_REVENUE,SMG_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.SMG_ACCOMMODATION_COSTS,SMG_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SMG_EARLY_BOOKING_DISCOUNTS,SMG_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SMG_LATE_BOOKING_DISCOUNTS,SMG_FLYING_COSTS = DBT_INTERNAL_SOURCE.SMG_FLYING_COSTS,SMG_OTHER_COSTS = DBT_INTERNAL_SOURCE.SMG_OTHER_COSTS,SMG_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.SMG_DISTRIBUTION_COSTS,SMG_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.SMG_NON_MARGIN_ITEMS,SMG_MARGIN = DBT_INTERNAL_SOURCE.SMG_MARGIN,REP_CURRENCY = DBT_INTERNAL_SOURCE.REP_CURRENCY,REP_REVENUE = DBT_INTERNAL_SOURCE.REP_REVENUE,REP_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.REP_CNX_AND_AMEND_REVENUE,REP_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.REP_ACCOMMODATION_COSTS,REP_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.REP_EARLY_BOOKING_DISCOUNTS,REP_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.REP_LATE_BOOKING_DISCOUNTS,REP_FLYING_COSTS = DBT_INTERNAL_SOURCE.REP_FLYING_COSTS,REP_OTHER_COSTS = DBT_INTERNAL_SOURCE.REP_OTHER_COSTS,REP_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.REP_DISTRIBUTION_COSTS,REP_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.REP_NON_MARGIN_ITEMS,REP_MARGIN = DBT_INTERNAL_SOURCE.REP_MARGIN,FFD_FLAG = DBT_INTERNAL_SOURCE.FFD_FLAG,RECORD_TYPE = DBT_INTERNAL_SOURCE.RECORD_TYPE,EFFECTIVE_FROM = DBT_INTERNAL_SOURCE.EFFECTIVE_FROM,EFFECTIVE_TO = DBT_INTERNAL_SOURCE.EFFECTIVE_TO,SM_CREATED_DATETIME = DBT_INTERNAL_SOURCE.SM_CREATED_DATETIME,SM_UPDATED_DATETIME = DBT_INTERNAL_SOURCE.SM_UPDATED_DATETIME,DM_CREATED_DATETIME = DBT_INTERNAL_SOURCE.DM_CREATED_DATETIME,LATEST_RECORD_INDICATOR = DBT_INTERNAL_SOURCE.LATEST_RECORD_INDICATOR
    

    when not matched then insert
        (BK_BOOKING, BK_PRIMARY_ACCOM, BK_PRIMARY_ROOM, BK_FIRST_FLIGHT, BK_LAST_FLIGHT, BK_SOURCE_MARKET, BK_ORIGINATING_SYSTEM, BK_BOOKING_TYPE, BK_BOOKING_STATUS, SOURCE_BOOKING_ID, SOURCE_BOOKING_VERSION, BOOKING_CREATED_DATETIME, BOOKING_CONFIRMED_DATETIME, BOOKING_CANCELLED_DATETIME, GROUP_SEASON, SM_SEASON, CHANNEL_CODE, CHANNEL_DESC, BOOKED_BOARD_CODE, BOOKED_BOARD_NAME, MULTI_ROOM_BOOKING, NUMBER_OF_BOOKED_ROOMS, MULTI_CENTRE_BOOKING, DEPARTURE_DATE, RETURN_DATE, DURATION, STD_NUMBER_OF_BOOKING_ADULT_PAX, STD_NUMBER_OF_BOOKING_CHILD_PAX, STD_NUMBER_OF_BOOKING_INFANT_PAX, STD_NUMBER_OF_BOOKING_PAX, SM_NUMBER_OF_BOOKING_ADULT_PAX, SM_NUMBER_OF_BOOKING_TEENAGER_PAX, SM_NUMBER_OF_BOOKING_CHILD_PAX, SM_NUMBER_OF_BOOKING_INFANT_PAX, SM_NUMBER_OF_BOOKING_PAX, PRIMARY_GATEWAY, SM_CURRENCY, SM_REVENUE, SM_CNX_AND_AMEND_REVENUE, SM_ACCOMMODATION_COSTS, SM_EARLY_BOOKING_DISCOUNTS, SM_LATE_BOOKING_DISCOUNTS, SM_FLYING_COSTS, SM_OTHER_COSTS, SM_DISTRIBUTION_COSTS, SM_NON_MARGIN_ITEMS, SM_MARGIN, SMG_CURRENCY, SMG_REVENUE, SMG_CNX_AND_AMEND_REVENUE, SMG_ACCOMMODATION_COSTS, SMG_EARLY_BOOKING_DISCOUNTS, SMG_LATE_BOOKING_DISCOUNTS, SMG_FLYING_COSTS, SMG_OTHER_COSTS, SMG_DISTRIBUTION_COSTS, SMG_NON_MARGIN_ITEMS, SMG_MARGIN, REP_CURRENCY, REP_REVENUE, REP_CNX_AND_AMEND_REVENUE, REP_ACCOMMODATION_COSTS, REP_EARLY_BOOKING_DISCOUNTS, REP_LATE_BOOKING_DISCOUNTS, REP_FLYING_COSTS, REP_OTHER_COSTS, REP_DISTRIBUTION_COSTS, REP_NON_MARGIN_ITEMS, REP_MARGIN, FFD_FLAG, RECORD_TYPE, EFFECTIVE_FROM, EFFECTIVE_TO, SM_CREATED_DATETIME, SM_UPDATED_DATETIME, DM_CREATED_DATETIME, LATEST_RECORD_INDICATOR)
    values
        (BK_BOOKING, BK_PRIMARY_ACCOM, BK_PRIMARY_ROOM, BK_FIRST_FLIGHT, BK_LAST_FLIGHT, BK_SOURCE_MARKET, BK_ORIGINATING_SYSTEM, BK_BOOKING_TYPE, BK_BOOKING_STATUS, SOURCE_BOOKING_ID, SOURCE_BOOKING_VERSION, BOOKING_CREATED_DATETIME, BOOKING_CONFIRMED_DATETIME, BOOKING_CANCELLED_DATETIME, GROUP_SEASON, SM_SEASON, CHANNEL_CODE, CHANNEL_DESC, BOOKED_BOARD_CODE, BOOKED_BOARD_NAME, MULTI_ROOM_BOOKING, NUMBER_OF_BOOKED_ROOMS, MULTI_CENTRE_BOOKING, DEPARTURE_DATE, RETURN_DATE, DURATION, STD_NUMBER_OF_BOOKING_ADULT_PAX, STD_NUMBER_OF_BOOKING_CHILD_PAX, STD_NUMBER_OF_BOOKING_INFANT_PAX, STD_NUMBER_OF_BOOKING_PAX, SM_NUMBER_OF_BOOKING_ADULT_PAX, SM_NUMBER_OF_BOOKING_TEENAGER_PAX, SM_NUMBER_OF_BOOKING_CHILD_PAX, SM_NUMBER_OF_BOOKING_INFANT_PAX, SM_NUMBER_OF_BOOKING_PAX, PRIMARY_GATEWAY, SM_CURRENCY, SM_REVENUE, SM_CNX_AND_AMEND_REVENUE, SM_ACCOMMODATION_COSTS, SM_EARLY_BOOKING_DISCOUNTS, SM_LATE_BOOKING_DISCOUNTS, SM_FLYING_COSTS, SM_OTHER_COSTS, SM_DISTRIBUTION_COSTS, SM_NON_MARGIN_ITEMS, SM_MARGIN, SMG_CURRENCY, SMG_REVENUE, SMG_CNX_AND_AMEND_REVENUE, SMG_ACCOMMODATION_COSTS, SMG_EARLY_BOOKING_DISCOUNTS, SMG_LATE_BOOKING_DISCOUNTS, SMG_FLYING_COSTS, SMG_OTHER_COSTS, SMG_DISTRIBUTION_COSTS, SMG_NON_MARGIN_ITEMS, SMG_MARGIN, REP_CURRENCY, REP_REVENUE, REP_CNX_AND_AMEND_REVENUE, REP_ACCOMMODATION_COSTS, REP_EARLY_BOOKING_DISCOUNTS, REP_LATE_BOOKING_DISCOUNTS, REP_FLYING_COSTS, REP_OTHER_COSTS, REP_DISTRIBUTION_COSTS, REP_NON_MARGIN_ITEMS, REP_MARGIN, FFD_FLAG, RECORD_TYPE, EFFECTIVE_FROM, EFFECTIVE_TO, SM_CREATED_DATETIME, SM_UPDATED_DATETIME, DM_CREATED_DATETIME, LATEST_RECORD_INDICATOR)
2019-10-02 15:01:53,691 (Thread-1): SQL status: SUCCESS 3 in 1.95 seconds
2019-10-02 15:01:53,694 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:01:53,695 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:01:53,695 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:01:54,030 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-02 15:01:54,052 (Thread-1): 15:01:54 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 3 in 70.36s]
2019-10-02 15:01:54,074 (MainThread): Using snowflake connection "master".
2019-10-02 15:01:54,075 (MainThread): On master: BEGIN
2019-10-02 15:01:54,231 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 15:01:54,234 (MainThread): On master: COMMIT
2019-10-02 15:01:54,235 (MainThread): Using snowflake connection "master".
2019-10-02 15:01:54,235 (MainThread): On master: COMMIT
2019-10-02 15:01:54,384 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 15:01:54,386 (MainThread): 15:01:54 | 
2019-10-02 15:01:54,387 (MainThread): 15:01:54 | Finished running 5 incremental models in 116.74s.
2019-10-02 15:01:54,388 (MainThread): Connection 'master' was left open.
2019-10-02 15:01:54,390 (MainThread): On master: Close
2019-10-02 15:01:54,524 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 15:01:54,524 (MainThread): On booking_fact_uk: Close
2019-10-02 15:01:54,723 (MainThread): 
2019-10-02 15:01:54,723 (MainThread): Completed successfully
2019-10-02 15:01:54,724 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 15:01:54,725 (MainThread): Flushing usage events
2019-10-02 15:03:30,674 (MainThread): Tracking: tracking
2019-10-02 15:03:30,681 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059754C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005975948>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594C888>]}
2019-10-02 15:03:30,979 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 15:03:30,980 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60501), raddr=('54.164.98.48', 443)>

2019-10-02 15:03:30,984 (MainThread): Error sending message, disabling tracking
2019-10-02 15:03:31,034 (MainThread): Parsing macros\core.sql
2019-10-02 15:03:31,044 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:03:31,091 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:03:31,102 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:03:31,104 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:03:31,107 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:03:31,110 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:03:31,114 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:03:31,116 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:03:31,125 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:03:31,133 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:03:31,143 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:03:31,160 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:03:31,182 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:03:31,185 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:03:31,198 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:03:31,205 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:03:31,212 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:03:31,218 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:03:31,220 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:03:31,222 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:03:31,225 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:03:31,228 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:03:31,241 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:03:31,244 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:03:31,252 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:03:31,255 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:03:31,259 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:03:31,285 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 15:03:31,287 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:03:31,287 (MainThread): Opening a new connection, currently in state init
2019-10-02 15:03:31,289 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 15:03:31,547 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 15:03:31,563 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 15:03:32,202 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 15:03:32,203 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:03:32,203 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 15:03:32,208 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 15:03:32,209 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:03:32,209 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:03:32,214 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 15:03:32,214 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:03:32,215 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:03:32,219 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 15:03:32,220 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:03:32,220 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:03:32,225 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 15:03:32,226 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:03:32,226 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:03:32,231 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 15:03:32,231 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:03:32,232 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:03:32,236 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 15:03:32,237 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:03:32,237 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:03:32,242 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 15:03:32,243 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:03:32,243 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:03:32,248 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 15:03:32,249 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:03:32,249 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:03:32,253 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 15:03:32,254 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:03:32,254 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:03:32,259 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:03:32,260 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:03:32,260 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:03:32,265 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 15:03:32,266 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:03:32,266 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:03:32,270 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 15:03:32,271 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:03:32,271 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:03:32,276 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 15:03:32,277 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:03:32,277 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:03:32,282 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 15:03:32,283 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:03:32,283 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:03:32,287 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 15:03:32,288 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 15:03:32,288 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:03:32,293 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 15:03:32,294 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:03:32,294 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:03:32,304 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:03:32,305 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:03:32,305 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:03:32,310 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 15:03:32,311 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:03:32,312 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:03:32,316 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 15:03:32,317 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:03:32,318 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:03:32,375 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 15:03:32,378 (MainThread): 
2019-10-02 15:03:32,379 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 15:03:32,379 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:03:32,401 (MainThread): Parsing macros\core.sql
2019-10-02 15:03:32,412 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:03:32,500 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:03:32,511 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:03:32,513 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:03:32,517 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:03:32,520 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:03:32,524 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:03:32,526 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:03:32,539 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:03:32,547 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:03:32,555 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:03:32,574 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:03:32,609 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:03:32,613 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:03:32,645 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:03:32,657 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:03:32,664 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:03:32,671 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:03:32,678 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:03:32,682 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:03:32,685 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:03:32,689 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:03:32,712 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:03:32,719 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:03:32,736 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:03:32,743 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:03:32,758 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:03:32,933 (MainThread): Using snowflake connection "master".
2019-10-02 15:03:32,934 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 15:03:33,693 (MainThread): SQL status: SUCCESS 29 in 0.76 seconds
2019-10-02 15:03:33,766 (MainThread): Using snowflake connection "master".
2019-10-02 15:03:33,766 (MainThread): On master: BEGIN
2019-10-02 15:03:33,882 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:03:33,882 (MainThread): Using snowflake connection "master".
2019-10-02 15:03:33,883 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 15:03:35,567 (MainThread): SQL status: SUCCESS 5 in 1.68 seconds
2019-10-02 15:03:35,588 (MainThread): On master: ROLLBACK
2019-10-02 15:03:35,763 (MainThread): Using snowflake connection "master".
2019-10-02 15:03:35,764 (MainThread): On master: BEGIN
2019-10-02 15:03:35,873 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:03:35,875 (MainThread): On master: COMMIT
2019-10-02 15:03:35,875 (MainThread): Using snowflake connection "master".
2019-10-02 15:03:35,876 (MainThread): On master: COMMIT
2019-10-02 15:03:36,121 (MainThread): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 15:03:36,122 (MainThread): 15:03:36 | Concurrency: 1 threads (target='dev')
2019-10-02 15:03:36,124 (MainThread): 15:03:36 | 
2019-10-02 15:03:36,135 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:03:36,135 (Thread-1): Opening a new connection, currently in state init
2019-10-02 15:03:36,649 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 15:03:36,673 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 15:03:36,683 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:03:36,684 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:03:36,685 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 15:03:36,699 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 15:03:36,707 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:03:36,707 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:03:36,708 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 15:03:36,720 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 15:03:36,726 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:03:36,726 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:03:36,727 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 15:03:36,738 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 15:03:36,746 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:03:36,746 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:03:36,747 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 15:03:36,762 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 15:03:36,770 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:03:36,773 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:03:36,774 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 15:03:36,785 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 15:03:36,793 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:03:36,793 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:03:36,798 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 15:03:36,810 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 15:03:36,816 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:03:36,818 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:03:36,819 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 15:03:36,829 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 15:03:36,835 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:03:36,837 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:03:36,838 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 15:03:36,847 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 15:03:36,853 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:03:36,853 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:03:36,857 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:03:36,866 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 15:03:36,873 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:03:36,874 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:03:36,875 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 15:03:36,880 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 15:03:36,885 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:03:36,886 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:03:36,887 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 15:03:36,892 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 15:03:36,899 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:03:36,901 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:03:36,902 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 15:03:36,911 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 15:03:36,917 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:03:36,920 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:03:36,921 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 15:03:36,931 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 15:03:36,938 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 15:03:36,940 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:03:36,941 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 15:03:36,946 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 15:03:36,953 (Thread-1): 15:03:36 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 15:03:36,955 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:03:36,955 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:03:36,956 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 15:03:36,967 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:03:37,081 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:03:37,088 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:03:37,088 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 15:03:37,206 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 15:03:37,207 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:03:37,207 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

      );
2019-10-02 15:03:39,153 (Thread-1): SQL status: SUCCESS 1 in 1.95 seconds
2019-10-02 15:03:39,154 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:03:39,155 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:03:39,155 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:03:39,287 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 15:03:39,291 (Thread-1): 15:03:39 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 2.34s]
2019-10-02 15:03:39,293 (Thread-1): 15:03:39 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 15:03:39,294 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:03:39,294 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:03:39,295 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:03:39,301 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:03:39,317 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:03:39,321 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:03:39,322 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 15:03:39,422 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 15:03:39,422 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:03:39,423 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

      );
2019-10-02 15:03:40,497 (Thread-1): SQL status: SUCCESS 1 in 1.07 seconds
2019-10-02 15:03:40,501 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:03:40,502 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:03:40,502 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:03:40,587 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 15:03:40,602 (Thread-1): 15:03:40 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 1.30s]
2019-10-02 15:03:40,605 (Thread-1): 15:03:40 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 15:03:40,609 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:03:40,609 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:03:40,610 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 15:03:40,622 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:03:40,638 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:03:40,642 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:03:40,642 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 15:03:40,803 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 15:03:40,804 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:03:40,804 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

      );
2019-10-02 15:03:46,441 (Thread-1): SQL status: SUCCESS 1 in 5.64 seconds
2019-10-02 15:03:46,445 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:03:46,446 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:03:46,446 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:03:46,546 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 15:03:46,561 (Thread-1): 15:03:46 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 5.95s]
2019-10-02 15:03:46,565 (Thread-1): 15:03:46 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 15:03:46,571 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:03:46,572 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:03:46,573 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 15:03:46,586 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:03:46,604 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:03:46,608 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:03:46,608 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 15:03:47,055 (Thread-1): SQL status: SUCCESS 1 in 0.45 seconds
2019-10-02 15:03:47,056 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:03:47,057 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

      );
2019-10-02 15:03:47,964 (Thread-1): SQL status: SUCCESS 1 in 0.91 seconds
2019-10-02 15:03:47,966 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:03:47,966 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:03:47,966 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:03:48,085 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 15:03:48,088 (Thread-1): 15:03:48 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 1.52s]
2019-10-02 15:03:48,089 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:03:48,091 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:03:48,093 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 15:03:48,099 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 15:03:48,107 (Thread-1): 15:03:48 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 15:03:48,111 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:03:48,111 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:03:48,112 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 15:03:49,836 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:03:49,878 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:03:50,034 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:03:50,034 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 15:03:50,157 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 15:03:50,158 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:03:50,158 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
  AND bk.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk.sk_booking_id = bk_2.sk_booking_id AND bk.booking_version = bk_2.booking_version)
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 15:04:29,634 (Thread-1): SQL status: SUCCESS 1 in 39.48 seconds
2019-10-02 15:04:29,635 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:04:29,636 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:04:29,636 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:04:29,711 (Thread-1): SQL status: SUCCESS 1 in 0.07 seconds
2019-10-02 15:04:29,720 (Thread-1): 15:04:29 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 1 in 41.61s]
2019-10-02 15:04:29,736 (MainThread): Using snowflake connection "master".
2019-10-02 15:04:29,736 (MainThread): On master: BEGIN
2019-10-02 15:04:29,827 (MainThread): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 15:04:29,827 (MainThread): On master: COMMIT
2019-10-02 15:04:29,828 (MainThread): Using snowflake connection "master".
2019-10-02 15:04:29,828 (MainThread): On master: COMMIT
2019-10-02 15:04:29,970 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 15:04:29,974 (MainThread): 15:04:29 | 
2019-10-02 15:04:29,976 (MainThread): 15:04:29 | Finished running 5 incremental models in 57.60s.
2019-10-02 15:04:29,978 (MainThread): Connection 'master' was left open.
2019-10-02 15:04:29,980 (MainThread): On master: Close
2019-10-02 15:04:30,178 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 15:04:30,180 (MainThread): On booking_fact_uk: Close
2019-10-02 15:04:30,348 (MainThread): 
2019-10-02 15:04:30,349 (MainThread): Completed successfully
2019-10-02 15:04:30,350 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 15:04:30,351 (MainThread): Flushing usage events
2019-10-02 15:08:17,102 (MainThread): Tracking: tracking
2019-10-02 15:08:17,104 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005971248>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059719C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000596E748>]}
2019-10-02 15:08:17,412 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 15:08:17,414 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60559), raddr=('54.164.98.48', 443)>

2019-10-02 15:08:17,417 (MainThread): Error sending message, disabling tracking
2019-10-02 15:08:17,458 (MainThread): Parsing macros\core.sql
2019-10-02 15:08:17,467 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:08:17,505 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:08:17,514 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:08:17,516 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:08:17,520 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:08:17,523 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:08:17,526 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:08:17,528 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:08:17,540 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:08:17,552 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:08:17,565 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:08:17,584 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:08:17,604 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:08:17,607 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:08:17,620 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:08:17,628 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:08:17,634 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:08:17,640 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:08:17,643 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:08:17,645 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:08:17,648 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:08:17,651 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:08:17,663 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:08:17,667 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:08:17,675 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:08:17,679 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:08:17,683 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:08:17,710 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 15:08:17,712 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:08:17,712 (MainThread): Opening a new connection, currently in state init
2019-10-02 15:08:17,714 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 15:08:18,020 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 15:08:18,040 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 15:08:18,592 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 15:08:18,593 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:08:18,594 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 15:08:18,598 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 15:08:18,599 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:08:18,599 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:08:18,603 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 15:08:18,604 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:08:18,605 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:08:18,609 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 15:08:18,610 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:08:18,610 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:08:18,614 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 15:08:18,615 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:08:18,616 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:08:18,620 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 15:08:18,621 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:08:18,621 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:08:18,626 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 15:08:18,626 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:08:18,627 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:08:18,631 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 15:08:18,632 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:08:18,632 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:08:18,637 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 15:08:18,638 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:08:18,638 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:08:18,642 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 15:08:18,643 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:08:18,643 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:08:18,648 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:08:18,649 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:08:18,649 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:08:18,653 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 15:08:18,654 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:08:18,655 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:08:18,659 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 15:08:18,660 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:08:18,660 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:08:18,664 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 15:08:18,665 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:08:18,665 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:08:18,670 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 15:08:18,671 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:08:18,671 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:08:18,676 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 15:08:18,677 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 15:08:18,678 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:08:18,683 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 15:08:18,684 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:08:18,684 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:08:18,699 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:08:18,701 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:08:18,702 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:08:18,711 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 15:08:18,714 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:08:18,714 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:08:18,728 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 15:08:18,730 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:08:18,730 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:08:18,830 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 15:08:18,834 (MainThread): 
2019-10-02 15:08:18,834 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 15:08:18,834 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:08:18,866 (MainThread): Parsing macros\core.sql
2019-10-02 15:08:18,874 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:08:18,922 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:08:18,935 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:08:18,937 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:08:18,942 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:08:18,946 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:08:18,949 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:08:18,953 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:08:18,974 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:08:18,990 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:08:19,001 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:08:19,028 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:08:19,064 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:08:19,068 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:08:19,089 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:08:19,103 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:08:19,117 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:08:19,131 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:08:19,135 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:08:19,139 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:08:19,142 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:08:19,148 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:08:19,172 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:08:19,178 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:08:19,187 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:08:19,190 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:08:19,196 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:08:19,375 (MainThread): Using snowflake connection "master".
2019-10-02 15:08:19,375 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 15:08:20,163 (MainThread): SQL status: SUCCESS 29 in 0.79 seconds
2019-10-02 15:08:20,270 (MainThread): Using snowflake connection "master".
2019-10-02 15:08:20,270 (MainThread): On master: BEGIN
2019-10-02 15:08:20,377 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:08:20,378 (MainThread): Using snowflake connection "master".
2019-10-02 15:08:20,378 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 15:08:21,563 (MainThread): SQL status: SUCCESS 5 in 1.18 seconds
2019-10-02 15:08:21,583 (MainThread): On master: ROLLBACK
2019-10-02 15:08:21,773 (MainThread): Using snowflake connection "master".
2019-10-02 15:08:21,774 (MainThread): On master: BEGIN
2019-10-02 15:08:21,886 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:08:21,888 (MainThread): On master: COMMIT
2019-10-02 15:08:21,888 (MainThread): Using snowflake connection "master".
2019-10-02 15:08:21,889 (MainThread): On master: COMMIT
2019-10-02 15:08:22,057 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 15:08:22,058 (MainThread): 15:08:22 | Concurrency: 1 threads (target='dev')
2019-10-02 15:08:22,060 (MainThread): 15:08:22 | 
2019-10-02 15:08:22,071 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:08:22,071 (Thread-1): Opening a new connection, currently in state init
2019-10-02 15:08:22,569 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 15:08:22,593 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 15:08:22,604 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:08:22,604 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:08:22,605 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 15:08:22,614 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 15:08:22,623 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:08:22,625 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:08:22,626 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 15:08:22,635 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 15:08:22,640 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:08:22,641 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:08:22,641 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 15:08:22,653 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 15:08:22,659 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:08:22,659 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:08:22,663 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 15:08:22,669 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 15:08:22,674 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:08:22,674 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:08:22,675 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 15:08:22,683 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 15:08:22,690 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:08:22,695 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:08:22,696 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 15:08:22,702 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 15:08:22,708 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:08:22,710 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:08:22,711 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 15:08:22,717 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 15:08:22,723 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:08:22,723 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:08:22,724 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 15:08:22,739 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 15:08:22,747 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:08:22,750 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:08:22,752 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:08:22,764 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 15:08:22,773 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:08:22,773 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:08:22,774 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 15:08:22,787 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 15:08:22,795 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:08:22,798 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:08:22,799 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 15:08:22,809 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 15:08:22,816 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:08:22,819 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:08:22,820 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 15:08:22,830 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 15:08:22,837 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:08:22,842 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:08:22,843 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 15:08:22,852 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 15:08:22,859 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 15:08:22,862 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:08:22,863 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 15:08:22,869 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 15:08:22,875 (Thread-1): 15:08:22 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 15:08:22,879 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:08:22,879 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:08:22,879 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 15:08:22,885 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:08:22,984 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:08:22,990 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:08:22,991 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 15:08:23,104 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:08:23,105 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:08:23,106 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

      );
2019-10-02 15:08:23,858 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2019-10-02 15:08:23,862 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:08:23,863 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:08:23,863 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:08:23,974 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:08:23,985 (Thread-1): 15:08:23 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.10s]
2019-10-02 15:08:23,987 (Thread-1): 15:08:23 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 15:08:23,991 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:08:23,992 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:08:23,993 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:08:24,010 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:08:24,022 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:08:24,026 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:08:24,026 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 15:08:24,152 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 15:08:24,153 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:08:24,154 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

      );
2019-10-02 15:08:24,977 (Thread-1): SQL status: SUCCESS 1 in 0.82 seconds
2019-10-02 15:08:24,978 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:08:24,978 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:08:24,978 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:08:25,069 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 15:08:25,073 (Thread-1): 15:08:25 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 1.08s]
2019-10-02 15:08:25,074 (Thread-1): 15:08:25 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 15:08:25,076 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:08:25,077 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:08:25,077 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 15:08:25,085 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:08:25,101 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:08:25,108 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:08:25,108 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 15:08:25,216 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:08:25,217 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:08:25,217 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

      );
2019-10-02 15:08:28,444 (Thread-1): SQL status: SUCCESS 1 in 3.23 seconds
2019-10-02 15:08:28,447 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:08:28,448 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:08:28,448 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:08:28,596 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 15:08:28,609 (Thread-1): 15:08:28 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 3.53s]
2019-10-02 15:08:28,611 (Thread-1): 15:08:28 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 15:08:28,615 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:08:28,616 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:08:28,617 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 15:08:28,632 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:08:28,645 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:08:28,649 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:08:28,649 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 15:08:28,762 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:08:28,763 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:08:28,763 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

      );
2019-10-02 15:08:29,613 (Thread-1): SQL status: SUCCESS 1 in 0.85 seconds
2019-10-02 15:08:29,617 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:08:29,618 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:08:29,618 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:08:29,714 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 15:08:29,724 (Thread-1): 15:08:29 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 1.11s]
2019-10-02 15:08:29,726 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:08:29,726 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:08:29,727 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 15:08:29,743 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 15:08:29,748 (Thread-1): 15:08:29 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 15:08:29,751 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:08:29,751 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:08:29,751 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 15:08:30,904 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:08:30,946 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:08:31,069 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:08:31,069 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 15:08:31,248 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 15:08:31,248 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:08:31,248 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
  AND bk.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk.sk_booking_id = bk_2.sk_booking_id AND bk.booking_version = bk_2.booking_version)
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 15:09:05,626 (Thread-1): SQL status: SUCCESS 1 in 34.38 seconds
2019-10-02 15:09:05,628 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:09:05,628 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:09:05,629 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:09:05,750 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 15:09:05,763 (Thread-1): 15:09:05 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 1 in 36.00s]
2019-10-02 15:09:05,806 (MainThread): Using snowflake connection "master".
2019-10-02 15:09:05,806 (MainThread): On master: BEGIN
2019-10-02 15:09:05,904 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 15:09:05,905 (MainThread): On master: COMMIT
2019-10-02 15:09:05,905 (MainThread): Using snowflake connection "master".
2019-10-02 15:09:05,905 (MainThread): On master: COMMIT
2019-10-02 15:09:06,159 (MainThread): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-02 15:09:06,160 (MainThread): 15:09:06 | 
2019-10-02 15:09:06,161 (MainThread): 15:09:06 | Finished running 5 incremental models in 47.33s.
2019-10-02 15:09:06,161 (MainThread): Connection 'master' was left open.
2019-10-02 15:09:06,162 (MainThread): On master: Close
2019-10-02 15:09:06,294 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 15:09:06,295 (MainThread): On booking_fact_uk: Close
2019-10-02 15:09:06,435 (MainThread): 
2019-10-02 15:09:06,435 (MainThread): Completed successfully
2019-10-02 15:09:06,436 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 15:09:06,436 (MainThread): Flushing usage events
2019-10-02 15:11:47,867 (MainThread): Tracking: tracking
2019-10-02 15:11:47,869 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005973E48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005973688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594DF88>]}
2019-10-02 15:11:48,187 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 15:11:48,190 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60584), raddr=('54.164.98.48', 443)>

2019-10-02 15:11:48,194 (MainThread): Error sending message, disabling tracking
2019-10-02 15:11:48,239 (MainThread): Parsing macros\core.sql
2019-10-02 15:11:48,250 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:11:48,288 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:11:48,298 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:11:48,300 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:11:48,303 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:11:48,307 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:11:48,310 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:11:48,312 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:11:48,321 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:11:48,329 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:11:48,337 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:11:48,354 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:11:48,377 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:11:48,381 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:11:48,396 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:11:48,404 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:11:48,422 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:11:48,438 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:11:48,444 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:11:48,449 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:11:48,453 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:11:48,456 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:11:48,469 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:11:48,472 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:11:48,481 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:11:48,483 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:11:48,487 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:11:48,515 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 15:11:48,516 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:11:48,516 (MainThread): Opening a new connection, currently in state init
2019-10-02 15:11:48,518 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 15:11:48,839 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 15:11:48,857 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 15:11:49,419 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 15:11:49,420 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:11:49,420 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 15:11:49,425 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 15:11:49,426 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:11:49,426 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:11:49,430 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 15:11:49,431 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:11:49,431 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:11:49,436 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 15:11:49,437 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:11:49,437 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:11:49,441 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 15:11:49,442 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:11:49,443 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:11:49,447 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 15:11:49,448 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:11:49,448 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:11:49,452 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 15:11:49,453 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:11:49,453 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:11:49,458 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 15:11:49,459 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:11:49,459 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:11:49,464 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 15:11:49,465 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:11:49,465 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:11:49,470 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 15:11:49,471 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:11:49,471 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:11:49,476 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:11:49,477 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:11:49,477 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:11:49,481 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 15:11:49,482 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:11:49,482 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:11:49,486 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 15:11:49,487 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:11:49,487 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:11:49,493 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 15:11:49,494 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:11:49,494 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:11:49,499 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 15:11:49,500 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:11:49,500 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:11:49,504 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 15:11:49,505 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 15:11:49,505 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:11:49,510 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 15:11:49,511 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:11:49,511 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:11:49,521 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:11:49,522 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:11:49,522 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:11:49,527 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 15:11:49,528 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:11:49,528 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:11:49,533 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 15:11:49,534 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:11:49,534 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:11:49,592 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 15:11:49,594 (MainThread): 
2019-10-02 15:11:49,595 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 15:11:49,595 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:11:49,624 (MainThread): Parsing macros\core.sql
2019-10-02 15:11:49,632 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:11:49,675 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:11:49,702 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:11:49,705 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:11:49,713 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:11:49,719 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:11:49,724 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:11:49,728 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:11:49,741 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:11:49,750 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:11:49,765 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:11:49,782 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:11:49,803 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:11:49,806 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:11:49,823 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:11:49,830 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:11:49,836 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:11:49,842 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:11:49,845 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:11:49,847 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:11:49,849 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:11:49,854 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:11:49,887 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:11:49,891 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:11:49,899 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:11:49,902 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:11:49,907 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:11:50,027 (MainThread): Using snowflake connection "master".
2019-10-02 15:11:50,027 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 15:11:50,603 (MainThread): SQL status: SUCCESS 29 in 0.58 seconds
2019-10-02 15:11:50,706 (MainThread): Using snowflake connection "master".
2019-10-02 15:11:50,706 (MainThread): On master: BEGIN
2019-10-02 15:11:50,816 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:11:50,817 (MainThread): Using snowflake connection "master".
2019-10-02 15:11:50,817 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 15:11:52,188 (MainThread): SQL status: SUCCESS 5 in 1.37 seconds
2019-10-02 15:11:52,206 (MainThread): On master: ROLLBACK
2019-10-02 15:11:52,351 (MainThread): Using snowflake connection "master".
2019-10-02 15:11:52,352 (MainThread): On master: BEGIN
2019-10-02 15:11:52,498 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 15:11:52,500 (MainThread): On master: COMMIT
2019-10-02 15:11:52,501 (MainThread): Using snowflake connection "master".
2019-10-02 15:11:52,502 (MainThread): On master: COMMIT
2019-10-02 15:11:52,654 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 15:11:52,656 (MainThread): 15:11:52 | Concurrency: 1 threads (target='dev')
2019-10-02 15:11:52,657 (MainThread): 15:11:52 | 
2019-10-02 15:11:52,668 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:11:52,668 (Thread-1): Opening a new connection, currently in state init
2019-10-02 15:11:53,171 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 15:11:53,195 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 15:11:53,205 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:11:53,210 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:11:53,211 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 15:11:53,220 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 15:11:53,227 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:11:53,227 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:11:53,228 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 15:11:53,240 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 15:11:53,248 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:11:53,250 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:11:53,252 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 15:11:53,261 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 15:11:53,270 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:11:53,277 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:11:53,278 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 15:11:53,289 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 15:11:53,294 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:11:53,295 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:11:53,295 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 15:11:53,303 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 15:11:53,308 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:11:53,308 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:11:53,312 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 15:11:53,318 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 15:11:53,326 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:11:53,330 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:11:53,331 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 15:11:53,343 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 15:11:53,351 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:11:53,351 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:11:53,355 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 15:11:53,365 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 15:11:53,372 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:11:53,375 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:11:53,376 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:11:53,385 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 15:11:53,391 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:11:53,392 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:11:53,393 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 15:11:53,398 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 15:11:53,403 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:11:53,406 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:11:53,407 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 15:11:53,415 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 15:11:53,420 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:11:53,423 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:11:53,424 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 15:11:53,430 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 15:11:53,436 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:11:53,439 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:11:53,440 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 15:11:53,451 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 15:11:53,456 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 15:11:53,458 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:11:53,459 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 15:11:53,464 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 15:11:53,468 (Thread-1): 15:11:53 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 15:11:53,471 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:11:53,471 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:11:53,471 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 15:11:53,478 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:11:53,585 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:11:53,589 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:11:53,589 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 15:11:54,028 (Thread-1): SQL status: SUCCESS 1 in 0.44 seconds
2019-10-02 15:11:54,029 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:11:54,029 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

      );
2019-10-02 15:11:54,824 (Thread-1): SQL status: SUCCESS 1 in 0.80 seconds
2019-10-02 15:11:54,826 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:11:54,827 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:11:54,827 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:11:54,923 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 15:11:54,927 (Thread-1): 15:11:54 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 1.46s]
2019-10-02 15:11:54,928 (Thread-1): 15:11:54 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 15:11:54,930 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:11:54,930 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:11:54,931 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:11:54,942 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:11:54,956 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:11:54,962 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:11:54,962 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 15:11:55,249 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-02 15:11:55,250 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:11:55,250 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

      );
2019-10-02 15:11:55,800 (Thread-1): SQL status: SUCCESS 1 in 0.55 seconds
2019-10-02 15:11:55,804 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:11:55,805 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:11:55,805 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:11:56,012 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-02 15:11:56,027 (Thread-1): 15:11:56 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 1.09s]
2019-10-02 15:11:56,030 (Thread-1): 15:11:56 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 15:11:56,035 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:11:56,036 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:11:56,038 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 15:11:56,056 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:11:56,076 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:11:56,085 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:11:56,086 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 15:11:56,205 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 15:11:56,206 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:11:56,206 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

      );
2019-10-02 15:11:59,229 (Thread-1): SQL status: SUCCESS 1 in 3.02 seconds
2019-10-02 15:11:59,233 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:11:59,233 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:11:59,234 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:11:59,398 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 15:11:59,414 (Thread-1): 15:11:59 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 3.37s]
2019-10-02 15:11:59,418 (Thread-1): 15:11:59 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 15:11:59,426 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:11:59,427 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:11:59,428 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 15:11:59,447 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:11:59,469 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:11:59,476 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:11:59,476 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 15:11:59,588 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:11:59,589 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:11:59,589 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

      );
2019-10-02 15:12:01,310 (Thread-1): SQL status: SUCCESS 1 in 1.72 seconds
2019-10-02 15:12:01,315 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:12:01,316 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:12:01,317 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:12:01,424 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:12:01,439 (Thread-1): 15:12:01 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 2.01s]
2019-10-02 15:12:01,442 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:12:01,447 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:12:01,449 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 15:12:01,463 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 15:12:01,471 (Thread-1): 15:12:01 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 15:12:01,475 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:12:01,475 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:12:01,476 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 15:12:02,614 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:12:02,641 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:12:02,748 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:12:02,748 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 15:12:02,923 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 15:12:02,924 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:12:02,924 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
  AND bk.file_dt = (SELECT MAX(bk_2.file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk_2 WHERE bk.sk_booking_id = bk_2.sk_booking_id AND bk.booking_version = bk_2.booking_version)
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 15:12:38,454 (Thread-1): SQL status: SUCCESS 1 in 35.53 seconds
2019-10-02 15:12:38,458 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:12:38,458 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:12:38,459 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:12:38,566 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:12:38,593 (Thread-1): 15:12:38 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 1 in 37.11s]
2019-10-02 15:12:38,612 (MainThread): Using snowflake connection "master".
2019-10-02 15:12:38,612 (MainThread): On master: BEGIN
2019-10-02 15:12:38,723 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 15:12:38,723 (MainThread): On master: COMMIT
2019-10-02 15:12:38,724 (MainThread): Using snowflake connection "master".
2019-10-02 15:12:38,724 (MainThread): On master: COMMIT
2019-10-02 15:12:38,989 (MainThread): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-02 15:12:38,991 (MainThread): 15:12:38 | 
2019-10-02 15:12:38,991 (MainThread): 15:12:38 | Finished running 5 incremental models in 49.40s.
2019-10-02 15:12:38,992 (MainThread): Connection 'master' was left open.
2019-10-02 15:12:38,992 (MainThread): On master: Close
2019-10-02 15:12:39,260 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 15:12:39,261 (MainThread): On booking_fact_uk: Close
2019-10-02 15:12:39,467 (MainThread): 
2019-10-02 15:12:39,467 (MainThread): Completed successfully
2019-10-02 15:12:39,468 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 15:12:39,469 (MainThread): Flushing usage events
2019-10-02 15:14:51,651 (MainThread): Tracking: tracking
2019-10-02 15:14:51,653 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000599E648>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000059747C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000594C588>]}
2019-10-02 15:14:51,968 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 15:14:51,971 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60600), raddr=('54.174.31.151', 443)>

2019-10-02 15:14:51,975 (MainThread): Error sending message, disabling tracking
2019-10-02 15:14:52,039 (MainThread): Parsing macros\core.sql
2019-10-02 15:14:52,052 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:14:52,108 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:14:52,118 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:14:52,120 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:14:52,124 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:14:52,127 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:14:52,130 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:14:52,132 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:14:52,140 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:14:52,149 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:14:52,157 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:14:52,174 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:14:52,197 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:14:52,201 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:14:52,217 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:14:52,224 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:14:52,232 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:14:52,241 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:14:52,247 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:14:52,251 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:14:52,256 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:14:52,262 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:14:52,296 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:14:52,304 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:14:52,316 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:14:52,319 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:14:52,323 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:14:52,350 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 15:14:52,351 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:14:52,352 (MainThread): Opening a new connection, currently in state init
2019-10-02 15:14:52,353 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 15:14:52,650 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 15:14:52,667 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 15:14:53,328 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 15:14:53,329 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:14:53,329 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 15:14:53,333 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 15:14:53,334 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:14:53,334 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:14:53,339 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 15:14:53,339 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:14:53,340 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:14:53,345 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 15:14:53,346 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:14:53,346 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:14:53,350 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 15:14:53,351 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:14:53,351 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:14:53,356 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 15:14:53,357 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:14:53,357 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:14:53,361 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 15:14:53,362 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:14:53,363 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:14:53,367 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 15:14:53,368 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:14:53,368 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:14:53,373 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 15:14:53,374 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:14:53,374 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:14:53,379 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 15:14:53,380 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:14:53,380 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:14:53,384 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:14:53,385 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:14:53,385 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:14:53,390 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 15:14:53,391 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:14:53,391 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:14:53,395 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 15:14:53,396 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:14:53,396 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:14:53,401 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 15:14:53,402 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:14:53,402 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:14:53,406 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 15:14:53,407 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:14:53,407 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:14:53,412 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 15:14:53,413 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 15:14:53,413 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:14:53,418 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 15:14:53,419 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:14:53,419 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:14:53,429 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:14:53,430 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:14:53,430 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:14:53,435 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 15:14:53,437 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:14:53,437 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:14:53,442 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 15:14:53,443 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:14:53,443 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:14:53,500 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 15:14:53,502 (MainThread): 
2019-10-02 15:14:53,503 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 15:14:53,503 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:14:53,531 (MainThread): Parsing macros\core.sql
2019-10-02 15:14:53,539 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 15:14:53,609 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 15:14:53,641 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 15:14:53,646 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 15:14:53,654 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 15:14:53,666 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 15:14:53,673 (MainThread): Parsing macros\etc\query.sql
2019-10-02 15:14:53,679 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 15:14:53,703 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 15:14:53,717 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 15:14:53,734 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 15:14:53,763 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 15:14:53,799 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 15:14:53,803 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 15:14:53,833 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 15:14:53,844 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 15:14:53,852 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 15:14:53,861 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 15:14:53,864 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 15:14:53,866 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 15:14:53,870 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 15:14:53,875 (MainThread): Parsing macros\adapters.sql
2019-10-02 15:14:53,890 (MainThread): Parsing macros\catalog.sql
2019-10-02 15:14:53,894 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 15:14:53,905 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 15:14:53,910 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 15:14:53,915 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 15:14:54,031 (MainThread): Using snowflake connection "master".
2019-10-02 15:14:54,031 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 15:14:54,834 (MainThread): SQL status: SUCCESS 29 in 0.80 seconds
2019-10-02 15:14:54,895 (MainThread): Using snowflake connection "master".
2019-10-02 15:14:54,895 (MainThread): On master: BEGIN
2019-10-02 15:14:54,987 (MainThread): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 15:14:54,988 (MainThread): Using snowflake connection "master".
2019-10-02 15:14:54,988 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 15:14:56,251 (MainThread): SQL status: SUCCESS 5 in 1.26 seconds
2019-10-02 15:14:56,272 (MainThread): On master: ROLLBACK
2019-10-02 15:14:56,591 (MainThread): Using snowflake connection "master".
2019-10-02 15:14:56,592 (MainThread): On master: BEGIN
2019-10-02 15:14:56,791 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 15:14:56,792 (MainThread): On master: COMMIT
2019-10-02 15:14:56,792 (MainThread): Using snowflake connection "master".
2019-10-02 15:14:56,793 (MainThread): On master: COMMIT
2019-10-02 15:14:56,928 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 15:14:56,928 (MainThread): 15:14:56 | Concurrency: 1 threads (target='dev')
2019-10-02 15:14:56,929 (MainThread): 15:14:56 | 
2019-10-02 15:14:56,932 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 15:14:56,932 (Thread-1): Opening a new connection, currently in state init
2019-10-02 15:14:57,485 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 15:14:57,498 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 15:14:57,506 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 15:14:57,511 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 15:14:57,512 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 15:14:57,523 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 15:14:57,530 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 15:14:57,530 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 15:14:57,533 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 15:14:57,539 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 15:14:57,545 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 15:14:57,548 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 15:14:57,549 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 15:14:57,555 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 15:14:57,562 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 15:14:57,563 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 15:14:57,564 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 15:14:57,570 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 15:14:57,576 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 15:14:57,576 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 15:14:57,577 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 15:14:57,584 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 15:14:57,591 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 15:14:57,591 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 15:14:57,592 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 15:14:57,599 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 15:14:57,606 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 15:14:57,608 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 15:14:57,609 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 15:14:57,617 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 15:14:57,629 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 15:14:57,632 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 15:14:57,634 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 15:14:57,645 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 15:14:57,653 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 15:14:57,657 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 15:14:57,658 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 15:14:57,669 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 15:14:57,677 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 15:14:57,678 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 15:14:57,678 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 15:14:57,693 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 15:14:57,700 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 15:14:57,700 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 15:14:57,704 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 15:14:57,716 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 15:14:57,728 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 15:14:57,729 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 15:14:57,731 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 15:14:57,747 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 15:14:57,761 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 15:14:57,770 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 15:14:57,775 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 15:14:57,787 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 15:14:57,794 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 15:14:57,795 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 15:14:57,795 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 15:14:57,811 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 15:14:57,819 (Thread-1): 15:14:57 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 15:14:57,822 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 15:14:57,822 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 15:14:57,823 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 15:14:57,836 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:14:57,974 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:14:57,974 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 15:14:58,078 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 15:14:58,079 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:14:58,079 (Thread-1): On with_fl_acr_booking: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on
  ,bk_1.file_dt

FROM opa_stg_uk.fl_acr_booking_stream_test bk_1
-- WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
-- AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
WHERE (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)


-- Incremental filters

  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_stream_test bk_1)

      );
2019-10-02 15:14:59,729 (Thread-1): SQL status: SUCCESS 1 in 1.65 seconds
2019-10-02 15:14:59,738 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:14:59,738 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:02,428 (Thread-1): SQL status: SUCCESS 24 in 2.69 seconds
2019-10-02 15:15:02,437 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:15:02,438 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:04,813 (Thread-1): SQL status: SUCCESS 24 in 2.38 seconds
2019-10-02 15:15:04,827 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:15:04,827 (Thread-1): On with_fl_acr_booking: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:07,451 (Thread-1): SQL status: SUCCESS 24 in 2.62 seconds
2019-10-02 15:15:07,490 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 15:15:07,495 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:15:07,495 (Thread-1): On with_fl_acr_booking: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking (SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT)
        (
            select SK_BOOKING_ID, BOOKING_VERSION, ATCOM_RES_ID, ATCOM_RES_VERSION, ATCOM_MARKET_ID, NUMBER_OF_ADULTS, NUMBER_OF_CHILDREN, NUMBER_OF_INFANTS, NUMBER_OF_PASSENGERS, SK_SEASON_ID, BOOKING_STATUS, ATCOM_AGENT_ID, ATCOM_SELL_CURRENCY_ID, SEASON_DATE, CONFIRMED_ON, CANCELLED_ON, SOURCE_CREATED_ON, MODIFIED_ON, EFFECTIVE_FROM, LEAD_EFFECTIVE_FROM, EFFECTIVE_TO, DWH_CREATED_ON, DWH_MODIFIED_ON, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking__dbt_tmp
        );
2019-10-02 15:15:08,414 (Thread-1): SQL status: SUCCESS 2 in 0.92 seconds
2019-10-02 15:15:08,415 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:15:08,416 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 15:15:08,416 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 15:15:08,652 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 15:15:08,658 (Thread-1): 15:15:08 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 2 in 10.83s]
2019-10-02 15:15:08,660 (Thread-1): 15:15:08 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 15:15:08,662 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:08,662 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 15:15:08,663 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 15:15:08,675 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:15:08,689 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:08,689 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 15:15:08,855 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 15:15:08,856 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:08,856 (Thread-1): On with_fl_acr_booking_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
  ,bk_ser_1.file_dt
FROM opa_stg_uk.fl_acr_booking_service_stream_test bk_ser_1
-- WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
-- AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
-- AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_booking_service_stream_test)

      );
2019-10-02 15:15:09,724 (Thread-1): SQL status: SUCCESS 1 in 0.87 seconds
2019-10-02 15:15:09,735 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:09,735 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:11,617 (Thread-1): SQL status: SUCCESS 6 in 1.88 seconds
2019-10-02 15:15:11,636 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:11,636 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:14,800 (Thread-1): SQL status: SUCCESS 6 in 3.16 seconds
2019-10-02 15:15:14,818 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:14,818 (Thread-1): On with_fl_acr_booking_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_booking_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:17,103 (Thread-1): SQL status: SUCCESS 6 in 2.28 seconds
2019-10-02 15:15:17,111 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 15:15:17,119 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:17,119 (Thread-1): On with_fl_acr_booking_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_booking_service (SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT)
        (
            select SK_BOOKING_SERVICE_ID, SK_BOOKING_ID, SK_SERVICE_ID, SERVICE_VERSION, BOOKING_VERSION, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_booking_service__dbt_tmp
        );
2019-10-02 15:15:17,784 (Thread-1): SQL status: SUCCESS 7 in 0.66 seconds
2019-10-02 15:15:17,788 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:15:17,788 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 15:15:17,789 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 15:15:18,151 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-02 15:15:18,166 (Thread-1): 15:15:18 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 7 in 9.50s]
2019-10-02 15:15:18,170 (Thread-1): 15:15:18 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 15:15:18,177 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 15:15:18,178 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 15:15:18,180 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 15:15:18,199 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:15:18,217 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:15:18,217 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 15:15:18,688 (Thread-1): SQL status: SUCCESS 1 in 0.47 seconds
2019-10-02 15:15:18,689 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:15:18,690 (Thread-1): On with_fl_acr_service: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
  ,ser_1.file_dt
FROM opa_stg_uk.fl_acr_service_stream_test ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

  -- this filter will only be applied on an incremental run
  AND file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_stream_test)

      );
2019-10-02 15:15:21,666 (Thread-1): SQL status: SUCCESS 1 in 2.98 seconds
2019-10-02 15:15:21,682 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:15:21,682 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:24,537 (Thread-1): SQL status: SUCCESS 15 in 2.86 seconds
2019-10-02 15:15:24,556 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:15:24,556 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:26,732 (Thread-1): SQL status: SUCCESS 15 in 2.18 seconds
2019-10-02 15:15:26,758 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:15:26,759 (Thread-1): On with_fl_acr_service: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:28,746 (Thread-1): SQL status: SUCCESS 15 in 1.99 seconds
2019-10-02 15:15:28,752 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 15:15:28,757 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:15:28,757 (Thread-1): On with_fl_acr_service: insert into OPA_DEV.DBT_TEST.with_fl_acr_service (SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT)
        (
            select SK_SERVICE_ID, ATCOM_SER_ID, ATCOM_DEP_POINT_ID, SERVICE_VERSION, SERVICE_STATUS, DIRECTION, SELL_TYPE, SERVICE_TYPE, FLIGHT_TYPE_CODE, SERVICE_START_DATE1, SERVICE_END_DATE1, DEPARTURE_FLIGHT_NUMBER, ATCOM_ARR_POINT_ID, SOURCE_STOCK_TYPE_CODE, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service__dbt_tmp
        );
2019-10-02 15:15:29,473 (Thread-1): SQL status: SUCCESS 12 in 0.72 seconds
2019-10-02 15:15:29,477 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:15:29,477 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 15:15:29,478 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 15:15:29,710 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-02 15:15:29,725 (Thread-1): 15:15:29 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 12 in 11.54s]
2019-10-02 15:15:29,729 (Thread-1): 15:15:29 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 15:15:29,736 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:29,736 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 15:15:29,738 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 15:15:29,753 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:15:29,770 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:29,770 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 15:15:29,887 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 15:15:29,888 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:29,888 (Thread-1): On with_fl_acr_service_element: create or replace temporary table OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
  ,ser_e_1.file_dt
FROM opa_stg_uk.fl_acr_service_element_stream_test ser_e_1
-- WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

  -- this filter will only be applied on an incremental run
  WHERE file_dt >= (SELECT MAX(file_dt) FROM opa_stg_uk.fl_acr_service_element_stream_test)

      );
2019-10-02 15:15:30,776 (Thread-1): SQL status: SUCCESS 1 in 0.89 seconds
2019-10-02 15:15:30,786 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:30,786 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:32,853 (Thread-1): SQL status: SUCCESS 5 in 2.07 seconds
2019-10-02 15:15:32,858 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:32,858 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:34,888 (Thread-1): SQL status: SUCCESS 5 in 2.03 seconds
2019-10-02 15:15:34,895 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:34,895 (Thread-1): On with_fl_acr_service_element: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'with_fl_acr_service_element'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:15:37,029 (Thread-1): SQL status: SUCCESS 5 in 2.13 seconds
2019-10-02 15:15:37,031 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 15:15:37,034 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:37,035 (Thread-1): On with_fl_acr_service_element: insert into OPA_DEV.DBT_TEST.with_fl_acr_service_element (SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT)
        (
            select SK_SERVICE_ELEMENT_ID, SK_SERVICE_ID, SERVICE_VERSION, ATCOM_SUB_SER_ID, FILE_DT
            from OPA_DEV.DBT_TEST.with_fl_acr_service_element__dbt_tmp
        );
2019-10-02 15:15:37,480 (Thread-1): SQL status: SUCCESS 6 in 0.45 seconds
2019-10-02 15:15:37,484 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:15:37,485 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 15:15:37,485 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 15:15:38,207 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2019-10-02 15:15:38,213 (Thread-1): 15:15:38 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 6 in 8.47s]
2019-10-02 15:15:38,214 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 15:15:38,214 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 15:15:38,218 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 15:15:38,229 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 15:15:38,238 (Thread-1): 15:15:38 | 5 of 5 START incremental model DBT_TEST.booking_fact_uk.............. [RUN]
2019-10-02 15:15:38,244 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 15:15:38,244 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 15:15:38,245 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 15:15:40,277 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:15:40,469 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:15:40,469 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 15:15:40,720 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-02 15:15:40,721 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:15:40,721 (Thread-1): On booking_fact_uk: create or replace temporary table OPA_DEV.DBT_TEST.booking_fact_uk__dbt_tmp
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
  AND bk.file_dt = (SELECT MAX(bk_2.file_dt) FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk_2 WHERE bk.sk_booking_id = bk_2.sk_booking_id AND bk.booking_version = bk_2.booking_version)
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 15:16:18,163 (Thread-1): SQL status: SUCCESS 1 in 37.44 seconds
2019-10-02 15:16:18,174 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:16:18,175 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk__dbt_tmp'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:16:20,076 (Thread-1): SQL status: SUCCESS 77 in 1.90 seconds
2019-10-02 15:16:20,107 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:16:20,107 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:16:23,545 (Thread-1): SQL status: SUCCESS 77 in 3.44 seconds
2019-10-02 15:16:23,574 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:16:23,575 (Thread-1): On booking_fact_uk: select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from
      OPA_DEV.information_schema.columns

      where table_name ilike 'booking_fact_uk'
        
        and table_schema ilike 'DBT_TEST'
        
        
        and table_catalog ilike 'OPA_DEV'
        
      order by ordinal_position
2019-10-02 15:16:25,872 (Thread-1): SQL status: SUCCESS 77 in 2.30 seconds
2019-10-02 15:16:25,904 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 15:16:25,941 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:16:25,941 (Thread-1): On booking_fact_uk: merge into OPA_DEV.DBT_TEST.booking_fact_uk as DBT_INTERNAL_DEST
    using OPA_DEV.DBT_TEST.booking_fact_uk__dbt_tmp as DBT_INTERNAL_SOURCE

    
        on DBT_INTERNAL_SOURCE.bk_booking = DBT_INTERNAL_DEST.bk_booking
    

    
    when matched then update set
        BK_BOOKING = DBT_INTERNAL_SOURCE.BK_BOOKING,BK_PRIMARY_ACCOM = DBT_INTERNAL_SOURCE.BK_PRIMARY_ACCOM,BK_PRIMARY_ROOM = DBT_INTERNAL_SOURCE.BK_PRIMARY_ROOM,BK_FIRST_FLIGHT = DBT_INTERNAL_SOURCE.BK_FIRST_FLIGHT,BK_LAST_FLIGHT = DBT_INTERNAL_SOURCE.BK_LAST_FLIGHT,BK_SOURCE_MARKET = DBT_INTERNAL_SOURCE.BK_SOURCE_MARKET,BK_ORIGINATING_SYSTEM = DBT_INTERNAL_SOURCE.BK_ORIGINATING_SYSTEM,BK_BOOKING_TYPE = DBT_INTERNAL_SOURCE.BK_BOOKING_TYPE,BK_BOOKING_STATUS = DBT_INTERNAL_SOURCE.BK_BOOKING_STATUS,SOURCE_BOOKING_ID = DBT_INTERNAL_SOURCE.SOURCE_BOOKING_ID,SOURCE_BOOKING_VERSION = DBT_INTERNAL_SOURCE.SOURCE_BOOKING_VERSION,BOOKING_CREATED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CREATED_DATETIME,BOOKING_CONFIRMED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CONFIRMED_DATETIME,BOOKING_CANCELLED_DATETIME = DBT_INTERNAL_SOURCE.BOOKING_CANCELLED_DATETIME,GROUP_SEASON = DBT_INTERNAL_SOURCE.GROUP_SEASON,SM_SEASON = DBT_INTERNAL_SOURCE.SM_SEASON,CHANNEL_CODE = DBT_INTERNAL_SOURCE.CHANNEL_CODE,CHANNEL_DESC = DBT_INTERNAL_SOURCE.CHANNEL_DESC,BOOKED_BOARD_CODE = DBT_INTERNAL_SOURCE.BOOKED_BOARD_CODE,BOOKED_BOARD_NAME = DBT_INTERNAL_SOURCE.BOOKED_BOARD_NAME,MULTI_ROOM_BOOKING = DBT_INTERNAL_SOURCE.MULTI_ROOM_BOOKING,NUMBER_OF_BOOKED_ROOMS = DBT_INTERNAL_SOURCE.NUMBER_OF_BOOKED_ROOMS,MULTI_CENTRE_BOOKING = DBT_INTERNAL_SOURCE.MULTI_CENTRE_BOOKING,DEPARTURE_DATE = DBT_INTERNAL_SOURCE.DEPARTURE_DATE,RETURN_DATE = DBT_INTERNAL_SOURCE.RETURN_DATE,DURATION = DBT_INTERNAL_SOURCE.DURATION,STD_NUMBER_OF_BOOKING_ADULT_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_ADULT_PAX,STD_NUMBER_OF_BOOKING_CHILD_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_CHILD_PAX,STD_NUMBER_OF_BOOKING_INFANT_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_INFANT_PAX,STD_NUMBER_OF_BOOKING_PAX = DBT_INTERNAL_SOURCE.STD_NUMBER_OF_BOOKING_PAX,SM_NUMBER_OF_BOOKING_ADULT_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_ADULT_PAX,SM_NUMBER_OF_BOOKING_TEENAGER_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_TEENAGER_PAX,SM_NUMBER_OF_BOOKING_CHILD_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_CHILD_PAX,SM_NUMBER_OF_BOOKING_INFANT_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_INFANT_PAX,SM_NUMBER_OF_BOOKING_PAX = DBT_INTERNAL_SOURCE.SM_NUMBER_OF_BOOKING_PAX,PRIMARY_GATEWAY = DBT_INTERNAL_SOURCE.PRIMARY_GATEWAY,SM_CURRENCY = DBT_INTERNAL_SOURCE.SM_CURRENCY,SM_REVENUE = DBT_INTERNAL_SOURCE.SM_REVENUE,SM_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.SM_CNX_AND_AMEND_REVENUE,SM_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.SM_ACCOMMODATION_COSTS,SM_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SM_EARLY_BOOKING_DISCOUNTS,SM_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SM_LATE_BOOKING_DISCOUNTS,SM_FLYING_COSTS = DBT_INTERNAL_SOURCE.SM_FLYING_COSTS,SM_OTHER_COSTS = DBT_INTERNAL_SOURCE.SM_OTHER_COSTS,SM_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.SM_DISTRIBUTION_COSTS,SM_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.SM_NON_MARGIN_ITEMS,SM_MARGIN = DBT_INTERNAL_SOURCE.SM_MARGIN,SMG_CURRENCY = DBT_INTERNAL_SOURCE.SMG_CURRENCY,SMG_REVENUE = DBT_INTERNAL_SOURCE.SMG_REVENUE,SMG_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.SMG_CNX_AND_AMEND_REVENUE,SMG_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.SMG_ACCOMMODATION_COSTS,SMG_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SMG_EARLY_BOOKING_DISCOUNTS,SMG_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.SMG_LATE_BOOKING_DISCOUNTS,SMG_FLYING_COSTS = DBT_INTERNAL_SOURCE.SMG_FLYING_COSTS,SMG_OTHER_COSTS = DBT_INTERNAL_SOURCE.SMG_OTHER_COSTS,SMG_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.SMG_DISTRIBUTION_COSTS,SMG_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.SMG_NON_MARGIN_ITEMS,SMG_MARGIN = DBT_INTERNAL_SOURCE.SMG_MARGIN,REP_CURRENCY = DBT_INTERNAL_SOURCE.REP_CURRENCY,REP_REVENUE = DBT_INTERNAL_SOURCE.REP_REVENUE,REP_CNX_AND_AMEND_REVENUE = DBT_INTERNAL_SOURCE.REP_CNX_AND_AMEND_REVENUE,REP_ACCOMMODATION_COSTS = DBT_INTERNAL_SOURCE.REP_ACCOMMODATION_COSTS,REP_EARLY_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.REP_EARLY_BOOKING_DISCOUNTS,REP_LATE_BOOKING_DISCOUNTS = DBT_INTERNAL_SOURCE.REP_LATE_BOOKING_DISCOUNTS,REP_FLYING_COSTS = DBT_INTERNAL_SOURCE.REP_FLYING_COSTS,REP_OTHER_COSTS = DBT_INTERNAL_SOURCE.REP_OTHER_COSTS,REP_DISTRIBUTION_COSTS = DBT_INTERNAL_SOURCE.REP_DISTRIBUTION_COSTS,REP_NON_MARGIN_ITEMS = DBT_INTERNAL_SOURCE.REP_NON_MARGIN_ITEMS,REP_MARGIN = DBT_INTERNAL_SOURCE.REP_MARGIN,FFD_FLAG = DBT_INTERNAL_SOURCE.FFD_FLAG,RECORD_TYPE = DBT_INTERNAL_SOURCE.RECORD_TYPE,EFFECTIVE_FROM = DBT_INTERNAL_SOURCE.EFFECTIVE_FROM,EFFECTIVE_TO = DBT_INTERNAL_SOURCE.EFFECTIVE_TO,SM_CREATED_DATETIME = DBT_INTERNAL_SOURCE.SM_CREATED_DATETIME,SM_UPDATED_DATETIME = DBT_INTERNAL_SOURCE.SM_UPDATED_DATETIME,DM_CREATED_DATETIME = DBT_INTERNAL_SOURCE.DM_CREATED_DATETIME,LATEST_RECORD_INDICATOR = DBT_INTERNAL_SOURCE.LATEST_RECORD_INDICATOR
    

    when not matched then insert
        (BK_BOOKING, BK_PRIMARY_ACCOM, BK_PRIMARY_ROOM, BK_FIRST_FLIGHT, BK_LAST_FLIGHT, BK_SOURCE_MARKET, BK_ORIGINATING_SYSTEM, BK_BOOKING_TYPE, BK_BOOKING_STATUS, SOURCE_BOOKING_ID, SOURCE_BOOKING_VERSION, BOOKING_CREATED_DATETIME, BOOKING_CONFIRMED_DATETIME, BOOKING_CANCELLED_DATETIME, GROUP_SEASON, SM_SEASON, CHANNEL_CODE, CHANNEL_DESC, BOOKED_BOARD_CODE, BOOKED_BOARD_NAME, MULTI_ROOM_BOOKING, NUMBER_OF_BOOKED_ROOMS, MULTI_CENTRE_BOOKING, DEPARTURE_DATE, RETURN_DATE, DURATION, STD_NUMBER_OF_BOOKING_ADULT_PAX, STD_NUMBER_OF_BOOKING_CHILD_PAX, STD_NUMBER_OF_BOOKING_INFANT_PAX, STD_NUMBER_OF_BOOKING_PAX, SM_NUMBER_OF_BOOKING_ADULT_PAX, SM_NUMBER_OF_BOOKING_TEENAGER_PAX, SM_NUMBER_OF_BOOKING_CHILD_PAX, SM_NUMBER_OF_BOOKING_INFANT_PAX, SM_NUMBER_OF_BOOKING_PAX, PRIMARY_GATEWAY, SM_CURRENCY, SM_REVENUE, SM_CNX_AND_AMEND_REVENUE, SM_ACCOMMODATION_COSTS, SM_EARLY_BOOKING_DISCOUNTS, SM_LATE_BOOKING_DISCOUNTS, SM_FLYING_COSTS, SM_OTHER_COSTS, SM_DISTRIBUTION_COSTS, SM_NON_MARGIN_ITEMS, SM_MARGIN, SMG_CURRENCY, SMG_REVENUE, SMG_CNX_AND_AMEND_REVENUE, SMG_ACCOMMODATION_COSTS, SMG_EARLY_BOOKING_DISCOUNTS, SMG_LATE_BOOKING_DISCOUNTS, SMG_FLYING_COSTS, SMG_OTHER_COSTS, SMG_DISTRIBUTION_COSTS, SMG_NON_MARGIN_ITEMS, SMG_MARGIN, REP_CURRENCY, REP_REVENUE, REP_CNX_AND_AMEND_REVENUE, REP_ACCOMMODATION_COSTS, REP_EARLY_BOOKING_DISCOUNTS, REP_LATE_BOOKING_DISCOUNTS, REP_FLYING_COSTS, REP_OTHER_COSTS, REP_DISTRIBUTION_COSTS, REP_NON_MARGIN_ITEMS, REP_MARGIN, FFD_FLAG, RECORD_TYPE, EFFECTIVE_FROM, EFFECTIVE_TO, SM_CREATED_DATETIME, SM_UPDATED_DATETIME, DM_CREATED_DATETIME, LATEST_RECORD_INDICATOR)
    values
        (BK_BOOKING, BK_PRIMARY_ACCOM, BK_PRIMARY_ROOM, BK_FIRST_FLIGHT, BK_LAST_FLIGHT, BK_SOURCE_MARKET, BK_ORIGINATING_SYSTEM, BK_BOOKING_TYPE, BK_BOOKING_STATUS, SOURCE_BOOKING_ID, SOURCE_BOOKING_VERSION, BOOKING_CREATED_DATETIME, BOOKING_CONFIRMED_DATETIME, BOOKING_CANCELLED_DATETIME, GROUP_SEASON, SM_SEASON, CHANNEL_CODE, CHANNEL_DESC, BOOKED_BOARD_CODE, BOOKED_BOARD_NAME, MULTI_ROOM_BOOKING, NUMBER_OF_BOOKED_ROOMS, MULTI_CENTRE_BOOKING, DEPARTURE_DATE, RETURN_DATE, DURATION, STD_NUMBER_OF_BOOKING_ADULT_PAX, STD_NUMBER_OF_BOOKING_CHILD_PAX, STD_NUMBER_OF_BOOKING_INFANT_PAX, STD_NUMBER_OF_BOOKING_PAX, SM_NUMBER_OF_BOOKING_ADULT_PAX, SM_NUMBER_OF_BOOKING_TEENAGER_PAX, SM_NUMBER_OF_BOOKING_CHILD_PAX, SM_NUMBER_OF_BOOKING_INFANT_PAX, SM_NUMBER_OF_BOOKING_PAX, PRIMARY_GATEWAY, SM_CURRENCY, SM_REVENUE, SM_CNX_AND_AMEND_REVENUE, SM_ACCOMMODATION_COSTS, SM_EARLY_BOOKING_DISCOUNTS, SM_LATE_BOOKING_DISCOUNTS, SM_FLYING_COSTS, SM_OTHER_COSTS, SM_DISTRIBUTION_COSTS, SM_NON_MARGIN_ITEMS, SM_MARGIN, SMG_CURRENCY, SMG_REVENUE, SMG_CNX_AND_AMEND_REVENUE, SMG_ACCOMMODATION_COSTS, SMG_EARLY_BOOKING_DISCOUNTS, SMG_LATE_BOOKING_DISCOUNTS, SMG_FLYING_COSTS, SMG_OTHER_COSTS, SMG_DISTRIBUTION_COSTS, SMG_NON_MARGIN_ITEMS, SMG_MARGIN, REP_CURRENCY, REP_REVENUE, REP_CNX_AND_AMEND_REVENUE, REP_ACCOMMODATION_COSTS, REP_EARLY_BOOKING_DISCOUNTS, REP_LATE_BOOKING_DISCOUNTS, REP_FLYING_COSTS, REP_OTHER_COSTS, REP_DISTRIBUTION_COSTS, REP_NON_MARGIN_ITEMS, REP_MARGIN, FFD_FLAG, RECORD_TYPE, EFFECTIVE_FROM, EFFECTIVE_TO, SM_CREATED_DATETIME, SM_UPDATED_DATETIME, DM_CREATED_DATETIME, LATEST_RECORD_INDICATOR)
2019-10-02 15:16:27,593 (Thread-1): SQL status: SUCCESS 3 in 1.65 seconds
2019-10-02 15:16:27,596 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:16:27,597 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 15:16:27,597 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 15:16:27,838 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-02 15:16:27,866 (Thread-1): 15:16:27 | 5 of 5 OK created incremental model DBT_TEST.booking_fact_uk......... [SUCCESS 3 in 49.61s]
2019-10-02 15:16:27,963 (MainThread): Using snowflake connection "master".
2019-10-02 15:16:27,963 (MainThread): On master: BEGIN
2019-10-02 15:16:28,084 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 15:16:28,085 (MainThread): On master: COMMIT
2019-10-02 15:16:28,086 (MainThread): Using snowflake connection "master".
2019-10-02 15:16:28,087 (MainThread): On master: COMMIT
2019-10-02 15:16:28,234 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 15:16:28,236 (MainThread): 15:16:28 | 
2019-10-02 15:16:28,237 (MainThread): 15:16:28 | Finished running 5 incremental models in 94.73s.
2019-10-02 15:16:28,238 (MainThread): Connection 'master' was left open.
2019-10-02 15:16:28,240 (MainThread): On master: Close
2019-10-02 15:16:28,373 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 15:16:28,374 (MainThread): On booking_fact_uk: Close
2019-10-02 15:16:28,568 (MainThread): 
2019-10-02 15:16:28,569 (MainThread): Completed successfully
2019-10-02 15:16:28,571 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 15:16:28,571 (MainThread): Flushing usage events
