2019-09-30 16:57:24,844 (MainThread): Tracking: tracking
2019-09-30 16:57:24,887 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC608>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B508>]}
2019-09-30 16:57:25,238 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-09-30 16:57:25,238 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.61', 64360), raddr=('54.164.98.48', 443)>

2019-09-30 16:57:25,240 (MainThread): Error sending message, disabling tracking
2019-09-30 16:57:25,310 (MainThread): Parsing macros\core.sql
2019-09-30 16:57:25,358 (MainThread): Parsing macros\adapters\common.sql
2019-09-30 16:57:25,454 (MainThread): Parsing macros\etc\datetime.sql
2019-09-30 16:57:25,492 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-09-30 16:57:25,511 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-09-30 16:57:25,532 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-09-30 16:57:25,554 (MainThread): Parsing macros\etc\is_incremental.sql
2019-09-30 16:57:25,610 (MainThread): Parsing macros\etc\query.sql
2019-09-30 16:57:25,651 (MainThread): Parsing macros\materializations\helpers.sql
2019-09-30 16:57:25,679 (MainThread): Parsing macros\materializations\common\merge.sql
2019-09-30 16:57:25,702 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-09-30 16:57:25,733 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-09-30 16:57:25,770 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-09-30 16:57:25,827 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-09-30 16:57:25,844 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-09-30 16:57:25,874 (MainThread): Parsing macros\materializations\table\table.sql
2019-09-30 16:57:25,896 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-09-30 16:57:25,991 (MainThread): Parsing macros\materializations\view\view.sql
2019-09-30 16:57:26,018 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-09-30 16:57:26,037 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-09-30 16:57:26,058 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-09-30 16:57:26,075 (MainThread): Parsing macros\schema_tests\unique.sql
2019-09-30 16:57:26,091 (MainThread): Parsing macros\adapters.sql
2019-09-30 16:57:26,125 (MainThread): Parsing macros\catalog.sql
2019-09-30 16:57:26,145 (MainThread): Parsing macros\materializations\incremental.sql
2019-09-30 16:57:26,169 (MainThread): Parsing macros\materializations\merge.sql
2019-09-30 16:57:26,188 (MainThread): Parsing macros\materializations\table.sql
2019-09-30 16:57:26,202 (MainThread): Parsing macros\materializations\view.sql
2019-09-30 16:57:26,234 (MainThread): Parsing model.dbt_test.create_table_booking_fact_uk
2019-09-30 16:57:26,237 (MainThread): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-09-30 16:57:26,237 (MainThread): Opening a new connection, currently in state init
2019-09-30 16:57:26,239 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-09-30 16:57:27,486 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-09-30 16:57:27,526 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-09-30 16:57:28,135 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-09-30 16:57:28,137 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-09-30 16:57:28,137 (MainThread): Re-using an available connection from the pool (formerly create_table_booking_fact_uk).
2019-09-30 16:57:28,241 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-09-30 16:57:28,243 (MainThread): 
2019-09-30 16:57:28,245 (MainThread): 16:57:28 | Concurrency: 1 threads (target='dev')
2019-09-30 16:57:28,246 (MainThread): 16:57:28 | 
2019-09-30 16:57:28,255 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-09-30 16:57:28,256 (Thread-1): Opening a new connection, currently in state init
2019-09-30 16:57:28,811 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-09-30 16:57:28,854 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-09-30 16:57:28,878 (Thread-1): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-09-30 16:57:28,878 (Thread-1): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-09-30 16:57:28,879 (Thread-1): Compiling model.dbt_test.create_table_booking_fact_uk
2019-09-30 16:57:28,891 (Thread-1): Writing injected SQL for node "model.dbt_test.create_table_booking_fact_uk"
2019-09-30 16:57:28,972 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-09-30 16:57:28,973 (MainThread): On v_booking_fact_uk: Close
2019-09-30 16:57:29,048 (MainThread): Connection 'create_table_booking_fact_uk' was left open.
2019-09-30 16:57:29,049 (MainThread): On create_table_booking_fact_uk: Close
2019-09-30 16:57:29,157 (MainThread): 16:57:29 | Done.
2019-09-30 16:57:29,159 (MainThread): Flushing usage events
2019-10-01 11:52:28,542 (MainThread): Tracking: tracking
2019-10-01 11:52:28,557 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8D5C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C927C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6CD88>]}
2019-10-01 11:52:28,911 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 11:52:28,912 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 52588), raddr=('54.164.98.48', 443)>

2019-10-01 11:52:28,915 (MainThread): Error sending message, disabling tracking
2019-10-01 11:52:28,993 (MainThread): Parsing macros\core.sql
2019-10-01 11:52:29,023 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 11:52:29,084 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 11:52:29,106 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 11:52:29,111 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 11:52:29,115 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 11:52:29,119 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 11:52:29,123 (MainThread): Parsing macros\etc\query.sql
2019-10-01 11:52:29,139 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 11:52:29,175 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 11:52:29,188 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 11:52:29,207 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 11:52:29,238 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 11:52:29,270 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 11:52:29,274 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 11:52:29,289 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 11:52:29,297 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 11:52:29,304 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 11:52:29,313 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 11:52:29,316 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 11:52:29,319 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 11:52:29,322 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 11:52:29,339 (MainThread): Parsing macros\adapters.sql
2019-10-01 11:52:29,353 (MainThread): Parsing macros\catalog.sql
2019-10-01 11:52:29,357 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 11:52:29,366 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 11:52:29,381 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 11:52:29,398 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 11:52:29,417 (MainThread): Parsing model.dbt_test.create_table_booking_fact_uk
2019-10-01 11:52:29,418 (MainThread): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-10-01 11:52:29,418 (MainThread): Opening a new connection, currently in state init
2019-10-01 11:52:29,421 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 11:52:30,017 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 11:52:30,051 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 11:52:30,632 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 11:52:30,633 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 11:52:30,633 (MainThread): Re-using an available connection from the pool (formerly create_table_booking_fact_uk).
2019-10-01 11:52:30,703 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 11:52:30,704 (MainThread): 
2019-10-01 11:52:30,705 (MainThread): 11:52:30 | Concurrency: 1 threads (target='dev')
2019-10-01 11:52:30,706 (MainThread): 11:52:30 | 
2019-10-01 11:52:30,709 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 11:52:30,710 (Thread-1): Opening a new connection, currently in state init
2019-10-01 11:52:31,268 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 11:52:31,291 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 11:52:31,301 (Thread-1): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-10-01 11:52:31,301 (Thread-1): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 11:52:31,302 (Thread-1): Compiling model.dbt_test.create_table_booking_fact_uk
2019-10-01 11:52:31,313 (Thread-1): Writing injected SQL for node "model.dbt_test.create_table_booking_fact_uk"
2019-10-01 11:52:31,414 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 11:52:31,414 (MainThread): On v_booking_fact_uk: Close
2019-10-01 11:52:31,488 (MainThread): Connection 'create_table_booking_fact_uk' was left open.
2019-10-01 11:52:31,489 (MainThread): On create_table_booking_fact_uk: Close
2019-10-01 11:52:31,582 (MainThread): 11:52:31 | Done.
2019-10-01 11:52:31,583 (MainThread): Flushing usage events
2019-10-01 13:50:19,609 (MainThread): Tracking: tracking
2019-10-01 13:50:19,613 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91448>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C808>]}
2019-10-01 13:50:19,959 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:50:19,960 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57844), raddr=('54.164.98.48', 443)>

2019-10-01 13:50:19,961 (MainThread): Error sending message, disabling tracking
2019-10-01 13:50:19,991 (MainThread): Parsing macros\core.sql
2019-10-01 13:50:20,005 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:50:20,053 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:50:20,064 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:50:20,067 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:50:20,072 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:50:20,076 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:50:20,080 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:50:20,085 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:50:20,096 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:50:20,107 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:50:20,124 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:50:20,156 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:50:20,198 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:50:20,205 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:50:20,220 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:50:20,228 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:50:20,235 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:50:20,244 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:50:20,248 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:50:20,251 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:50:20,256 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:50:20,271 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:50:20,289 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:50:20,309 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:50:20,318 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:50:20,323 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:50:20,328 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:50:20,375 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:50:20,376 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:50:20,376 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:50:20,379 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:50:20,730 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:50:20,752 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:50:21,409 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:50:21,410 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:50:21,410 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:50:21,415 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:50:21,416 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:50:21,416 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:50:21,420 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:50:21,421 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:50:21,421 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:50:21,426 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:50:21,428 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:50:21,428 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:50:21,433 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:50:21,434 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:50:21,434 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:50:21,442 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:50:21,445 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:50:21,445 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:50:21,454 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:50:21,455 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:50:21,455 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:50:21,459 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:50:21,460 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:50:21,461 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:50:21,466 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:50:21,468 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:50:21,468 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:50:21,476 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:50:21,478 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:50:21,478 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:50:21,484 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:50:21,485 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:50:21,485 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:50:21,490 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:50:21,491 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:50:21,491 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:50:21,495 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:50:21,498 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:50:21,498 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:50:21,506 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:50:21,508 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:50:21,508 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:50:21,518 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:50:21,520 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:50:21,520 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:50:21,529 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:50:21,531 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:50:21,531 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:50:21,536 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:50:21,537 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:50:21,537 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:50:21,542 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:50:21,543 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:50:21,543 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:50:21,548 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:50:21,549 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:50:21,549 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:50:21,609 (MainThread): Found 20 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 13:50:21,612 (MainThread): 
2019-10-01 13:50:21,613 (MainThread): 13:50:21 | Concurrency: 1 threads (target='dev')
2019-10-01 13:50:21,613 (MainThread): 13:50:21 | 
2019-10-01 13:50:21,618 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:50:21,618 (Thread-1): Opening a new connection, currently in state init
2019-10-01 13:50:22,147 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 13:50:22,159 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:50:22,174 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:50:22,174 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:50:22,178 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 13:50:22,187 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:50:22,209 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:50:22,215 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:50:22,216 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 13:50:22,238 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:50:22,293 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:50:22,297 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:50:22,299 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 13:50:22,324 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:50:22,383 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:50:22,386 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:50:22,387 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 13:50:22,401 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:50:22,423 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:50:22,427 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:50:22,428 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 13:50:22,440 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:50:22,455 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:50:22,458 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:50:22,459 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 13:50:22,469 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:50:22,485 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:50:22,485 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:50:22,486 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 13:50:22,500 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:50:22,517 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:50:22,517 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:50:22,518 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 13:50:22,531 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:50:22,559 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:50:22,563 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:50:22,564 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 13:50:22,584 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:50:22,612 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:50:22,612 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:50:22,620 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:50:22,635 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:50:22,650 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:50:22,651 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:50:22,651 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 13:50:22,667 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:50:22,689 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:50:22,690 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:50:22,693 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 13:50:22,704 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:50:22,729 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:50:22,729 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:50:22,730 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 13:50:22,741 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:50:22,761 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:50:22,762 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:50:22,762 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 13:50:22,783 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:50:22,820 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 13:50:22,820 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:50:22,821 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 13:50:22,850 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 13:50:22,880 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:50:22,880 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:50:22,881 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 13:50:22,904 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:50:22,927 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:50:22,929 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:50:22,930 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:50:22,940 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:50:22,953 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:50:22,956 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:50:22,957 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 13:50:22,967 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:50:22,994 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:50:22,997 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:50:22,998 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 13:50:23,011 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:50:23,074 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:50:23,075 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:50:23,162 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:50:23,162 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:50:23,339 (MainThread): 13:50:23 | Done.
2019-10-01 13:50:23,339 (MainThread): Flushing usage events
2019-10-01 13:51:52,928 (MainThread): Tracking: tracking
2019-10-01 13:51:52,930 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBE388>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBE5C8>]}
2019-10-01 13:51:53,243 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:51:53,244 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57859), raddr=('54.174.31.151', 443)>

2019-10-01 13:51:53,246 (MainThread): Error sending message, disabling tracking
2019-10-01 13:51:53,272 (MainThread): Parsing macros\core.sql
2019-10-01 13:51:53,283 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:51:53,349 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:51:53,359 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:51:53,361 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:51:53,364 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:51:53,368 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:51:53,370 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:51:53,373 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:51:53,382 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:51:53,396 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:51:53,410 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:51:53,427 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:51:53,451 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:51:53,454 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:51:53,468 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:51:53,475 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:51:53,486 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:51:53,496 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:51:53,501 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:51:53,503 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:51:53,505 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:51:53,508 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:51:53,521 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:51:53,524 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:51:53,536 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:51:53,539 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:51:53,543 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:51:53,567 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:51:53,570 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:51:53,570 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:51:53,572 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:51:53,840 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:51:53,855 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:51:54,475 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:51:54,476 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:51:54,476 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:51:54,481 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:51:54,482 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:51:54,482 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:51:54,486 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:51:54,487 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:51:54,487 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:51:54,492 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:51:54,493 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:51:54,493 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:51:54,498 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:51:54,499 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:51:54,499 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:51:54,504 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:51:54,505 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:51:54,505 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:51:54,510 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:51:54,512 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:51:54,512 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:51:54,516 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:51:54,518 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:51:54,518 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:51:54,524 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:51:54,524 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:51:54,525 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:51:54,529 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:51:54,530 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:51:54,531 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:51:54,535 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:51:54,536 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:51:54,536 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:51:54,541 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:51:54,542 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:51:54,543 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:51:54,548 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:51:54,549 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:51:54,549 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:51:54,554 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:51:54,555 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:51:54,555 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:51:54,560 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:51:54,561 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:51:54,561 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:51:54,565 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:51:54,566 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:51:54,567 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:51:54,571 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:51:54,572 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:51:54,573 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:51:54,577 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:51:54,579 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:51:54,579 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:51:54,585 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:51:54,586 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:51:54,586 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:51:54,646 (MainThread): Found 20 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 13:51:54,649 (MainThread): 
2019-10-01 13:51:54,650 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 13:51:54,650 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 13:51:54,671 (MainThread): Parsing macros\core.sql
2019-10-01 13:51:54,676 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:51:54,749 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:51:54,759 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:51:54,761 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:51:54,767 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:51:54,771 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:51:54,774 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:51:54,776 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:51:54,784 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:51:54,793 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:51:54,801 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:51:54,819 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:51:54,840 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:51:54,843 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:51:54,862 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:51:54,869 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:51:54,875 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:51:54,881 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:51:54,884 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:51:54,886 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:51:54,889 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:51:54,892 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:51:54,904 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:51:54,907 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:51:54,924 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:51:54,928 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:51:54,934 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:51:55,113 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:55,113 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 13:51:55,796 (MainThread): SQL status: SUCCESS 29 in 0.68 seconds
2019-10-01 13:51:55,852 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:55,852 (MainThread): On master: BEGIN
2019-10-01 13:51:55,985 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:51:55,986 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:55,986 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 13:51:57,282 (MainThread): SQL status: SUCCESS 2 in 1.30 seconds
2019-10-01 13:51:57,284 (MainThread): On master: ROLLBACK
2019-10-01 13:51:57,661 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:57,661 (MainThread): On master: BEGIN
2019-10-01 13:51:57,810 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:51:57,811 (MainThread): On master: COMMIT
2019-10-01 13:51:57,811 (MainThread): Using snowflake connection "master".
2019-10-01 13:51:57,811 (MainThread): On master: COMMIT
2019-10-01 13:51:57,971 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:51:57,972 (MainThread): 13:51:57 | Concurrency: 1 threads (target='dev')
2019-10-01 13:51:57,972 (MainThread): 13:51:57 | 
2019-10-01 13:51:57,975 (Thread-1): 13:51:57 | 1 of 20 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 13:51:57,976 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:51:57,976 (Thread-1): Opening a new connection, currently in state init
2019-10-01 13:51:58,449 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 13:51:58,454 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:51:58,487 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:51:58,511 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 13:51:58,511 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 13:51:58,668 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:51:58,668 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 13:51:58,669 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 13:51:58,950 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 13:51:58,952 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 13:51:58,952 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 13:51:58,952 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 13:51:59,046 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:51:59,051 (Thread-1): 13:51:59 | 1 of 20 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.07s]
2019-10-01 13:51:59,053 (Thread-1): 13:51:59 | 2 of 20 START view model DBT_TEST.with_ar_currency................... [RUN]
2019-10-01 13:51:59,056 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:51:59,056 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:51:59,057 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 13:51:59,065 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:51:59,076 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:51:59,084 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 13:51:59,084 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 13:51:59,207 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:51:59,207 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 13:51:59,208 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 13:51:59,557 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 13:51:59,558 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 13:51:59,559 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 13:51:59,559 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 13:51:59,654 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:51:59,658 (Thread-1): 13:51:59 | 2 of 20 OK created view model DBT_TEST.with_ar_currency.............. [SUCCESS 1 in 0.60s]
2019-10-01 13:51:59,659 (Thread-1): 13:51:59 | 3 of 20 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 13:51:59,662 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:51:59,662 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:51:59,663 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 13:51:59,670 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:51:59,679 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:51:59,685 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 13:51:59,685 (Thread-1): On with_ar_market: BEGIN
2019-10-01 13:51:59,794 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:51:59,794 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 13:51:59,795 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 13:52:00,049 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 13:52:00,051 (Thread-1): On with_ar_market: COMMIT
2019-10-01 13:52:00,051 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 13:52:00,051 (Thread-1): On with_ar_market: COMMIT
2019-10-01 13:52:00,144 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:00,148 (Thread-1): 13:52:00 | 3 of 20 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.49s]
2019-10-01 13:52:00,149 (Thread-1): 13:52:00 | 4 of 20 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 13:52:00,150 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:52:00,150 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:52:00,151 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 13:52:00,156 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:52:00,164 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:52:00,171 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 13:52:00,171 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 13:52:00,277 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:00,277 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 13:52:00,278 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 13:52:00,583 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 13:52:00,584 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 13:52:00,584 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 13:52:00,584 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 13:52:00,700 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:00,704 (Thread-1): 13:52:00 | 4 of 20 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.55s]
2019-10-01 13:52:00,705 (Thread-1): 13:52:00 | 5 of 20 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 13:52:00,707 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:52:00,707 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:52:00,707 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 13:52:00,715 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:52:00,725 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:52:00,733 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 13:52:00,733 (Thread-1): On with_ar_point: BEGIN
2019-10-01 13:52:00,858 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:00,858 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 13:52:00,859 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 13:52:01,217 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 13:52:01,218 (Thread-1): On with_ar_point: COMMIT
2019-10-01 13:52:01,218 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 13:52:01,218 (Thread-1): On with_ar_point: COMMIT
2019-10-01 13:52:01,311 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:01,314 (Thread-1): 13:52:01 | 5 of 20 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.61s]
2019-10-01 13:52:01,315 (Thread-1): 13:52:01 | 6 of 20 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 13:52:01,317 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,317 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:52:01,317 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 13:52:01,322 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:52:01,334 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:52:01,343 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,343 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 13:52:01,448 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:01,448 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,448 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 13:52:01,761 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 13:52:01,763 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 13:52:01,763 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 13:52:01,763 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 13:52:01,898 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:01,902 (Thread-1): 13:52:01 | 6 of 20 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.58s]
2019-10-01 13:52:01,904 (Thread-1): 13:52:01 | 7 of 20 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 13:52:01,905 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:52:01,906 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:52:01,906 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 13:52:01,912 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:52:01,920 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:52:01,928 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 13:52:01,928 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 13:52:02,093 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:52:02,094 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 13:52:02,094 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 13:52:02,495 (Thread-1): SQL status: SUCCESS 1 in 0.40 seconds
2019-10-01 13:52:02,497 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 13:52:02,497 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 13:52:02,498 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 13:52:02,606 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:02,610 (Thread-1): 13:52:02 | 7 of 20 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.70s]
2019-10-01 13:52:02,611 (Thread-1): 13:52:02 | 8 of 20 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 13:52:02,613 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:52:02,613 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:52:02,614 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 13:52:02,619 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:52:02,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:52:02,639 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 13:52:02,639 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 13:52:02,756 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:02,756 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 13:52:02,757 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 13:52:03,016 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 13:52:03,017 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 13:52:03,017 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 13:52:03,017 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 13:52:03,258 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 13:52:03,262 (Thread-1): 13:52:03 | 8 of 20 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.65s]
2019-10-01 13:52:03,263 (Thread-1): 13:52:03 | 9 of 20 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 13:52:03,264 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,264 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:52:03,265 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 13:52:03,270 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:52:03,277 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:52:03,282 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,282 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 13:52:03,421 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 13:52:03,422 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,422 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 13:52:03,771 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 13:52:03,772 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 13:52:03,772 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 13:52:03,772 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 13:52:03,895 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:03,899 (Thread-1): 13:52:03 | 9 of 20 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.63s]
2019-10-01 13:52:03,900 (Thread-1): 13:52:03 | 10 of 20 START view model DBT_TEST.with_ar_transinvroute............. [RUN]
2019-10-01 13:52:03,902 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:03,902 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:52:03,902 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 13:52:03,907 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:52:03,918 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:52:03,924 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:03,925 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 13:52:04,077 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:52:04,078 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:04,078 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 13:52:04,501 (Thread-1): SQL status: SUCCESS 1 in 0.42 seconds
2019-10-01 13:52:04,503 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 13:52:04,503 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 13:52:04,503 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 13:52:04,608 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:04,612 (Thread-1): 13:52:04 | 10 of 20 OK created view model DBT_TEST.with_ar_transinvroute........ [SUCCESS 1 in 0.71s]
2019-10-01 13:52:04,614 (Thread-1): 13:52:04 | 11 of 20 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 13:52:04,615 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:04,615 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:52:04,616 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:52:04,621 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:52:04,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:52:04,640 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:04,641 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 13:52:04,757 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:04,758 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:04,758 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 13:52:05,016 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 13:52:05,018 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 13:52:05,018 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:52:05,019 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 13:52:05,151 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:05,154 (Thread-1): 13:52:05 | 11 of 20 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.54s]
2019-10-01 13:52:05,155 (Thread-1): 13:52:05 | 12 of 20 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 13:52:05,157 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,157 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:52:05,157 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 13:52:05,162 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:52:05,171 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:52:05,181 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,181 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 13:52:05,415 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 13:52:05,416 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,416 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 13:52:05,799 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2019-10-01 13:52:05,800 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 13:52:05,801 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 13:52:05,801 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 13:52:05,909 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:05,913 (Thread-1): 13:52:05 | 12 of 20 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.76s]
2019-10-01 13:52:05,914 (Thread-1): 13:52:05 | 13 of 20 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 13:52:05,915 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:52:05,915 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:52:05,915 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 13:52:05,921 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:52:05,933 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:52:05,943 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 13:52:05,943 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 13:52:06,055 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 13:52:06,055 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 13:52:06,055 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 13:52:06,308 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 13:52:06,309 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 13:52:06,309 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 13:52:06,309 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 13:52:06,401 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:06,410 (Thread-1): 13:52:06 | 13 of 20 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.49s]
2019-10-01 13:52:06,412 (Thread-1): 13:52:06 | 14 of 20 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 13:52:06,418 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:52:06,419 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:52:06,420 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 13:52:06,430 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:52:06,446 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:52:06,467 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 13:52:06,468 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 13:52:06,642 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 13:52:06,643 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 13:52:06,643 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 13:52:07,029 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2019-10-01 13:52:07,030 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 13:52:07,030 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 13:52:07,031 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 13:52:07,126 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 13:52:07,132 (Thread-1): 13:52:07 | 14 of 20 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.71s]
2019-10-01 13:52:07,134 (Thread-1): 13:52:07 | 15 of 20 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 13:52:07,138 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,139 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:52:07,139 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 13:52:07,149 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:52:07,163 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:52:07,174 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,174 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 13:52:07,419 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 13:52:07,419 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,419 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 13:52:07,938 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2019-10-01 13:52:07,939 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 13:52:07,939 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 13:52:07,940 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 13:52:08,061 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 13:52:08,065 (Thread-1): 13:52:08 | 15 of 20 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.93s]
2019-10-01 13:52:08,067 (Thread-1): 13:52:08 | 16 of 20 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 13:52:08,071 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 13:52:08,071 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:52:08,072 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 13:52:08,079 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 13:52:08,092 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 13:52:08,099 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 13:52:08,099 (Thread-1): On with_dates: BEGIN
2019-10-01 13:52:08,227 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:08,228 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 13:52:08,228 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim
  );
2019-10-01 13:52:08,498 (Thread-1): Snowflake error: 000904 (42000): 018f4144-0006-fbe4-0000-0e29015fd5aa: SQL compilation error: error line 6 at position 1
invalid identifier 'DD.BK_DATE'
2019-10-01 13:52:08,498 (Thread-1): On with_dates: ROLLBACK
2019-10-01 13:52:08,635 (Thread-1): 13:52:08 | 16 of 20 ERROR creating view model DBT_TEST.with_dates............... [ERROR in 0.56s]
2019-10-01 13:52:08,637 (Thread-1): 13:52:08 | 17 of 20 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 13:52:08,641 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:08,641 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:52:08,642 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 13:52:08,649 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:52:08,661 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:52:08,669 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:08,669 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 13:52:08,833 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:52:08,833 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:08,833 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 13:52:09,146 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 13:52:09,147 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 13:52:09,147 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 13:52:09,147 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 13:52:09,250 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:09,254 (Thread-1): 13:52:09 | 17 of 20 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.61s]
2019-10-01 13:52:09,256 (Thread-1): 13:52:09 | 18 of 20 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 13:52:09,259 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,260 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:52:09,260 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:52:09,267 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:52:09,276 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:52:09,286 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,287 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 13:52:09,462 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 13:52:09,463 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,463 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 13:52:09,826 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 13:52:09,827 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 13:52:09,827 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:52:09,827 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 13:52:09,987 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 13:52:09,991 (Thread-1): 13:52:09 | 18 of 20 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.73s]
2019-10-01 13:52:09,993 (Thread-1): 13:52:09 | 19 of 20 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 13:52:09,997 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:52:09,997 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:52:09,998 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 13:52:10,007 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:52:10,020 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:52:10,031 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 13:52:10,031 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 13:52:10,161 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 13:52:10,161 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 13:52:10,161 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 13:52:10,556 (Thread-1): SQL status: SUCCESS 1 in 0.39 seconds
2019-10-01 13:52:10,558 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 13:52:10,558 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 13:52:10,558 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 13:52:10,656 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:10,663 (Thread-1): 13:52:10 | 19 of 20 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.66s]
2019-10-01 13:52:10,664 (Thread-1): 13:52:10 | 20 of 20 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 13:52:10,668 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:10,669 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:52:10,670 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 13:52:10,679 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:52:10,690 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:52:10,699 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:10,699 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 13:52:10,896 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 13:52:10,896 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:10,896 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 13:52:11,175 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 13:52:11,176 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 13:52:11,176 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 13:52:11,176 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 13:52:11,274 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 13:52:11,278 (Thread-1): 13:52:11 | 20 of 20 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.61s]
2019-10-01 13:52:11,370 (MainThread): Using snowflake connection "master".
2019-10-01 13:52:11,371 (MainThread): On master: BEGIN
2019-10-01 13:52:11,520 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:52:11,520 (MainThread): On master: COMMIT
2019-10-01 13:52:11,520 (MainThread): Using snowflake connection "master".
2019-10-01 13:52:11,520 (MainThread): On master: COMMIT
2019-10-01 13:52:11,674 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 13:52:11,675 (MainThread): 13:52:11 | 
2019-10-01 13:52:11,676 (MainThread): 13:52:11 | Finished running 20 view models in 17.03s.
2019-10-01 13:52:11,677 (MainThread): Connection 'master' was left open.
2019-10-01 13:52:11,677 (MainThread): On master: Close
2019-10-01 13:52:11,870 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:52:11,870 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:52:12,140 (MainThread): 
2019-10-01 13:52:12,141 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 13:52:12,143 (MainThread): 
2019-10-01 13:52:12,144 (MainThread): Database Error in model with_dates (models\with_dates.sql)
2019-10-01 13:52:12,150 (MainThread):   000904 (42000): 018f4144-0006-fbe4-0000-0e29015fd5aa: SQL compilation error: error line 6 at position 1
2019-10-01 13:52:12,155 (MainThread):   invalid identifier 'DD.BK_DATE'
2019-10-01 13:52:12,157 (MainThread):   compiled SQL at target\compiled\dbt_test\with_dates.sql
2019-10-01 13:52:12,161 (MainThread): 
Done. PASS=19 WARN=0 ERROR=1 SKIP=0 TOTAL=20
2019-10-01 13:52:12,166 (MainThread): Flushing usage events
2019-10-01 13:57:15,082 (MainThread): Tracking: tracking
2019-10-01 13:57:15,084 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C96408>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DF88>]}
2019-10-01 13:57:15,415 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:57:15,416 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57927), raddr=('54.174.31.151', 443)>

2019-10-01 13:57:15,418 (MainThread): Error sending message, disabling tracking
2019-10-01 13:57:15,439 (MainThread): Parsing macros\core.sql
2019-10-01 13:57:15,447 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:57:15,502 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:57:15,523 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:57:15,526 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:57:15,532 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:57:15,539 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:57:15,543 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:57:15,548 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:57:15,560 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:57:15,569 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:57:15,581 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:57:15,599 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:57:15,620 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:57:15,623 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:57:15,640 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:57:15,652 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:57:15,658 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:57:15,665 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:57:15,670 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:57:15,672 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:57:15,674 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:57:15,677 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:57:15,690 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:57:15,694 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:57:15,702 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:57:15,705 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:57:15,710 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:57:15,750 (MainThread): Parsing model.dbt_test.create_table_booking_fact_uk
2019-10-01 13:57:15,752 (MainThread): Acquiring new snowflake connection "create_table_booking_fact_uk".
2019-10-01 13:57:15,752 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:57:15,755 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:57:16,051 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:57:16,078 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:57:16,742 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 13:57:16,745 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:57:16,745 (MainThread): Re-using an available connection from the pool (formerly create_table_booking_fact_uk).
2019-10-01 13:57:16,800 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:57:16,801 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:57:16,801 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 13:57:16,807 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:57:16,809 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:57:16,809 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:57:16,816 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:57:16,818 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:57:16,818 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:57:16,829 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:57:16,833 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:57:16,833 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:57:16,842 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:57:16,843 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:57:16,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:57:16,851 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:57:16,853 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:57:16,853 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:57:16,861 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:57:16,863 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:57:16,864 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:57:16,875 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:57:16,877 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:57:16,878 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:57:16,888 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:57:16,891 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:57:16,891 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:57:16,900 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:57:16,901 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:57:16,901 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:57:16,907 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:57:16,909 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:57:16,910 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:57:16,919 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:57:16,921 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:57:16,921 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:57:16,927 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:57:16,929 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:57:16,929 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:57:16,935 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:57:16,936 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:57:16,936 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:57:16,942 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:57:16,944 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:57:16,944 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:57:16,951 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:57:16,953 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:57:16,953 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:57:16,964 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:57:16,966 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:57:16,966 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:57:16,976 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:57:16,978 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:57:16,978 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:57:16,985 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:57:16,986 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:57:16,987 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:57:16,996 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:57:16,998 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:57:16,999 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:57:17,064 (MainThread): Flushing usage events
2019-10-01 13:57:17,064 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:57:17,064 (MainThread): Encountered an error:
2019-10-01 13:57:17,065 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:57:17,065 (MainThread): Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled
2019-10-01 13:57:17,166 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 164, in _load_from_projects
    return loader.create_manifest()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 153, in create_manifest
    self.root_project.project_name)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 217, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 204, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 399, in invalid_ref_fail_unless_test
    target_model_package)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 402, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled

2019-10-01 13:58:39,441 (MainThread): Tracking: tracking
2019-10-01 13:58:39,443 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91A08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91A48>]}
2019-10-01 13:58:39,767 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:58:39,768 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57975), raddr=('54.164.98.48', 443)>

2019-10-01 13:58:39,770 (MainThread): Error sending message, disabling tracking
2019-10-01 13:58:39,810 (MainThread): Parsing macros\core.sql
2019-10-01 13:58:39,825 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:58:39,906 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:58:39,927 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:58:39,931 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:58:39,938 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:58:39,945 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:58:39,951 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:58:39,956 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:58:39,977 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:58:39,994 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:58:40,010 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:58:40,048 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:58:40,093 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:58:40,100 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:58:40,132 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:58:40,151 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:58:40,164 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:58:40,181 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:58:40,186 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:58:40,190 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:58:40,194 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:58:40,200 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:58:40,228 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:58:40,234 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:58:40,251 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:58:40,256 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:58:40,266 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:58:40,314 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 13:58:40,316 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:58:40,317 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:58:40,319 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:58:40,627 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:58:40,651 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:58:41,302 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:58:41,304 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:58:41,304 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 13:58:41,313 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:58:41,315 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:58:41,315 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:58:41,324 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:58:41,326 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:58:41,326 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:58:41,333 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:58:41,334 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:58:41,335 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:58:41,340 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:58:41,341 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:58:41,341 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:58:41,345 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:58:41,346 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:58:41,346 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:58:41,351 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:58:41,353 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:58:41,353 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:58:41,361 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:58:41,363 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:58:41,363 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:58:41,370 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:58:41,371 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:58:41,371 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:58:41,380 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:58:41,382 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:58:41,382 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:58:41,390 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:58:41,392 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:58:41,393 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:58:41,400 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:58:41,401 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:58:41,401 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:58:41,409 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:58:41,411 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:58:41,411 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:58:41,419 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:58:41,421 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:58:41,421 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:58:41,428 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:58:41,430 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:58:41,430 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:58:41,436 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:58:41,438 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:58:41,438 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:58:41,444 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:58:41,446 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:58:41,446 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:58:41,456 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:58:41,458 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:58:41,458 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:58:41,468 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:58:41,470 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:58:41,470 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:58:41,478 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:58:41,480 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:58:41,480 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:58:41,542 (MainThread): Flushing usage events
2019-10-01 13:58:41,543 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:58:41,543 (MainThread): Encountered an error:
2019-10-01 13:58:41,544 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:58:41,544 (MainThread): Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled
2019-10-01 13:58:41,577 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 164, in _load_from_projects
    return loader.create_manifest()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 153, in create_manifest
    self.root_project.project_name)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 217, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "c:\python\python37\lib\site-packages\dbt\parser\util.py", line 204, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 399, in invalid_ref_fail_unless_test
    target_model_package)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 402, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
  Model 'model.dbt_test.v_booking_fact_uk' depends on model 'with_arusercodes' which was not found or is disabled

2019-10-01 13:59:30,890 (MainThread): Tracking: tracking
2019-10-01 13:59:30,893 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C938C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93DC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6CA48>]}
2019-10-01 13:59:31,188 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 13:59:31,189 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58000), raddr=('54.164.98.48', 443)>

2019-10-01 13:59:31,191 (MainThread): Error sending message, disabling tracking
2019-10-01 13:59:31,232 (MainThread): Parsing macros\core.sql
2019-10-01 13:59:31,246 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 13:59:31,322 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 13:59:31,342 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 13:59:31,346 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 13:59:31,351 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 13:59:31,358 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 13:59:31,363 (MainThread): Parsing macros\etc\query.sql
2019-10-01 13:59:31,367 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 13:59:31,382 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 13:59:31,399 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 13:59:31,411 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 13:59:31,437 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 13:59:31,475 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 13:59:31,480 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 13:59:31,494 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 13:59:31,506 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 13:59:31,518 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 13:59:31,529 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 13:59:31,533 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 13:59:31,536 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 13:59:31,542 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 13:59:31,547 (MainThread): Parsing macros\adapters.sql
2019-10-01 13:59:31,569 (MainThread): Parsing macros\catalog.sql
2019-10-01 13:59:31,575 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 13:59:31,591 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 13:59:31,598 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 13:59:31,605 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 13:59:31,679 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 13:59:31,685 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:59:31,685 (MainThread): Opening a new connection, currently in state init
2019-10-01 13:59:31,688 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 13:59:32,084 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 13:59:32,111 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 13:59:32,829 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 13:59:32,831 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:59:32,832 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 13:59:32,841 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 13:59:32,844 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:59:32,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:59:32,854 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 13:59:32,857 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:59:32,857 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:59:32,869 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 13:59:32,871 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:59:32,871 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:59:32,881 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 13:59:32,884 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:59:32,884 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:59:32,894 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 13:59:32,896 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:59:32,896 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:59:32,907 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 13:59:32,910 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:59:32,910 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:59:32,922 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 13:59:32,924 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:59:32,924 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:59:32,934 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 13:59:32,937 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:59:32,937 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:59:32,947 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 13:59:32,948 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:59:32,949 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:59:32,958 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:59:32,960 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:59:32,961 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:59:32,971 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 13:59:32,974 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:59:32,974 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:59:32,984 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 13:59:32,987 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:59:32,988 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:59:32,998 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 13:59:33,000 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:59:33,000 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:59:33,009 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 13:59:33,012 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:59:33,012 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:59:33,028 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 13:59:33,032 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 13:59:33,033 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:59:33,047 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 13:59:33,050 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:59:33,050 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:59:33,063 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:59:33,066 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:59:33,066 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:59:33,078 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 13:59:33,081 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:59:33,081 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:59:33,092 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 13:59:33,095 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:59:33,095 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:59:33,254 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 13:59:33,263 (MainThread): 
2019-10-01 13:59:33,270 (MainThread): 13:59:33 | Concurrency: 1 threads (target='dev')
2019-10-01 13:59:33,273 (MainThread): 13:59:33 | 
2019-10-01 13:59:33,305 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 13:59:33,307 (Thread-1): Opening a new connection, currently in state init
2019-10-01 13:59:33,900 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 13:59:33,916 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 13:59:33,940 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 13:59:33,943 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 13:59:33,945 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 13:59:33,957 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 13:59:33,980 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 13:59:33,984 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 13:59:33,985 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 13:59:33,995 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 13:59:34,017 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 13:59:34,017 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 13:59:34,019 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 13:59:34,035 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 13:59:34,050 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 13:59:34,054 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 13:59:34,064 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 13:59:34,084 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 13:59:34,098 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 13:59:34,102 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 13:59:34,103 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 13:59:34,113 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 13:59:34,130 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 13:59:34,133 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 13:59:34,134 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 13:59:34,144 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 13:59:34,158 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 13:59:34,161 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 13:59:34,162 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 13:59:34,173 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 13:59:34,203 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 13:59:34,204 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 13:59:34,205 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 13:59:34,228 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 13:59:34,244 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 13:59:34,248 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 13:59:34,250 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 13:59:34,262 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 13:59:34,279 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 13:59:34,279 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 13:59:34,280 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 13:59:34,290 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 13:59:34,313 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 13:59:34,314 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 13:59:34,321 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 13:59:34,337 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 13:59:34,377 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 13:59:34,381 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 13:59:34,382 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 13:59:34,394 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 13:59:34,409 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 13:59:34,409 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 13:59:34,410 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 13:59:34,423 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 13:59:34,463 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 13:59:34,466 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 13:59:34,467 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 13:59:34,477 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 13:59:34,496 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 13:59:34,498 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 13:59:34,499 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 13:59:34,510 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 13:59:34,544 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 13:59:34,547 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 13:59:34,548 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 13:59:34,558 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 13:59:34,576 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 13:59:34,576 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 13:59:34,577 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 13:59:34,587 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 13:59:34,608 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 13:59:34,611 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 13:59:34,612 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 13:59:34,621 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 13:59:34,637 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 13:59:34,638 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 13:59:34,639 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 13:59:34,652 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 13:59:34,670 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 13:59:34,674 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 13:59:34,675 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 13:59:34,773 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 13:59:34,846 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-01 13:59:34,847 (MainThread): On with_fl_acr_service_element: Close
2019-10-01 13:59:34,981 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 13:59:34,982 (MainThread): On v_booking_fact_uk: Close
2019-10-01 13:59:35,143 (MainThread): 13:59:35 | Done.
2019-10-01 13:59:35,144 (MainThread): Flushing usage events
2019-10-01 14:00:45,846 (MainThread): Tracking: tracking
2019-10-01 14:00:45,849 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000070CB748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93B08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6E588>]}
2019-10-01 14:00:46,163 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:00:46,163 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58028), raddr=('54.174.31.151', 443)>

2019-10-01 14:00:46,164 (MainThread): Error sending message, disabling tracking
2019-10-01 14:00:46,190 (MainThread): Parsing macros\core.sql
2019-10-01 14:00:46,202 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:00:46,277 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:00:46,293 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:00:46,296 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:00:46,299 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:00:46,303 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:00:46,306 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:00:46,309 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:00:46,321 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:00:46,332 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:00:46,344 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:00:46,372 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:00:46,414 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:00:46,420 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:00:46,444 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:00:46,458 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:00:46,470 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:00:46,484 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:00:46,489 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:00:46,493 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:00:46,497 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:00:46,502 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:00:46,530 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:00:46,540 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:00:46,568 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:00:46,575 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:00:46,586 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:00:46,630 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:00:46,633 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:00:46,633 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:00:46,636 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:00:46,919 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:00:46,947 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:00:47,635 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:00:47,636 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:00:47,636 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:00:47,640 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:00:47,641 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:00:47,641 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:00:47,645 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:00:47,646 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:00:47,646 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:00:47,653 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:00:47,655 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:00:47,656 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:00:47,664 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:00:47,667 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:00:47,667 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:00:47,676 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:00:47,676 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:47,677 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:00:47,681 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:00:47,682 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:00:47,682 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:00:47,686 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:00:47,687 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:00:47,687 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:00:47,693 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:00:47,694 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:00:47,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:00:47,698 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:00:47,699 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:00:47,699 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:00:47,703 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:00:47,704 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:00:47,705 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:00:47,709 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:00:47,710 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:00:47,710 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:00:47,714 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:00:47,715 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:00:47,715 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:00:47,720 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:00:47,721 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:00:47,721 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:00:47,725 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:00:47,726 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:00:47,726 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:00:47,731 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:00:47,732 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:00:47,732 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:00:47,737 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:00:47,738 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:00:47,738 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:00:47,742 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:00:47,743 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:00:47,744 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:00:47,748 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:00:47,749 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:00:47,749 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:00:47,753 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:00:47,754 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:00:47,754 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:00:47,820 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:00:47,825 (MainThread): 
2019-10-01 14:00:47,825 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:00:47,826 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:00:47,865 (MainThread): Parsing macros\core.sql
2019-10-01 14:00:47,876 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:00:47,975 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:00:47,997 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:00:48,001 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:00:48,008 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:00:48,015 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:00:48,021 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:00:48,026 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:00:48,042 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:00:48,051 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:00:48,065 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:00:48,093 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:00:48,123 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:00:48,126 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:00:48,146 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:00:48,158 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:00:48,168 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:00:48,186 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:00:48,194 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:00:48,199 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:00:48,204 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:00:48,211 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:00:48,238 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:00:48,244 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:00:48,260 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:00:48,265 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:00:48,272 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:00:48,411 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:48,412 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:00:49,621 (MainThread): SQL status: SUCCESS 29 in 1.21 seconds
2019-10-01 14:00:49,700 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:49,701 (MainThread): On master: BEGIN
2019-10-01 14:00:49,872 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:00:49,873 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:49,873 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:00:52,615 (MainThread): SQL status: SUCCESS 19 in 2.74 seconds
2019-10-01 14:00:52,634 (MainThread): On master: ROLLBACK
2019-10-01 14:00:52,837 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:52,837 (MainThread): On master: BEGIN
2019-10-01 14:00:52,947 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:00:52,947 (MainThread): On master: COMMIT
2019-10-01 14:00:52,947 (MainThread): Using snowflake connection "master".
2019-10-01 14:00:52,947 (MainThread): On master: COMMIT
2019-10-01 14:00:53,111 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:00:53,112 (MainThread): 14:00:53 | Concurrency: 1 threads (target='dev')
2019-10-01 14:00:53,112 (MainThread): 14:00:53 | 
2019-10-01 14:00:53,121 (Thread-1): 14:00:53 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:00:53,122 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:00:53,122 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:00:53,692 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:00:53,698 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:00:53,732 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:00:53,741 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:00:53,742 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:00:53,863 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:53,863 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:00:53,864 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:00:54,812 (Thread-1): SQL status: SUCCESS 1 in 0.95 seconds
2019-10-01 14:00:54,814 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:00:54,814 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:00:54,814 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:00:54,914 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:00:54,924 (Thread-1): 14:00:54 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.80s]
2019-10-01 14:00:54,927 (Thread-1): 14:00:54 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:00:54,931 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:00:54,931 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:00:54,933 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:00:54,945 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:00:54,963 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:00:54,971 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:00:54,971 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:00:55,092 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:55,093 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:00:55,093 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:00:56,051 (Thread-1): SQL status: SUCCESS 1 in 0.96 seconds
2019-10-01 14:00:56,052 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:00:56,052 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:00:56,052 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:00:56,226 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:00:56,232 (Thread-1): 14:00:56 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 1.30s]
2019-10-01 14:00:56,233 (Thread-1): 14:00:56 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:00:56,237 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:00:56,238 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:00:56,239 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:00:56,250 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:00:56,263 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:00:56,272 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:00:56,272 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:00:56,436 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:00:56,437 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:00:56,437 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:00:56,720 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:00:56,722 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:00:56,722 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:00:56,722 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:00:56,811 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:00:56,822 (Thread-1): 14:00:56 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.58s]
2019-10-01 14:00:56,826 (Thread-1): 14:00:56 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:00:56,831 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:00:56,832 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:00:56,833 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:00:56,848 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:00:56,866 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:00:56,876 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:00:56,876 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:00:56,996 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:56,997 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:00:56,997 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:00:57,273 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:00:57,276 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:00:57,276 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:00:57,276 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:00:57,886 (Thread-1): SQL status: SUCCESS 1 in 0.61 seconds
2019-10-01 14:00:57,893 (Thread-1): 14:00:57 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 1.06s]
2019-10-01 14:00:57,894 (Thread-1): 14:00:57 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:00:57,899 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:57,899 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:00:57,901 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:00:57,907 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:00:57,917 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:00:57,924 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:57,924 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:00:58,109 (Thread-1): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-01 14:00:58,109 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:58,109 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:00:59,095 (Thread-1): SQL status: SUCCESS 1 in 0.99 seconds
2019-10-01 14:00:59,097 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:00:59,097 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:00:59,097 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:00:59,234 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:00:59,241 (Thread-1): 14:00:59 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 1.34s]
2019-10-01 14:00:59,244 (Thread-1): 14:00:59 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:00:59,250 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,250 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:00:59,251 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:00:59,260 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:00:59,273 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:00:59,282 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,283 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:00:59,390 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:00:59,391 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,391 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:00:59,682 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:00:59,683 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:00:59,683 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:00:59,683 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:00:59,777 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:00:59,782 (Thread-1): 14:00:59 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.53s]
2019-10-01 14:00:59,784 (Thread-1): 14:00:59 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:00:59,788 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:00:59,788 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:00:59,789 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:00:59,796 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:00:59,808 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:00:59,815 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:00:59,815 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:00:59,933 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:00:59,933 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:00:59,933 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:01:00,267 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2019-10-01 14:01:00,269 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:01:00,269 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:01:00,270 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:01:00,361 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:00,370 (Thread-1): 14:01:00 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.58s]
2019-10-01 14:01:00,372 (Thread-1): 14:01:00 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:01:00,376 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,376 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:01:00,378 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:01:00,391 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:01:00,406 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:01:00,416 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,416 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:01:00,532 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:00,533 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,533 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:01:00,898 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 14:01:00,900 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:01:00,901 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:01:00,901 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:01:00,999 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:01:01,008 (Thread-1): 14:01:01 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.63s]
2019-10-01 14:01:01,012 (Thread-1): 14:01:01 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:01:01,018 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,018 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:01:01,020 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:01:01,032 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:01:01,051 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:01:01,059 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,059 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:01:01,248 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:01:01,249 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,249 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:01:01,495 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:01:01,496 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:01:01,496 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:01:01,496 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:01:01,589 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:01,593 (Thread-1): 14:01:01 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.57s]
2019-10-01 14:01:01,594 (Thread-1): 14:01:01 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:01:01,598 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:01,598 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:01:01,599 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:01:01,609 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:01:01,622 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:01:01,629 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:01,630 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:01:01,750 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:01,751 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:01,751 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:01:02,180 (Thread-1): SQL status: SUCCESS 1 in 0.43 seconds
2019-10-01 14:01:02,182 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:01:02,182 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:01:02,182 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:01:02,296 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:02,313 (Thread-1): 14:01:02 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.71s]
2019-10-01 14:01:02,319 (Thread-1): 14:01:02 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:01:02,323 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:02,324 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:01:02,325 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:01:02,331 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:01:02,350 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:01:02,359 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:02,359 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:01:02,880 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2019-10-01 14:01:02,881 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:02,881 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:01:03,330 (Thread-1): SQL status: SUCCESS 1 in 0.45 seconds
2019-10-01 14:01:03,332 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:01:03,332 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:01:03,332 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:01:03,455 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:03,459 (Thread-1): 14:01:03 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 1.13s]
2019-10-01 14:01:03,461 (Thread-1): 14:01:03 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:01:03,465 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,466 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:01:03,466 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:01:03,476 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:01:03,489 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:01:03,495 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,495 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:01:03,643 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:01:03,644 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,644 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:01:03,925 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:01:03,927 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:01:03,927 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:01:03,927 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:01:04,024 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:01:04,033 (Thread-1): 14:01:04 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.56s]
2019-10-01 14:01:04,035 (Thread-1): 14:01:04 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:01:04,040 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:01:04,040 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:01:04,042 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:01:04,054 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:01:04,067 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:01:04,074 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:01:04,074 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:01:04,186 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:04,187 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:01:04,187 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:01:05,238 (Thread-1): SQL status: SUCCESS 1 in 1.05 seconds
2019-10-01 14:01:05,240 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:01:05,240 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:01:05,240 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:01:05,371 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:05,379 (Thread-1): 14:01:05 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 1.34s]
2019-10-01 14:01:05,380 (Thread-1): 14:01:05 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:01:05,384 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:05,385 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:01:05,386 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:01:05,400 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:01:05,414 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:01:05,421 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:05,421 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:01:06,196 (Thread-1): SQL status: SUCCESS 1 in 0.78 seconds
2019-10-01 14:01:06,197 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:06,197 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:01:06,704 (Thread-1): SQL status: SUCCESS 1 in 0.51 seconds
2019-10-01 14:01:06,706 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:01:06,706 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:01:06,707 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:01:06,807 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:01:06,811 (Thread-1): 14:01:06 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 1.42s]
2019-10-01 14:01:06,813 (Thread-1): 14:01:06 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:01:06,816 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:01:06,817 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:01:06,817 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:01:06,824 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:01:06,832 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:01:06,838 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:01:06,838 (Thread-1): On with_dates: BEGIN
2019-10-01 14:01:06,964 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:06,964 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:01:06,965 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:01:07,229 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:01:07,231 (Thread-1): On with_dates: COMMIT
2019-10-01 14:01:07,232 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:01:07,232 (Thread-1): On with_dates: COMMIT
2019-10-01 14:01:07,353 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:07,362 (Thread-1): 14:01:07 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.54s]
2019-10-01 14:01:07,365 (Thread-1): 14:01:07 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:01:07,371 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:07,371 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:01:07,373 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:01:07,385 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:01:07,399 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:01:07,407 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:07,408 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:01:07,517 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:07,518 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:07,518 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:01:08,267 (Thread-1): SQL status: SUCCESS 1 in 0.75 seconds
2019-10-01 14:01:08,268 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:01:08,269 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:01:08,269 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:01:08,363 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:08,367 (Thread-1): 14:01:08 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.99s]
2019-10-01 14:01:08,368 (Thread-1): 14:01:08 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:01:08,372 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,373 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:01:08,373 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:01:08,381 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:01:08,394 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:01:08,403 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,403 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:01:08,524 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:01:08,525 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,525 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:01:08,762 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:01:08,764 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:01:08,764 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:01:08,764 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:01:09,005 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:01:09,016 (Thread-1): 14:01:09 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.64s]
2019-10-01 14:01:09,018 (Thread-1): 14:01:09 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:01:09,024 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,024 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:01:09,026 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:01:09,039 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:01:09,054 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:01:09,061 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,062 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:01:09,170 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:09,170 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,170 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:01:09,585 (Thread-1): SQL status: SUCCESS 1 in 0.41 seconds
2019-10-01 14:01:09,586 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:01:09,587 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:01:09,587 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:01:09,680 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:01:09,684 (Thread-1): 14:01:09 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.66s]
2019-10-01 14:01:09,686 (Thread-1): 14:01:09 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:01:09,690 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:09,690 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:01:09,691 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:01:09,699 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:01:09,707 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:01:09,714 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:09,714 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:01:09,919 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:01:09,919 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:09,920 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:01:10,235 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:01:10,237 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:01:10,238 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:01:10,238 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:01:10,352 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:10,358 (Thread-1): 14:01:10 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.67s]
2019-10-01 14:01:10,360 (Thread-1): 14:01:10 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:01:10,366 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:01:10,366 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:01:10,368 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:01:10,378 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:01:10,391 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:01:10,397 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:01:10,397 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:01:10,504 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:10,505 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:01:10,506 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:01:10,948 (Thread-1): SQL status: SUCCESS 1 in 0.44 seconds
2019-10-01 14:01:10,950 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:01:10,950 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:01:10,950 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:01:11,075 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:11,079 (Thread-1): 14:01:11 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.71s]
2019-10-01 14:01:11,081 (Thread-1): 14:01:11 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:01:11,085 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:01:11,085 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:01:11,086 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:01:11,144 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:01:11,191 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:01:11,322 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:01:11,322 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:01:11,435 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:01:11,436 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:01:11,436 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m   ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
);
2019-10-01 14:01:12,475 (Thread-1): Snowflake error: 000904 (42000): 018f414d-005d-aaf4-0000-0e29015fd91e: SQL compilation error: error line 502 at position 22
invalid identifier 'BS.SERVICE_TYPE'
2019-10-01 14:01:12,475 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:01:12,616 (Thread-1): 14:01:12 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 1.53s]
2019-10-01 14:01:12,662 (MainThread): Using snowflake connection "master".
2019-10-01 14:01:12,662 (MainThread): On master: BEGIN
2019-10-01 14:01:12,791 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:01:12,791 (MainThread): On master: COMMIT
2019-10-01 14:01:12,791 (MainThread): Using snowflake connection "master".
2019-10-01 14:01:12,791 (MainThread): On master: COMMIT
2019-10-01 14:01:12,939 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:01:12,940 (MainThread): 14:01:12 | 
2019-10-01 14:01:12,940 (MainThread): 14:01:12 | Finished running 21 view models in 25.12s.
2019-10-01 14:01:12,941 (MainThread): Connection 'master' was left open.
2019-10-01 14:01:12,942 (MainThread): On master: Close
2019-10-01 14:01:13,121 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:01:13,122 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:01:13,354 (MainThread): 
2019-10-01 14:01:13,354 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:01:13,356 (MainThread): 
2019-10-01 14:01:13,357 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:01:13,364 (MainThread):   000904 (42000): 018f414d-005d-aaf4-0000-0e29015fd91e: SQL compilation error: error line 502 at position 22
2019-10-01 14:01:13,367 (MainThread):   invalid identifier 'BS.SERVICE_TYPE'
2019-10-01 14:01:13,370 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:01:13,375 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:01:13,379 (MainThread): Flushing usage events
2019-10-01 14:04:03,404 (MainThread): Tracking: tracking
2019-10-01 14:04:03,406 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93E48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C937C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6EE08>]}
2019-10-01 14:04:03,715 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:04:03,716 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58088), raddr=('54.164.98.48', 443)>

2019-10-01 14:04:03,717 (MainThread): Error sending message, disabling tracking
2019-10-01 14:04:03,745 (MainThread): Parsing macros\core.sql
2019-10-01 14:04:03,754 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:04:03,793 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:04:03,803 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:04:03,806 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:04:03,810 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:04:03,814 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:04:03,817 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:04:03,820 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:04:03,829 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:04:03,838 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:04:03,851 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:04:03,878 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:04:03,914 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:04:03,920 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:04:03,948 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:04:03,956 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:04:03,963 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:04:03,972 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:04:03,975 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:04:03,980 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:04:03,984 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:04:03,990 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:04:04,013 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:04:04,016 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:04:04,027 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:04:04,032 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:04:04,037 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:04:04,066 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:04:04,069 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:04,069 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:04:04,071 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:04:04,351 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:04:04,376 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:04:04,962 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:04:04,964 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:04:04,965 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:04:04,975 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:04:04,977 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:04:04,978 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:04:04,988 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:04:04,991 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:04:04,991 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:04:05,003 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:04:05,005 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:04:05,005 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:04:05,017 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:04:05,019 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:04:05,020 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:04:05,031 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:04:05,034 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:05,034 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:04:05,046 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:04:05,048 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:04:05,048 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:04:05,059 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:04:05,062 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:04:05,062 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:04:05,072 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:04:05,074 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:04:05,074 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:04:05,082 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:04:05,084 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:05,084 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:04:05,091 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:04:05,093 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:05,093 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:04:05,100 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:04:05,102 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:05,102 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:04:05,110 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:04:05,112 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:04:05,112 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:04:05,119 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:04:05,121 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:04:05,121 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:04:05,129 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:04:05,130 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:05,131 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:04:05,140 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:04:05,142 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:04:05,143 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:04:05,152 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:04:05,154 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:05,154 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:04:05,164 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:04:05,165 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:05,165 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:04:05,176 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:04:05,179 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:04:05,179 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:04:05,189 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:04:05,191 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:05,191 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:04:05,301 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:04:05,305 (MainThread): 
2019-10-01 14:04:05,306 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:04:05,307 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:04:05,334 (MainThread): Parsing macros\core.sql
2019-10-01 14:04:05,342 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:04:05,422 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:04:05,447 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:04:05,451 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:04:05,459 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:04:05,468 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:04:05,473 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:04:05,477 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:04:05,491 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:04:05,502 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:04:05,511 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:04:05,530 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:04:05,568 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:04:05,572 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:04:05,599 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:04:05,615 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:04:05,629 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:04:05,646 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:04:05,651 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:04:05,655 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:04:05,659 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:04:05,666 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:04:05,696 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:04:05,702 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:04:05,710 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:04:05,713 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:04:05,717 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:04:05,872 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:05,873 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:04:06,472 (MainThread): SQL status: SUCCESS 29 in 0.60 seconds
2019-10-01 14:04:06,524 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:06,525 (MainThread): On master: BEGIN
2019-10-01 14:04:06,642 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:06,643 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:06,643 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:04:07,873 (MainThread): SQL status: SUCCESS 21 in 1.23 seconds
2019-10-01 14:04:07,883 (MainThread): On master: ROLLBACK
2019-10-01 14:04:08,055 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:08,055 (MainThread): On master: BEGIN
2019-10-01 14:04:08,193 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:08,193 (MainThread): On master: COMMIT
2019-10-01 14:04:08,193 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:08,193 (MainThread): On master: COMMIT
2019-10-01 14:04:08,339 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:04:08,339 (MainThread): 14:04:08 | Concurrency: 1 threads (target='dev')
2019-10-01 14:04:08,340 (MainThread): 14:04:08 | 
2019-10-01 14:04:08,345 (Thread-1): 14:04:08 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:04:08,346 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:04:08,346 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:04:08,784 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:04:08,791 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:04:08,843 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:04:08,851 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:04:08,851 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:04:09,048 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 14:04:09,049 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:04:09,049 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:04:09,350 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:04:09,351 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:04:09,351 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:04:09,351 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:04:09,465 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:09,469 (Thread-1): 14:04:09 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.12s]
2019-10-01 14:04:09,470 (Thread-1): 14:04:09 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:04:09,473 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:04:09,473 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:04:09,474 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:04:09,481 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:04:09,495 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:04:09,500 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:04:09,500 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:04:09,790 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:09,791 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:04:09,791 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:04:10,065 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:04:10,067 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:04:10,067 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:04:10,067 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:04:10,205 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:10,209 (Thread-1): 14:04:10 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.74s]
2019-10-01 14:04:10,211 (Thread-1): 14:04:10 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:04:10,214 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:04:10,214 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:04:10,214 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:04:10,219 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:04:10,227 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:04:10,232 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:04:10,232 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:04:10,352 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:10,353 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:04:10,353 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:04:10,639 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:10,640 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:04:10,641 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:04:10,641 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:04:10,735 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:04:10,738 (Thread-1): 14:04:10 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.52s]
2019-10-01 14:04:10,739 (Thread-1): 14:04:10 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:04:10,741 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:04:10,741 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:04:10,742 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:04:10,747 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:04:10,761 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:04:10,767 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:04:10,767 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:04:10,884 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:10,885 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:04:10,885 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:04:11,115 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:04:11,116 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:04:11,116 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:04:11,116 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:04:11,237 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:11,244 (Thread-1): 14:04:11 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.50s]
2019-10-01 14:04:11,245 (Thread-1): 14:04:11 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:04:11,246 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,247 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:04:11,247 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:04:11,252 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:04:11,267 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:04:11,273 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,273 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:04:11,386 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:11,386 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,386 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:04:11,618 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:04:11,620 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:04:11,621 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:04:11,621 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:04:11,781 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:04:11,785 (Thread-1): 14:04:11 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.54s]
2019-10-01 14:04:11,786 (Thread-1): 14:04:11 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:04:11,789 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:04:11,789 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:04:11,790 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:04:11,801 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:04:11,815 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:04:11,820 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:04:11,820 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:04:11,939 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:11,940 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:04:11,940 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:04:12,224 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:04:12,225 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:04:12,225 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:04:12,225 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:04:12,320 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:12,324 (Thread-1): 14:04:12 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.53s]
2019-10-01 14:04:12,325 (Thread-1): 14:04:12 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:04:12,328 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,329 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:04:12,330 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:04:12,338 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:04:12,353 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:04:12,359 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,359 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:04:12,492 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:12,493 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,493 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:04:12,759 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:04:12,761 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:04:12,761 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:04:12,762 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:04:12,868 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:12,878 (Thread-1): 14:04:12 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.55s]
2019-10-01 14:04:12,879 (Thread-1): 14:04:12 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:04:12,882 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:04:12,882 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:04:12,883 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:04:12,894 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:04:12,908 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:04:12,915 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:04:12,915 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:04:13,055 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:13,056 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:04:13,056 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:04:13,397 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:04:13,398 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:04:13,398 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:04:13,398 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:04:13,507 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:13,515 (Thread-1): 14:04:13 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.63s]
2019-10-01 14:04:13,517 (Thread-1): 14:04:13 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:04:13,518 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:13,518 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:04:13,519 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:04:13,524 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:04:13,539 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:04:13,545 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:13,546 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:04:13,670 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:13,671 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:13,671 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:04:14,010 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:04:14,011 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:04:14,011 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:04:14,011 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:04:14,146 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:14,149 (Thread-1): 14:04:14 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.63s]
2019-10-01 14:04:14,151 (Thread-1): 14:04:14 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:04:14,154 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:14,154 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:04:14,155 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:04:14,160 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:04:14,169 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:04:14,174 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:14,174 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:04:14,293 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:14,294 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:14,294 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:04:15,052 (Thread-1): SQL status: SUCCESS 1 in 0.76 seconds
2019-10-01 14:04:15,054 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:04:15,054 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:04:15,054 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:04:15,155 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:15,164 (Thread-1): 14:04:15 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 1.01s]
2019-10-01 14:04:15,164 (Thread-1): 14:04:15 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:04:15,168 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,168 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:04:15,169 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:04:15,179 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:04:15,194 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:04:15,200 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,201 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:04:15,328 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:15,329 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,329 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:04:15,624 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:04:15,625 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:04:15,626 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:04:15,626 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:04:15,718 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:04:15,723 (Thread-1): 14:04:15 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.55s]
2019-10-01 14:04:15,724 (Thread-1): 14:04:15 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:04:15,726 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:04:15,726 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:04:15,726 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:04:15,732 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:04:15,746 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:04:15,754 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:04:15,754 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:04:15,866 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:15,867 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:04:15,867 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:04:16,103 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:04:16,105 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:04:16,105 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:04:16,106 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:04:16,212 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:16,221 (Thread-1): 14:04:16 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.49s]
2019-10-01 14:04:16,222 (Thread-1): 14:04:16 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:04:16,225 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,225 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:04:16,226 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:04:16,237 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:04:16,251 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:04:16,255 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,255 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:04:16,376 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:16,376 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,377 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:04:16,658 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:04:16,660 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:04:16,660 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:04:16,660 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:04:16,792 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:16,800 (Thread-1): 14:04:16 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.57s]
2019-10-01 14:04:16,801 (Thread-1): 14:04:16 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:04:16,805 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:16,805 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:04:16,806 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:04:16,818 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:04:16,832 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:04:16,841 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:16,841 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:04:16,972 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:16,972 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:16,972 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:04:17,493 (Thread-1): SQL status: SUCCESS 1 in 0.52 seconds
2019-10-01 14:04:17,494 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:04:17,494 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:04:17,495 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:04:17,596 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:17,605 (Thread-1): 14:04:17 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.80s]
2019-10-01 14:04:17,606 (Thread-1): 14:04:17 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:04:17,608 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:04:17,608 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:04:17,608 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:04:17,615 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:04:17,625 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:04:17,629 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:04:17,629 (Thread-1): On with_dates: BEGIN
2019-10-01 14:04:17,740 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:17,741 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:04:17,741 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:04:17,991 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:04:17,992 (Thread-1): On with_dates: COMMIT
2019-10-01 14:04:17,992 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:04:17,992 (Thread-1): On with_dates: COMMIT
2019-10-01 14:04:18,110 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:18,115 (Thread-1): 14:04:18 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.51s]
2019-10-01 14:04:18,116 (Thread-1): 14:04:18 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:04:18,118 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,118 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:04:18,118 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:04:18,124 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:04:18,138 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:04:18,147 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,147 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:04:18,266 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:18,266 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,267 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:04:18,505 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:04:18,506 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:04:18,506 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:04:18,506 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:04:18,602 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:18,607 (Thread-1): 14:04:18 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.49s]
2019-10-01 14:04:18,608 (Thread-1): 14:04:18 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:04:18,610 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:18,610 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:04:18,611 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:04:18,619 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:04:18,635 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:04:18,641 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:18,641 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:04:18,779 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:04:18,779 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:18,779 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:04:19,080 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:04:19,082 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:04:19,082 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:04:19,082 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:04:19,188 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:19,193 (Thread-1): 14:04:19 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.58s]
2019-10-01 14:04:19,194 (Thread-1): 14:04:19 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:04:19,194 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,194 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:04:19,195 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:04:19,203 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:04:19,222 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:04:19,228 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,229 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:04:19,363 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:19,364 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,364 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:04:19,657 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:19,659 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:04:19,659 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:04:19,660 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:04:19,789 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:04:19,793 (Thread-1): 14:04:19 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.60s]
2019-10-01 14:04:19,794 (Thread-1): 14:04:19 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:04:19,795 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:19,795 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:04:19,796 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:04:19,807 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:04:19,816 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:04:19,821 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:19,821 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:04:19,937 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:19,938 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:19,938 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:04:20,230 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:04:20,231 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:04:20,231 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:04:20,232 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:04:20,338 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:20,342 (Thread-1): 14:04:20 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.54s]
2019-10-01 14:04:20,343 (Thread-1): 14:04:20 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:04:20,343 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:04:20,343 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:04:20,343 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:04:20,348 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:04:20,364 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:04:20,368 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:04:20,368 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:04:20,490 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:04:20,491 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:04:20,491 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:04:20,908 (Thread-1): SQL status: SUCCESS 1 in 0.42 seconds
2019-10-01 14:04:20,909 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:04:20,909 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:04:20,909 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:04:21,005 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:04:21,015 (Thread-1): 14:04:21 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.67s]
2019-10-01 14:04:21,017 (Thread-1): 14:04:21 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:04:21,022 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:21,023 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:04:21,024 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:04:21,099 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:04:21,143 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:04:21,306 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:21,306 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:04:21,416 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:21,417 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:04:21,417 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m   ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
);
2019-10-01 14:04:22,343 (Thread-1): Snowflake error: 000904 (42000): 018f4150-00c8-b342-0000-0e29015fbcb2: SQL compilation error: error line 970 at position 14
invalid identifier 'BK.EFFECTIVE_FROM'
2019-10-01 14:04:22,343 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:04:22,523 (Thread-1): 14:04:22 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 1.50s]
2019-10-01 14:04:22,564 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:22,565 (MainThread): On master: BEGIN
2019-10-01 14:04:22,675 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:04:22,676 (MainThread): On master: COMMIT
2019-10-01 14:04:22,676 (MainThread): Using snowflake connection "master".
2019-10-01 14:04:22,676 (MainThread): On master: COMMIT
2019-10-01 14:04:22,829 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:04:22,830 (MainThread): 14:04:22 | 
2019-10-01 14:04:22,831 (MainThread): 14:04:22 | Finished running 21 view models in 17.52s.
2019-10-01 14:04:22,831 (MainThread): Connection 'master' was left open.
2019-10-01 14:04:22,832 (MainThread): On master: Close
2019-10-01 14:04:23,001 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:04:23,001 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:04:23,186 (MainThread): 
2019-10-01 14:04:23,187 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:04:23,187 (MainThread): 
2019-10-01 14:04:23,187 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:04:23,188 (MainThread):   000904 (42000): 018f4150-00c8-b342-0000-0e29015fbcb2: SQL compilation error: error line 970 at position 14
2019-10-01 14:04:23,188 (MainThread):   invalid identifier 'BK.EFFECTIVE_FROM'
2019-10-01 14:04:23,188 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:04:23,188 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:04:23,189 (MainThread): Flushing usage events
2019-10-01 14:10:32,169 (MainThread): Tracking: tracking
2019-10-01 14:10:32,171 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004972FC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C108>]}
2019-10-01 14:10:32,509 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:10:32,510 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58148), raddr=('54.164.98.48', 443)>

2019-10-01 14:10:32,512 (MainThread): Error sending message, disabling tracking
2019-10-01 14:10:32,545 (MainThread): Parsing macros\core.sql
2019-10-01 14:10:32,555 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:10:32,592 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:10:32,605 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:10:32,608 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:10:32,611 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:10:32,615 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:10:32,618 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:10:32,620 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:10:32,629 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:10:32,638 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:10:32,647 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:10:32,665 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:10:32,685 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:10:32,688 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:10:32,704 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:10:32,710 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:10:32,717 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:10:32,723 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:10:32,726 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:10:32,728 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:10:32,731 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:10:32,734 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:10:32,748 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:10:32,753 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:10:32,762 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:10:32,764 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:10:32,769 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:10:32,796 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:10:32,798 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:32,798 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:10:32,800 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:10:33,112 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:10:33,128 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:10:33,696 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:10:33,697 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:10:33,698 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:10:33,702 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:10:33,703 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:10:33,703 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:10:33,708 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:10:33,709 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:10:33,709 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:10:33,714 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:10:33,715 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:10:33,715 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:10:33,720 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:10:33,721 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:10:33,722 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:10:33,726 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:10:33,727 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:33,727 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:10:33,732 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:10:33,733 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:10:33,733 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:10:33,738 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:10:33,738 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:10:33,739 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:10:33,744 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:10:33,745 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:10:33,745 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:10:33,750 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:10:33,750 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:33,751 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:10:33,755 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:10:33,756 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:33,757 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:10:33,761 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:10:33,762 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:33,762 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:10:33,769 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:10:33,770 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:10:33,770 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:10:33,775 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:10:33,776 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:10:33,776 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:10:33,781 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:10:33,783 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:33,783 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:10:33,788 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:10:33,789 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:10:33,789 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:10:33,794 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:10:33,795 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:33,795 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:10:33,800 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:10:33,801 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:33,801 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:10:33,806 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:10:33,807 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:10:33,807 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:10:33,812 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:10:33,813 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:33,813 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:10:33,873 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:10:33,875 (MainThread): 
2019-10-01 14:10:33,877 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:10:33,877 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:10:33,911 (MainThread): Parsing macros\core.sql
2019-10-01 14:10:33,922 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:10:34,024 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:10:34,051 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:10:34,060 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:10:34,073 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:10:34,086 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:10:34,093 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:10:34,100 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:10:34,126 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:10:34,151 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:10:34,163 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:10:34,198 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:10:34,233 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:10:34,239 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:10:34,280 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:10:34,292 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:10:34,299 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:10:34,312 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:10:34,315 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:10:34,321 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:10:34,326 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:10:34,332 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:10:34,359 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:10:34,365 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:10:34,387 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:10:34,395 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:10:34,406 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:10:34,591 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:34,591 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:10:35,366 (MainThread): SQL status: SUCCESS 28 in 0.77 seconds
2019-10-01 14:10:35,375 (MainThread): Creating schema "OPA_DEV"."DBT_TEST".
2019-10-01 14:10:35,377 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,378 (MainThread): On master: BEGIN
2019-10-01 14:10:35,503 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:35,504 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,505 (MainThread): On master: create schema if not exists OPA_DEV.DBT_TEST
2019-10-01 14:10:35,696 (MainThread): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:10:35,697 (MainThread): On master: COMMIT
2019-10-01 14:10:35,698 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,698 (MainThread): On master: COMMIT
2019-10-01 14:10:35,803 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:35,885 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:35,885 (MainThread): On master: BEGIN
2019-10-01 14:10:36,010 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:36,010 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:36,010 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:10:37,201 (MainThread): SQL status: SUCCESS 0 in 1.19 seconds
2019-10-01 14:10:37,203 (MainThread): On master: ROLLBACK
2019-10-01 14:10:37,493 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:37,494 (MainThread): On master: BEGIN
2019-10-01 14:10:37,626 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:37,627 (MainThread): On master: COMMIT
2019-10-01 14:10:37,627 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:37,627 (MainThread): On master: COMMIT
2019-10-01 14:10:37,789 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:37,791 (MainThread): 14:10:37 | Concurrency: 1 threads (target='dev')
2019-10-01 14:10:37,792 (MainThread): 14:10:37 | 
2019-10-01 14:10:37,806 (Thread-1): 14:10:37 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:10:37,808 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:10:37,809 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:10:38,396 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:10:38,421 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:10:38,481 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:10:38,485 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:10:38,485 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:10:38,617 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:38,617 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:10:38,617 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:10:38,998 (Thread-1): SQL status: SUCCESS 1 in 0.38 seconds
2019-10-01 14:10:38,999 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:10:38,999 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:10:38,999 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:10:39,106 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:39,111 (Thread-1): 14:10:39 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.30s]
2019-10-01 14:10:39,112 (Thread-1): 14:10:39 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:10:39,114 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:10:39,115 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:10:39,115 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:10:39,122 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:10:39,130 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:10:39,134 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:10:39,135 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:10:39,244 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:39,245 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:10:39,245 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:10:39,503 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:10:39,505 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:10:39,505 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:10:39,506 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:10:39,596 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:10:39,600 (Thread-1): 14:10:39 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.49s]
2019-10-01 14:10:39,601 (Thread-1): 14:10:39 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:10:39,604 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:10:39,604 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:10:39,605 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:10:39,610 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:10:39,620 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:10:39,624 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:10:39,624 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:10:39,746 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:39,746 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:10:39,747 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:10:40,024 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:10:40,026 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:10:40,027 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:10:40,027 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:10:40,126 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:40,132 (Thread-1): 14:10:40 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.53s]
2019-10-01 14:10:40,133 (Thread-1): 14:10:40 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:10:40,135 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:10:40,135 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:10:40,135 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:10:40,141 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:10:40,149 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:10:40,154 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:10:40,155 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:10:40,259 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:40,260 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:10:40,260 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:10:40,546 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:10:40,548 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:10:40,549 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:10:40,549 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:10:40,654 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:40,661 (Thread-1): 14:10:40 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.52s]
2019-10-01 14:10:40,663 (Thread-1): 14:10:40 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:10:40,663 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:40,663 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:10:40,664 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:10:40,675 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:10:40,732 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:10:40,737 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:40,737 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:10:40,845 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:40,845 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:40,846 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:10:41,305 (Thread-1): SQL status: SUCCESS 1 in 0.46 seconds
2019-10-01 14:10:41,306 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:10:41,307 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:10:41,307 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:10:41,402 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:10:41,408 (Thread-1): 14:10:41 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.74s]
2019-10-01 14:10:41,409 (Thread-1): 14:10:41 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:10:41,412 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,412 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:10:41,412 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:10:41,417 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:10:41,427 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:10:41,431 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,431 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:10:41,598 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:10:41,599 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,599 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:10:41,958 (Thread-1): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-01 14:10:41,960 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:10:41,960 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:10:41,960 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:10:42,065 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:42,077 (Thread-1): 14:10:42 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.66s]
2019-10-01 14:10:42,079 (Thread-1): 14:10:42 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:10:42,089 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,089 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:10:42,091 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:10:42,103 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:10:42,113 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:10:42,117 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,118 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:10:42,245 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:42,245 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,245 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:10:42,518 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:10:42,521 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:10:42,522 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:10:42,522 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:10:42,618 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:42,628 (Thread-1): 14:10:42 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.53s]
2019-10-01 14:10:42,630 (Thread-1): 14:10:42 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:10:42,635 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:10:42,635 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:10:42,637 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:10:42,645 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:10:42,656 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:10:42,661 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:10:42,661 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:10:42,778 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:42,778 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:10:42,778 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:10:43,317 (Thread-1): SQL status: SUCCESS 1 in 0.54 seconds
2019-10-01 14:10:43,320 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:10:43,320 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:10:43,321 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:10:43,427 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:43,433 (Thread-1): 14:10:43 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.80s]
2019-10-01 14:10:43,435 (Thread-1): 14:10:43 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:10:43,438 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,439 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:10:43,440 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:10:43,447 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:10:43,459 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:10:43,463 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,464 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:10:43,650 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:10:43,650 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,650 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:10:43,972 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:10:43,973 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:10:43,974 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:10:43,974 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:10:44,091 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:44,095 (Thread-1): 14:10:44 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.66s]
2019-10-01 14:10:44,096 (Thread-1): 14:10:44 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:10:44,098 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,098 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:10:44,099 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:10:44,105 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:10:44,116 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:10:44,121 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,121 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:10:44,233 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:44,233 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,234 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:10:44,480 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:10:44,482 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:10:44,482 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:10:44,483 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:10:44,590 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:44,601 (Thread-1): 14:10:44 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.50s]
2019-10-01 14:10:44,602 (Thread-1): 14:10:44 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:10:44,605 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:44,605 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:10:44,607 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:10:44,615 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:10:44,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:10:44,638 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:44,638 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:10:44,750 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:44,751 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:44,751 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:10:45,038 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:10:45,039 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:10:45,039 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:10:45,039 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:10:45,132 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:10:45,137 (Thread-1): 14:10:45 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.53s]
2019-10-01 14:10:45,138 (Thread-1): 14:10:45 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:10:45,139 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,139 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:10:45,139 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:10:45,149 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:10:45,163 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:10:45,168 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,169 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:10:45,325 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:45,325 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,325 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:10:45,652 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2019-10-01 14:10:45,654 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:10:45,655 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:10:45,655 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:10:45,753 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:45,757 (Thread-1): 14:10:45 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.62s]
2019-10-01 14:10:45,759 (Thread-1): 14:10:45 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:10:45,761 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:10:45,761 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:10:45,761 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:10:45,768 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:10:45,781 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:10:45,786 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:10:45,786 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:10:45,891 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:45,892 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:10:45,892 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:10:46,106 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:10:46,109 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:10:46,109 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:10:46,109 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:10:46,204 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:46,212 (Thread-1): 14:10:46 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.45s]
2019-10-01 14:10:46,215 (Thread-1): 14:10:46 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:10:46,218 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,218 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:10:46,219 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:10:46,228 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:10:46,242 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:10:46,250 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,250 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:10:46,370 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:46,371 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,371 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:10:46,675 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:10:46,678 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:10:46,678 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:10:46,678 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:10:46,835 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:46,842 (Thread-1): 14:10:46 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.62s]
2019-10-01 14:10:46,845 (Thread-1): 14:10:46 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:10:46,847 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:10:46,847 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:10:46,848 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:10:46,856 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:10:46,869 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:10:46,875 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:10:46,875 (Thread-1): On with_dates: BEGIN
2019-10-01 14:10:47,088 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:10:47,089 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:10:47,089 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:10:47,363 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:10:47,365 (Thread-1): On with_dates: COMMIT
2019-10-01 14:10:47,365 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:10:47,365 (Thread-1): On with_dates: COMMIT
2019-10-01 14:10:47,538 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:10:47,548 (Thread-1): 14:10:47 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.70s]
2019-10-01 14:10:47,558 (Thread-1): 14:10:47 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:10:47,558 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:47,558 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:10:47,568 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:10:47,578 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:10:47,593 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:10:47,601 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:47,601 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:10:47,826 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:10:47,827 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:47,827 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:10:48,149 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:10:48,150 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:10:48,151 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:10:48,151 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:10:48,499 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:10:48,517 (Thread-1): 14:10:48 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.95s]
2019-10-01 14:10:48,521 (Thread-1): 14:10:48 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:10:48,527 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:48,528 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:10:48,530 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:10:48,550 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:10:48,565 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:10:48,574 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:48,576 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:10:48,692 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:10:48,693 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:48,693 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:10:49,280 (Thread-1): SQL status: SUCCESS 1 in 0.59 seconds
2019-10-01 14:10:49,280 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:10:49,280 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:10:49,280 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:10:49,421 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:10:49,441 (Thread-1): 14:10:49 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.90s]
2019-10-01 14:10:49,441 (Thread-1): 14:10:49 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:10:49,442 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,442 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:10:49,442 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:10:49,448 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:10:49,457 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:10:49,462 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,462 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:10:49,610 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:10:49,610 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,610 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:10:49,958 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:10:49,958 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:10:49,958 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:10:49,958 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:10:50,071 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:50,081 (Thread-1): 14:10:50 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.64s]
2019-10-01 14:10:50,091 (Thread-1): 14:10:50 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:10:50,091 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,091 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:10:50,091 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:10:50,101 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:10:50,105 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:10:50,111 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,111 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:10:50,273 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:50,273 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,273 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:10:50,523 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:10:50,525 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:10:50,526 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:10:50,526 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:10:50,682 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:50,698 (Thread-1): 14:10:50 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.60s]
2019-10-01 14:10:50,708 (Thread-1): 14:10:50 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:10:50,708 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:10:50,708 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:10:50,708 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:10:50,718 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:10:50,728 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:10:50,738 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:10:50,738 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:10:50,850 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:10:50,850 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:10:50,850 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:10:51,199 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:10:51,199 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:10:51,199 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:10:51,199 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:10:51,298 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:10:51,306 (Thread-1): 14:10:51 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.59s]
2019-10-01 14:10:51,307 (Thread-1): 14:10:51 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:10:51,310 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:51,310 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:10:51,311 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:10:51,366 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:10:51,401 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:10:51,498 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:51,498 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:10:51,627 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:51,627 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:51,627 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
);
2019-10-01 14:10:54,467 (Thread-1): SQL status: SUCCESS 1 in 2.84 seconds
2019-10-01 14:10:54,467 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:10:54,467 (Thread-1): On v_booking_fact_uk: );
2019-10-01 14:10:54,768 (Thread-1): Snowflake error: 001003 (42000): 018f4156-0031-3e69-0000-0e29015fbfea: SQL compilation error:
syntax error line 1 at position 0 unexpected ')'.
2019-10-01 14:10:54,768 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:10:54,935 (Thread-1): 14:10:54 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 3.62s]
2019-10-01 14:10:55,012 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:55,012 (MainThread): On master: BEGIN
2019-10-01 14:10:55,138 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:10:55,138 (MainThread): On master: COMMIT
2019-10-01 14:10:55,138 (MainThread): Using snowflake connection "master".
2019-10-01 14:10:55,138 (MainThread): On master: COMMIT
2019-10-01 14:10:55,301 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:10:55,301 (MainThread): 14:10:55 | 
2019-10-01 14:10:55,301 (MainThread): 14:10:55 | Finished running 21 view models in 21.42s.
2019-10-01 14:10:55,301 (MainThread): Connection 'master' was left open.
2019-10-01 14:10:55,301 (MainThread): On master: Close
2019-10-01 14:10:55,462 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:10:55,464 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:10:55,690 (MainThread): 
2019-10-01 14:10:55,690 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:10:55,690 (MainThread): 
2019-10-01 14:10:55,690 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:10:55,690 (MainThread):   001003 (42000): 018f4156-0031-3e69-0000-0e29015fbfea: SQL compilation error:
2019-10-01 14:10:55,690 (MainThread):   syntax error line 1 at position 0 unexpected ')'.
2019-10-01 14:10:55,690 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:10:55,690 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:10:55,690 (MainThread): Flushing usage events
2019-10-01 14:28:20,946 (MainThread): Tracking: tracking
2019-10-01 14:28:20,948 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBD188>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBD1C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8C588>]}
2019-10-01 14:28:21,289 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:28:21,292 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57927), raddr=('54.174.31.151', 443)>

2019-10-01 14:28:21,297 (MainThread): Error sending message, disabling tracking
2019-10-01 14:28:21,364 (MainThread): Parsing macros\core.sql
2019-10-01 14:28:21,377 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:28:21,416 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:28:21,428 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:28:21,431 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:28:21,434 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:28:21,438 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:28:21,441 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:28:21,443 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:28:21,452 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:28:21,460 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:28:21,470 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:28:21,486 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:28:21,507 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:28:21,510 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:28:21,523 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:28:21,530 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:28:21,536 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:28:21,543 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:28:21,546 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:28:21,548 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:28:21,550 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:28:21,553 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:28:21,566 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:28:21,570 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:28:21,578 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:28:21,581 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:28:21,586 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:28:21,614 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:28:21,616 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:21,616 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:28:21,618 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:28:21,974 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:28:21,990 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:28:22,626 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:28:22,627 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:28:22,627 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:28:22,632 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:28:22,633 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:28:22,633 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:28:22,637 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:28:22,638 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:28:22,639 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:28:22,643 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:28:22,644 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:28:22,644 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:28:22,651 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:28:22,654 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:28:22,654 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:28:22,663 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:28:22,665 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:22,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:28:22,674 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:28:22,676 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:28:22,676 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:28:22,683 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:28:22,684 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:28:22,684 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:28:22,690 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:28:22,691 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:28:22,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:28:22,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:28:22,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:22,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:28:22,701 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:28:22,702 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:22,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:28:22,707 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:28:22,708 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:22,708 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:28:22,713 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:28:22,714 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:28:22,714 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:28:22,718 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:28:22,719 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:28:22,719 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:28:22,724 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:28:22,725 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:22,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:28:22,730 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:28:22,731 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:28:22,731 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:28:22,736 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:28:22,737 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:22,737 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:28:22,741 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:28:22,742 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:22,742 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:28:22,747 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:28:22,748 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:28:22,749 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:28:22,754 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:28:22,755 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:22,755 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:28:22,817 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:28:22,820 (MainThread): 
2019-10-01 14:28:22,820 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:28:22,821 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:28:22,857 (MainThread): Parsing macros\core.sql
2019-10-01 14:28:22,869 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:28:22,941 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:28:22,954 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:28:22,956 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:28:22,959 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:28:22,963 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:28:22,966 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:28:22,968 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:28:22,977 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:28:22,986 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:28:22,995 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:28:23,017 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:28:23,037 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:28:23,042 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:28:23,068 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:28:23,082 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:28:23,090 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:28:23,098 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:28:23,102 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:28:23,104 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:28:23,107 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:28:23,110 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:28:23,125 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:28:23,131 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:28:23,143 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:28:23,148 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:28:23,153 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:28:23,267 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:23,267 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:28:23,771 (MainThread): SQL status: SUCCESS 29 in 0.50 seconds
2019-10-01 14:28:23,858 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:23,858 (MainThread): On master: BEGIN
2019-10-01 14:28:23,989 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:28:23,991 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:23,991 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:28:25,064 (MainThread): SQL status: SUCCESS 21 in 1.07 seconds
2019-10-01 14:28:25,117 (MainThread): On master: ROLLBACK
2019-10-01 14:28:25,288 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:25,289 (MainThread): On master: BEGIN
2019-10-01 14:28:25,432 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:28:25,434 (MainThread): On master: COMMIT
2019-10-01 14:28:25,435 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:25,435 (MainThread): On master: COMMIT
2019-10-01 14:28:25,590 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:28:25,592 (MainThread): 14:28:25 | Concurrency: 1 threads (target='dev')
2019-10-01 14:28:25,594 (MainThread): 14:28:25 | 
2019-10-01 14:28:25,607 (Thread-1): 14:28:25 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:28:25,609 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:28:25,610 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:28:25,922 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:28:25,938 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:28:25,987 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:28:25,991 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:28:25,991 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:28:26,096 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:26,097 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:28:26,097 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:28:26,330 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:28:26,332 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:28:26,333 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:28:26,333 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:28:26,432 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:26,439 (Thread-1): 14:28:26 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 0.83s]
2019-10-01 14:28:26,440 (Thread-1): 14:28:26 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:28:26,442 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:28:26,442 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:28:26,442 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:28:26,447 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:28:26,462 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:28:26,467 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:28:26,467 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:28:26,567 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:26,567 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:28:26,568 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:28:26,825 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:26,828 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:28:26,828 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:28:26,828 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:28:26,912 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-01 14:28:26,917 (Thread-1): 14:28:26 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.47s]
2019-10-01 14:28:26,918 (Thread-1): 14:28:26 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:28:26,920 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:28:26,920 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:28:26,921 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:28:26,925 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:28:26,939 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:28:26,945 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:28:26,945 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:28:27,055 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:27,055 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:28:27,055 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:28:27,275 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:27,277 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:28:27,278 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:28:27,278 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:28:27,379 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:27,386 (Thread-1): 14:28:27 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.46s]
2019-10-01 14:28:27,387 (Thread-1): 14:28:27 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:28:27,390 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:28:27,390 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:28:27,391 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:28:27,396 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:28:27,407 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:28:27,411 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:28:27,411 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:28:27,528 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:27,528 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:28:27,528 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:28:27,786 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:27,788 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:28:27,788 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:28:27,789 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:28:27,905 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:27,911 (Thread-1): 14:28:27 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.52s]
2019-10-01 14:28:27,912 (Thread-1): 14:28:27 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:28:27,912 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:27,912 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:28:27,913 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:28:27,921 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:28:27,930 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:28:27,934 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:27,935 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:28:28,042 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:28,043 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:28,043 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:28:28,306 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:28,310 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:28:28,310 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:28:28,311 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:28:28,448 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:28:28,464 (Thread-1): 14:28:28 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.55s]
2019-10-01 14:28:28,466 (Thread-1): 14:28:28 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:28:28,473 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,473 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:28:28,474 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:28:28,483 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:28:28,497 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:28:28,502 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,502 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:28:28,607 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:28,608 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,608 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:28:28,862 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:28,864 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:28:28,864 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:28:28,864 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:28:28,951 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:28:28,966 (Thread-1): 14:28:28 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.49s]
2019-10-01 14:28:28,970 (Thread-1): 14:28:28 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:28:28,976 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:28:28,976 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:28:28,978 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:28:28,993 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:28:29,009 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:28:29,014 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:28:29,015 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:28:29,121 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:29,122 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:28:29,122 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:28:29,356 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:28:29,360 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:28:29,361 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:28:29,361 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:28:29,454 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:28:29,473 (Thread-1): 14:28:29 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.49s]
2019-10-01 14:28:29,476 (Thread-1): 14:28:29 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:28:29,482 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,482 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:28:29,484 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:28:29,501 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:28:29,518 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:28:29,524 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,525 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:28:29,631 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:29,632 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,632 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:28:29,898 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:28:29,903 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:28:29,903 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:28:29,904 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:28:30,013 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:30,025 (Thread-1): 14:28:30 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.54s]
2019-10-01 14:28:30,026 (Thread-1): 14:28:30 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:28:30,027 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,028 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:28:30,029 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:28:30,044 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:28:30,057 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:28:30,061 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,061 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:28:30,166 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:30,167 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,168 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:28:30,382 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:28:30,384 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:28:30,384 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:28:30,384 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:28:30,493 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:30,508 (Thread-1): 14:28:30 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.48s]
2019-10-01 14:28:30,512 (Thread-1): 14:28:30 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:28:30,518 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,519 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:28:30,520 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:28:30,528 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:28:30,539 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:28:30,544 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,545 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:28:30,659 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:30,659 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,659 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:28:30,934 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:28:30,935 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:28:30,935 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:28:30,935 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:28:31,054 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:31,058 (Thread-1): 14:28:31 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.54s]
2019-10-01 14:28:31,059 (Thread-1): 14:28:31 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:28:31,060 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,060 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:28:31,060 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:28:31,070 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:28:31,083 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:28:31,088 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,088 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:28:31,197 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:31,197 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,198 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:28:31,415 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:31,417 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:28:31,417 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:28:31,417 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:28:31,527 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:31,532 (Thread-1): 14:28:31 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.47s]
2019-10-01 14:28:31,533 (Thread-1): 14:28:31 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:28:31,535 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,535 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:28:31,535 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:28:31,542 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:28:31,551 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:28:31,557 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,557 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:28:31,694 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:28:31,695 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,695 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:28:31,944 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:31,948 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:28:31,948 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:28:31,949 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:28:32,044 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:32,053 (Thread-1): 14:28:32 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.51s]
2019-10-01 14:28:32,054 (Thread-1): 14:28:32 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:28:32,056 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,056 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:28:32,057 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:28:32,070 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:28:32,083 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:28:32,088 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,088 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:28:32,195 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:32,195 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,195 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:28:32,420 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:32,424 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:28:32,424 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:28:32,425 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:28:32,536 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:32,543 (Thread-1): 14:28:32 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.48s]
2019-10-01 14:28:32,545 (Thread-1): 14:28:32 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:28:32,548 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:32,548 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:28:32,549 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:28:32,560 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:28:32,568 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:28:32,574 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:32,574 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:28:32,691 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:32,692 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:32,692 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:28:33,181 (Thread-1): SQL status: SUCCESS 1 in 0.49 seconds
2019-10-01 14:28:33,187 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:28:33,188 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:28:33,188 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:28:33,339 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:28:33,348 (Thread-1): 14:28:33 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.80s]
2019-10-01 14:28:33,350 (Thread-1): 14:28:33 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:28:33,352 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:28:33,353 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:28:33,354 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:28:33,366 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:28:33,380 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:28:33,385 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:28:33,385 (Thread-1): On with_dates: BEGIN
2019-10-01 14:28:33,508 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:33,509 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:28:33,509 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:28:33,874 (Thread-1): SQL status: SUCCESS 1 in 0.37 seconds
2019-10-01 14:28:33,875 (Thread-1): On with_dates: COMMIT
2019-10-01 14:28:33,876 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:28:33,876 (Thread-1): On with_dates: COMMIT
2019-10-01 14:28:33,958 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-01 14:28:33,963 (Thread-1): 14:28:33 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.61s]
2019-10-01 14:28:33,964 (Thread-1): 14:28:33 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:28:33,965 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:33,966 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:28:33,966 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:28:33,973 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:28:33,985 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:28:33,992 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:33,992 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:28:34,112 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:34,113 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:34,113 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:28:34,366 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:34,369 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:28:34,370 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:28:34,370 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:28:34,520 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:28:34,530 (Thread-1): 14:28:34 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.56s]
2019-10-01 14:28:34,533 (Thread-1): 14:28:34 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:28:34,536 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,536 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:28:34,537 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:28:34,545 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:28:34,553 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:28:34,558 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,559 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:28:34,678 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:28:34,678 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,678 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:28:34,939 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:34,946 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:28:34,948 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:28:34,948 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:28:35,052 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:28:35,075 (Thread-1): 14:28:35 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.53s]
2019-10-01 14:28:35,078 (Thread-1): 14:28:35 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:28:35,082 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,083 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:28:35,084 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:28:35,095 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:28:35,113 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:28:35,117 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,118 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:28:35,228 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:35,229 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,229 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:28:35,483 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:28:35,486 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:28:35,487 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:28:35,487 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:28:35,602 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:35,610 (Thread-1): 14:28:35 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.53s]
2019-10-01 14:28:35,611 (Thread-1): 14:28:35 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:28:35,614 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:35,615 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:28:35,615 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:28:35,622 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:28:35,631 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:28:35,635 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:35,635 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:28:35,796 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:28:35,796 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:35,796 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:28:36,052 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:28:36,054 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:28:36,055 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:28:36,055 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:28:36,150 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:28:36,159 (Thread-1): 14:28:36 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.54s]
2019-10-01 14:28:36,160 (Thread-1): 14:28:36 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:28:36,162 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:28:36,162 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:28:36,162 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:28:36,169 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:28:36,179 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:28:36,182 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:28:36,183 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:28:36,295 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:36,296 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:28:36,296 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:28:36,506 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:28:36,508 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:28:36,508 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:28:36,508 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:28:36,615 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:36,619 (Thread-1): 14:28:36 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.46s]
2019-10-01 14:28:36,620 (Thread-1): 14:28:36 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:28:36,623 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:36,623 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:28:36,624 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:28:36,668 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:28:36,703 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:28:36,830 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:36,830 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:28:36,939 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:36,939 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:28:36,940 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
;
2019-10-01 14:28:37,169 (Thread-1): Snowflake error: 001003 (42000): 018f4168-00fb-6626-0000-0e29015fe866: SQL compilation error:
syntax error line 1,093 at position 0 unexpected ';'.
2019-10-01 14:28:37,169 (Thread-1): On v_booking_fact_uk: ROLLBACK
2019-10-01 14:28:37,306 (Thread-1): 14:28:37 | 21 of 21 ERROR creating view model DBT_TEST.v_booking_fact_uk........ [ERROR in 0.68s]
2019-10-01 14:28:37,314 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:37,314 (MainThread): On master: BEGIN
2019-10-01 14:28:37,427 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:28:37,428 (MainThread): On master: COMMIT
2019-10-01 14:28:37,428 (MainThread): Using snowflake connection "master".
2019-10-01 14:28:37,428 (MainThread): On master: COMMIT
2019-10-01 14:28:37,652 (MainThread): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:28:37,652 (MainThread): 14:28:37 | 
2019-10-01 14:28:37,653 (MainThread): 14:28:37 | Finished running 21 view models in 14.83s.
2019-10-01 14:28:37,653 (MainThread): Connection 'master' was left open.
2019-10-01 14:28:37,653 (MainThread): On master: Close
2019-10-01 14:28:37,782 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:28:37,782 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:28:38,025 (MainThread): 
2019-10-01 14:28:38,026 (MainThread): Completed with 1 error and 0 warnings:
2019-10-01 14:28:38,027 (MainThread): 
2019-10-01 14:28:38,027 (MainThread): Database Error in model v_booking_fact_uk (models\v_booking_fact_uk.sql)
2019-10-01 14:28:38,029 (MainThread):   001003 (42000): 018f4168-00fb-6626-0000-0e29015fe866: SQL compilation error:
2019-10-01 14:28:38,030 (MainThread):   syntax error line 1,093 at position 0 unexpected ';'.
2019-10-01 14:28:38,030 (MainThread):   compiled SQL at target\compiled\dbt_test\v_booking_fact_uk.sql
2019-10-01 14:28:38,031 (MainThread): 
Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
2019-10-01 14:28:38,032 (MainThread): Flushing usage events
2019-10-01 14:29:03,111 (MainThread): Tracking: tracking
2019-10-01 14:29:03,113 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005B85708>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92888>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C7C8>]}
2019-10-01 14:29:03,378 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:29:03,379 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 57939), raddr=('54.174.31.151', 443)>

2019-10-01 14:29:03,381 (MainThread): Error sending message, disabling tracking
2019-10-01 14:29:03,420 (MainThread): Parsing macros\core.sql
2019-10-01 14:29:03,433 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:29:03,496 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:29:03,506 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:29:03,508 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:29:03,512 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:29:03,515 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:29:03,518 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:29:03,521 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:29:03,530 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:29:03,539 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:29:03,556 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:29:03,576 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:29:03,598 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:29:03,602 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:29:03,616 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:29:03,624 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:29:03,632 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:29:03,639 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:29:03,642 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:29:03,645 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:29:03,647 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:29:03,650 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:29:03,665 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:29:03,669 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:29:03,685 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:29:03,690 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:29:03,699 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:29:03,743 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:29:03,745 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:03,745 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:29:03,747 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:29:04,003 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:29:04,023 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:29:04,577 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:29:04,578 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:29:04,578 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:29:04,582 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:29:04,583 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:29:04,583 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:29:04,588 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:29:04,589 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:29:04,589 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:29:04,593 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:29:04,594 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:29:04,595 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:29:04,599 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:29:04,600 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:29:04,600 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:29:04,607 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:29:04,609 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:04,609 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:29:04,613 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:29:04,614 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:29:04,615 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:29:04,619 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:29:04,620 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:29:04,620 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:29:04,628 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:29:04,629 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:29:04,629 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:29:04,634 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:29:04,635 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:04,635 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:29:04,640 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:29:04,641 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:04,641 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:29:04,645 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:29:04,646 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:04,646 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:29:04,651 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:29:04,652 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:29:04,652 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:29:04,660 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:29:04,662 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:29:04,662 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:29:04,667 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:29:04,668 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:04,668 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:29:04,673 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:29:04,674 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:29:04,674 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:29:04,680 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:29:04,682 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:04,682 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:29:04,689 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:29:04,691 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:04,691 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:29:04,700 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:29:04,702 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:29:04,702 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:29:04,710 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:29:04,711 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:04,711 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:29:04,805 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:29:04,808 (MainThread): 
2019-10-01 14:29:04,809 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:29:04,809 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:29:04,848 (MainThread): Parsing macros\core.sql
2019-10-01 14:29:04,861 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:29:04,966 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:29:04,982 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:29:04,986 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:29:04,992 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:29:04,997 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:29:05,001 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:29:05,006 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:29:05,020 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:29:05,035 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:29:05,050 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:29:05,077 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:29:05,129 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:29:05,135 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:29:05,164 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:29:05,179 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:29:05,193 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:29:05,215 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:29:05,222 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:29:05,227 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:29:05,232 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:29:05,239 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:29:05,272 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:29:05,279 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:29:05,298 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:29:05,303 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:29:05,313 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:29:05,540 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:05,540 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:29:06,060 (MainThread): SQL status: SUCCESS 29 in 0.52 seconds
2019-10-01 14:29:06,118 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:06,118 (MainThread): On master: BEGIN
2019-10-01 14:29:06,226 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:06,227 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:06,227 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:29:07,298 (MainThread): SQL status: SUCCESS 21 in 1.07 seconds
2019-10-01 14:29:07,311 (MainThread): On master: ROLLBACK
2019-10-01 14:29:07,467 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:07,467 (MainThread): On master: BEGIN
2019-10-01 14:29:07,572 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:07,572 (MainThread): On master: COMMIT
2019-10-01 14:29:07,573 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:07,573 (MainThread): On master: COMMIT
2019-10-01 14:29:07,713 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:29:07,714 (MainThread): 14:29:07 | Concurrency: 1 threads (target='dev')
2019-10-01 14:29:07,714 (MainThread): 14:29:07 | 
2019-10-01 14:29:07,718 (Thread-1): 14:29:07 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:29:07,719 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:29:07,720 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:29:08,038 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:29:08,046 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:29:08,110 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:29:08,119 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:29:08,121 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:29:08,234 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:08,235 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:29:08,235 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:29:08,459 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:29:08,461 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:29:08,461 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:29:08,462 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:29:08,626 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:29:08,633 (Thread-1): 14:29:08 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 0.91s]
2019-10-01 14:29:08,634 (Thread-1): 14:29:08 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:29:08,636 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:29:08,636 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:29:08,636 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:29:08,645 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:29:08,661 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:29:08,667 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:29:08,667 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:29:08,794 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:08,794 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:29:08,795 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:29:09,016 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:29:09,018 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:29:09,019 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:29:09,019 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:29:09,128 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:09,136 (Thread-1): 14:29:09 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.50s]
2019-10-01 14:29:09,137 (Thread-1): 14:29:09 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:29:09,140 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:29:09,140 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:29:09,141 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:29:09,151 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:29:09,166 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:29:09,172 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:29:09,172 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:29:09,477 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:29:09,477 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:29:09,478 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:29:09,717 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:09,718 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:29:09,718 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:29:09,718 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:29:09,930 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:09,934 (Thread-1): 14:29:09 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.79s]
2019-10-01 14:29:09,934 (Thread-1): 14:29:09 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:29:09,935 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:29:09,935 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:29:09,935 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:29:09,941 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:29:09,951 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:29:09,954 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:29:09,954 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:29:10,113 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:29:10,113 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:29:10,113 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:29:10,355 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:10,356 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:29:10,356 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:29:10,356 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:29:10,449 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:10,456 (Thread-1): 14:29:10 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.52s]
2019-10-01 14:29:10,457 (Thread-1): 14:29:10 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:29:10,458 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,458 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:29:10,459 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:29:10,469 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:29:10,480 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:29:10,484 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,485 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:29:10,590 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:10,591 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,591 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:29:10,831 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:10,832 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:29:10,832 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:29:10,832 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:29:10,952 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:10,961 (Thread-1): 14:29:10 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.50s]
2019-10-01 14:29:10,962 (Thread-1): 14:29:10 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:29:10,966 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:29:10,966 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:29:10,967 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:29:10,980 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:29:11,001 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:29:11,005 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:29:11,006 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:29:11,138 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:29:11,139 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:29:11,139 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:29:11,376 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:11,378 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:29:11,378 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:29:11,378 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:29:11,462 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-01 14:29:11,470 (Thread-1): 14:29:11 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.50s]
2019-10-01 14:29:11,471 (Thread-1): 14:29:11 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:29:11,474 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,474 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:29:11,476 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:29:11,489 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:29:11,507 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:29:11,515 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,516 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:29:11,664 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:29:11,665 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,665 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:29:11,964 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:29:11,965 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:29:11,965 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:29:11,965 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:29:12,060 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:12,065 (Thread-1): 14:29:12 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.59s]
2019-10-01 14:29:12,066 (Thread-1): 14:29:12 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:29:12,068 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,068 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:29:12,068 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:29:12,074 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:29:12,087 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:29:12,091 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,091 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:29:12,213 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:12,214 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,214 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:29:12,454 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:29:12,455 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:29:12,455 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:29:12,455 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:29:12,550 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:12,554 (Thread-1): 14:29:12 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.48s]
2019-10-01 14:29:12,555 (Thread-1): 14:29:12 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:29:12,556 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,556 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:29:12,557 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:29:12,563 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:29:12,574 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:29:12,578 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,578 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:29:12,687 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:12,688 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,688 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:29:12,904 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:29:12,905 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:29:12,905 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:29:12,905 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:29:13,009 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:13,019 (Thread-1): 14:29:13 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.46s]
2019-10-01 14:29:13,021 (Thread-1): 14:29:13 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:29:13,025 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,025 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:29:13,026 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:29:13,038 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:29:13,053 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:29:13,059 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,059 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:29:13,207 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:29:13,208 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,208 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:29:13,435 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:29:13,438 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:29:13,438 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:29:13,438 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:29:13,543 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:13,547 (Thread-1): 14:29:13 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.52s]
2019-10-01 14:29:13,548 (Thread-1): 14:29:13 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:29:13,548 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:13,548 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:29:13,549 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:29:13,554 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:29:13,564 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:29:13,568 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:13,568 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:29:13,708 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:29:13,708 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:13,709 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:29:14,017 (Thread-1): SQL status: SUCCESS 1 in 0.31 seconds
2019-10-01 14:29:14,019 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:29:14,020 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:29:14,020 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:29:14,121 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:14,126 (Thread-1): 14:29:14 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.58s]
2019-10-01 14:29:14,127 (Thread-1): 14:29:14 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:29:14,129 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,130 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:29:14,130 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:29:14,141 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:29:14,152 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:29:14,156 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,156 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:29:14,271 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:14,272 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,272 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:29:14,480 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:14,482 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:29:14,482 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:29:14,483 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:29:14,620 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:29:14,625 (Thread-1): 14:29:14 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.49s]
2019-10-01 14:29:14,626 (Thread-1): 14:29:14 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:29:14,628 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:29:14,628 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:29:14,629 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:29:14,638 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:29:14,652 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:29:14,658 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:29:14,658 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:29:14,791 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:29:14,792 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:29:14,792 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:29:15,376 (Thread-1): SQL status: SUCCESS 1 in 0.58 seconds
2019-10-01 14:29:15,378 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:29:15,379 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:29:15,379 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:29:15,483 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:15,493 (Thread-1): 14:29:15 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.86s]
2019-10-01 14:29:15,495 (Thread-1): 14:29:15 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:29:15,499 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,500 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:29:15,501 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:29:15,510 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:29:15,528 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:29:15,534 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,535 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:29:15,646 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:15,647 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,647 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:29:15,987 (Thread-1): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:29:15,988 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:29:15,988 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:29:15,988 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:29:16,080 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:16,087 (Thread-1): 14:29:16 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.59s]
2019-10-01 14:29:16,088 (Thread-1): 14:29:16 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:29:16,090 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:29:16,090 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:29:16,091 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:29:16,099 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:29:16,116 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:29:16,123 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:29:16,123 (Thread-1): On with_dates: BEGIN
2019-10-01 14:29:16,238 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:16,239 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:29:16,239 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:29:16,446 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:16,448 (Thread-1): On with_dates: COMMIT
2019-10-01 14:29:16,448 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:29:16,448 (Thread-1): On with_dates: COMMIT
2019-10-01 14:29:16,544 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:16,551 (Thread-1): 14:29:16 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.46s]
2019-10-01 14:29:16,552 (Thread-1): 14:29:16 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:29:16,554 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:16,554 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:29:16,555 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:29:16,565 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:29:16,580 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:29:16,590 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:16,590 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:29:16,703 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:16,704 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:16,704 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:29:17,050 (Thread-1): SQL status: SUCCESS 1 in 0.35 seconds
2019-10-01 14:29:17,052 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:29:17,052 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:29:17,052 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:29:17,146 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:17,155 (Thread-1): 14:29:17 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.60s]
2019-10-01 14:29:17,156 (Thread-1): 14:29:17 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:29:17,159 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,159 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:29:17,160 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:29:17,171 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:29:17,186 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:29:17,193 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,193 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:29:17,306 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:17,307 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,307 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:29:17,536 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:29:17,538 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:29:17,539 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:29:17,539 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:29:17,658 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:17,664 (Thread-1): 14:29:17 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.50s]
2019-10-01 14:29:17,665 (Thread-1): 14:29:17 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:29:17,669 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:29:17,669 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:29:17,670 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:29:17,679 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:29:17,711 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:29:17,717 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:29:17,717 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:29:17,835 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:17,835 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:29:17,836 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:29:18,120 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:29:18,122 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:29:18,122 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:29:18,122 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:29:18,244 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:18,255 (Thread-1): 14:29:18 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.58s]
2019-10-01 14:29:18,257 (Thread-1): 14:29:18 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:29:18,260 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,260 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:29:18,261 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:29:18,273 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:29:18,291 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:29:18,296 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,296 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:29:18,402 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:18,403 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,403 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:29:18,694 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:29:18,695 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:29:18,695 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:29:18,695 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:29:18,790 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:18,797 (Thread-1): 14:29:18 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.54s]
2019-10-01 14:29:18,798 (Thread-1): 14:29:18 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:29:18,801 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:29:18,801 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:29:18,802 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:29:18,811 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:29:18,826 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:29:18,831 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:29:18,831 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:29:18,948 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:18,948 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:29:18,949 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:29:19,162 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:29:19,165 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:29:19,165 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:29:19,165 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:29:19,256 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:29:19,262 (Thread-1): 14:29:19 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.46s]
2019-10-01 14:29:19,263 (Thread-1): 14:29:19 | 21 of 21 START view model DBT_TEST.v_booking_fact_uk................. [RUN]
2019-10-01 14:29:19,265 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:19,265 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:29:19,265 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:29:19,319 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:29:19,363 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:29:19,511 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:19,511 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:29:19,628 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:29:19,629 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:19,629 (Thread-1): On v_booking_fact_uk: create or replace view OPA_DEV.DBT_TEST.v_booking_fact_uk as (
    

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
  );
2019-10-01 14:29:21,718 (Thread-1): SQL status: SUCCESS 1 in 2.09 seconds
2019-10-01 14:29:21,720 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:29:21,721 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:29:21,721 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:29:21,819 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:29:21,828 (Thread-1): 14:29:21 | 21 of 21 OK created view model DBT_TEST.v_booking_fact_uk............ [SUCCESS 1 in 2.56s]
2019-10-01 14:29:21,840 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:21,840 (MainThread): On master: BEGIN
2019-10-01 14:29:21,954 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:29:21,954 (MainThread): On master: COMMIT
2019-10-01 14:29:21,954 (MainThread): Using snowflake connection "master".
2019-10-01 14:29:21,954 (MainThread): On master: COMMIT
2019-10-01 14:29:22,115 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:29:22,116 (MainThread): 14:29:22 | 
2019-10-01 14:29:22,117 (MainThread): 14:29:22 | Finished running 21 view models in 17.31s.
2019-10-01 14:29:22,117 (MainThread): Connection 'master' was left open.
2019-10-01 14:29:22,118 (MainThread): On master: Close
2019-10-01 14:29:22,265 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:29:22,265 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:29:22,437 (MainThread): 
2019-10-01 14:29:22,437 (MainThread): Completed successfully
2019-10-01 14:29:22,438 (MainThread): 
Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
2019-10-01 14:29:22,439 (MainThread): Flushing usage events
2019-10-01 14:46:33,726 (MainThread): Tracking: tracking
2019-10-01 14:46:33,728 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92A88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92448>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92648>]}
2019-10-01 14:46:34,040 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:46:34,041 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58066), raddr=('54.174.31.151', 443)>

2019-10-01 14:46:34,042 (MainThread): Error sending message, disabling tracking
2019-10-01 14:46:34,063 (MainThread): Parsing macros\core.sql
2019-10-01 14:46:34,073 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:46:34,107 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:46:34,117 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:46:34,119 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:46:34,122 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:46:34,125 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:46:34,128 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:46:34,131 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:46:34,139 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:46:34,147 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:46:34,155 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:46:34,173 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:46:34,194 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:46:34,198 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:46:34,211 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:46:34,218 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:46:34,225 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:46:34,232 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:46:34,234 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:46:34,236 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:46:34,239 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:46:34,242 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:46:34,259 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:46:34,262 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:46:34,271 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:46:34,274 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:46:34,278 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:46:34,322 (MainThread): Parsing model.dbt_test.v_booking_fact_uk
2019-10-01 14:46:34,325 (MainThread): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:34,325 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:46:34,327 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:46:34,571 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:46:34,590 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:46:35,179 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:46:35,180 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:46:35,181 (MainThread): Re-using an available connection from the pool (formerly v_booking_fact_uk).
2019-10-01 14:46:35,185 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:46:35,186 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:46:35,186 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:46:35,191 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:46:35,192 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:46:35,192 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:46:35,196 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:46:35,197 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:46:35,197 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:46:35,204 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:46:35,206 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:46:35,206 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:46:35,211 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:46:35,212 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:35,212 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:46:35,217 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:46:35,219 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:46:35,219 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:46:35,224 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:46:35,225 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:46:35,225 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:46:35,230 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:46:35,231 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:46:35,231 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:46:35,236 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:46:35,237 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:35,237 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:46:35,242 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:46:35,243 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:35,243 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:46:35,247 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:46:35,248 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:35,249 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:46:35,254 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:46:35,255 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:46:35,255 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:46:35,263 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:46:35,265 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:46:35,265 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:46:35,275 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:46:35,277 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:35,277 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:46:35,285 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:46:35,287 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:46:35,287 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:46:35,296 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:46:35,298 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:35,299 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:46:35,304 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:46:35,305 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:35,305 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:46:35,311 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:46:35,312 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:46:35,312 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:46:35,316 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:46:35,317 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:35,317 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:46:35,408 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:46:35,412 (MainThread): 
2019-10-01 14:46:35,413 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:46:35,413 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:46:35,460 (MainThread): Parsing macros\core.sql
2019-10-01 14:46:35,473 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:46:35,565 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:46:35,580 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:46:35,582 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:46:35,586 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:46:35,593 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:46:35,598 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:46:35,601 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:46:35,618 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:46:35,634 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:46:35,644 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:46:35,679 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:46:35,721 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:46:35,728 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:46:35,753 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:46:35,761 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:46:35,769 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:46:35,781 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:46:35,786 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:46:35,788 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:46:35,791 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:46:35,796 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:46:35,820 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:46:35,825 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:46:35,840 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:46:35,844 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:46:35,851 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:46:35,994 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:35,994 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:46:36,606 (MainThread): SQL status: SUCCESS 29 in 0.61 seconds
2019-10-01 14:46:36,672 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:36,672 (MainThread): On master: BEGIN
2019-10-01 14:46:36,792 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:36,793 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:36,793 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:46:37,858 (MainThread): SQL status: SUCCESS 21 in 1.07 seconds
2019-10-01 14:46:37,872 (MainThread): On master: ROLLBACK
2019-10-01 14:46:38,016 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:38,016 (MainThread): On master: BEGIN
2019-10-01 14:46:38,132 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:38,132 (MainThread): On master: COMMIT
2019-10-01 14:46:38,132 (MainThread): Using snowflake connection "master".
2019-10-01 14:46:38,132 (MainThread): On master: COMMIT
2019-10-01 14:46:38,279 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:46:38,279 (MainThread): 14:46:38 | Concurrency: 1 threads (target='dev')
2019-10-01 14:46:38,280 (MainThread): 14:46:38 | 
2019-10-01 14:46:38,283 (Thread-1): 14:46:38 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:46:38,284 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:46:38,284 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:46:38,802 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:46:38,815 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:46:38,856 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:46:38,861 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:46:38,861 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:46:38,982 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:38,983 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:46:38,983 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:46:39,234 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:46:39,236 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:46:39,236 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:46:39,237 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:46:39,335 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:39,344 (Thread-1): 14:46:39 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.06s]
2019-10-01 14:46:39,345 (Thread-1): 14:46:39 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:46:39,352 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:46:39,352 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:46:39,353 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:46:39,364 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:46:39,381 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:46:39,387 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:46:39,387 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:46:39,578 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:46:39,578 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:46:39,579 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:46:39,819 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:39,820 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:46:39,821 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:46:39,821 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:46:39,912 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:39,923 (Thread-1): 14:46:39 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.57s]
2019-10-01 14:46:39,924 (Thread-1): 14:46:39 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:46:39,925 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:46:39,926 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:46:39,927 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:46:39,943 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:46:39,958 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:46:39,964 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:46:39,964 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:46:40,081 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:40,082 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:46:40,082 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:46:40,326 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:40,328 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:46:40,328 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:46:40,328 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:46:40,424 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:40,428 (Thread-1): 14:46:40 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.50s]
2019-10-01 14:46:40,428 (Thread-1): 14:46:40 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:46:40,431 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:46:40,431 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:46:40,431 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:46:40,436 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:46:40,445 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:46:40,449 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:46:40,449 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:46:40,567 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:40,567 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:46:40,567 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:46:40,833 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:46:40,834 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:46:40,834 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:46:40,834 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:46:40,927 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:40,931 (Thread-1): 14:46:40 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.50s]
2019-10-01 14:46:40,932 (Thread-1): 14:46:40 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:46:40,933 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:40,933 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:46:40,934 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:46:40,939 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:46:40,954 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:46:40,961 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:40,961 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:46:41,101 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:41,102 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:41,102 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:46:41,360 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:46:41,362 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:46:41,362 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:46:41,363 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:46:41,511 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:46:41,516 (Thread-1): 14:46:41 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.58s]
2019-10-01 14:46:41,517 (Thread-1): 14:46:41 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:46:41,520 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,520 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:46:41,521 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:46:41,526 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:46:41,542 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:46:41,548 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,548 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:46:41,676 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:41,677 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,677 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:46:41,933 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:46:41,935 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:46:41,936 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:46:41,936 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:46:42,041 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:42,044 (Thread-1): 14:46:42 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.52s]
2019-10-01 14:46:42,045 (Thread-1): 14:46:42 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:46:42,047 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,047 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:46:42,048 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:46:42,057 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:46:42,066 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:46:42,070 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,071 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:46:42,211 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:42,212 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,212 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:46:42,436 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:46:42,438 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:46:42,438 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:46:42,438 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:46:42,576 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:42,580 (Thread-1): 14:46:42 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.53s]
2019-10-01 14:46:42,581 (Thread-1): 14:46:42 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:46:42,584 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,584 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:46:42,585 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:46:42,589 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:46:42,599 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:46:42,603 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,603 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:46:42,721 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:42,722 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,723 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:46:42,945 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:46:42,946 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:46:42,946 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:46:42,946 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:46:43,047 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:43,051 (Thread-1): 14:46:43 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.46s]
2019-10-01 14:46:43,053 (Thread-1): 14:46:43 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:46:43,057 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,057 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:46:43,057 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:46:43,066 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:46:43,081 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:46:43,085 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,085 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:46:43,203 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:43,204 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,204 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:46:43,432 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:46:43,433 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:46:43,434 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:46:43,434 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:46:43,530 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:43,534 (Thread-1): 14:46:43 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.48s]
2019-10-01 14:46:43,535 (Thread-1): 14:46:43 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:46:43,537 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:43,537 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:46:43,537 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:46:43,542 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:46:43,551 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:46:43,555 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:43,555 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:46:43,750 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-01 14:46:43,751 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:43,751 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:46:44,030 (Thread-1): SQL status: SUCCESS 1 in 0.28 seconds
2019-10-01 14:46:44,033 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:46:44,033 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:46:44,033 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:46:44,123 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:44,131 (Thread-1): 14:46:44 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.59s]
2019-10-01 14:46:44,133 (Thread-1): 14:46:44 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:46:44,136 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,137 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:46:44,138 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:46:44,150 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:46:44,162 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:46:44,167 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,167 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:46:44,276 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:44,277 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,277 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:46:44,520 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:44,521 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:46:44,521 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:46:44,521 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:46:44,632 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:44,636 (Thread-1): 14:46:44 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.50s]
2019-10-01 14:46:44,637 (Thread-1): 14:46:44 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:46:44,640 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:46:44,640 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:46:44,641 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:46:44,648 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:46:44,657 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:46:44,662 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:46:44,662 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:46:44,775 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:46:44,776 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:46:44,776 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:46:45,025 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:46:45,027 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:46:45,027 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:46:45,027 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:46:45,144 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:45,154 (Thread-1): 14:46:45 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.51s]
2019-10-01 14:46:45,155 (Thread-1): 14:46:45 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:46:45,158 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,158 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:46:45,159 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:46:45,170 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:46:45,185 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:46:45,190 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,190 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:46:45,294 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:45,295 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,295 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:46:45,600 (Thread-1): SQL status: SUCCESS 1 in 0.30 seconds
2019-10-01 14:46:45,602 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:46:45,602 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:46:45,603 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:46:45,697 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:45,701 (Thread-1): 14:46:45 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.54s]
2019-10-01 14:46:45,702 (Thread-1): 14:46:45 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:46:45,704 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:45,704 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:46:45,705 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:46:45,713 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:46:45,727 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:46:45,732 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:45,732 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:46:45,865 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:45,866 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:45,866 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:46:46,196 (Thread-1): SQL status: SUCCESS 1 in 0.33 seconds
2019-10-01 14:46:46,198 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:46:46,198 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:46:46,199 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:46:46,294 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:46:46,297 (Thread-1): 14:46:46 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.59s]
2019-10-01 14:46:46,299 (Thread-1): 14:46:46 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:46:46,300 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:46:46,300 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:46:46,301 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:46:46,306 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:46:46,314 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:46:46,320 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:46:46,320 (Thread-1): On with_dates: BEGIN
2019-10-01 14:46:46,464 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:46,465 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:46:46,465 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:46:46,689 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:46:46,691 (Thread-1): On with_dates: COMMIT
2019-10-01 14:46:46,692 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:46:46,692 (Thread-1): On with_dates: COMMIT
2019-10-01 14:46:46,790 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:46,799 (Thread-1): 14:46:46 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.50s]
2019-10-01 14:46:46,800 (Thread-1): 14:46:46 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:46:46,801 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:46,802 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:46:46,802 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:46:46,811 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:46:46,826 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:46:46,835 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:46,835 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:46:46,973 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:46,974 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:46,974 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:46:47,212 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:47,215 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:46:47,215 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:46:47,215 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:46:47,316 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:47,324 (Thread-1): 14:46:47 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.52s]
2019-10-01 14:46:47,326 (Thread-1): 14:46:47 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:46:47,326 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,326 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:46:47,327 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:46:47,340 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:46:47,359 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:46:47,366 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,366 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:46:47,486 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:47,487 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,487 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:46:47,713 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:46:47,715 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:46:47,715 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:46:47,716 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:46:47,817 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:47,826 (Thread-1): 14:46:47 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.50s]
2019-10-01 14:46:47,827 (Thread-1): 14:46:47 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:46:47,830 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:46:47,830 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:46:47,831 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:46:47,839 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:46:47,855 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:46:47,861 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:46:47,861 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:46:47,976 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:47,977 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:46:47,977 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:46:48,216 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:48,218 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:46:48,218 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:46:48,218 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:46:48,313 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:46:48,317 (Thread-1): 14:46:48 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.49s]
2019-10-01 14:46:48,318 (Thread-1): 14:46:48 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:46:48,318 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,318 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:46:48,318 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:46:48,323 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:46:48,332 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:46:48,338 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,338 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:46:48,455 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:46:48,456 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,456 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:46:48,684 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:46:48,685 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:46:48,685 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:46:48,685 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:46:48,898 (Thread-1): SQL status: SUCCESS 1 in 0.21 seconds
2019-10-01 14:46:48,901 (Thread-1): 14:46:48 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.58s]
2019-10-01 14:46:48,902 (Thread-1): 14:46:48 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:46:48,905 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:46:48,905 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:46:48,906 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:46:48,913 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:46:48,926 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:46:48,930 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:46:48,930 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:46:49,062 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:49,063 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:46:49,063 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:46:49,303 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:46:49,304 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:46:49,304 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:46:49,304 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:46:49,447 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:46:49,455 (Thread-1): 14:46:49 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.55s]
2019-10-01 14:46:49,457 (Thread-1): 14:46:49 | 21 of 21 START table model DBT_TEST.v_booking_fact_uk................ [RUN]
2019-10-01 14:46:49,460 (Thread-1): Acquiring new snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:49,460 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:46:49,461 (Thread-1): Compiling model.dbt_test.v_booking_fact_uk
2019-10-01 14:46:49,510 (Thread-1): Writing injected SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:46:49,540 (Thread-1): Dropping relation "OPA_DEV"."DBT_TEST"."V_BOOKING_FACT_UK" because it is of type view
2019-10-01 14:46:49,549 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:49,550 (Thread-1): On v_booking_fact_uk: drop view if exists "OPA_DEV"."DBT_TEST"."V_BOOKING_FACT_UK" cascade
2019-10-01 14:46:49,753 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 14:46:49,783 (Thread-1): Writing runtime SQL for node "model.dbt_test.v_booking_fact_uk"
2019-10-01 14:46:49,951 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:49,952 (Thread-1): On v_booking_fact_uk: BEGIN
2019-10-01 14:46:50,084 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:46:50,085 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:46:50,085 (Thread-1): On v_booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.v_booking_fact_uk
      as (

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-01 14:48:02,740 (Thread-1): SQL status: SUCCESS 1 in 72.65 seconds
2019-10-01 14:48:02,742 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:48:02,742 (Thread-1): Using snowflake connection "v_booking_fact_uk".
2019-10-01 14:48:02,743 (Thread-1): On v_booking_fact_uk: COMMIT
2019-10-01 14:48:02,842 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:48:02,853 (Thread-1): 14:48:02 | 21 of 21 OK created table model DBT_TEST.v_booking_fact_uk........... [SUCCESS 1 in 73.39s]
2019-10-01 14:51:53,354 (MainThread): Using snowflake connection "master".
2019-10-01 14:51:53,354 (MainThread): On master: BEGIN
2019-10-01 14:51:53,692 (MainThread): SQL status: SUCCESS 1 in 0.34 seconds
2019-10-01 14:51:53,693 (MainThread): On master: COMMIT
2019-10-01 14:51:53,693 (MainThread): Using snowflake connection "master".
2019-10-01 14:51:53,694 (MainThread): On master: COMMIT
2019-10-01 14:51:53,846 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:51:53,847 (MainThread): 14:51:53 | 
2019-10-01 14:51:53,848 (MainThread): 14:51:53 | Finished running 20 view models, 1 table model in 318.43s.
2019-10-01 14:51:53,848 (MainThread): Connection 'master' was left open.
2019-10-01 14:51:53,849 (MainThread): On master: Close
2019-10-01 14:51:54,074 (MainThread): Connection 'v_booking_fact_uk' was left open.
2019-10-01 14:51:54,075 (MainThread): On v_booking_fact_uk: Close
2019-10-01 14:51:54,505 (MainThread): 
2019-10-01 14:51:54,506 (MainThread): Completed successfully
2019-10-01 14:51:54,507 (MainThread): 
Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
2019-10-01 14:51:54,507 (MainThread): Flushing usage events
2019-10-01 14:52:47,695 (MainThread): Tracking: tracking
2019-10-01 14:52:47,698 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93B08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93508>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8F6C8>]}
2019-10-01 14:52:47,972 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-01 14:52:47,973 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.32.130.75', 58279), raddr=('54.164.98.48', 443)>

2019-10-01 14:52:47,974 (MainThread): Error sending message, disabling tracking
2019-10-01 14:52:47,998 (MainThread): Parsing macros\core.sql
2019-10-01 14:52:48,007 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:52:48,045 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:52:48,055 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:52:48,057 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:52:48,060 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:52:48,064 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:52:48,067 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:52:48,070 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:52:48,078 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:52:48,086 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:52:48,096 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:52:48,113 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:52:48,134 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:52:48,137 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:52:48,151 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:52:48,157 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:52:48,164 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:52:48,172 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:52:48,175 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:52:48,177 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:52:48,180 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:52:48,185 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:52:48,204 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:52:48,208 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:52:48,217 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:52:48,220 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:52:48,224 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:52:48,269 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-01 14:52:48,271 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-01 14:52:48,271 (MainThread): Opening a new connection, currently in state init
2019-10-01 14:52:48,272 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-01 14:52:48,612 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-01 14:52:48,642 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-01 14:52:49,669 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-01 14:52:49,670 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:52:49,670 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-01 14:52:49,674 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-01 14:52:49,675 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:52:49,676 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:52:49,680 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-01 14:52:49,681 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:52:49,681 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:52:49,686 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-01 14:52:49,687 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:52:49,687 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:52:49,693 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-01 14:52:49,694 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:52:49,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:52:49,699 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-01 14:52:49,700 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:49,700 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:52:49,705 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-01 14:52:49,706 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:52:49,706 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:52:49,711 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-01 14:52:49,712 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:52:49,712 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:52:49,718 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-01 14:52:49,719 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:52:49,720 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:52:49,724 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-01 14:52:49,725 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:49,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:52:49,730 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:52:49,731 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:49,731 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:52:49,737 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-01 14:52:49,739 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:49,739 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:52:49,744 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-01 14:52:49,745 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:52:49,745 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:52:49,751 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-01 14:52:49,752 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:52:49,752 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:52:49,758 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-01 14:52:49,759 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:52:49,759 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:52:49,764 (MainThread): Parsing model.dbt_test.with_dates
2019-10-01 14:52:49,765 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-01 14:52:49,765 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:52:49,769 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-01 14:52:49,770 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:52:49,770 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:52:49,775 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:52:49,776 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:52:49,776 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:52:49,781 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-01 14:52:49,784 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:52:49,784 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:52:49,793 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-01 14:52:49,794 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:52:49,794 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:52:49,858 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-01 14:52:49,863 (MainThread): 
2019-10-01 14:52:49,865 (MainThread): Acquiring new snowflake connection "master".
2019-10-01 14:52:49,866 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:52:49,912 (MainThread): Parsing macros\core.sql
2019-10-01 14:52:49,923 (MainThread): Parsing macros\adapters\common.sql
2019-10-01 14:52:50,009 (MainThread): Parsing macros\etc\datetime.sql
2019-10-01 14:52:50,029 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-01 14:52:50,032 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-01 14:52:50,041 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-01 14:52:50,047 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-01 14:52:50,052 (MainThread): Parsing macros\etc\query.sql
2019-10-01 14:52:50,056 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-01 14:52:50,071 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-01 14:52:50,080 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-01 14:52:50,088 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-01 14:52:50,123 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-01 14:52:50,150 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-01 14:52:50,155 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-01 14:52:50,183 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-01 14:52:50,192 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-01 14:52:50,208 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-01 14:52:50,224 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-01 14:52:50,230 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-01 14:52:50,235 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-01 14:52:50,240 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-01 14:52:50,246 (MainThread): Parsing macros\adapters.sql
2019-10-01 14:52:50,270 (MainThread): Parsing macros\catalog.sql
2019-10-01 14:52:50,276 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-01 14:52:50,290 (MainThread): Parsing macros\materializations\merge.sql
2019-10-01 14:52:50,295 (MainThread): Parsing macros\materializations\table.sql
2019-10-01 14:52:50,303 (MainThread): Parsing macros\materializations\view.sql
2019-10-01 14:52:50,552 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:50,552 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-01 14:52:51,080 (MainThread): SQL status: SUCCESS 29 in 0.53 seconds
2019-10-01 14:52:51,130 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:51,130 (MainThread): On master: BEGIN
2019-10-01 14:52:51,282 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-01 14:52:51,282 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:51,282 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-01 14:52:52,500 (MainThread): SQL status: SUCCESS 20 in 1.22 seconds
2019-10-01 14:52:52,522 (MainThread): On master: ROLLBACK
2019-10-01 14:52:52,680 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:52,680 (MainThread): On master: BEGIN
2019-10-01 14:52:52,789 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:52:52,789 (MainThread): On master: COMMIT
2019-10-01 14:52:52,789 (MainThread): Using snowflake connection "master".
2019-10-01 14:52:52,789 (MainThread): On master: COMMIT
2019-10-01 14:52:52,956 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:52:52,957 (MainThread): 14:52:52 | Concurrency: 1 threads (target='dev')
2019-10-01 14:52:52,957 (MainThread): 14:52:52 | 
2019-10-01 14:52:52,963 (Thread-1): 14:52:52 | 1 of 21 START view model DBT_TEST.with_ar_agent...................... [RUN]
2019-10-01 14:52:52,964 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-01 14:52:52,964 (Thread-1): Opening a new connection, currently in state init
2019-10-01 14:52:53,467 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-01 14:52:53,477 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:52:53,533 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_agent"
2019-10-01 14:52:53,538 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:52:53,538 (Thread-1): On with_ar_agent: BEGIN
2019-10-01 14:52:53,657 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:53,658 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:52:53,658 (Thread-1): On with_ar_agent: create or replace view OPA_DEV.DBT_TEST.with_ar_agent as (
    

SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
  );
2019-10-01 14:52:53,946 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:52:53,948 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:52:53,948 (Thread-1): Using snowflake connection "with_ar_agent".
2019-10-01 14:52:53,948 (Thread-1): On with_ar_agent: COMMIT
2019-10-01 14:52:54,047 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:54,056 (Thread-1): 14:52:54 | 1 of 21 OK created view model DBT_TEST.with_ar_agent................. [SUCCESS 1 in 1.09s]
2019-10-01 14:52:54,057 (Thread-1): 14:52:54 | 2 of 21 START view model DBT_TEST.with_ar_market..................... [RUN]
2019-10-01 14:52:54,060 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-01 14:52:54,060 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-01 14:52:54,061 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-01 14:52:54,073 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:52:54,088 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_market"
2019-10-01 14:52:54,093 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:52:54,094 (Thread-1): On with_ar_market: BEGIN
2019-10-01 14:52:54,222 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:54,223 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:52:54,223 (Thread-1): On with_ar_market: create or replace view OPA_DEV.DBT_TEST.with_ar_market as (
    

SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
  );
2019-10-01 14:52:54,476 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:52:54,478 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:52:54,478 (Thread-1): Using snowflake connection "with_ar_market".
2019-10-01 14:52:54,479 (Thread-1): On with_ar_market: COMMIT
2019-10-01 14:52:54,579 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:54,585 (Thread-1): 14:52:54 | 2 of 21 OK created view model DBT_TEST.with_ar_market................ [SUCCESS 1 in 0.52s]
2019-10-01 14:52:54,586 (Thread-1): 14:52:54 | 3 of 21 START view model DBT_TEST.with_ar_officename................. [RUN]
2019-10-01 14:52:54,588 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-01 14:52:54,588 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-01 14:52:54,589 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-01 14:52:54,599 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:52:54,612 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_officename"
2019-10-01 14:52:54,618 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:52:54,618 (Thread-1): On with_ar_officename: BEGIN
2019-10-01 14:52:54,738 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:54,739 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:52:54,739 (Thread-1): On with_ar_officename: create or replace view OPA_DEV.DBT_TEST.with_ar_officename as (
    

SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
  );
2019-10-01 14:52:54,991 (Thread-1): SQL status: SUCCESS 1 in 0.25 seconds
2019-10-01 14:52:54,993 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:52:54,994 (Thread-1): Using snowflake connection "with_ar_officename".
2019-10-01 14:52:54,994 (Thread-1): On with_ar_officename: COMMIT
2019-10-01 14:52:55,090 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:55,103 (Thread-1): 14:52:55 | 3 of 21 OK created view model DBT_TEST.with_ar_officename............ [SUCCESS 1 in 0.51s]
2019-10-01 14:52:55,104 (Thread-1): 14:52:55 | 4 of 21 START view model DBT_TEST.with_ar_point...................... [RUN]
2019-10-01 14:52:55,107 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-01 14:52:55,108 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-01 14:52:55,109 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-01 14:52:55,123 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:52:55,139 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_point"
2019-10-01 14:52:55,145 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:52:55,146 (Thread-1): On with_ar_point: BEGIN
2019-10-01 14:52:55,276 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:55,276 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:52:55,277 (Thread-1): On with_ar_point: create or replace view OPA_DEV.DBT_TEST.with_ar_point as (
    

SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
  );
2019-10-01 14:52:55,518 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:52:55,519 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:52:55,520 (Thread-1): Using snowflake connection "with_ar_point".
2019-10-01 14:52:55,520 (Thread-1): On with_ar_point: COMMIT
2019-10-01 14:52:55,636 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:55,645 (Thread-1): 14:52:55 | 4 of 21 OK created view model DBT_TEST.with_ar_point................. [SUCCESS 1 in 0.53s]
2019-10-01 14:52:55,646 (Thread-1): 14:52:55 | 5 of 21 START view model DBT_TEST.with_ar_sellstatic................. [RUN]
2019-10-01 14:52:55,649 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:55,650 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-01 14:52:55,651 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-01 14:52:55,662 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:52:55,682 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-01 14:52:55,693 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:55,693 (Thread-1): On with_ar_sellstatic: BEGIN
2019-10-01 14:52:55,829 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:52:55,830 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:55,830 (Thread-1): On with_ar_sellstatic: create or replace view OPA_DEV.DBT_TEST.with_ar_sellstatic as (
    

SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
  );
2019-10-01 14:52:56,056 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:52:56,058 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:52:56,059 (Thread-1): Using snowflake connection "with_ar_sellstatic".
2019-10-01 14:52:56,059 (Thread-1): On with_ar_sellstatic: COMMIT
2019-10-01 14:52:56,216 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:52:56,224 (Thread-1): 14:52:56 | 5 of 21 OK created view model DBT_TEST.with_ar_sellstatic............ [SUCCESS 1 in 0.57s]
2019-10-01 14:52:56,226 (Thread-1): 14:52:56 | 6 of 21 START view model DBT_TEST.with_ar_sellunit................... [RUN]
2019-10-01 14:52:56,230 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,230 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-01 14:52:56,231 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-01 14:52:56,256 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:52:56,288 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-01 14:52:56,296 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,297 (Thread-1): On with_ar_sellunit: BEGIN
2019-10-01 14:52:56,418 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:56,419 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,419 (Thread-1): On with_ar_sellunit: create or replace view OPA_DEV.DBT_TEST.with_ar_sellunit as (
    

SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
  );
2019-10-01 14:52:56,741 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:52:56,744 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:52:56,744 (Thread-1): Using snowflake connection "with_ar_sellunit".
2019-10-01 14:52:56,744 (Thread-1): On with_ar_sellunit: COMMIT
2019-10-01 14:52:56,949 (Thread-1): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-01 14:52:56,959 (Thread-1): 14:52:56 | 6 of 21 OK created view model DBT_TEST.with_ar_sellunit.............. [SUCCESS 1 in 0.73s]
2019-10-01 14:52:56,961 (Thread-1): 14:52:56 | 7 of 21 START view model DBT_TEST.with_ar_staticroom................. [RUN]
2019-10-01 14:52:56,964 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-01 14:52:56,964 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-01 14:52:56,965 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-01 14:52:56,977 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:52:56,994 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-01 14:52:56,999 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:52:56,999 (Thread-1): On with_ar_staticroom: BEGIN
2019-10-01 14:52:57,120 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:52:57,121 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:52:57,122 (Thread-1): On with_ar_staticroom: create or replace view OPA_DEV.DBT_TEST.with_ar_staticroom as (
    

SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
  );
2019-10-01 14:52:57,344 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:52:57,346 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:52:57,347 (Thread-1): Using snowflake connection "with_ar_staticroom".
2019-10-01 14:52:57,347 (Thread-1): On with_ar_staticroom: COMMIT
2019-10-01 14:52:57,441 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:52:57,450 (Thread-1): 14:52:57 | 7 of 21 OK created view model DBT_TEST.with_ar_staticroom............ [SUCCESS 1 in 0.48s]
2019-10-01 14:52:57,451 (Thread-1): 14:52:57 | 8 of 21 START view model DBT_TEST.with_ar_staticstock................ [RUN]
2019-10-01 14:52:57,456 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,456 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-01 14:52:57,457 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-01 14:52:57,467 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:52:57,486 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-01 14:52:57,492 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,493 (Thread-1): On with_ar_staticstock: BEGIN
2019-10-01 14:52:57,606 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:52:57,607 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,608 (Thread-1): On with_ar_staticstock: create or replace view OPA_DEV.DBT_TEST.with_ar_staticstock as (
    

SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
  );
2019-10-01 14:52:57,826 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:52:57,828 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:52:57,828 (Thread-1): Using snowflake connection "with_ar_staticstock".
2019-10-01 14:52:57,829 (Thread-1): On with_ar_staticstock: COMMIT
2019-10-01 14:52:57,925 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:57,935 (Thread-1): 14:52:57 | 8 of 21 OK created view model DBT_TEST.with_ar_staticstock........... [SUCCESS 1 in 0.48s]
2019-10-01 14:52:57,936 (Thread-1): 14:52:57 | 9 of 21 START view model DBT_TEST.with_ar_transinvroute.............. [RUN]
2019-10-01 14:52:57,942 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:57,942 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-01 14:52:57,945 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-01 14:52:57,957 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:52:57,980 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-01 14:52:57,987 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:57,988 (Thread-1): On with_ar_transinvroute: BEGIN
2019-10-01 14:52:58,115 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:58,116 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:58,116 (Thread-1): On with_ar_transinvroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroute as (
    

SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
  );
2019-10-01 14:52:58,361 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:52:58,363 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:52:58,363 (Thread-1): Using snowflake connection "with_ar_transinvroute".
2019-10-01 14:52:58,364 (Thread-1): On with_ar_transinvroute: COMMIT
2019-10-01 14:52:58,497 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:58,503 (Thread-1): 14:52:58 | 9 of 21 OK created view model DBT_TEST.with_ar_transinvroute......... [SUCCESS 1 in 0.56s]
2019-10-01 14:52:58,505 (Thread-1): 14:52:58 | 10 of 21 START view model DBT_TEST.with_ar_transinvroutesector....... [RUN]
2019-10-01 14:52:58,510 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,510 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-01 14:52:58,511 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-01 14:52:58,518 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:52:58,533 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-01 14:52:58,537 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,538 (Thread-1): On with_ar_transinvroutesector: BEGIN
2019-10-01 14:52:58,664 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:58,664 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,665 (Thread-1): On with_ar_transinvroutesector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvroutesector as (
    

SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
  );
2019-10-01 14:52:58,909 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:52:58,912 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:52:58,912 (Thread-1): Using snowflake connection "with_ar_transinvroutesector".
2019-10-01 14:52:58,913 (Thread-1): On with_ar_transinvroutesector: COMMIT
2019-10-01 14:52:59,015 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:52:59,023 (Thread-1): 14:52:59 | 10 of 21 OK created view model DBT_TEST.with_ar_transinvroutesector.. [SUCCESS 1 in 0.51s]
2019-10-01 14:52:59,024 (Thread-1): 14:52:59 | 11 of 21 START view model DBT_TEST.with_ar_transinvsector............ [RUN]
2019-10-01 14:52:59,027 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,028 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-01 14:52:59,028 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-01 14:52:59,040 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:52:59,057 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-01 14:52:59,064 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,065 (Thread-1): On with_ar_transinvsector: BEGIN
2019-10-01 14:52:59,227 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:52:59,228 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,228 (Thread-1): On with_ar_transinvsector: create or replace view OPA_DEV.DBT_TEST.with_ar_transinvsector as (
    

SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
  );
2019-10-01 14:52:59,451 (Thread-1): SQL status: SUCCESS 1 in 0.22 seconds
2019-10-01 14:52:59,453 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:52:59,453 (Thread-1): Using snowflake connection "with_ar_transinvsector".
2019-10-01 14:52:59,454 (Thread-1): On with_ar_transinvsector: COMMIT
2019-10-01 14:52:59,579 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:52:59,588 (Thread-1): 14:52:59 | 11 of 21 OK created view model DBT_TEST.with_ar_transinvsector....... [SUCCESS 1 in 0.56s]
2019-10-01 14:52:59,590 (Thread-1): 14:52:59 | 12 of 21 START view model DBT_TEST.with_ar_transroute................ [RUN]
2019-10-01 14:52:59,608 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-01 14:52:59,608 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-01 14:52:59,609 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-01 14:52:59,620 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:52:59,643 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_transroute"
2019-10-01 14:52:59,647 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:52:59,648 (Thread-1): On with_ar_transroute: BEGIN
2019-10-01 14:52:59,785 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:52:59,786 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:52:59,786 (Thread-1): On with_ar_transroute: create or replace view OPA_DEV.DBT_TEST.with_ar_transroute as (
    

SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
  );
2019-10-01 14:53:00,015 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:53:00,016 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:53:00,016 (Thread-1): Using snowflake connection "with_ar_transroute".
2019-10-01 14:53:00,017 (Thread-1): On with_ar_transroute: COMMIT
2019-10-01 14:53:00,109 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-01 14:53:00,113 (Thread-1): 14:53:00 | 12 of 21 OK created view model DBT_TEST.with_ar_transroute........... [SUCCESS 1 in 0.51s]
2019-10-01 14:53:00,114 (Thread-1): 14:53:00 | 13 of 21 START view model DBT_TEST.with_ar_usercodes................. [RUN]
2019-10-01 14:53:00,115 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,116 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-01 14:53:00,116 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-01 14:53:00,121 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:53:00,131 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-01 14:53:00,135 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,135 (Thread-1): On with_ar_usercodes: BEGIN
2019-10-01 14:53:00,309 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:53:00,310 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,310 (Thread-1): On with_ar_usercodes: create or replace view OPA_DEV.DBT_TEST.with_ar_usercodes as (
    

SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
  );
2019-10-01 14:53:00,541 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:53:00,542 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:53:00,542 (Thread-1): Using snowflake connection "with_ar_usercodes".
2019-10-01 14:53:00,542 (Thread-1): On with_ar_usercodes: COMMIT
2019-10-01 14:53:00,709 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:53:00,716 (Thread-1): 14:53:00 | 13 of 21 OK created view model DBT_TEST.with_ar_usercodes............ [SUCCESS 1 in 0.60s]
2019-10-01 14:53:00,717 (Thread-1): 14:53:00 | 14 of 21 START view model DBT_TEST.with_booking_fact_margin.......... [RUN]
2019-10-01 14:53:00,720 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:00,720 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-01 14:53:00,720 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-01 14:53:00,728 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:53:00,740 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-01 14:53:00,748 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:00,748 (Thread-1): On with_booking_fact_margin: BEGIN
2019-10-01 14:53:00,883 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:53:00,883 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:00,884 (Thread-1): On with_booking_fact_margin: create or replace view OPA_DEV.DBT_TEST.with_booking_fact_margin as (
    

SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
  );
2019-10-01 14:53:01,603 (Thread-1): SQL status: SUCCESS 1 in 0.72 seconds
2019-10-01 14:53:01,605 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:53:01,605 (Thread-1): Using snowflake connection "with_booking_fact_margin".
2019-10-01 14:53:01,605 (Thread-1): On with_booking_fact_margin: COMMIT
2019-10-01 14:53:01,701 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:53:01,710 (Thread-1): 14:53:01 | 14 of 21 OK created view model DBT_TEST.with_booking_fact_margin..... [SUCCESS 1 in 0.99s]
2019-10-01 14:53:01,711 (Thread-1): 14:53:01 | 15 of 21 START view model DBT_TEST.with_dates........................ [RUN]
2019-10-01 14:53:01,714 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-01 14:53:01,714 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-01 14:53:01,715 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-01 14:53:01,720 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-01 14:53:01,732 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_dates"
2019-10-01 14:53:01,736 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:53:01,737 (Thread-1): On with_dates: BEGIN
2019-10-01 14:53:01,863 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-01 14:53:01,864 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:53:01,864 (Thread-1): On with_dates: create or replace view OPA_DEV.DBT_TEST.with_dates as (
    


SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
  );
2019-10-01 14:53:02,096 (Thread-1): SQL status: SUCCESS 1 in 0.23 seconds
2019-10-01 14:53:02,098 (Thread-1): On with_dates: COMMIT
2019-10-01 14:53:02,099 (Thread-1): Using snowflake connection "with_dates".
2019-10-01 14:53:02,099 (Thread-1): On with_dates: COMMIT
2019-10-01 14:53:02,205 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:53:02,215 (Thread-1): 14:53:02 | 15 of 21 OK created view model DBT_TEST.with_dates................... [SUCCESS 1 in 0.50s]
2019-10-01 14:53:02,216 (Thread-1): 14:53:02 | 16 of 21 START view model DBT_TEST.with_fl_acr_booking............... [RUN]
2019-10-01 14:53:02,222 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,222 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-01 14:53:02,224 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-01 14:53:02,236 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:53:02,255 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-01 14:53:02,263 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,263 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-01 14:53:02,374 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:53:02,374 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,374 (Thread-1): On with_fl_acr_booking: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking as (
    

SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:53:02,666 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-01 14:53:02,668 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:53:02,668 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-01 14:53:02,668 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-01 14:53:02,810 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:53:02,818 (Thread-1): 14:53:02 | 16 of 21 OK created view model DBT_TEST.with_fl_acr_booking.......... [SUCCESS 1 in 0.59s]
2019-10-01 14:53:02,820 (Thread-1): 14:53:02 | 17 of 21 START view model DBT_TEST.with_fl_acr_booking_service....... [RUN]
2019-10-01 14:53:02,826 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:02,827 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-01 14:53:02,828 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-01 14:53:02,839 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:53:02,872 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-01 14:53:02,889 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:02,889 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-01 14:53:03,029 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:53:03,030 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:03,030 (Thread-1): On with_fl_acr_booking_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_booking_service as (
    

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
  );
2019-10-01 14:53:03,268 (Thread-1): SQL status: SUCCESS 1 in 0.24 seconds
2019-10-01 14:53:03,270 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:53:03,270 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-01 14:53:03,271 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-01 14:53:03,368 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:53:03,376 (Thread-1): 14:53:03 | 17 of 21 OK created view model DBT_TEST.with_fl_acr_booking_service.. [SUCCESS 1 in 0.55s]
2019-10-01 14:53:03,377 (Thread-1): 14:53:03 | 18 of 21 START view model DBT_TEST.with_fl_acr_service............... [RUN]
2019-10-01 14:53:03,382 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,382 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-01 14:53:03,384 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-01 14:53:03,402 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:53:03,431 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-01 14:53:03,440 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,440 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-01 14:53:03,564 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:03,565 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,565 (Thread-1): On with_fl_acr_service: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service as (
    

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
  );
2019-10-01 14:53:03,821 (Thread-1): SQL status: SUCCESS 1 in 0.26 seconds
2019-10-01 14:53:03,823 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:53:03,824 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-01 14:53:03,824 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-01 14:53:03,949 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:03,957 (Thread-1): 14:53:03 | 18 of 21 OK created view model DBT_TEST.with_fl_acr_service.......... [SUCCESS 1 in 0.57s]
2019-10-01 14:53:03,958 (Thread-1): 14:53:03 | 19 of 21 START view model DBT_TEST.with_fl_acr_service_element....... [RUN]
2019-10-01 14:53:03,968 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:03,969 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-01 14:53:03,971 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-01 14:53:04,006 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:53:04,040 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-01 14:53:04,050 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:04,054 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-01 14:53:04,182 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:04,185 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:04,186 (Thread-1): On with_fl_acr_service_element: create or replace view OPA_DEV.DBT_TEST.with_fl_acr_service_element as (
    

SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
  );
2019-10-01 14:53:04,507 (Thread-1): SQL status: SUCCESS 1 in 0.32 seconds
2019-10-01 14:53:04,511 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:53:04,512 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-01 14:53:04,513 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-01 14:53:04,654 (Thread-1): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-01 14:53:04,667 (Thread-1): 14:53:04 | 19 of 21 OK created view model DBT_TEST.with_fl_acr_service_element.. [SUCCESS 1 in 0.69s]
2019-10-01 14:53:04,669 (Thread-1): 14:53:04 | 20 of 21 START view model DBT_TEST.with_ar_currency.................. [RUN]
2019-10-01 14:53:04,676 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-01 14:53:04,678 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-01 14:53:04,683 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-01 14:53:04,693 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:53:04,715 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_ar_currency"
2019-10-01 14:53:04,729 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:53:04,739 (Thread-1): On with_ar_currency: BEGIN
2019-10-01 14:53:04,914 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:53:04,914 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:53:04,915 (Thread-1): On with_ar_currency: create or replace view OPA_DEV.DBT_TEST.with_ar_currency as (
    

SELECT DISTINCT
  cur_1.cur_id
  ,cur_1.cd
  ,cur_1.name
FROM opa_stg_uk.ar_currency cur_1
WHERE cur_1.file_dt = (SELECT MAX(cur_2.file_dt) FROM opa_stg_uk.ar_currency cur_2 WHERE cur_1.cur_id = cur_2.cur_id)
  );
2019-10-01 14:53:05,183 (Thread-1): SQL status: SUCCESS 1 in 0.27 seconds
2019-10-01 14:53:05,192 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:53:05,192 (Thread-1): Using snowflake connection "with_ar_currency".
2019-10-01 14:53:05,192 (Thread-1): On with_ar_currency: COMMIT
2019-10-01 14:53:05,310 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-01 14:53:05,324 (Thread-1): 14:53:05 | 20 of 21 OK created view model DBT_TEST.with_ar_currency............. [SUCCESS 1 in 0.64s]
2019-10-01 14:53:05,327 (Thread-1): 14:53:05 | 21 of 21 START table model DBT_TEST.booking_fact_uk.................. [RUN]
2019-10-01 14:53:05,329 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-01 14:53:05,329 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-01 14:53:05,341 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-01 14:53:05,490 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-01 14:53:05,652 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-01 14:53:05,900 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-01 14:53:05,900 (Thread-1): On booking_fact_uk: BEGIN
2019-10-01 14:53:06,058 (Thread-1): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-01 14:53:06,059 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-01 14:53:06,059 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-01 14:54:14,006 (Thread-1): SQL status: SUCCESS 1 in 67.95 seconds
2019-10-01 14:54:14,007 (Thread-1): On booking_fact_uk: COMMIT
2019-10-01 14:54:14,007 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-01 14:54:14,007 (Thread-1): On booking_fact_uk: COMMIT
2019-10-01 14:54:14,107 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-01 14:54:14,113 (Thread-1): 14:54:14 | 21 of 21 OK created table model DBT_TEST.booking_fact_uk............. [SUCCESS 1 in 68.78s]
2019-10-01 14:54:14,164 (MainThread): Using snowflake connection "master".
2019-10-01 14:54:14,164 (MainThread): On master: BEGIN
2019-10-01 14:54:14,277 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-01 14:54:14,277 (MainThread): On master: COMMIT
2019-10-01 14:54:14,277 (MainThread): Using snowflake connection "master".
2019-10-01 14:54:14,277 (MainThread): On master: COMMIT
2019-10-01 14:54:14,452 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-01 14:54:14,452 (MainThread): 14:54:14 | 
2019-10-01 14:54:14,453 (MainThread): 14:54:14 | Finished running 20 view models, 1 table model in 84.59s.
2019-10-01 14:54:14,453 (MainThread): Connection 'master' was left open.
2019-10-01 14:54:14,453 (MainThread): On master: Close
2019-10-01 14:54:14,628 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-01 14:54:14,629 (MainThread): On booking_fact_uk: Close
2019-10-01 14:54:14,893 (MainThread): 
2019-10-01 14:54:14,893 (MainThread): Completed successfully
2019-10-01 14:54:14,894 (MainThread): 
Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
2019-10-01 14:54:14,895 (MainThread): Flushing usage events
2019-10-02 10:02:04,320 (MainThread): Tracking: tracking
2019-10-02 10:02:04,324 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C95888>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92148>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C848>]}
2019-10-02 10:02:04,662 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 10:02:04,663 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60589), raddr=('54.174.31.151', 443)>

2019-10-02 10:02:04,664 (MainThread): Error sending message, disabling tracking
2019-10-02 10:02:04,710 (MainThread): Parsing macros\core.sql
2019-10-02 10:02:04,728 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 10:02:04,802 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 10:02:04,829 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 10:02:04,837 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 10:02:04,844 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 10:02:04,853 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 10:02:04,859 (MainThread): Parsing macros\etc\query.sql
2019-10-02 10:02:04,865 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 10:02:04,883 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 10:02:04,900 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 10:02:04,923 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 10:02:04,962 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 10:02:05,005 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 10:02:05,012 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 10:02:05,060 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 10:02:05,074 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 10:02:05,088 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 10:02:05,109 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 10:02:05,115 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 10:02:05,120 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 10:02:05,125 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 10:02:05,157 (MainThread): Parsing macros\adapters.sql
2019-10-02 10:02:05,185 (MainThread): Parsing macros\catalog.sql
2019-10-02 10:02:05,201 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 10:02:05,222 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 10:02:05,240 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 10:02:05,252 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 10:02:05,306 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 10:02:05,310 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:05,310 (MainThread): Opening a new connection, currently in state init
2019-10-02 10:02:05,316 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 10:02:05,763 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 10:02:05,793 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 10:02:06,509 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 10:02:06,511 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:06,512 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 10:02:06,522 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 10:02:06,524 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:06,524 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:06,535 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 10:02:06,537 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:06,537 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:06,547 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 10:02:06,549 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:06,549 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:06,561 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 10:02:06,563 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:06,563 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:06,573 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:06,575 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:06,576 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:06,585 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 10:02:06,588 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:06,588 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:06,598 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 10:02:06,601 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:06,601 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:06,613 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 10:02:06,615 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:06,615 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:06,625 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:06,628 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:06,628 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:06,638 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:06,640 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:06,641 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:06,650 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:06,653 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:06,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:06,664 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 10:02:06,666 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:06,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:06,676 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 10:02:06,678 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:06,678 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:06,688 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:06,690 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:06,690 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:06,702 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 10:02:06,704 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:06,705 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:06,714 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:06,717 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:06,717 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:06,729 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:06,731 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:06,731 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:06,742 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 10:02:06,744 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:06,745 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:06,757 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:06,759 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:06,759 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:06,943 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 10:02:06,948 (MainThread): 
2019-10-02 10:02:06,949 (MainThread): 10:02:06 | Concurrency: 1 threads (target='dev')
2019-10-02 10:02:06,950 (MainThread): 10:02:06 | 
2019-10-02 10:02:06,966 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:06,966 (Thread-1): Opening a new connection, currently in state init
2019-10-02 10:02:07,348 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 10:02:07,363 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 10:02:07,373 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:07,379 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:07,384 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 10:02:07,394 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 10:02:07,403 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:07,408 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:07,412 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 10:02:07,421 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 10:02:07,430 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:07,433 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:07,434 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 10:02:07,445 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 10:02:07,454 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:07,460 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:07,461 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:07,475 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 10:02:07,489 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:07,493 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:07,494 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 10:02:07,504 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 10:02:07,514 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:07,514 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:07,516 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 10:02:07,538 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 10:02:07,550 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:07,550 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:07,552 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 10:02:07,573 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 10:02:07,590 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:07,590 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:07,591 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:07,606 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 10:02:07,623 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:07,628 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:07,630 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:07,669 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 10:02:07,691 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:07,695 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:07,696 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:07,717 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 10:02:07,728 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:07,732 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:07,734 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 10:02:07,755 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 10:02:07,771 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:07,776 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:07,777 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 10:02:07,786 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 10:02:07,804 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:07,807 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:07,808 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:07,819 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 10:02:07,831 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:07,831 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:07,832 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 10:02:07,846 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 10:02:07,856 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:07,860 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:07,862 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:07,875 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 10:02:07,906 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:07,906 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:07,907 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:07,922 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 10:02:07,935 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:07,935 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:07,936 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 10:02:07,951 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 10:02:07,966 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:07,966 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:07,967 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:07,981 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 10:02:07,996 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:07,996 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 10:02:07,997 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 10:02:08,006 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 10:02:08,024 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:08,027 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:08,029 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 10:02:10,505 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 10:02:10,592 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 10:02:10,592 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 10:02:11,072 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 10:02:11,072 (MainThread): On booking_fact_uk: Close
2019-10-02 10:02:11,233 (MainThread): 10:02:11 | Done.
2019-10-02 10:02:11,234 (MainThread): Flushing usage events
2019-10-02 10:02:21,756 (MainThread): Tracking: tracking
2019-10-02 10:02:21,759 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004933D88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92DC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C148>]}
2019-10-02 10:02:22,034 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 10:02:22,035 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60594), raddr=('54.174.31.151', 443)>

2019-10-02 10:02:22,036 (MainThread): Error sending message, disabling tracking
2019-10-02 10:02:22,062 (MainThread): Parsing macros\core.sql
2019-10-02 10:02:22,071 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 10:02:22,119 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 10:02:22,135 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 10:02:22,138 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 10:02:22,143 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 10:02:22,148 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 10:02:22,152 (MainThread): Parsing macros\etc\query.sql
2019-10-02 10:02:22,156 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 10:02:22,169 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 10:02:22,180 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 10:02:22,188 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 10:02:22,205 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 10:02:22,227 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 10:02:22,230 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 10:02:22,243 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 10:02:22,249 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 10:02:22,258 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 10:02:22,269 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 10:02:22,272 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 10:02:22,276 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 10:02:22,279 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 10:02:22,282 (MainThread): Parsing macros\adapters.sql
2019-10-02 10:02:22,304 (MainThread): Parsing macros\catalog.sql
2019-10-02 10:02:22,313 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 10:02:22,326 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 10:02:22,330 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 10:02:22,336 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 10:02:22,379 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 10:02:22,382 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:22,383 (MainThread): Opening a new connection, currently in state init
2019-10-02 10:02:22,385 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 10:02:22,652 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 10:02:22,683 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 10:02:23,378 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 10:02:23,380 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:23,380 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 10:02:23,391 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 10:02:23,393 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:23,394 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:23,409 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 10:02:23,412 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:23,412 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:23,423 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 10:02:23,426 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:23,426 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:23,437 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 10:02:23,439 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:23,440 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:23,449 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:23,452 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:23,452 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:23,464 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 10:02:23,467 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:23,467 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:23,478 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 10:02:23,480 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:23,481 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:23,491 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 10:02:23,494 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:23,494 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:23,504 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:23,506 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:23,506 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:23,516 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:23,518 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:23,518 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:23,528 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:23,530 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:23,531 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:23,542 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 10:02:23,544 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:23,544 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:23,555 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 10:02:23,558 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:23,559 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:23,569 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:23,571 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:23,571 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:23,582 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 10:02:23,585 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:23,585 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:23,595 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:23,597 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:23,597 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:23,608 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:23,610 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:23,611 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:23,620 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 10:02:23,622 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:23,622 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:23,631 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:23,632 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:23,633 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:23,770 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 10:02:23,774 (MainThread): 
2019-10-02 10:02:23,774 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 10:02:23,774 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 10:02:23,836 (MainThread): Parsing macros\core.sql
2019-10-02 10:02:23,848 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 10:02:23,935 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 10:02:23,963 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 10:02:23,969 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 10:02:23,976 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 10:02:23,985 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 10:02:23,992 (MainThread): Parsing macros\etc\query.sql
2019-10-02 10:02:23,999 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 10:02:24,017 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 10:02:24,034 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 10:02:24,055 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 10:02:24,093 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 10:02:24,136 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 10:02:24,141 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 10:02:24,163 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 10:02:24,174 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 10:02:24,185 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 10:02:24,195 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 10:02:24,199 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 10:02:24,202 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 10:02:24,206 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 10:02:24,210 (MainThread): Parsing macros\adapters.sql
2019-10-02 10:02:24,237 (MainThread): Parsing macros\catalog.sql
2019-10-02 10:02:24,243 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 10:02:24,261 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 10:02:24,274 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 10:02:24,298 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 10:02:24,499 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:24,500 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 10:02:25,254 (MainThread): SQL status: SUCCESS 29 in 0.75 seconds
2019-10-02 10:02:25,344 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:25,344 (MainThread): On master: BEGIN
2019-10-02 10:02:25,461 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 10:02:25,462 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:25,462 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 10:02:27,122 (MainThread): SQL status: SUCCESS 0 in 1.66 seconds
2019-10-02 10:02:27,124 (MainThread): On master: ROLLBACK
2019-10-02 10:02:27,294 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:27,295 (MainThread): On master: BEGIN
2019-10-02 10:02:27,400 (MainThread): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 10:02:27,401 (MainThread): On master: COMMIT
2019-10-02 10:02:27,401 (MainThread): Using snowflake connection "master".
2019-10-02 10:02:27,401 (MainThread): On master: COMMIT
2019-10-02 10:02:27,545 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 10:02:27,546 (MainThread): 10:02:27 | Concurrency: 1 threads (target='dev')
2019-10-02 10:02:27,547 (MainThread): 10:02:27 | 
2019-10-02 10:02:27,552 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 10:02:27,552 (Thread-1): Opening a new connection, currently in state init
2019-10-02 10:02:28,106 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 10:02:28,112 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 10:02:28,117 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 10:02:28,117 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 10:02:28,117 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 10:02:28,122 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 10:02:28,128 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 10:02:28,128 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 10:02:28,128 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 10:02:28,134 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 10:02:28,140 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 10:02:28,141 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 10:02:28,142 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 10:02:28,146 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 10:02:28,151 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 10:02:28,153 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 10:02:28,154 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 10:02:28,159 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 10:02:28,167 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 10:02:28,167 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 10:02:28,168 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 10:02:28,180 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 10:02:28,186 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 10:02:28,186 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 10:02:28,187 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 10:02:28,199 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 10:02:28,209 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 10:02:28,210 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 10:02:28,210 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 10:02:28,234 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 10:02:28,240 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 10:02:28,243 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 10:02:28,244 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 10:02:28,255 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 10:02:28,262 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 10:02:28,265 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 10:02:28,266 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 10:02:28,276 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 10:02:28,294 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 10:02:28,296 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 10:02:28,297 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 10:02:28,307 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 10:02:28,314 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 10:02:28,316 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 10:02:28,317 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 10:02:28,327 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 10:02:28,334 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 10:02:28,334 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 10:02:28,335 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 10:02:28,348 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 10:02:28,354 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 10:02:28,354 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 10:02:28,355 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 10:02:28,366 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 10:02:28,374 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 10:02:28,378 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 10:02:28,379 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 10:02:28,388 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 10:02:28,395 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 10:02:28,398 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 10:02:28,398 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 10:02:28,408 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 10:02:28,415 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 10:02:28,415 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 10:02:28,416 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 10:02:28,429 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 10:02:28,442 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 10:02:28,444 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 10:02:28,445 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 10:02:28,455 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 10:02:28,510 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 10:02:28,514 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 10:02:28,515 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 10:02:28,527 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 10:02:28,534 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 10:02:28,538 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 10:02:28,539 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 10:02:28,549 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 10:02:28,556 (Thread-1): 10:02:28 | 1 of 1 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 10:02:28,559 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 10:02:28,559 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 10:02:28,560 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 10:02:30,422 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 10:02:30,524 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 10:02:30,706 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 10:02:30,707 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 10:02:30,873 (Thread-1): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 10:02:30,874 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 10:02:30,874 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_fl_acr_booking_service as (


SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
),  __dbt__CTE__with_fl_acr_service as (


SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)
),  __dbt__CTE__with_fl_acr_service_element as (


SELECT
  ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)
),  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_fl_acr_booking as (


SELECT
  bk_1.sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM __dbt__CTE__with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN __dbt__CTE__with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN __dbt__CTE__with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM __dbt__CTE__with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 10:03:53,985 (Thread-1): SQL status: SUCCESS 1 in 83.11 seconds
2019-10-02 10:03:53,986 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 10:03:53,987 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 10:03:53,987 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 10:03:54,088 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 10:03:54,107 (Thread-1): 10:03:54 | 1 of 1 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 85.54s]
2019-10-02 10:03:54,197 (MainThread): Using snowflake connection "master".
2019-10-02 10:03:54,198 (MainThread): On master: BEGIN
2019-10-02 10:03:54,327 (MainThread): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 10:03:54,328 (MainThread): On master: COMMIT
2019-10-02 10:03:54,328 (MainThread): Using snowflake connection "master".
2019-10-02 10:03:54,328 (MainThread): On master: COMMIT
2019-10-02 10:03:54,489 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 10:03:54,489 (MainThread): 10:03:54 | 
2019-10-02 10:03:54,489 (MainThread): 10:03:54 | Finished running 1 table model in 90.72s.
2019-10-02 10:03:54,490 (MainThread): Connection 'master' was left open.
2019-10-02 10:03:54,490 (MainThread): On master: Close
2019-10-02 10:03:54,692 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 10:03:54,692 (MainThread): On booking_fact_uk: Close
2019-10-02 10:03:54,867 (MainThread): 
2019-10-02 10:03:54,867 (MainThread): Completed successfully
2019-10-02 10:03:54,868 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2019-10-02 10:03:54,868 (MainThread): Flushing usage events
2019-10-02 12:55:39,742 (MainThread): Tracking: tracking
2019-10-02 12:55:39,745 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004932F08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C808>]}
2019-10-02 12:55:40,043 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:55:40,044 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60637), raddr=('54.164.98.48', 443)>

2019-10-02 12:55:40,045 (MainThread): Error sending message, disabling tracking
2019-10-02 12:55:40,078 (MainThread): Parsing macros\core.sql
2019-10-02 12:55:40,091 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:55:40,161 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:55:40,174 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:55:40,177 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:55:40,181 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:55:40,189 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:55:40,195 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:55:40,199 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:55:40,215 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:55:40,229 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:55:40,244 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:55:40,263 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:55:40,294 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:55:40,300 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:55:40,318 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:55:40,326 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:55:40,333 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:55:40,344 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:55:40,348 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:55:40,351 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:55:40,354 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:55:40,359 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:55:40,376 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:55:40,383 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:55:40,395 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:55:40,399 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:55:40,405 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:55:40,449 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:55:40,451 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:55:40,451 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:55:40,455 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:55:40,937 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:55:40,963 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:55:41,680 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:55:41,681 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:55:41,681 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:55:41,686 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:55:41,687 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:55:41,687 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:55:41,692 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:55:41,693 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:55:41,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:55:41,699 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:55:41,700 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:55:41,700 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:55:41,709 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:55:41,710 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:55:41,710 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:55:41,719 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:55:41,722 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:55:41,722 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:55:41,730 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:55:41,732 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:55:41,732 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:55:41,741 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:55:41,743 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:55:41,743 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:55:41,750 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:55:41,751 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:55:41,751 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:55:41,757 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:55:41,758 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:55:41,758 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:55:41,766 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:55:41,767 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:55:41,767 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:55:41,774 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:55:41,776 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:55:41,776 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:55:41,781 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:55:41,783 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:55:41,783 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:55:41,790 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:55:41,791 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:55:41,791 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:55:41,796 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:55:41,798 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:55:41,798 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:55:41,805 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:55:41,806 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:55:41,806 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:55:41,811 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:55:41,813 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:55:41,813 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:55:41,832 (MainThread): Flushing usage events
2019-10-02 12:55:41,832 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:55:41,832 (MainThread): Encountered an error:
2019-10-02 12:55:41,833 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:55:41,833 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got 'unique_key'
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table
2019-10-02 12:55:42,003 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got 'unique_key'
  line 3
    unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got 'unique_key'
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

2019-10-02 12:56:29,386 (MainThread): Tracking: tracking
2019-10-02 12:56:29,388 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004935D08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBD288>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DA48>]}
2019-10-02 12:56:29,653 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:56:29,656 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60646), raddr=('54.164.98.48', 443)>

2019-10-02 12:56:29,661 (MainThread): Error sending message, disabling tracking
2019-10-02 12:56:29,724 (MainThread): Parsing macros\core.sql
2019-10-02 12:56:29,735 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:56:29,772 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:56:29,782 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:56:29,784 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:56:29,787 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:56:29,791 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:56:29,794 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:56:29,796 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:56:29,804 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:56:29,812 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:56:29,820 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:56:29,837 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:56:29,857 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:56:29,860 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:56:29,873 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:56:29,879 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:56:29,885 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:56:29,893 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:56:29,896 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:56:29,898 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:56:29,901 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:56:29,904 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:56:29,930 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:56:29,937 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:56:29,953 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:56:29,956 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:56:29,961 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:56:29,988 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:56:29,990 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:56:29,990 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:56:29,992 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:56:30,279 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:56:30,298 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:56:30,777 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:56:30,779 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:56:30,779 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:56:30,784 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:56:30,785 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:56:30,785 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:56:30,793 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:56:30,795 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:56:30,795 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:56:30,804 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:56:30,806 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:56:30,806 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:56:30,816 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:56:30,817 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:56:30,817 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:56:30,823 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:56:30,825 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:56:30,825 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:56:30,831 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:56:30,833 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:56:30,833 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:56:30,839 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:56:30,840 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:56:30,841 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:56:30,848 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:56:30,849 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:56:30,849 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:56:30,855 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:56:30,857 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:56:30,857 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:56:30,863 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:56:30,865 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:56:30,865 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:56:30,872 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:56:30,874 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:56:30,874 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:56:30,884 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:56:30,887 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:56:30,887 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:56:30,898 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:56:30,900 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:56:30,900 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:56:30,910 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:56:30,912 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:56:30,912 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:56:30,921 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:56:30,922 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:56:30,922 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:56:30,929 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:56:30,931 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:56:30,931 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:56:30,937 (MainThread): Flushing usage events
2019-10-02 12:56:30,937 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:56:30,937 (MainThread): Encountered an error:
2019-10-02 12:56:30,938 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:56:30,938 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table
2019-10-02 12:56:30,948 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

2019-10-02 12:57:48,308 (MainThread): Tracking: tracking
2019-10-02 12:57:48,310 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C959C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92808>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6B488>]}
2019-10-02 12:57:48,633 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:57:48,634 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60667), raddr=('54.174.31.151', 443)>

2019-10-02 12:57:48,637 (MainThread): Error sending message, disabling tracking
2019-10-02 12:57:48,677 (MainThread): Parsing macros\core.sql
2019-10-02 12:57:48,686 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:57:48,726 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:57:48,736 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:57:48,738 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:57:48,741 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:57:48,745 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:57:48,747 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:57:48,756 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:57:48,764 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:57:48,776 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:57:48,793 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:57:48,818 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:57:48,845 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:57:48,849 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:57:48,867 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:57:48,876 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:57:48,887 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:57:48,897 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:57:48,900 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:57:48,903 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:57:48,906 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:57:48,910 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:57:48,925 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:57:48,929 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:57:48,939 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:57:48,941 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:57:48,946 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:57:48,973 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:57:48,975 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:57:48,975 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:57:48,977 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:57:49,202 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:57:49,219 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:57:49,760 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:57:49,761 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:57:49,761 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:57:49,765 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:57:49,766 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:57:49,766 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:57:49,771 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:57:49,772 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:57:49,772 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:57:49,777 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:57:49,778 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:57:49,778 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:57:49,782 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:57:49,783 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:57:49,784 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:57:49,789 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:57:49,790 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:57:49,790 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:57:49,795 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:57:49,796 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:57:49,796 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:57:49,801 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:57:49,802 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:57:49,802 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:57:49,808 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:57:49,809 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:57:49,809 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:57:49,813 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:57:49,814 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:57:49,814 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:57:49,819 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:57:49,820 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:57:49,821 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:57:49,825 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:57:49,826 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:57:49,826 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:57:49,830 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:57:49,831 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:57:49,832 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:57:49,837 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:57:49,838 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:57:49,838 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:57:49,842 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:57:49,843 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:57:49,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:57:49,848 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:57:49,849 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:57:49,849 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:57:49,854 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:57:49,855 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:57:49,856 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:57:49,861 (MainThread): Flushing usage events
2019-10-02 12:57:49,861 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:57:49,861 (MainThread): Encountered an error:
2019-10-02 12:57:49,862 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:57:49,862 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, |, booking_version) -- bk in the target table
2019-10-02 12:57:49,874 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=concat(sk_booking_id, |, booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, |, booking_version) -- bk in the target table

2019-10-02 12:58:49,021 (MainThread): Tracking: tracking
2019-10-02 12:58:49,023 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004937308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E8C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B648>]}
2019-10-02 12:58:49,347 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:58:49,349 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60682), raddr=('54.164.98.48', 443)>

2019-10-02 12:58:49,354 (MainThread): Error sending message, disabling tracking
2019-10-02 12:58:49,410 (MainThread): Parsing macros\core.sql
2019-10-02 12:58:49,422 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:58:49,473 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:58:49,483 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:58:49,486 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:58:49,489 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:58:49,492 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:58:49,495 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:58:49,498 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:58:49,506 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:58:49,514 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:58:49,523 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:58:49,543 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:58:49,588 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:58:49,591 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:58:49,603 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:58:49,610 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:58:49,616 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:58:49,623 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:58:49,625 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:58:49,627 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:58:49,630 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:58:49,633 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:58:49,652 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:58:49,655 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:58:49,663 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:58:49,666 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:58:49,670 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:58:49,697 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:58:49,699 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:58:49,699 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:58:49,701 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:58:49,966 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:58:49,983 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:58:50,550 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:58:50,551 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:58:50,551 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:58:50,555 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:58:50,556 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:58:50,556 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:58:50,561 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:58:50,562 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:58:50,562 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:58:50,566 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:58:50,567 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:58:50,567 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:58:50,572 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:58:50,574 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:58:50,574 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:58:50,579 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:58:50,580 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:58:50,580 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:58:50,585 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:58:50,586 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:58:50,586 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:58:50,592 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:58:50,593 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:58:50,593 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:58:50,598 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:58:50,599 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:58:50,599 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:58:50,604 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:58:50,605 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:58:50,605 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:58:50,610 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:58:50,611 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:58:50,611 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:58:50,615 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:58:50,616 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:58:50,616 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:58:50,621 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:58:50,622 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:58:50,622 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:58:50,627 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:58:50,628 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:58:50,628 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:58:50,633 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:58:50,634 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:58:50,634 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:58:50,639 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:58:50,641 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:58:50,641 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:58:50,646 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:58:50,647 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:58:50,647 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:58:50,652 (MainThread): Flushing usage events
2019-10-02 12:58:50,652 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:58:50,652 (MainThread): Encountered an error:
2019-10-02 12:58:50,653 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:58:50,653 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table
2019-10-02 12:58:50,665 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

2019-10-02 12:59:06,375 (MainThread): Tracking: tracking
2019-10-02 12:59:06,377 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92708>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92AC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C088>]}
2019-10-02 12:59:06,662 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:59:06,665 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60686), raddr=('54.164.98.48', 443)>

2019-10-02 12:59:06,670 (MainThread): Error sending message, disabling tracking
2019-10-02 12:59:06,717 (MainThread): Parsing macros\core.sql
2019-10-02 12:59:06,727 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 12:59:06,779 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 12:59:06,788 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 12:59:06,790 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 12:59:06,794 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 12:59:06,798 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 12:59:06,800 (MainThread): Parsing macros\etc\query.sql
2019-10-02 12:59:06,803 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 12:59:06,812 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 12:59:06,819 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 12:59:06,831 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 12:59:06,865 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 12:59:06,915 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 12:59:06,923 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 12:59:06,956 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 12:59:06,972 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 12:59:06,982 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 12:59:06,989 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 12:59:06,993 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 12:59:06,995 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 12:59:06,998 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 12:59:07,002 (MainThread): Parsing macros\adapters.sql
2019-10-02 12:59:07,015 (MainThread): Parsing macros\catalog.sql
2019-10-02 12:59:07,020 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 12:59:07,028 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 12:59:07,031 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 12:59:07,036 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 12:59:07,069 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 12:59:07,072 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 12:59:07,073 (MainThread): Opening a new connection, currently in state init
2019-10-02 12:59:07,076 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 12:59:07,313 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 12:59:07,329 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 12:59:07,945 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 12:59:07,946 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 12:59:07,946 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 12:59:07,950 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 12:59:07,951 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 12:59:07,951 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 12:59:07,955 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 12:59:07,956 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 12:59:07,956 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 12:59:07,961 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 12:59:07,962 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 12:59:07,962 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 12:59:07,967 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 12:59:07,968 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 12:59:07,968 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 12:59:07,972 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 12:59:07,973 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 12:59:07,973 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 12:59:07,978 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 12:59:07,978 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 12:59:07,979 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 12:59:07,983 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 12:59:07,984 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 12:59:07,984 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 12:59:07,989 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 12:59:07,990 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 12:59:07,990 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 12:59:07,995 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 12:59:07,996 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 12:59:07,996 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 12:59:08,001 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 12:59:08,002 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 12:59:08,002 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 12:59:08,006 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 12:59:08,008 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 12:59:08,008 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 12:59:08,013 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 12:59:08,014 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 12:59:08,014 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 12:59:08,018 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 12:59:08,019 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 12:59:08,019 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 12:59:08,023 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 12:59:08,024 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 12:59:08,025 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 12:59:08,029 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 12:59:08,030 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 12:59:08,030 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 12:59:08,035 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 12:59:08,036 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 12:59:08,036 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 12:59:08,041 (MainThread): Flushing usage events
2019-10-02 12:59:08,041 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:59:08,041 (MainThread): Encountered an error:
2019-10-02 12:59:08,042 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 12:59:08,042 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=sk_booking_id -- bk in the target table
2019-10-02 12:59:08,056 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 3, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 876, in subparse
    self.stream.expect('variable_end')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token 'end of print statement', got '='
  line 3
    unique_key=sk_booking_id -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token 'end of print statement', got '='
    line 3
      unique_key=sk_booking_id -- bk in the target table

2019-10-02 13:01:29,206 (MainThread): Tracking: tracking
2019-10-02 13:01:29,208 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C926C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92988>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6BC48>]}
2019-10-02 13:01:29,500 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:01:29,500 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60709), raddr=('54.174.31.151', 443)>

2019-10-02 13:01:29,502 (MainThread): Error sending message, disabling tracking
2019-10-02 13:01:29,527 (MainThread): Parsing macros\core.sql
2019-10-02 13:01:29,537 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:01:29,576 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:01:29,592 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:01:29,596 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:01:29,601 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:01:29,607 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:01:29,611 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:01:29,615 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:01:29,626 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:01:29,638 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:01:29,651 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:01:29,675 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:01:29,714 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:01:29,718 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:01:29,736 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:01:29,744 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:01:29,751 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:01:29,758 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:01:29,761 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:01:29,763 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:01:29,765 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:01:29,768 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:01:29,787 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:01:29,791 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:01:29,800 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:01:29,804 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:01:29,810 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:01:29,843 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:01:29,845 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:01:29,845 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:01:29,847 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:01:30,075 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:01:30,094 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:01:30,666 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:01:30,667 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:01:30,667 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:01:30,672 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:01:30,673 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:01:30,673 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:01:30,681 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:01:30,683 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:01:30,683 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:01:30,692 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:01:30,694 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:01:30,695 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:01:30,700 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:01:30,701 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:01:30,701 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:01:30,707 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:01:30,709 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:01:30,709 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:01:30,717 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:01:30,718 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:01:30,718 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:01:30,724 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:01:30,725 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:01:30,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:01:30,731 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:01:30,732 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:01:30,733 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:01:30,741 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:01:30,743 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:01:30,743 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:01:30,751 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:01:30,753 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:01:30,753 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:01:30,758 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:01:30,759 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:01:30,759 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:01:30,763 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:01:30,764 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:01:30,764 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:01:30,774 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:01:30,775 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:01:30,775 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:01:30,786 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:01:30,791 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:01:30,791 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:01:30,801 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:01:30,803 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:01:30,804 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:01:30,815 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:01:30,817 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:01:30,818 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:01:30,830 (MainThread): Flushing usage events
2019-10-02 13:01:30,830 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:01:30,831 (MainThread): Encountered an error:
2019-10-02 13:01:30,832 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:01:30,832 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table
2019-10-02 13:01:30,851 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', '|', 'booking_version') -- bk in the target table

2019-10-02 13:02:15,763 (MainThread): Tracking: tracking
2019-10-02 13:02:15,765 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000000000497E8C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC4C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005737B08>]}
2019-10-02 13:02:16,051 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:16,053 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60726), raddr=('54.174.31.151', 443)>

2019-10-02 13:02:16,058 (MainThread): Error sending message, disabling tracking
2019-10-02 13:02:16,110 (MainThread): Parsing macros\core.sql
2019-10-02 13:02:16,118 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:02:16,152 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:02:16,162 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:02:16,165 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:02:16,168 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:02:16,172 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:02:16,175 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:02:16,177 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:02:16,186 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:02:16,194 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:02:16,202 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:02:16,219 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:02:16,239 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:02:16,242 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:02:16,255 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:02:16,262 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:02:16,268 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:02:16,275 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:02:16,278 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:02:16,280 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:02:16,282 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:02:16,285 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:02:16,298 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:02:16,301 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:02:16,310 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:02:16,313 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:02:16,317 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:02:16,347 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:02:16,349 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:02:16,349 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:02:16,351 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:02:16,589 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:02:16,607 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:02:17,755 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:02:17,756 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:02:17,756 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:02:17,761 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:02:17,762 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:02:17,762 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:02:17,766 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:02:17,767 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:02:17,767 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:02:17,773 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:02:17,774 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:02:17,774 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:02:17,778 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:02:17,779 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:02:17,780 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:02:17,784 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:02:17,785 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:02:17,786 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:02:17,790 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:02:17,791 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:02:17,791 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:02:17,796 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:02:17,797 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:02:17,797 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:02:17,803 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:02:17,804 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:02:17,804 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:02:17,809 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:02:17,810 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:02:17,810 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:02:17,814 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:02:17,815 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:02:17,816 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:02:17,821 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:02:17,822 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:02:17,822 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:02:17,826 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:02:17,827 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:02:17,827 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:02:17,832 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:02:17,833 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:02:17,833 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:02:17,838 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:02:17,839 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:02:17,839 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:02:17,843 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:02:17,844 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:02:17,844 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:02:17,849 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:02:17,850 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:02:17,850 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:02:17,856 (MainThread): Flushing usage events
2019-10-02 13:02:17,856 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:17,856 (MainThread): Encountered an error:
2019-10-02 13:02:17,856 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:17,857 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, '|', booking_version) -- bk in the target table
2019-10-02 13:02:17,869 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat(sk_booking_id, '|', booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, '|', booking_version) -- bk in the target table

2019-10-02 13:02:49,503 (MainThread): Tracking: tracking
2019-10-02 13:02:49,505 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C910C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6BE08>]}
2019-10-02 13:02:49,855 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:49,856 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60737), raddr=('54.164.98.48', 443)>

2019-10-02 13:02:49,857 (MainThread): Error sending message, disabling tracking
2019-10-02 13:02:49,891 (MainThread): Parsing macros\core.sql
2019-10-02 13:02:49,903 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:02:49,945 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:02:49,955 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:02:49,957 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:02:49,960 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:02:49,964 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:02:49,967 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:02:49,970 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:02:49,979 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:02:49,987 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:02:49,996 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:02:50,013 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:02:50,034 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:02:50,037 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:02:50,050 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:02:50,056 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:02:50,062 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:02:50,069 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:02:50,071 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:02:50,073 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:02:50,075 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:02:50,078 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:02:50,093 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:02:50,098 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:02:50,106 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:02:50,109 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:02:50,113 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:02:50,140 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:02:50,142 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:02:50,142 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:02:50,145 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:02:50,417 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:02:50,434 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:02:51,321 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:02:51,322 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:02:51,322 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:02:51,326 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:02:51,327 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:02:51,327 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:02:51,331 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:02:51,332 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:02:51,332 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:02:51,338 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:02:51,339 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:02:51,339 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:02:51,343 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:02:51,344 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:02:51,344 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:02:51,349 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:02:51,350 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:02:51,350 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:02:51,355 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:02:51,356 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:02:51,356 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:02:51,360 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:02:51,361 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:02:51,361 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:02:51,366 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:02:51,367 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:02:51,368 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:02:51,373 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:02:51,374 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:02:51,374 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:02:51,378 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:02:51,379 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:02:51,379 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:02:51,383 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:02:51,384 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:02:51,385 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:02:51,390 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:02:51,391 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:02:51,391 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:02:51,395 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:02:51,396 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:02:51,396 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:02:51,401 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:02:51,402 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:02:51,402 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:02:51,408 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:02:51,409 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:02:51,409 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:02:51,414 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:02:51,415 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:02:51,415 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:02:51,420 (MainThread): Flushing usage events
2019-10-02 13:02:51,421 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:51,421 (MainThread): Encountered an error:
2019-10-02 13:02:51,421 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:02:51,421 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table
2019-10-02 13:02:51,432 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat(sk_booking_id, booking_version) -- bk in the target table

2019-10-02 13:04:04,077 (MainThread): Tracking: tracking
2019-10-02 13:04:04,083 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC648>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B908>]}
2019-10-02 13:04:04,408 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:04,409 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60804), raddr=('54.164.98.48', 443)>

2019-10-02 13:04:04,412 (MainThread): Error sending message, disabling tracking
2019-10-02 13:04:04,449 (MainThread): Parsing macros\core.sql
2019-10-02 13:04:04,458 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:04:04,494 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:04:04,504 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:04:04,506 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:04:04,509 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:04:04,512 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:04:04,515 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:04:04,518 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:04:04,526 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:04:04,535 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:04:04,544 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:04:04,560 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:04:04,581 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:04:04,584 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:04:04,598 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:04:04,606 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:04:04,612 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:04:04,619 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:04:04,622 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:04:04,624 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:04:04,626 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:04:04,629 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:04:04,642 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:04:04,645 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:04:04,654 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:04:04,657 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:04:04,662 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:04:04,690 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:04:04,692 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:04:04,692 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:04:04,694 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:04:04,948 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:04:04,963 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:04:05,636 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:04:05,637 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:04:05,637 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:04:05,641 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:04:05,642 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:04:05,642 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:04:05,647 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:04:05,648 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:04:05,648 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:04:05,652 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:04:05,653 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:04:05,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:04:05,658 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:04:05,660 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:04:05,660 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:04:05,666 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:04:05,667 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:04:05,667 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:04:05,671 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:04:05,672 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:04:05,672 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:04:05,677 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:04:05,678 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:04:05,678 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:04:05,683 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:04:05,684 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:04:05,684 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:04:05,689 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:04:05,690 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:04:05,690 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:04:05,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:04:05,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:04:05,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:04:05,701 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:04:05,702 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:04:05,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:04:05,707 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:04:05,708 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:04:05,708 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:04:05,713 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:04:05,714 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:04:05,714 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:04:05,718 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:04:05,720 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:04:05,720 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:04:05,724 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:04:05,725 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:04:05,726 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:04:05,730 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:04:05,731 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:04:05,731 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:04:05,737 (MainThread): Flushing usage events
2019-10-02 13:04:05,737 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:05,737 (MainThread): Encountered an error:
2019-10-02 13:04:05,738 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:05,738 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', 'booking_version') -- bk in the target table
2019-10-02 13:04:05,751 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key=concat('sk_booking_id', 'booking_version') -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key=concat('sk_booking_id', 'booking_version') -- bk in the target table

2019-10-02 13:04:31,188 (MainThread): Tracking: tracking
2019-10-02 13:04:31,190 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92988>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B688>]}
2019-10-02 13:04:31,479 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:31,481 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60812), raddr=('54.164.98.48', 443)>

2019-10-02 13:04:31,487 (MainThread): Error sending message, disabling tracking
2019-10-02 13:04:31,534 (MainThread): Parsing macros\core.sql
2019-10-02 13:04:31,543 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:04:31,582 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:04:31,593 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:04:31,595 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:04:31,598 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:04:31,602 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:04:31,605 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:04:31,607 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:04:31,616 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:04:31,624 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:04:31,632 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:04:31,649 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:04:31,671 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:04:31,674 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:04:31,688 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:04:31,694 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:04:31,700 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:04:31,707 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:04:31,710 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:04:31,712 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:04:31,714 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:04:31,717 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:04:31,730 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:04:31,734 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:04:31,742 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:04:31,745 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:04:31,749 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:04:31,778 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:04:31,779 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:04:31,779 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:04:31,781 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:04:32,069 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:04:32,093 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:04:32,618 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:04:32,619 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:04:32,619 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:04:32,624 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:04:32,625 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:04:32,625 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:04:32,629 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:04:32,630 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:04:32,630 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:04:32,634 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:04:32,636 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:04:32,636 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:04:32,641 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:04:32,642 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:04:32,642 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:04:32,647 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:04:32,648 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:04:32,648 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:04:32,653 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:04:32,654 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:04:32,654 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:04:32,659 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:04:32,660 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:04:32,660 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:04:32,666 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:04:32,667 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:04:32,667 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:04:32,672 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:04:32,673 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:04:32,673 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:04:32,678 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:04:32,679 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:04:32,679 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:04:32,683 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:04:32,684 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:04:32,684 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:04:32,689 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:04:32,690 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:04:32,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:04:32,695 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:04:32,696 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:04:32,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:04:32,701 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:04:32,702 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:04:32,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:04:32,707 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:04:32,708 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:04:32,708 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:04:32,713 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:04:32,714 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:04:32,714 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:04:32,719 (MainThread): Flushing usage events
2019-10-02 13:04:32,719 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:32,719 (MainThread): Encountered an error:
2019-10-02 13:04:32,720 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:04:32,720 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_id' -- bk in the target table
2019-10-02 13:04:32,731 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_id' -- bk in the target table

2019-10-02 13:05:05,095 (MainThread): Tracking: tracking
2019-10-02 13:05:05,097 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004938248>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E248>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B6C8>]}
2019-10-02 13:05:05,384 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:05,386 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60820), raddr=('54.164.98.48', 443)>

2019-10-02 13:05:05,392 (MainThread): Error sending message, disabling tracking
2019-10-02 13:05:05,451 (MainThread): Parsing macros\core.sql
2019-10-02 13:05:05,462 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:05:05,503 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:05:05,513 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:05:05,515 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:05:05,519 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:05:05,523 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:05:05,525 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:05:05,528 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:05:05,537 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:05:05,545 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:05:05,554 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:05:05,572 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:05:05,593 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:05:05,596 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:05:05,609 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:05:05,616 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:05:05,623 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:05:05,629 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:05:05,632 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:05:05,634 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:05:05,637 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:05:05,640 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:05:05,654 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:05:05,657 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:05:05,666 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:05:05,669 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:05:05,674 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:05:05,701 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:05:05,703 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:05:05,703 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:05:05,705 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:05:05,946 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:05:05,962 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:05:06,640 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:05:06,641 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:05:06,641 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:05:06,646 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:05:06,647 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:05:06,647 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:05:06,652 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:05:06,653 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:05:06,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:05:06,658 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:05:06,659 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:05:06,659 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:05:06,664 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:05:06,665 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:05:06,666 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:05:06,670 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:05:06,671 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:05:06,671 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:05:06,676 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:05:06,677 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:05:06,677 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:05:06,681 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:05:06,682 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:05:06,682 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:05:06,687 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:05:06,688 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:05:06,688 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:05:06,693 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:05:06,694 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:05:06,694 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:05:06,698 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:05:06,699 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:05:06,699 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:05:06,705 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:05:06,706 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:05:06,706 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:05:06,711 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:05:06,712 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:05:06,712 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:05:06,717 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:05:06,718 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:05:06,718 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:05:06,723 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:05:06,723 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:05:06,724 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:05:06,728 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:05:06,729 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:05:06,729 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:05:06,734 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:05:06,735 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:05:06,735 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:05:06,745 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:05:06,746 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:05:06,746 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:05:06,751 (MainThread): Flushing usage events
2019-10-02 13:05:06,751 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:06,751 (MainThread): Encountered an error:
2019-10-02 13:05:06,752 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:06,752 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:05:06,764 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:05:32,509 (MainThread): Tracking: tracking
2019-10-02 13:05:32,511 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004933D88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92808>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C848>]}
2019-10-02 13:05:32,797 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:32,799 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60829), raddr=('54.164.98.48', 443)>

2019-10-02 13:05:32,803 (MainThread): Error sending message, disabling tracking
2019-10-02 13:05:32,852 (MainThread): Parsing macros\core.sql
2019-10-02 13:05:32,862 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:05:32,908 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:05:32,931 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:05:32,935 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:05:32,941 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:05:32,947 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:05:32,952 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:05:32,955 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:05:32,966 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:05:32,976 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:05:32,988 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:05:33,008 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:05:33,034 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:05:33,040 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:05:33,054 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:05:33,061 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:05:33,067 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:05:33,074 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:05:33,077 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:05:33,080 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:05:33,082 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:05:33,087 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:05:33,118 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:05:33,124 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:05:33,138 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:05:33,142 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:05:33,150 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:05:33,197 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:05:33,200 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:05:33,200 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:05:33,204 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:05:33,453 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:05:33,472 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:05:33,949 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:05:33,950 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:05:33,950 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:05:33,954 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:05:33,955 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:05:33,955 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:05:33,960 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:05:33,961 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:05:33,961 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:05:33,966 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:05:33,967 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:05:33,967 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:05:33,972 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:05:33,972 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:05:33,973 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:05:33,978 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:05:33,979 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:05:33,979 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:05:33,984 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:05:33,985 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:05:33,985 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:05:33,990 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:05:33,991 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:05:33,991 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:05:33,996 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:05:33,997 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:05:33,997 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:05:34,002 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:05:34,003 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:05:34,003 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:05:34,007 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:05:34,008 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:05:34,009 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:05:34,013 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:05:34,014 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:05:34,014 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:05:34,019 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:05:34,019 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:05:34,020 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:05:34,024 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:05:34,025 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:05:34,025 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:05:34,030 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:05:34,031 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:05:34,031 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:05:34,036 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:05:34,037 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:05:34,037 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:05:34,043 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:05:34,044 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:05:34,044 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:05:34,053 (MainThread): dbt encountered an undefined variable, "sk_booking_id" in node dbt_test.with_fl_acr_booking (source path: C:\Users\EXTMB2\github\dbt_test\models\with_fl_acr_booking.sql)
2019-10-02 13:05:34,053 (MainThread): Flushing usage events
2019-10-02 13:05:34,054 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:34,054 (MainThread): Encountered an error:
2019-10-02 13:05:34,055 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:34,055 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined
2019-10-02 13:05:34,103 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 278, in parse_node
    self._update_parsed_node_info(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 210, in _update_parsed_node_info
    model_tags = config.config.get('tags', [])
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 81, in config
    self.in_model_config)
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 44, in _merge
    merged_config.copy(), config.copy()
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 193, in deep_merge
    last = copy.deepcopy(lst.pop(len(lst) - 1))
  File "c:\python\python37\lib\copy.py", line 150, in deepcopy
    y = copier(x, memo)
  File "c:\python\python37\lib\copy.py", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "c:\python\python37\lib\copy.py", line 161, in deepcopy
    y = copier(memo)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 224, in __deepcopy__
    node=self.node
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined

2019-10-02 13:05:59,013 (MainThread): Tracking: tracking
2019-10-02 13:05:59,014 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C942C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91AC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DB88>]}
2019-10-02 13:05:59,279 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:05:59,280 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60835), raddr=('54.164.98.48', 443)>

2019-10-02 13:05:59,284 (MainThread): Error sending message, disabling tracking
2019-10-02 13:05:59,332 (MainThread): Parsing macros\core.sql
2019-10-02 13:05:59,341 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:05:59,378 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:05:59,389 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:05:59,391 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:05:59,394 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:05:59,398 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:05:59,400 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:05:59,404 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:05:59,412 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:05:59,421 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:05:59,429 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:05:59,446 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:05:59,468 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:05:59,472 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:05:59,487 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:05:59,496 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:05:59,503 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:05:59,512 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:05:59,514 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:05:59,516 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:05:59,519 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:05:59,522 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:05:59,539 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:05:59,543 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:05:59,552 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:05:59,557 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:05:59,561 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:05:59,598 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:05:59,601 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:05:59,602 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:05:59,606 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:05:59,855 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:05:59,877 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:00,384 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:00,385 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:00,385 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:00,390 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:00,391 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:00,391 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:00,395 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:00,396 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:00,397 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:00,402 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:00,404 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:00,404 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:00,414 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:00,415 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:00,415 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:00,421 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:00,422 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:00,422 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:00,427 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:00,428 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:00,428 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:00,433 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:00,434 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:00,434 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:00,440 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:00,441 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:00,441 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:00,446 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:00,447 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:00,447 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:00,452 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:00,453 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:00,453 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:00,461 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:00,463 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:00,463 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:00,470 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:00,471 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:00,471 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:00,476 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:00,477 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:00,477 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:00,482 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:00,483 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:00,483 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:00,488 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:00,489 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:00,489 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:00,494 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:00,495 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:00,496 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:00,505 (MainThread): dbt encountered an undefined variable, "sk_booking_id" in node dbt_test.with_fl_acr_booking (source path: C:\Users\EXTMB2\github\dbt_test\models\with_fl_acr_booking.sql)
2019-10-02 13:06:00,506 (MainThread): Flushing usage events
2019-10-02 13:06:00,506 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:00,506 (MainThread): Encountered an error:
2019-10-02 13:06:00,506 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:00,507 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined
2019-10-02 13:06:00,517 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 278, in parse_node
    self._update_parsed_node_info(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 210, in _update_parsed_node_info
    model_tags = config.config.get('tags', [])
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 81, in config
    self.in_model_config)
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 44, in _merge
    merged_config.copy(), config.copy()
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 193, in deep_merge
    last = copy.deepcopy(lst.pop(len(lst) - 1))
  File "c:\python\python37\lib\copy.py", line 150, in deepcopy
    y = copier(x, memo)
  File "c:\python\python37\lib\copy.py", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "c:\python\python37\lib\copy.py", line 161, in deepcopy
    y = copier(memo)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 224, in __deepcopy__
    node=self.node
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined

2019-10-02 13:06:23,364 (MainThread): Tracking: tracking
2019-10-02 13:06:23,366 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC688>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC148>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91408>]}
2019-10-02 13:06:23,665 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:23,666 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60840), raddr=('54.174.31.151', 443)>

2019-10-02 13:06:23,669 (MainThread): Error sending message, disabling tracking
2019-10-02 13:06:23,708 (MainThread): Parsing macros\core.sql
2019-10-02 13:06:23,720 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:06:23,759 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:06:23,769 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:06:23,771 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:06:23,775 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:06:23,778 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:06:23,781 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:06:23,783 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:06:23,792 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:06:23,800 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:06:23,810 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:06:23,827 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:06:23,850 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:06:23,854 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:06:23,867 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:06:23,874 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:06:23,880 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:06:23,887 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:06:23,890 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:06:23,892 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:06:23,895 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:06:23,898 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:06:23,911 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:06:23,914 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:06:23,923 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:06:23,926 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:06:23,930 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:06:23,961 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:06:23,962 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:06:23,962 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:06:23,964 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:06:24,247 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:06:24,263 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:24,824 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:24,825 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:24,825 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:24,831 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:24,832 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:24,832 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:24,844 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:24,847 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:24,847 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:24,862 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:24,864 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:24,865 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:24,875 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:24,877 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:24,877 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:24,889 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:24,892 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:24,892 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:24,903 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:24,905 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:24,905 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:24,914 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:24,916 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:24,916 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:24,924 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:24,926 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:24,926 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:24,930 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:24,931 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:24,932 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:24,938 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:24,939 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:24,939 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:24,944 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:24,945 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:24,945 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:24,950 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:24,951 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:24,951 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:24,959 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:24,960 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:24,960 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:24,964 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:24,966 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:24,966 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:24,972 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:24,974 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:24,974 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:24,979 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:24,980 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:24,980 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:24,992 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:06:24,993 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:06:24,993 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:06:24,998 (MainThread): Flushing usage events
2019-10-02 13:06:24,998 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:24,998 (MainThread): Encountered an error:
2019-10-02 13:06:24,999 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:24,999 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:06:25,010 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:06:47,165 (MainThread): Tracking: tracking
2019-10-02 13:06:47,169 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E508>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B348>]}
2019-10-02 13:06:47,435 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:47,436 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60846), raddr=('54.174.31.151', 443)>

2019-10-02 13:06:47,437 (MainThread): Error sending message, disabling tracking
2019-10-02 13:06:47,460 (MainThread): Parsing macros\core.sql
2019-10-02 13:06:47,468 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:06:47,517 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:06:47,537 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:06:47,541 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:06:47,553 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:06:47,560 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:06:47,563 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:06:47,566 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:06:47,583 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:06:47,592 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:06:47,601 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:06:47,618 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:06:47,639 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:06:47,642 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:06:47,657 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:06:47,665 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:06:47,674 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:06:47,680 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:06:47,683 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:06:47,685 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:06:47,689 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:06:47,693 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:06:47,713 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:06:47,717 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:06:47,728 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:06:47,731 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:06:47,736 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:06:47,781 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:06:47,782 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:06:47,782 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:06:47,785 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:06:48,024 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:06:48,044 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:48,634 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:48,636 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:48,637 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:48,641 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:48,642 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:48,642 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:48,647 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:48,648 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:48,648 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:48,654 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:48,655 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:48,655 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:48,660 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:48,662 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:48,662 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:48,667 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:48,669 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:48,669 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:48,675 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:48,676 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:48,676 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:48,681 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:48,682 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:48,682 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:48,689 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:48,690 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:48,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:48,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:48,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:48,696 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:48,701 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:48,703 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:48,703 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:48,708 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:48,710 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:48,710 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:48,715 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:48,716 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:48,717 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:48,722 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:48,723 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:48,723 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:48,727 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:48,728 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:48,728 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:48,733 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:48,734 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:48,734 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:48,739 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:48,740 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:48,740 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:48,750 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:06:48,751 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:06:48,751 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:06:48,757 (MainThread): Flushing usage events
2019-10-02 13:06:48,757 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:48,757 (MainThread): Encountered an error:
2019-10-02 13:06:48,758 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:48,758 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:06:48,776 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:06:55,891 (MainThread): Tracking: tracking
2019-10-02 13:06:55,893 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004932BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C925C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DB08>]}
2019-10-02 13:06:56,177 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:56,179 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60850), raddr=('54.174.31.151', 443)>

2019-10-02 13:06:56,184 (MainThread): Error sending message, disabling tracking
2019-10-02 13:06:56,249 (MainThread): Parsing macros\core.sql
2019-10-02 13:06:56,257 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:06:56,295 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:06:56,305 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:06:56,307 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:06:56,311 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:06:56,315 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:06:56,318 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:06:56,320 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:06:56,328 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:06:56,337 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:06:56,345 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:06:56,362 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:06:56,382 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:06:56,385 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:06:56,399 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:06:56,405 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:06:56,412 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:06:56,418 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:06:56,421 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:06:56,423 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:06:56,426 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:06:56,429 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:06:56,442 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:06:56,445 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:06:56,453 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:06:56,456 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:06:56,460 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:06:56,489 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:06:56,490 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:06:56,490 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:06:56,493 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:06:56,743 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:06:56,761 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:06:57,343 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:06:57,344 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:06:57,344 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:06:57,349 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:06:57,350 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:06:57,350 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:06:57,355 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:06:57,356 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:06:57,356 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:06:57,361 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:06:57,361 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:06:57,362 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:06:57,366 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:06:57,367 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:06:57,367 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:06:57,372 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:06:57,373 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:06:57,373 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:06:57,378 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:06:57,379 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:06:57,379 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:06:57,383 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:06:57,384 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:06:57,384 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:06:57,390 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:06:57,391 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:06:57,391 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:06:57,396 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:06:57,397 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:06:57,397 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:06:57,402 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:06:57,403 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:06:57,403 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:06:57,407 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:06:57,408 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:06:57,408 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:06:57,413 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:06:57,414 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:06:57,414 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:06:57,418 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:06:57,420 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:06:57,420 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:06:57,424 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:06:57,425 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:06:57,425 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:06:57,430 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:06:57,431 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:06:57,431 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:06:57,436 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:06:57,437 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:06:57,438 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:06:57,446 (MainThread): dbt encountered an undefined variable, "sk_booking_id" in node dbt_test.with_fl_acr_booking (source path: C:\Users\EXTMB2\github\dbt_test\models\with_fl_acr_booking.sql)
2019-10-02 13:06:57,447 (MainThread): Flushing usage events
2019-10-02 13:06:57,447 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:57,447 (MainThread): Encountered an error:
2019-10-02 13:06:57,448 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:06:57,448 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined
2019-10-02 13:06:57,460 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 278, in parse_node
    self._update_parsed_node_info(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 210, in _update_parsed_node_info
    model_tags = config.config.get('tags', [])
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 81, in config
    self.in_model_config)
  File "c:\python\python37\lib\site-packages\dbt\parser\source_config.py", line 44, in _merge
    merged_config.copy(), config.copy()
  File "c:\python\python37\lib\site-packages\dbt\utils.py", line 193, in deep_merge
    last = copy.deepcopy(lst.pop(len(lst) - 1))
  File "c:\python\python37\lib\copy.py", line 150, in deepcopy
    y = copier(x, memo)
  File "c:\python\python37\lib\copy.py", line 240, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "c:\python\python37\lib\copy.py", line 161, in deepcopy
    y = copier(memo)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 224, in __deepcopy__
    node=self.node
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  'sk_booking_id' is undefined

2019-10-02 13:09:23,769 (MainThread): Tracking: tracking
2019-10-02 13:09:23,771 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C90308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C90288>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6CEC8>]}
2019-10-02 13:09:24,087 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:09:24,088 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60896), raddr=('54.174.31.151', 443)>

2019-10-02 13:09:24,090 (MainThread): Error sending message, disabling tracking
2019-10-02 13:09:24,132 (MainThread): Parsing macros\core.sql
2019-10-02 13:09:24,148 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:09:24,229 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:09:24,239 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:09:24,241 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:09:24,245 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:09:24,248 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:09:24,251 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:09:24,254 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:09:24,262 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:09:24,272 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:09:24,281 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:09:24,298 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:09:24,319 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:09:24,323 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:09:24,336 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:09:24,343 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:09:24,349 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:09:24,356 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:09:24,358 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:09:24,360 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:09:24,363 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:09:24,366 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:09:24,379 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:09:24,382 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:09:24,392 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:09:24,394 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:09:24,399 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:09:24,426 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:09:24,428 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:09:24,428 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:09:24,431 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:09:24,671 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:09:24,689 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:09:25,196 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:09:25,197 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:09:25,198 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:09:25,202 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:09:25,203 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:09:25,203 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:09:25,207 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:09:25,208 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:09:25,209 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:09:25,213 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:09:25,214 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:09:25,214 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:09:25,219 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:09:25,220 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:09:25,220 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:09:25,224 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:09:25,225 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:09:25,225 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:09:25,230 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:09:25,231 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:09:25,231 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:09:25,235 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:09:25,236 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:09:25,237 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:09:25,242 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:09:25,243 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:09:25,243 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:09:25,247 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:09:25,248 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:09:25,248 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:09:25,253 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:09:25,254 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:09:25,254 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:09:25,258 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:09:25,259 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:09:25,259 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:09:25,264 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:09:25,265 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:09:25,265 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:09:25,269 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:09:25,270 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:09:25,270 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:09:25,275 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:09:25,276 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:09:25,276 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:09:25,281 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:09:25,282 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:09:25,282 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:09:25,287 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:09:25,288 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:09:25,288 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:09:25,298 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:09:25,299 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:09:25,299 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:09:25,304 (MainThread): Flushing usage events
2019-10-02 13:09:25,304 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:09:25,304 (MainThread): Encountered an error:
2019-10-02 13:09:25,305 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:09:25,305 (MainThread): Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table
2019-10-02 13:09:25,318 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'target'
  line 4
    unique_key='sk_booking_service_id' -- bk in the target table

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
  expected token ',', got 'target'
    line 4
      unique_key='sk_booking_service_id' -- bk in the target table

2019-10-02 13:10:17,497 (MainThread): Tracking: tracking
2019-10-02 13:10:17,499 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93288>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8F548>]}
2019-10-02 13:10:17,783 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:17,786 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60903), raddr=('54.174.31.151', 443)>

2019-10-02 13:10:17,789 (MainThread): Error sending message, disabling tracking
2019-10-02 13:10:17,832 (MainThread): Parsing macros\core.sql
2019-10-02 13:10:17,844 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:10:17,881 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:10:17,890 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:10:17,893 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:10:17,896 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:10:17,899 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:10:17,902 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:10:17,904 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:10:17,912 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:10:17,921 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:10:17,929 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:10:17,946 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:10:17,968 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:10:17,971 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:10:17,985 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:10:17,992 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:10:17,998 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:10:18,006 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:10:18,008 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:10:18,011 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:10:18,013 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:10:18,016 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:10:18,029 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:10:18,032 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:10:18,041 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:10:18,044 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:10:18,048 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:10:18,077 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:10:18,079 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:10:18,079 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:10:18,081 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:10:18,319 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:10:18,337 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:10:18,993 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:10:18,994 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:10:18,994 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:10:18,998 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:10:18,999 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:10:18,999 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:10:19,005 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:10:19,006 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:10:19,006 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:10:19,011 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:10:19,012 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:10:19,012 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:10:19,016 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:10:19,017 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:10:19,018 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:10:19,023 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:10:19,024 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:10:19,024 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:10:19,033 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:10:19,036 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:10:19,037 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:10:19,048 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:10:19,051 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:10:19,051 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:10:19,061 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:10:19,063 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:10:19,063 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:10:19,072 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:10:19,074 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:10:19,075 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:10:19,083 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:10:19,084 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:10:19,085 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:10:19,093 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:10:19,095 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:10:19,095 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:10:19,101 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:10:19,102 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:10:19,102 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:10:19,111 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:10:19,112 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:10:19,112 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:10:19,117 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:10:19,118 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:10:19,118 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:10:19,127 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:10:19,128 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:10:19,129 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:10:19,138 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:10:19,140 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:10:19,140 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:10:19,148 (MainThread): Flushing usage events
2019-10-02 13:10:19,148 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:19,148 (MainThread): Encountered an error:
2019-10-02 13:10:19,149 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:19,149 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id
2019-10-02 13:10:19,163 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 500, in parse_math1
    right = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 541, in parse_unary
    node = nodes.Neg(self.parse_unary(False), lineno=lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 583, in parse_primary
    self.fail("unexpected '%s'" % describe_token(token), token.lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 59, in fail
    raise exc(msg, lineno, self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 4
    --,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id

2019-10-02 13:10:58,711 (MainThread): Tracking: tracking
2019-10-02 13:10:58,713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004972BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C933C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8F088>]}
2019-10-02 13:10:59,004 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:10:59,005 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60908), raddr=('54.174.31.151', 443)>

2019-10-02 13:10:59,006 (MainThread): Error sending message, disabling tracking
2019-10-02 13:10:59,030 (MainThread): Parsing macros\core.sql
2019-10-02 13:10:59,041 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:10:59,103 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:10:59,115 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:10:59,119 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:10:59,123 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:10:59,127 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:10:59,130 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:10:59,133 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:10:59,143 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:10:59,156 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:10:59,170 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:10:59,188 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:10:59,208 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:10:59,211 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:10:59,225 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:10:59,231 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:10:59,239 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:10:59,245 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:10:59,248 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:10:59,250 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:10:59,254 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:10:59,257 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:10:59,270 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:10:59,274 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:10:59,282 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:10:59,284 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:10:59,289 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:10:59,317 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:10:59,319 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:10:59,320 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:10:59,322 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:10:59,555 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:10:59,571 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:11:00,082 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:11:00,084 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:11:00,084 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:11:00,088 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:11:00,089 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:11:00,089 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:11:00,095 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:11:00,097 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:11:00,097 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:11:00,107 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:11:00,109 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:11:00,110 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:11:00,118 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:11:00,119 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:11:00,119 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:11:00,127 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:11:00,128 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:11:00,128 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:11:00,135 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:11:00,137 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:11:00,137 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:11:00,144 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:11:00,146 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:11:00,146 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:11:00,152 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:11:00,153 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:11:00,153 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:11:00,158 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:11:00,160 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:11:00,160 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:11:00,165 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:11:00,168 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:11:00,168 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:11:00,176 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:11:00,177 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:11:00,177 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:11:00,182 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:11:00,183 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:11:00,183 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:11:00,191 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:11:00,192 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:11:00,192 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:11:00,198 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:11:00,199 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:11:00,200 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:11:00,204 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:11:00,205 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:11:00,206 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:11:00,210 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:11:00,211 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:11:00,211 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:11:00,216 (MainThread): Flushing usage events
2019-10-02 13:11:00,217 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:00,217 (MainThread): Encountered an error:
2019-10-02 13:11:00,217 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:00,217 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id
2019-10-02 13:11:00,231 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 500, in parse_math1
    right = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 541, in parse_unary
    node = nodes.Neg(self.parse_unary(False), lineno=lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 583, in parse_primary
    self.fail("unexpected '%s'" % describe_token(token), token.lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 59, in fail
    raise exc(msg, lineno, self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 4
    --,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id

2019-10-02 13:11:28,222 (MainThread): Tracking: tracking
2019-10-02 13:11:28,223 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92088>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92788>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6C9C8>]}
2019-10-02 13:11:28,503 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:28,505 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60912), raddr=('54.174.31.151', 443)>

2019-10-02 13:11:28,510 (MainThread): Error sending message, disabling tracking
2019-10-02 13:11:28,576 (MainThread): Parsing macros\core.sql
2019-10-02 13:11:28,591 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:11:28,639 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:11:28,648 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:11:28,650 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:11:28,655 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:11:28,658 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:11:28,661 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:11:28,664 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:11:28,673 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:11:28,682 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:11:28,691 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:11:28,709 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:11:28,729 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:11:28,732 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:11:28,746 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:11:28,753 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:11:28,759 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:11:28,772 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:11:28,775 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:11:28,777 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:11:28,779 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:11:28,782 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:11:28,796 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:11:28,801 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:11:28,815 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:11:28,820 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:11:28,827 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:11:28,897 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:11:28,900 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:11:28,901 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:11:28,906 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:11:29,180 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:11:29,199 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:11:30,260 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:11:30,261 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:11:30,261 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:11:30,266 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:11:30,267 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:11:30,267 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:11:30,271 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:11:30,272 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:11:30,272 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:11:30,276 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:11:30,277 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:11:30,278 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:11:30,283 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:11:30,284 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:11:30,284 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:11:30,288 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:11:30,289 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:11:30,289 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:11:30,293 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:11:30,295 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:11:30,295 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:11:30,299 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:11:30,300 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:11:30,300 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:11:30,305 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:11:30,306 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:11:30,306 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:11:30,311 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:11:30,312 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:11:30,312 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:11:30,316 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:11:30,317 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:11:30,318 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:11:30,322 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:11:30,323 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:11:30,323 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:11:30,327 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:11:30,328 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:11:30,328 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:11:30,333 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:11:30,334 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:11:30,334 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:11:30,338 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:11:30,339 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:11:30,339 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:11:30,344 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:11:30,345 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:11:30,345 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:11:30,349 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:11:30,350 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:11:30,351 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:11:30,355 (MainThread): Flushing usage events
2019-10-02 13:11:30,356 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:30,356 (MainThread): Encountered an error:
2019-10-02 13:11:30,356 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:11:30,356 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id
2019-10-02 13:11:30,369 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 500, in parse_math1
    right = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 541, in parse_unary
    node = nodes.Neg(self.parse_unary(False), lineno=lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 583, in parse_primary
    self.fail("unexpected '%s'" % describe_token(token), token.lineno)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 59, in fail
    raise exc(msg, lineno, self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: unexpected ','
  line 4
    --,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected ','
    line 4
      --,unique_key=sk_booking_id

2019-10-02 13:13:52,101 (MainThread): Tracking: tracking
2019-10-02 13:13:52,104 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C94348>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C94188>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C86A88>]}
2019-10-02 13:13:52,419 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:13:52,421 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60958), raddr=('54.164.98.48', 443)>

2019-10-02 13:13:52,426 (MainThread): Error sending message, disabling tracking
2019-10-02 13:13:52,476 (MainThread): Parsing macros\core.sql
2019-10-02 13:13:52,484 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:13:52,523 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:13:52,533 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:13:52,535 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:13:52,539 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:13:52,542 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:13:52,545 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:13:52,548 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:13:52,557 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:13:52,565 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:13:52,574 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:13:52,591 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:13:52,614 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:13:52,617 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:13:52,632 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:13:52,640 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:13:52,647 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:13:52,662 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:13:52,667 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:13:52,672 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:13:52,677 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:13:52,683 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:13:52,717 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:13:52,722 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:13:52,730 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:13:52,732 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:13:52,737 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:13:52,765 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:13:52,774 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:13:52,774 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:13:52,776 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:13:53,025 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:13:53,048 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:13:53,587 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:13:53,588 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:13:53,588 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:13:53,593 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:13:53,594 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:13:53,594 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:13:53,599 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:13:53,600 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:13:53,600 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:13:53,605 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:13:53,606 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:13:53,606 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:13:53,610 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:13:53,611 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:13:53,612 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:13:53,616 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:13:53,617 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:13:53,618 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:13:53,622 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:13:53,623 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:13:53,623 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:13:53,628 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:13:53,629 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:13:53,629 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:13:53,634 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:13:53,635 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:13:53,635 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:13:53,639 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:13:53,640 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:13:53,640 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:13:53,645 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:13:53,646 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:13:53,646 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:13:53,651 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:13:53,652 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:13:53,653 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:13:53,657 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:13:53,658 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:13:53,658 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:13:53,663 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:13:53,664 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:13:53,664 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:13:53,669 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:13:53,670 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:13:53,670 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:13:53,675 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:13:53,676 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:13:53,676 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:13:53,681 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:13:53,682 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:13:53,682 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:13:53,687 (MainThread): Flushing usage events
2019-10-02 13:13:53,688 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:13:53,688 (MainThread): Encountered an error:
2019-10-02 13:13:53,688 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:13:53,688 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      # ,unique_key=sk_booking_id#
2019-10-02 13:13:53,704 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 564, in parse_primary
    next(self.stream)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 359, in __next__
    self.current = next(self._iter)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 562, in wrap
    for lineno, token, value in stream:
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 739, in tokeniter
    name, filename)
jinja2.exceptions.TemplateSyntaxError: unexpected char '#' at 48
  line 4
    # ,unique_key=sk_booking_id#

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      # ,unique_key=sk_booking_id#

2019-10-02 13:14:18,787 (MainThread): Tracking: tracking
2019-10-02 13:14:18,789 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C92908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C927C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C922C8>]}
2019-10-02 13:14:19,075 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:14:19,077 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 60964), raddr=('54.164.98.48', 443)>

2019-10-02 13:14:19,080 (MainThread): Error sending message, disabling tracking
2019-10-02 13:14:19,128 (MainThread): Parsing macros\core.sql
2019-10-02 13:14:19,139 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:14:19,178 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:14:19,189 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:14:19,191 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:14:19,194 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:14:19,198 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:14:19,201 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:14:19,204 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:14:19,212 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:14:19,221 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:14:19,229 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:14:19,246 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:14:19,268 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:14:19,271 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:14:19,283 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:14:19,290 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:14:19,296 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:14:19,303 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:14:19,306 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:14:19,308 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:14:19,310 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:14:19,313 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:14:19,326 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:14:19,329 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:14:19,338 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:14:19,340 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:14:19,345 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:14:19,375 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:14:19,377 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:14:19,377 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:14:19,379 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:14:19,630 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:14:19,651 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:14:20,176 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:14:20,177 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:14:20,177 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:14:20,182 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:14:20,183 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:14:20,183 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:14:20,189 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:14:20,189 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:14:20,190 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:14:20,194 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:14:20,195 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:14:20,195 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:14:20,200 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:14:20,201 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:14:20,201 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:14:20,206 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:14:20,207 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:14:20,207 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:14:20,211 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:14:20,212 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:14:20,212 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:14:20,217 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:14:20,219 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:14:20,219 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:14:20,224 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:14:20,226 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:14:20,226 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:14:20,230 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:14:20,231 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:14:20,231 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:14:20,236 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:14:20,237 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:14:20,237 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:14:20,241 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:14:20,242 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:14:20,242 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:14:20,246 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:14:20,247 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:14:20,248 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:14:20,252 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:14:20,253 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:14:20,253 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:14:20,257 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:14:20,258 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:14:20,259 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:14:20,263 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:14:20,264 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:14:20,264 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:14:20,269 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:14:20,270 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:14:20,270 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:14:20,275 (MainThread): Flushing usage events
2019-10-02 13:14:20,275 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:14:20,275 (MainThread): Encountered an error:
2019-10-02 13:14:20,276 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:14:20,276 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got '{'
    line 4
      {# ,unique_key=sk_booking_id #}
2019-10-02 13:14:20,290 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 767, in parse_call
    self.stream.expect('comma')
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 384, in expect
    self.name, self.filename)
jinja2.exceptions.TemplateSyntaxError: expected token ',', got '{'
  line 4
    {# ,unique_key=sk_booking_id #}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  expected token ',', got '{'
    line 4
      {# ,unique_key=sk_booking_id #}

2019-10-02 13:15:11,327 (MainThread): Tracking: tracking
2019-10-02 13:15:11,329 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C938C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DD48>]}
2019-10-02 13:15:11,653 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:11,654 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61012), raddr=('54.164.98.48', 443)>

2019-10-02 13:15:11,656 (MainThread): Error sending message, disabling tracking
2019-10-02 13:15:11,688 (MainThread): Parsing macros\core.sql
2019-10-02 13:15:11,698 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:15:11,739 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:15:11,749 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:15:11,752 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:15:11,755 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:15:11,759 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:15:11,762 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:15:11,764 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:15:11,773 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:15:11,781 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:15:11,790 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:15:11,807 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:15:11,828 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:15:11,831 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:15:11,845 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:15:11,852 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:15:11,858 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:15:11,865 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:15:11,868 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:15:11,870 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:15:11,873 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:15:11,876 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:15:11,889 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:15:11,892 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:15:11,900 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:15:11,904 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:15:11,909 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:15:11,937 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:15:11,939 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:15:11,939 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:15:11,941 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:15:12,173 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:15:12,191 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:15:12,758 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:15:12,759 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:15:12,759 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:15:12,763 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:15:12,764 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:15:12,764 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:15:12,769 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:15:12,770 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:15:12,770 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:15:12,774 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:15:12,775 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:15:12,775 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:15:12,787 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:15:12,788 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:15:12,788 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:15:12,796 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:15:12,798 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:15:12,798 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:15:12,808 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:15:12,811 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:15:12,811 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:15:12,819 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:15:12,822 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:15:12,822 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:15:12,829 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:15:12,830 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:15:12,830 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:15:12,835 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:15:12,837 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:15:12,837 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:15:12,843 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:15:12,844 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:15:12,844 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:15:12,848 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:15:12,849 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:15:12,850 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:15:12,855 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:15:12,856 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:15:12,856 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:15:12,861 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:15:12,862 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:15:12,862 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:15:12,873 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:15:12,875 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:15:12,875 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:15:12,889 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:15:12,891 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:15:12,892 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:15:12,902 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:15:12,905 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:12,905 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:15:12,914 (MainThread): Flushing usage events
2019-10-02 13:15:12,914 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:97: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:12,915 (MainThread): Encountered an error:
2019-10-02 13:15:12,915 (MainThread): c:\python\python37\lib\site-packages\dbt\main.py:98: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:12,915 (MainThread): Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      ## ,unique_key=sk_booking_id
2019-10-02 13:15:12,934 (MainThread): Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 279, in get_template
    return env.from_string(template_source, globals=ctx)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 880, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 591, in compile
    self.handle_exception(exc_info, source_hint=source_hint)
  File "c:\python\python37\lib\site-packages\jinja2\environment.py", line 780, in handle_exception
    reraise(exc_type, exc_value, tb)
  File "c:\python\python37\lib\site-packages\jinja2\_compat.py", line 37, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 4, in template
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 70, in _parse
    jinja2._compat.encode_filename(filename)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 901, in parse
    result = nodes.Template(self.subparse(), lineno=1)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 875, in subparse
    add_data(self.parse_tuple(with_condexpr=True))
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 620, in parse_tuple
    args.append(parse())
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 547, in parse_unary
    node = self.parse_postfix(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 676, in parse_postfix
    node = self.parse_call(node)
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 785, in parse_call
    value = self.parse_expression()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 432, in parse_expression
    return self.parse_condexpr()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 437, in parse_condexpr
    expr1 = self.parse_or()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 450, in parse_or
    left = self.parse_and()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 459, in parse_and
    left = self.parse_not()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 470, in parse_not
    return self.parse_compare()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 474, in parse_compare
    expr = self.parse_math1()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 496, in parse_math1
    left = self.parse_concat()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 507, in parse_concat
    args = [self.parse_math2()]
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 517, in parse_math2
    left = self.parse_pow()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 528, in parse_pow
    left = self.parse_unary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 546, in parse_unary
    node = self.parse_primary()
  File "c:\python\python37\lib\site-packages\jinja2\parser.py", line 564, in parse_primary
    next(self.stream)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 359, in __next__
    self.current = next(self._iter)
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 562, in wrap
    for lineno, token, value in stream:
  File "c:\python\python37\lib\site-packages\jinja2\lexer.py", line 739, in tokeniter
    name, filename)
jinja2.exceptions.TemplateSyntaxError: unexpected char '#' at 48
  line 4
    ## ,unique_key=sk_booking_id

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 82, in main
    results, succeeded = handle_and_check(args)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 151, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\python\python37\lib\site-packages\dbt\main.py", line 216, in run_from_args
    results = task.run()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 272, in run
    self._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 68, in _runtime_initialize
    super(GraphRunnableTask, self)._runtime_initialize()
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 46, in _runtime_initialize
    self.manifest = load_manifest(self.config)
  File "c:\python\python37\lib\site-packages\dbt\task\runnable.py", line 33, in load_manifest
    internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 170, in load_all
    internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 163, in _load_from_projects
    loader.load(internal_manifest=internal_manifest)
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 136, in load
    self._load_nodes()
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 77, in _load_nodes
    self._load_sql_nodes(ModelParser, NodeType.Model, 'source_paths')
  File "c:\python\python37\lib\site-packages\dbt\loader.py", line 42, in _load_sql_nodes
    **kwargs
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 64, in load_and_parse
    return self.parse_sql_nodes(result, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 102, in parse_sql_nodes
    node_path, node_parsed = self.parse_sql_node(n, tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base_sql.py", line 85, in parse_sql_node
    node_parsed = self.parse_node(node, unique_id, project, tags=tags)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 277, in parse_node
    self._render_with_context(parsed_node, config)
  File "c:\python\python37\lib\site-packages\dbt\parser\base.py", line 202, in _render_with_context
    capture_macros=True)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 300, in get_rendered
    capture_macros=capture_macros)
  File "c:\python\python37\lib\site-packages\dbt\clients\jinja.py", line 284, in get_template
    dbt.exceptions.raise_compiler_error(str(e), node)
  File "c:\python\python37\lib\site-packages\dbt\exceptions.py", line 286, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
  unexpected char '#' at 48
    line 4
      ## ,unique_key=sk_booking_id

2019-10-02 13:15:52,083 (MainThread): Tracking: tracking
2019-10-02 13:15:52,085 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000004938748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91948>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C6DA48>]}
2019-10-02 13:15:52,349 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:15:52,352 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61016), raddr=('54.164.98.48', 443)>

2019-10-02 13:15:52,357 (MainThread): Error sending message, disabling tracking
2019-10-02 13:15:52,411 (MainThread): Parsing macros\core.sql
2019-10-02 13:15:52,419 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:15:52,458 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:15:52,467 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:15:52,470 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:15:52,473 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:15:52,477 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:15:52,480 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:15:52,482 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:15:52,492 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:15:52,500 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:15:52,510 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:15:52,527 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:15:52,548 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:15:52,551 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:15:52,564 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:15:52,572 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:15:52,578 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:15:52,585 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:15:52,588 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:15:52,590 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:15:52,593 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:15:52,596 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:15:52,610 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:15:52,613 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:15:52,622 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:15:52,625 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:15:52,629 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:15:52,659 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:15:52,660 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:15:52,660 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:15:52,662 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:15:52,938 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:15:52,961 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:15:53,562 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:15:53,563 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:15:53,563 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:15:53,568 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:15:53,569 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:15:53,570 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:15:53,574 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:15:53,575 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:15:53,575 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:15:53,580 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:15:53,581 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:15:53,581 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:15:53,587 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:15:53,588 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:15:53,588 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:15:53,593 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:15:53,593 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:15:53,594 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:15:53,598 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:15:53,599 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:15:53,599 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:15:53,605 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:15:53,606 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:15:53,606 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:15:53,611 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:15:53,612 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:15:53,612 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:15:53,617 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:15:53,618 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:15:53,619 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:15:53,624 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:15:53,625 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:15:53,625 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:15:53,630 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:15:53,631 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:15:53,631 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:15:53,636 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:15:53,637 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:15:53,637 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:15:53,642 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:15:53,643 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:15:53,643 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:15:53,648 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:15:53,649 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:15:53,649 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:15:53,654 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:15:53,655 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:15:53,655 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:15:53,660 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:15:53,661 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:53,661 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:15:53,672 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:15:53,673 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:53,674 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:15:53,679 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:15:53,680 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:15:53,680 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:15:53,685 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:15:53,686 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:15:53,687 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:15:53,755 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:15:53,758 (MainThread): 
2019-10-02 13:15:53,759 (MainThread): 13:15:53 | Concurrency: 1 threads (target='dev')
2019-10-02 13:15:53,760 (MainThread): 13:15:53 | 
2019-10-02 13:15:53,773 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:15:53,774 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:15:54,287 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:15:54,304 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:15:54,310 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:15:54,313 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:15:54,314 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:15:54,322 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:15:54,328 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:15:54,330 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:15:54,330 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:15:54,335 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:15:54,340 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:15:54,342 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:15:54,342 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:15:54,349 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:15:54,355 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:15:54,357 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:15:54,358 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:15:54,366 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:15:54,376 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:15:54,380 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:15:54,381 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:15:54,392 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:15:54,400 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:15:54,400 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:15:54,405 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:15:54,417 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:15:54,427 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:15:54,427 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:15:54,432 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:15:54,445 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:15:54,454 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:15:54,457 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:15:54,458 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:15:54,466 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:15:54,474 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:15:54,474 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:15:54,477 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:15:54,488 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:15:54,496 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:15:54,496 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:15:54,497 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:15:54,510 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:15:54,517 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:15:54,520 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:15:54,521 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:15:54,530 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:15:54,537 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:15:54,540 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:15:54,540 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:15:54,548 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:15:54,555 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:15:54,557 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:15:54,558 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:15:54,568 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:15:54,575 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:15:54,578 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:15:54,579 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:15:54,588 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:15:54,594 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:54,597 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:15:54,598 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:15:54,607 (Thread-1): On "with_fl_acr_booking": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:15:54,649 (Thread-1): Parsing macros\core.sql
2019-10-02 13:15:54,664 (Thread-1): Parsing macros\adapters\common.sql
2019-10-02 13:15:54,742 (Thread-1): Parsing macros\etc\datetime.sql
2019-10-02 13:15:54,760 (Thread-1): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:15:54,763 (Thread-1): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:15:54,770 (Thread-1): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:15:54,776 (Thread-1): Parsing macros\etc\is_incremental.sql
2019-10-02 13:15:54,783 (Thread-1): Parsing macros\etc\query.sql
2019-10-02 13:15:54,788 (Thread-1): Parsing macros\materializations\helpers.sql
2019-10-02 13:15:54,809 (Thread-1): Parsing macros\materializations\common\merge.sql
2019-10-02 13:15:54,833 (Thread-1): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:15:54,858 (Thread-1): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:15:54,889 (Thread-1): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:15:54,925 (Thread-1): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:15:54,927 (Thread-1): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:15:54,950 (Thread-1): Parsing macros\materializations\table\table.sql
2019-10-02 13:15:54,961 (Thread-1): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:15:54,970 (Thread-1): Parsing macros\materializations\view\view.sql
2019-10-02 13:15:54,977 (Thread-1): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:15:54,983 (Thread-1): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:15:54,988 (Thread-1): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:15:54,992 (Thread-1): Parsing macros\schema_tests\unique.sql
2019-10-02 13:15:54,996 (Thread-1): Parsing macros\adapters.sql
2019-10-02 13:15:55,010 (Thread-1): Parsing macros\catalog.sql
2019-10-02 13:15:55,013 (Thread-1): Parsing macros\materializations\incremental.sql
2019-10-02 13:15:55,025 (Thread-1): Parsing macros\materializations\merge.sql
2019-10-02 13:15:55,030 (Thread-1): Parsing macros\materializations\table.sql
2019-10-02 13:15:55,043 (Thread-1): Parsing macros\materializations\view.sql
2019-10-02 13:15:55,270 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:55,270 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:15:55,383 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:15:55,383 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:15:55,383 (Thread-1): On with_fl_acr_booking: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:15:56,770 (Thread-1): SQL status: SUCCESS 1 in 1.39 seconds
2019-10-02 13:15:56,798 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:15:56,800 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:15:56,808 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:15:56,955 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:56,958 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:15:56,959 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:15:56,967 (Thread-1): On "with_fl_acr_booking_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:15:56,977 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:56,977 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:15:57,101 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:15:57,102 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:15:57,102 (Thread-1): On with_fl_acr_booking_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:15:58,412 (Thread-1): SQL status: SUCCESS 1 in 1.31 seconds
2019-10-02 13:15:58,419 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:15:58,425 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:15:58,440 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:15:58,583 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:15:58,583 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:15:58,584 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:15:58,596 (Thread-1): On "with_fl_acr_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:15:58,643 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:15:58,643 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:15:58,756 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:15:58,756 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:15:58,756 (Thread-1): On with_fl_acr_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:00,752 (Thread-1): SQL status: SUCCESS 1 in 2.00 seconds
2019-10-02 13:16:00,759 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:00,765 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:16:00,788 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:16:00,980 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:00,984 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:16:00,986 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:16:01,001 (Thread-1): On "with_fl_acr_service_element": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:01,010 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:01,010 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:16:01,137 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:16:01,137 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:01,138 (Thread-1): On with_fl_acr_service_element: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:02,432 (Thread-1): SQL status: SUCCESS 1 in 1.29 seconds
2019-10-02 13:16:02,439 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:02,446 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:16:02,461 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:16:02,621 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:16:02,624 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:16:02,625 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:16:02,635 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:16:02,642 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:16:02,643 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:16:02,643 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:16:03,925 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:16:04,026 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 13:16:04,027 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 13:16:04,106 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:16:04,107 (MainThread): On booking_fact_uk: Close
2019-10-02 13:16:04,298 (MainThread): 13:16:04 | Done.
2019-10-02 13:16:04,299 (MainThread): Flushing usage events
2019-10-02 13:16:21,259 (MainThread): Tracking: tracking
2019-10-02 13:16:21,261 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91F88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C91A48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E108>]}
2019-10-02 13:16:21,549 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:16:21,550 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61021), raddr=('54.164.98.48', 443)>

2019-10-02 13:16:21,553 (MainThread): Error sending message, disabling tracking
2019-10-02 13:16:21,591 (MainThread): Parsing macros\core.sql
2019-10-02 13:16:21,600 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:16:21,638 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:16:21,648 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:16:21,650 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:16:21,654 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:16:21,657 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:16:21,660 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:16:21,663 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:16:21,672 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:16:21,680 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:16:21,689 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:16:21,706 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:16:21,727 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:16:21,730 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:16:21,743 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:16:21,749 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:16:21,756 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:16:21,762 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:16:21,765 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:16:21,769 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:16:21,771 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:16:21,774 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:16:21,787 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:16:21,790 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:16:21,799 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:16:21,802 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:16:21,807 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:16:21,836 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:16:21,837 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:16:21,837 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:16:21,840 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:16:22,084 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:16:22,102 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:16:22,644 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:16:22,645 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:16:22,645 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:16:22,650 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:16:22,651 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:16:22,651 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:16:22,655 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:16:22,656 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:16:22,656 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:16:22,661 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:16:22,662 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:16:22,663 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:16:22,667 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:16:22,668 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:16:22,668 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:16:22,673 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:16:22,674 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:16:22,674 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:16:22,678 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:16:22,679 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:16:22,679 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:16:22,684 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:16:22,685 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:16:22,685 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:16:22,690 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:16:22,691 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:16:22,691 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:16:22,695 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:16:22,696 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:16:22,697 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:16:22,701 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:16:22,702 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:16:22,702 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:16:22,706 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:16:22,707 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:16:22,707 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:16:22,712 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:16:22,713 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:16:22,713 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:16:22,718 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:16:22,719 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:16:22,719 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:16:22,724 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:16:22,725 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:16:22,725 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:16:22,730 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:16:22,731 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:16:22,731 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:16:22,735 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:16:22,736 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:22,736 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:16:22,746 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:16:22,747 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:22,747 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:16:22,753 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:16:22,754 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:16:22,754 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:16:22,759 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:16:22,760 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:22,760 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:16:22,835 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:16:22,840 (MainThread): 
2019-10-02 13:16:22,841 (MainThread): 13:16:22 | Concurrency: 1 threads (target='dev')
2019-10-02 13:16:22,842 (MainThread): 13:16:22 | 
2019-10-02 13:16:22,851 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:16:22,852 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:16:23,293 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:16:23,299 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:16:23,304 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:16:23,306 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:16:23,307 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:16:23,311 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:16:23,316 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:16:23,319 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:16:23,319 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:16:23,324 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:16:23,330 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:16:23,330 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:16:23,330 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:16:23,335 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:16:23,341 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:16:23,342 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:16:23,342 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:16:23,347 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:16:23,354 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:16:23,354 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:16:23,355 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:16:23,363 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:16:23,370 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:16:23,370 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:16:23,371 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:16:23,382 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:16:23,386 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:16:23,386 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:16:23,387 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:16:23,395 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:16:23,400 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:16:23,400 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:16:23,400 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:16:23,409 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:16:23,413 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:16:23,416 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:16:23,416 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:16:23,427 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:16:23,437 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:16:23,438 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:16:23,443 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:16:23,450 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:16:23,457 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:16:23,457 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:16:23,458 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:16:23,475 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:16:23,482 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:16:23,483 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:16:23,486 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:16:23,494 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:16:23,501 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:16:23,501 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:16:23,502 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:16:23,516 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:16:23,527 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:16:23,531 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:16:23,533 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:16:23,546 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:16:23,554 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:23,554 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:16:23,558 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:16:23,568 (Thread-1): On "with_fl_acr_booking": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:23,616 (Thread-1): Parsing macros\core.sql
2019-10-02 13:16:23,624 (Thread-1): Parsing macros\adapters\common.sql
2019-10-02 13:16:23,689 (Thread-1): Parsing macros\etc\datetime.sql
2019-10-02 13:16:23,698 (Thread-1): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:16:23,701 (Thread-1): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:16:23,704 (Thread-1): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:16:23,708 (Thread-1): Parsing macros\etc\is_incremental.sql
2019-10-02 13:16:23,711 (Thread-1): Parsing macros\etc\query.sql
2019-10-02 13:16:23,713 (Thread-1): Parsing macros\materializations\helpers.sql
2019-10-02 13:16:23,731 (Thread-1): Parsing macros\materializations\common\merge.sql
2019-10-02 13:16:23,754 (Thread-1): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:16:23,765 (Thread-1): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:16:23,786 (Thread-1): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:16:23,819 (Thread-1): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:16:23,825 (Thread-1): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:16:23,861 (Thread-1): Parsing macros\materializations\table\table.sql
2019-10-02 13:16:23,878 (Thread-1): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:16:23,895 (Thread-1): Parsing macros\materializations\view\view.sql
2019-10-02 13:16:23,913 (Thread-1): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:16:23,917 (Thread-1): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:16:23,921 (Thread-1): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:16:23,925 (Thread-1): Parsing macros\schema_tests\unique.sql
2019-10-02 13:16:23,929 (Thread-1): Parsing macros\adapters.sql
2019-10-02 13:16:23,954 (Thread-1): Parsing macros\catalog.sql
2019-10-02 13:16:23,960 (Thread-1): Parsing macros\materializations\incremental.sql
2019-10-02 13:16:23,975 (Thread-1): Parsing macros\materializations\merge.sql
2019-10-02 13:16:23,980 (Thread-1): Parsing macros\materializations\table.sql
2019-10-02 13:16:23,987 (Thread-1): Parsing macros\materializations\view.sql
2019-10-02 13:16:24,188 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:24,188 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:16:24,288 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:16:24,290 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:16:24,290 (Thread-1): On with_fl_acr_booking: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:25,666 (Thread-1): SQL status: SUCCESS 1 in 1.37 seconds
2019-10-02 13:16:25,693 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:25,696 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:16:25,704 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:16:25,884 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:25,886 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:16:25,886 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:16:25,891 (Thread-1): On "with_fl_acr_booking_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:25,895 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:25,896 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:16:26,020 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:16:26,020 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:16:26,020 (Thread-1): On with_fl_acr_booking_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:27,355 (Thread-1): SQL status: SUCCESS 1 in 1.34 seconds
2019-10-02 13:16:27,357 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:27,359 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:16:27,366 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:16:27,675 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:16:27,678 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:16:27,679 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:16:27,694 (Thread-1): On "with_fl_acr_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:27,749 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:16:27,749 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:16:27,851 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:16:27,853 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:16:27,854 (Thread-1): On with_fl_acr_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:29,426 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2019-10-02 13:16:29,428 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:29,429 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:16:29,433 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:16:29,571 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:29,575 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:16:29,576 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:16:29,583 (Thread-1): On "with_fl_acr_service_element": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:16:29,589 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:29,590 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:16:29,681 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 13:16:29,682 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:16:29,682 (Thread-1): On with_fl_acr_service_element: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:16:31,489 (Thread-1): SQL status: SUCCESS 1 in 1.81 seconds
2019-10-02 13:16:31,492 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:16:31,495 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:16:31,501 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:16:31,632 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:16:31,633 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:16:31,634 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:16:31,639 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:16:31,645 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:16:31,648 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:16:31,649 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:16:33,172 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:16:33,261 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 13:16:33,262 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 13:16:33,336 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:16:33,337 (MainThread): On booking_fact_uk: Close
2019-10-02 13:16:33,494 (MainThread): 13:16:33 | Done.
2019-10-02 13:16:33,495 (MainThread): Flushing usage events
2019-10-02 13:17:06,889 (MainThread): Tracking: tracking
2019-10-02 13:17:06,891 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC308>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C90D08>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C80908>]}
2019-10-02 13:17:07,182 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:17:07,183 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61032), raddr=('54.164.98.48', 443)>

2019-10-02 13:17:07,186 (MainThread): Error sending message, disabling tracking
2019-10-02 13:17:07,233 (MainThread): Parsing macros\core.sql
2019-10-02 13:17:07,242 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:17:07,281 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:17:07,291 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:07,293 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:07,296 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:07,300 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:07,303 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:17:07,305 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:07,314 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:07,323 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:07,332 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:07,349 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:07,371 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:07,374 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:07,387 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:07,394 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:07,400 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:07,408 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:07,411 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:07,413 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:07,415 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:07,419 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:17:07,433 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:17:07,437 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:07,445 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:17:07,449 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:17:07,454 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:17:07,484 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:17:07,486 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:17:07,486 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:17:07,488 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:17:07,705 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:17:07,721 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:17:08,270 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:17:08,271 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:08,272 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:17:08,278 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:17:08,279 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:08,279 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:08,283 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:17:08,284 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:08,284 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:17:08,289 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:17:08,290 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:08,290 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:08,295 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:17:08,296 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:08,296 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:08,300 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:08,301 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:08,302 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:08,307 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:17:08,308 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:08,308 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:08,313 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:17:08,313 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:08,314 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:08,319 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:17:08,320 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:08,320 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:08,324 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:08,325 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:08,325 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:08,330 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:08,331 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:08,331 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:08,335 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:08,336 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:08,337 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:08,341 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:17:08,342 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:08,342 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:08,347 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:17:08,348 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:08,348 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:08,352 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:08,353 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:08,353 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:08,358 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:17:08,359 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:08,359 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:08,364 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:08,365 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:08,365 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:08,375 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:08,376 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:08,377 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:08,382 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:17:08,383 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:08,383 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:08,388 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:08,389 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:08,389 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:08,459 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:17:08,464 (MainThread): 
2019-10-02 13:17:08,465 (MainThread): 13:17:08 | Concurrency: 1 threads (target='dev')
2019-10-02 13:17:08,465 (MainThread): 13:17:08 | 
2019-10-02 13:17:08,475 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:08,476 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:17:08,968 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:17:08,975 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:17:08,980 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:08,982 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:08,983 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:17:08,988 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:17:08,992 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:08,994 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:08,994 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:17:08,999 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:17:09,005 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:09,005 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:09,007 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:17:09,013 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:17:09,017 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:09,017 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:09,018 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:09,024 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:17:09,034 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:09,034 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:09,035 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:17:09,047 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:17:09,054 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:09,056 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:09,057 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:17:09,068 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:17:09,075 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:09,075 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:09,080 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:17:09,094 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:17:09,101 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:09,102 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:09,103 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:09,113 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:17:09,123 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:09,124 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:09,125 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:09,137 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:17:09,144 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:09,146 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:09,146 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:09,156 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:17:09,166 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:09,171 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:09,172 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:17:09,185 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:17:09,194 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:09,194 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:09,195 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:17:09,209 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:17:09,218 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:09,219 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:09,223 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:09,235 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:17:09,244 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:09,244 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:09,245 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:17:09,258 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:17:09,265 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:09,267 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:09,267 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:09,275 (Thread-1): On "with_fl_acr_booking": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:09,299 (Thread-1): Parsing macros\core.sql
2019-10-02 13:17:09,308 (Thread-1): Parsing macros\adapters\common.sql
2019-10-02 13:17:09,391 (Thread-1): Parsing macros\etc\datetime.sql
2019-10-02 13:17:09,429 (Thread-1): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:09,437 (Thread-1): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:09,445 (Thread-1): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:09,454 (Thread-1): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:09,462 (Thread-1): Parsing macros\etc\query.sql
2019-10-02 13:17:09,467 (Thread-1): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:09,487 (Thread-1): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:09,505 (Thread-1): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:09,527 (Thread-1): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:09,573 (Thread-1): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:09,621 (Thread-1): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:09,625 (Thread-1): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:09,656 (Thread-1): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:09,671 (Thread-1): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:09,682 (Thread-1): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:09,699 (Thread-1): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:09,704 (Thread-1): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:09,709 (Thread-1): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:09,714 (Thread-1): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:09,718 (Thread-1): Parsing macros\adapters.sql
2019-10-02 13:17:09,743 (Thread-1): Parsing macros\catalog.sql
2019-10-02 13:17:09,749 (Thread-1): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:09,760 (Thread-1): Parsing macros\materializations\merge.sql
2019-10-02 13:17:09,765 (Thread-1): Parsing macros\materializations\table.sql
2019-10-02 13:17:09,771 (Thread-1): Parsing macros\materializations\view.sql
2019-10-02 13:17:09,951 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:09,951 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:17:10,080 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:17:10,081 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:10,082 (Thread-1): On with_fl_acr_booking: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:11,323 (Thread-1): SQL status: SUCCESS 1 in 1.24 seconds
2019-10-02 13:17:11,365 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:11,367 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:17:11,375 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:17:11,530 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:11,532 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:11,532 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:11,537 (Thread-1): On "with_fl_acr_booking_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:11,541 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:11,542 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:17:11,645 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:17:11,645 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:11,645 (Thread-1): On with_fl_acr_booking_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:13,215 (Thread-1): SQL status: SUCCESS 1 in 1.57 seconds
2019-10-02 13:17:13,219 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:13,224 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:17:13,239 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:17:13,371 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:13,372 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:13,372 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:17:13,378 (Thread-1): On "with_fl_acr_service": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:13,412 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:13,412 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:17:13,514 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:17:13,515 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:13,515 (Thread-1): On with_fl_acr_service: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:14,734 (Thread-1): SQL status: SUCCESS 1 in 1.22 seconds
2019-10-02 13:17:14,737 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:14,741 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:17:14,755 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:17:14,949 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:14,949 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:14,954 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:14,964 (Thread-1): On "with_fl_acr_service_element": cache miss for schema "OPA_DEV.DBT_TEST", this is inefficient
2019-10-02 13:17:14,974 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:14,975 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:17:15,127 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:17:15,128 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:15,128 (Thread-1): On with_fl_acr_service_element: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'DBT_TEST'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:16,397 (Thread-1): SQL status: SUCCESS 1 in 1.27 seconds
2019-10-02 13:17:16,398 (Thread-1): with database=OPA_DEV, schema=DBT_TEST, relations=[<SnowflakeRelation "OPA_DEV"."DBT_TEST"."BOOKING_FACT_UK">]
2019-10-02 13:17:16,401 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:17:16,410 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:17:16,558 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:16,560 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:17:16,561 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:17:16,565 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:17:16,573 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:17:16,577 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:17:16,578 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:17:18,178 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:17:18,237 (MainThread): Connection 'with_fl_acr_service_element' was left open.
2019-10-02 13:17:18,238 (MainThread): On with_fl_acr_service_element: Close
2019-10-02 13:17:18,318 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:17:18,319 (MainThread): On booking_fact_uk: Close
2019-10-02 13:17:18,642 (MainThread): 13:17:18 | Done.
2019-10-02 13:17:18,642 (MainThread): Flushing usage events
2019-10-02 13:17:47,703 (MainThread): Tracking: tracking
2019-10-02 13:17:47,706 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC108>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005CBC648>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8B5C8>]}
2019-10-02 13:17:48,011 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:17:48,012 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61046), raddr=('54.164.98.48', 443)>

2019-10-02 13:17:48,014 (MainThread): Error sending message, disabling tracking
2019-10-02 13:17:48,054 (MainThread): Parsing macros\core.sql
2019-10-02 13:17:48,063 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:17:48,100 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:17:48,111 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:48,113 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:48,116 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:48,120 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:48,123 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:17:48,126 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:48,134 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:48,143 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:48,152 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:48,170 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:48,191 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:48,194 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:48,208 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:48,214 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:48,221 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:48,228 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:48,231 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:48,233 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:48,237 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:48,240 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:17:48,253 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:17:48,256 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:48,264 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:17:48,267 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:17:48,273 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:17:48,300 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:17:48,301 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:17:48,301 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:17:48,304 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:17:48,600 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:17:48,616 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:17:49,179 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:17:49,180 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:49,181 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:17:49,185 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:17:49,186 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:49,186 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:49,191 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:17:49,192 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:49,192 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:17:49,197 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:17:49,198 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:49,198 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:49,203 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:17:49,204 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:49,205 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:49,209 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:49,210 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:49,210 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:49,215 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:17:49,216 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:49,216 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:49,222 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:17:49,223 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:49,223 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:49,228 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:17:49,229 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:49,229 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:49,234 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:49,235 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:49,235 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:49,240 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:49,241 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:49,241 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:49,245 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:49,246 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:49,246 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:49,250 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:17:49,251 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:49,251 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:49,256 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:17:49,257 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:49,257 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:49,265 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:49,266 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:49,266 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:49,272 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:17:49,273 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:49,273 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:49,278 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:49,279 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:49,279 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:49,289 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:49,290 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:49,290 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:49,296 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:17:49,297 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:49,297 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:49,303 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:49,304 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:49,304 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:49,361 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:17:49,364 (MainThread): 
2019-10-02 13:17:49,365 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 13:17:49,365 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:17:49,421 (MainThread): Parsing macros\core.sql
2019-10-02 13:17:49,434 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:17:49,537 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:17:49,551 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:17:49,555 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:17:49,560 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:17:49,564 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:17:49,568 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:17:49,572 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:17:49,588 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:17:49,605 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:17:49,620 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:17:49,637 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:17:49,683 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:17:49,687 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:17:49,714 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:17:49,724 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:17:49,733 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:17:49,742 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:17:49,745 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:17:49,747 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:17:49,749 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:17:49,753 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:17:49,765 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:17:49,769 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:17:49,777 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:17:49,780 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:17:49,784 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:17:49,896 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:49,897 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 13:17:50,463 (MainThread): SQL status: SUCCESS 29 in 0.57 seconds
2019-10-02 13:17:50,555 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:50,555 (MainThread): On master: BEGIN
2019-10-02 13:17:50,702 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:17:50,704 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:50,704 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:17:51,735 (MainThread): SQL status: SUCCESS 0 in 1.03 seconds
2019-10-02 13:17:51,740 (MainThread): On master: ROLLBACK
2019-10-02 13:17:51,887 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:51,888 (MainThread): On master: BEGIN
2019-10-02 13:17:52,003 (MainThread): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:17:52,005 (MainThread): On master: COMMIT
2019-10-02 13:17:52,006 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:52,006 (MainThread): On master: COMMIT
2019-10-02 13:17:52,172 (MainThread): SQL status: SUCCESS 1 in 0.17 seconds
2019-10-02 13:17:52,174 (MainThread): 13:17:52 | Concurrency: 1 threads (target='dev')
2019-10-02 13:17:52,175 (MainThread): 13:17:52 | 
2019-10-02 13:17:52,193 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:17:52,194 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:17:52,647 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:17:52,659 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:17:52,669 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:17:52,669 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:17:52,673 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:17:52,680 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:17:52,687 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:17:52,687 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:17:52,688 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:17:52,700 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:17:52,708 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:17:52,708 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:17:52,709 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:17:52,720 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:17:52,725 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:17:52,728 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:17:52,729 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:17:52,740 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:17:52,749 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:17:52,749 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:17:52,755 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:17:52,764 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:17:52,772 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:17:52,775 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:17:52,776 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:17:52,787 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:17:52,796 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:17:52,801 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:17:52,802 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:17:52,813 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:17:52,821 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:17:52,825 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:17:52,826 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:17:52,836 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:17:52,842 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:17:52,845 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:17:52,846 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:17:52,853 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:17:52,860 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:17:52,863 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:17:52,864 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:17:52,873 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:17:52,888 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:17:52,888 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:17:52,890 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:17:52,900 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:17:52,912 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:17:52,913 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:17:52,915 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:17:52,932 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:17:52,943 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:17:52,947 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:17:52,947 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:17:52,957 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:17:52,964 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:17:52,966 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:17:52,967 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:17:52,972 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:17:52,979 (Thread-1): 13:17:52 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 13:17:52,983 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:52,983 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:17:52,983 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:17:52,992 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:17:53,119 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:17:53,130 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:53,130 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:17:53,247 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:17:53,248 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:17:53,248 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id
    
SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:53,487 (Thread-1): Snowflake error: 000979 (42601): 018f46c1-005b-6135-0000-0e290161d586: SQL compilation error:
[BK_1.EFFECTIVE_FROM] is not a valid group by expression
2019-10-02 13:17:53,487 (Thread-1): On with_fl_acr_booking: ROLLBACK
2019-10-02 13:17:53,624 (Thread-1): 13:17:53 | 1 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking. [ERROR in 0.64s]
2019-10-02 13:17:53,626 (Thread-1): 13:17:53 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 13:17:53,629 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:53,629 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:17:53,630 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:17:53,643 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:17:53,658 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:17:53,666 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:53,666 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:17:53,773 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:17:53,774 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:17:53,774 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table
    
SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:54,011 (Thread-1): Snowflake error: 001104 (42601): 018f46c1-00b8-9f3f-0000-0e290161a832: SQL compilation error: error line 8 at position 3
'BK_SER_1.SK_BOOKING_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:54,011 (Thread-1): On with_fl_acr_booking_service: ROLLBACK
2019-10-02 13:17:54,218 (Thread-1): 13:17:54 | 2 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_booking_service [ERROR in 0.59s]
2019-10-02 13:17:54,219 (Thread-1): 13:17:54 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 13:17:54,221 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:17:54,221 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:17:54,221 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:17:54,227 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:17:54,241 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:17:54,250 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:54,250 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:17:54,446 (Thread-1): SQL status: SUCCESS 1 in 0.19 seconds
2019-10-02 13:17:54,446 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:17:54,446 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:54,671 (Thread-1): Snowflake error: 001104 (42601): 018f46c1-00d4-d908-0000-0e290161b6e6: SQL compilation error: error line 8 at position 3
'SER_1.ATCOM_SER_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:54,671 (Thread-1): On with_fl_acr_service: ROLLBACK
2019-10-02 13:17:54,843 (Thread-1): 13:17:54 | 3 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service. [ERROR in 0.62s]
2019-10-02 13:17:54,844 (Thread-1): 13:17:54 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 13:17:54,849 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:54,849 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:17:54,850 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:17:54,864 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:17:54,881 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:17:54,891 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:54,891 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:17:55,044 (Thread-1): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:17:55,044 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:17:55,045 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table
    
SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

GROUP BY 1
      );
2019-10-02 13:17:55,423 (Thread-1): Snowflake error: 001104 (42601): 018f46c1-0044-fc5a-0000-0e290161a83a: SQL compilation error: error line 8 at position 3
'SER_E_1.SK_SERVICE_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:55,423 (Thread-1): On with_fl_acr_service_element: ROLLBACK
2019-10-02 13:17:55,595 (Thread-1): 13:17:55 | 4 of 5 ERROR creating incremental model DBT_TEST.with_fl_acr_service_element [ERROR in 0.74s]
2019-10-02 13:17:55,599 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:17:55,599 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:17:55,602 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:17:55,625 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:17:55,633 (Thread-1): 13:17:55 | 5 of 5 SKIP relation DBT_TEST.booking_fact_uk........................ [SKIP]
2019-10-02 13:17:55,698 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:55,698 (MainThread): On master: BEGIN
2019-10-02 13:17:56,054 (MainThread): SQL status: SUCCESS 1 in 0.36 seconds
2019-10-02 13:17:56,055 (MainThread): On master: COMMIT
2019-10-02 13:17:56,055 (MainThread): Using snowflake connection "master".
2019-10-02 13:17:56,055 (MainThread): On master: COMMIT
2019-10-02 13:17:56,219 (MainThread): SQL status: SUCCESS 1 in 0.16 seconds
2019-10-02 13:17:56,220 (MainThread): 13:17:56 | 
2019-10-02 13:17:56,221 (MainThread): 13:17:56 | Finished running 4 incremental models, 1 table model in 6.86s.
2019-10-02 13:17:56,222 (MainThread): Connection 'master' was left open.
2019-10-02 13:17:56,223 (MainThread): On master: Close
2019-10-02 13:17:56,368 (MainThread): Connection 'with_ar_currency' was left open.
2019-10-02 13:17:56,368 (MainThread): On with_ar_currency: Close
2019-10-02 13:17:56,594 (MainThread): 
2019-10-02 13:17:56,595 (MainThread): Completed with 4 errors and 0 warnings:
2019-10-02 13:17:56,597 (MainThread): 
2019-10-02 13:17:56,598 (MainThread): Database Error in model with_fl_acr_booking (models\with_fl_acr_booking.sql)
2019-10-02 13:17:56,604 (MainThread):   000979 (42601): 018f46c1-005b-6135-0000-0e290161d586: SQL compilation error:
2019-10-02 13:17:56,606 (MainThread):   [BK_1.EFFECTIVE_FROM] is not a valid group by expression
2019-10-02 13:17:56,606 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking.sql
2019-10-02 13:17:56,606 (MainThread): 
2019-10-02 13:17:56,607 (MainThread): Database Error in model with_fl_acr_booking_service (models\with_fl_acr_booking_service.sql)
2019-10-02 13:17:56,607 (MainThread):   001104 (42601): 018f46c1-00b8-9f3f-0000-0e290161a832: SQL compilation error: error line 8 at position 3
2019-10-02 13:17:56,608 (MainThread):   'BK_SER_1.SK_BOOKING_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:56,609 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_booking_service.sql
2019-10-02 13:17:56,610 (MainThread): 
2019-10-02 13:17:56,610 (MainThread): Database Error in model with_fl_acr_service (models\with_fl_acr_service.sql)
2019-10-02 13:17:56,611 (MainThread):   001104 (42601): 018f46c1-00d4-d908-0000-0e290161b6e6: SQL compilation error: error line 8 at position 3
2019-10-02 13:17:56,612 (MainThread):   'SER_1.ATCOM_SER_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:56,613 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service.sql
2019-10-02 13:17:56,614 (MainThread): 
2019-10-02 13:17:56,616 (MainThread): Database Error in model with_fl_acr_service_element (models\with_fl_acr_service_element.sql)
2019-10-02 13:17:56,631 (MainThread):   001104 (42601): 018f46c1-0044-fc5a-0000-0e290161a83a: SQL compilation error: error line 8 at position 3
2019-10-02 13:17:56,632 (MainThread):   'SER_E_1.SK_SERVICE_ID' in select clause is neither an aggregate nor in the group by clause.
2019-10-02 13:17:56,632 (MainThread):   compiled SQL at target\compiled\dbt_test\with_fl_acr_service_element.sql
2019-10-02 13:17:56,633 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
2019-10-02 13:17:56,633 (MainThread): Flushing usage events
2019-10-02 13:19:53,823 (MainThread): Tracking: tracking
2019-10-02 13:19:53,825 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000000070CB7C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C93BC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000000005C8E0C8>]}
2019-10-02 13:19:54,130 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead

2019-10-02 13:19:54,130 (MainThread): c:\python\python37\lib\site-packages\snowplow_tracker\emitters.py:225: ResourceWarning: unclosed <socket.socket fd=488, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.33.118.79', 61057), raddr=('54.174.31.151', 443)>

2019-10-02 13:19:54,132 (MainThread): Error sending message, disabling tracking
2019-10-02 13:19:54,188 (MainThread): Parsing macros\core.sql
2019-10-02 13:19:54,196 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:19:54,236 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:19:54,246 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:19:54,248 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:19:54,253 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:19:54,261 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:19:54,267 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:19:54,273 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:19:54,295 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:19:54,308 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:19:54,317 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:19:54,334 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:19:54,356 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:19:54,359 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:19:54,373 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:19:54,380 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:19:54,387 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:19:54,393 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:19:54,396 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:19:54,398 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:19:54,400 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:19:54,404 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:19:54,417 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:19:54,420 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:19:54,429 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:19:54,431 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:19:54,436 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:19:54,464 (MainThread): Parsing model.dbt_test.booking_fact_uk
2019-10-02 13:19:54,466 (MainThread): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:19:54,466 (MainThread): Opening a new connection, currently in state init
2019-10-02 13:19:54,468 (MainThread): c:\python\python37\lib\site-packages\botocore\vendored\requests\models.py:169: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

2019-10-02 13:19:54,706 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\botocore\\vendored\\requests\\cacert.pem'>

2019-10-02 13:19:54,723 (MainThread): c:\python\python37\lib\site-packages\snowflake\connector\ocsp_asn1crypto.py:84: ResourceWarning: unclosed file <_io.BufferedReader name='c:\\python\\python37\\lib\\site-packages\\certifi\\cacert.pem'>

2019-10-02 13:19:55,300 (MainThread): Parsing model.dbt_test.with_ar_agent
2019-10-02 13:19:55,301 (MainThread): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:19:55,302 (MainThread): Re-using an available connection from the pool (formerly booking_fact_uk).
2019-10-02 13:19:55,307 (MainThread): Parsing model.dbt_test.with_ar_currency
2019-10-02 13:19:55,308 (MainThread): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:19:55,308 (MainThread): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:19:55,314 (MainThread): Parsing model.dbt_test.with_ar_market
2019-10-02 13:19:55,315 (MainThread): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:19:55,315 (MainThread): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:19:55,322 (MainThread): Parsing model.dbt_test.with_ar_officename
2019-10-02 13:19:55,323 (MainThread): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:19:55,323 (MainThread): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:19:55,329 (MainThread): Parsing model.dbt_test.with_ar_point
2019-10-02 13:19:55,330 (MainThread): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:19:55,330 (MainThread): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:19:55,338 (MainThread): Parsing model.dbt_test.with_ar_sellstatic
2019-10-02 13:19:55,339 (MainThread): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:19:55,339 (MainThread): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:19:55,345 (MainThread): Parsing model.dbt_test.with_ar_sellunit
2019-10-02 13:19:55,346 (MainThread): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:19:55,346 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:19:55,353 (MainThread): Parsing model.dbt_test.with_ar_staticroom
2019-10-02 13:19:55,354 (MainThread): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:19:55,354 (MainThread): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:19:55,361 (MainThread): Parsing model.dbt_test.with_ar_staticstock
2019-10-02 13:19:55,362 (MainThread): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:19:55,362 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:19:55,368 (MainThread): Parsing model.dbt_test.with_ar_transinvroute
2019-10-02 13:19:55,369 (MainThread): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:19:55,369 (MainThread): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:19:55,377 (MainThread): Parsing model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:19:55,379 (MainThread): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:19:55,379 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:19:55,385 (MainThread): Parsing model.dbt_test.with_ar_transinvsector
2019-10-02 13:19:55,387 (MainThread): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:19:55,387 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:19:55,392 (MainThread): Parsing model.dbt_test.with_ar_transroute
2019-10-02 13:19:55,394 (MainThread): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:19:55,394 (MainThread): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:19:55,398 (MainThread): Parsing model.dbt_test.with_ar_usercodes
2019-10-02 13:19:55,399 (MainThread): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:19:55,400 (MainThread): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:19:55,404 (MainThread): Parsing model.dbt_test.with_booking_fact_margin
2019-10-02 13:19:55,405 (MainThread): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:19:55,405 (MainThread): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:19:55,411 (MainThread): Parsing model.dbt_test.with_dates
2019-10-02 13:19:55,412 (MainThread): Acquiring new snowflake connection "with_dates".
2019-10-02 13:19:55,412 (MainThread): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:19:55,417 (MainThread): Parsing model.dbt_test.with_fl_acr_booking
2019-10-02 13:19:55,418 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:55,418 (MainThread): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:19:55,428 (MainThread): Parsing model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:19:55,429 (MainThread): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:19:55,429 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:19:55,434 (MainThread): Parsing model.dbt_test.with_fl_acr_service
2019-10-02 13:19:55,435 (MainThread): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:19:55,435 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:19:55,440 (MainThread): Parsing model.dbt_test.with_fl_acr_service_element
2019-10-02 13:19:55,442 (MainThread): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:19:55,442 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:19:55,499 (MainThread): Found 21 models, 0 tests, 0 snapshots, 0 analyses, 117 macros, 0 operations, 0 seed files, 0 sources
2019-10-02 13:19:55,501 (MainThread): 
2019-10-02 13:19:55,501 (MainThread): Acquiring new snowflake connection "master".
2019-10-02 13:19:55,502 (MainThread): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:19:55,525 (MainThread): Parsing macros\core.sql
2019-10-02 13:19:55,534 (MainThread): Parsing macros\adapters\common.sql
2019-10-02 13:19:55,628 (MainThread): Parsing macros\etc\datetime.sql
2019-10-02 13:19:55,642 (MainThread): Parsing macros\etc\get_custom_alias.sql
2019-10-02 13:19:55,645 (MainThread): Parsing macros\etc\get_custom_schema.sql
2019-10-02 13:19:55,648 (MainThread): Parsing macros\etc\get_relation_comment.sql
2019-10-02 13:19:55,652 (MainThread): Parsing macros\etc\is_incremental.sql
2019-10-02 13:19:55,655 (MainThread): Parsing macros\etc\query.sql
2019-10-02 13:19:55,657 (MainThread): Parsing macros\materializations\helpers.sql
2019-10-02 13:19:55,666 (MainThread): Parsing macros\materializations\common\merge.sql
2019-10-02 13:19:55,674 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2019-10-02 13:19:55,682 (MainThread): Parsing macros\materializations\seed\seed.sql
2019-10-02 13:19:55,703 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2019-10-02 13:19:55,743 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2019-10-02 13:19:55,748 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2019-10-02 13:19:55,777 (MainThread): Parsing macros\materializations\table\table.sql
2019-10-02 13:19:55,789 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2019-10-02 13:19:55,800 (MainThread): Parsing macros\materializations\view\view.sql
2019-10-02 13:19:55,811 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2019-10-02 13:19:55,814 (MainThread): Parsing macros\schema_tests\not_null.sql
2019-10-02 13:19:55,818 (MainThread): Parsing macros\schema_tests\relationships.sql
2019-10-02 13:19:55,821 (MainThread): Parsing macros\schema_tests\unique.sql
2019-10-02 13:19:55,826 (MainThread): Parsing macros\adapters.sql
2019-10-02 13:19:55,852 (MainThread): Parsing macros\catalog.sql
2019-10-02 13:19:55,859 (MainThread): Parsing macros\materializations\incremental.sql
2019-10-02 13:19:55,875 (MainThread): Parsing macros\materializations\merge.sql
2019-10-02 13:19:55,878 (MainThread): Parsing macros\materializations\table.sql
2019-10-02 13:19:55,883 (MainThread): Parsing macros\materializations\view.sql
2019-10-02 13:19:55,999 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:56,000 (MainThread): On master: select distinct schema_name
    from OPA_DEV.information_schema.schemata
    where catalog_name ilike 'OPA_DEV'
2019-10-02 13:19:56,513 (MainThread): SQL status: SUCCESS 29 in 0.51 seconds
2019-10-02 13:19:56,599 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:56,599 (MainThread): On master: BEGIN
2019-10-02 13:19:56,705 (MainThread): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:19:56,706 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:56,706 (MainThread): On master: select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case when table_type = 'BASE TABLE' then 'table'
           when table_type = 'VIEW' then 'view'
           when table_type = 'MATERIALIZED VIEW' then 'materializedview'
           when table_type = 'EXTERNAL TABLE' then 'externaltable'
           else table_type
      end as table_type
    from OPA_DEV.information_schema.tables
    where table_schema ilike 'dbt_test'
      and table_catalog ilike 'opa_dev'
2019-10-02 13:19:57,971 (MainThread): SQL status: SUCCESS 0 in 1.26 seconds
2019-10-02 13:19:57,974 (MainThread): On master: ROLLBACK
2019-10-02 13:19:58,108 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:58,108 (MainThread): On master: BEGIN
2019-10-02 13:19:58,284 (MainThread): SQL status: SUCCESS 1 in 0.18 seconds
2019-10-02 13:19:58,286 (MainThread): On master: COMMIT
2019-10-02 13:19:58,287 (MainThread): Using snowflake connection "master".
2019-10-02 13:19:58,288 (MainThread): On master: COMMIT
2019-10-02 13:19:58,431 (MainThread): SQL status: SUCCESS 1 in 0.14 seconds
2019-10-02 13:19:58,434 (MainThread): 13:19:58 | Concurrency: 1 threads (target='dev')
2019-10-02 13:19:58,435 (MainThread): 13:19:58 | 
2019-10-02 13:19:58,454 (Thread-1): Acquiring new snowflake connection "with_ar_agent".
2019-10-02 13:19:58,455 (Thread-1): Opening a new connection, currently in state init
2019-10-02 13:19:58,852 (Thread-1): Compiling model.dbt_test.with_ar_agent
2019-10-02 13:19:58,868 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_agent"
2019-10-02 13:19:58,874 (Thread-1): Acquiring new snowflake connection "with_ar_market".
2019-10-02 13:19:58,874 (Thread-1): Re-using an available connection from the pool (formerly with_ar_agent).
2019-10-02 13:19:58,875 (Thread-1): Compiling model.dbt_test.with_ar_market
2019-10-02 13:19:58,884 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_market"
2019-10-02 13:19:58,892 (Thread-1): Acquiring new snowflake connection "with_ar_officename".
2019-10-02 13:19:58,895 (Thread-1): Re-using an available connection from the pool (formerly with_ar_market).
2019-10-02 13:19:58,895 (Thread-1): Compiling model.dbt_test.with_ar_officename
2019-10-02 13:19:58,907 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_officename"
2019-10-02 13:19:58,915 (Thread-1): Acquiring new snowflake connection "with_ar_point".
2019-10-02 13:19:58,919 (Thread-1): Re-using an available connection from the pool (formerly with_ar_officename).
2019-10-02 13:19:58,920 (Thread-1): Compiling model.dbt_test.with_ar_point
2019-10-02 13:19:58,929 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_point"
2019-10-02 13:19:58,936 (Thread-1): Acquiring new snowflake connection "with_ar_sellstatic".
2019-10-02 13:19:58,939 (Thread-1): Re-using an available connection from the pool (formerly with_ar_point).
2019-10-02 13:19:58,939 (Thread-1): Compiling model.dbt_test.with_ar_sellstatic
2019-10-02 13:19:58,948 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellstatic"
2019-10-02 13:19:58,955 (Thread-1): Acquiring new snowflake connection "with_ar_sellunit".
2019-10-02 13:19:58,958 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellstatic).
2019-10-02 13:19:58,960 (Thread-1): Compiling model.dbt_test.with_ar_sellunit
2019-10-02 13:19:58,967 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_sellunit"
2019-10-02 13:19:58,974 (Thread-1): Acquiring new snowflake connection "with_ar_staticroom".
2019-10-02 13:19:58,977 (Thread-1): Re-using an available connection from the pool (formerly with_ar_sellunit).
2019-10-02 13:19:58,978 (Thread-1): Compiling model.dbt_test.with_ar_staticroom
2019-10-02 13:19:58,988 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticroom"
2019-10-02 13:19:58,995 (Thread-1): Acquiring new snowflake connection "with_ar_staticstock".
2019-10-02 13:19:58,998 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticroom).
2019-10-02 13:19:58,999 (Thread-1): Compiling model.dbt_test.with_ar_staticstock
2019-10-02 13:19:59,008 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_staticstock"
2019-10-02 13:19:59,015 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroute".
2019-10-02 13:19:59,015 (Thread-1): Re-using an available connection from the pool (formerly with_ar_staticstock).
2019-10-02 13:19:59,020 (Thread-1): Compiling model.dbt_test.with_ar_transinvroute
2019-10-02 13:19:59,029 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroute"
2019-10-02 13:19:59,036 (Thread-1): Acquiring new snowflake connection "with_ar_transinvroutesector".
2019-10-02 13:19:59,039 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroute).
2019-10-02 13:19:59,040 (Thread-1): Compiling model.dbt_test.with_ar_transinvroutesector
2019-10-02 13:19:59,049 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvroutesector"
2019-10-02 13:19:59,055 (Thread-1): Acquiring new snowflake connection "with_ar_transinvsector".
2019-10-02 13:19:59,057 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvroutesector).
2019-10-02 13:19:59,058 (Thread-1): Compiling model.dbt_test.with_ar_transinvsector
2019-10-02 13:19:59,063 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transinvsector"
2019-10-02 13:19:59,070 (Thread-1): Acquiring new snowflake connection "with_ar_transroute".
2019-10-02 13:19:59,072 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transinvsector).
2019-10-02 13:19:59,073 (Thread-1): Compiling model.dbt_test.with_ar_transroute
2019-10-02 13:19:59,086 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_transroute"
2019-10-02 13:19:59,095 (Thread-1): Acquiring new snowflake connection "with_ar_usercodes".
2019-10-02 13:19:59,100 (Thread-1): Re-using an available connection from the pool (formerly with_ar_transroute).
2019-10-02 13:19:59,103 (Thread-1): Compiling model.dbt_test.with_ar_usercodes
2019-10-02 13:19:59,114 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_usercodes"
2019-10-02 13:19:59,123 (Thread-1): Acquiring new snowflake connection "with_booking_fact_margin".
2019-10-02 13:19:59,126 (Thread-1): Re-using an available connection from the pool (formerly with_ar_usercodes).
2019-10-02 13:19:59,128 (Thread-1): Compiling model.dbt_test.with_booking_fact_margin
2019-10-02 13:19:59,140 (Thread-1): Writing injected SQL for node "model.dbt_test.with_booking_fact_margin"
2019-10-02 13:19:59,148 (Thread-1): Acquiring new snowflake connection "with_dates".
2019-10-02 13:19:59,150 (Thread-1): Re-using an available connection from the pool (formerly with_booking_fact_margin).
2019-10-02 13:19:59,151 (Thread-1): Compiling model.dbt_test.with_dates
2019-10-02 13:19:59,159 (Thread-1): Writing injected SQL for node "model.dbt_test.with_dates"
2019-10-02 13:19:59,167 (Thread-1): 13:19:59 | 1 of 5 START incremental model DBT_TEST.with_fl_acr_booking.......... [RUN]
2019-10-02 13:19:59,170 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:59,170 (Thread-1): Re-using an available connection from the pool (formerly with_dates).
2019-10-02 13:19:59,171 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking
2019-10-02 13:19:59,187 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:19:59,329 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking"
2019-10-02 13:19:59,337 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:59,337 (Thread-1): On with_fl_acr_booking: BEGIN
2019-10-02 13:19:59,463 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:19:59,463 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:19:59,463 (Thread-1): On with_fl_acr_booking: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking
      as (

    -- ,unique_key=sk_booking_id

SELECT
  bk_1.sk_booking_id as sk_booking_id
  ,bk_1.booking_version
  ,bk_1.atcom_res_id
  ,bk_1.atcom_res_version
  ,bk_1.atcom_market_id -- CG ADDED in V1.06 for new Source Market Derivation
  ,bk_1.number_of_adults
  ,bk_1.number_of_children
  ,bk_1.number_of_infants
  ,bk_1.number_of_passengers
  ,bk_1.sk_season_id
  ,bk_1.booking_status
  ,bk_1.atcom_agent_id
  ,bk_1.atcom_sell_currency_id
  ,bk_1.season_date
  ,bk_1.confirmed_on
  ,bk_1.cancelled_on
  ,bk_1.source_created_on
  ,bk_1.modified_on
  ,bk_1.effective_from
  ,DATEADD('second', -1, LEAD(bk_1.effective_from) OVER (PARTITION BY bk_1.sk_booking_id ORDER BY bk_1.booking_version)) AS lead_effective_from
  ,bk_1.effective_to
  ,bk_1.dwh_created_on
  ,bk_1.dwh_modified_on

FROM opa_stg_uk.fl_acr_booking bk_1
WHERE bk_1.file_dt = (SELECT MAX(bk_2.file_dt) FROM opa_stg_uk.fl_acr_booking bk_2 WHERE bk_1.sk_booking_id = bk_2.sk_booking_id AND bk_1.booking_version = bk_2.booking_version)
AND bk_1.booking_version = (SELECT MAX(bk_3.booking_version) FROM opa_stg_uk.fl_acr_booking bk_3 WHERE bk_1.sk_booking_id = bk_3.sk_booking_id)
AND (bk_1.sk_season_id > 201701 OR bk_1.sk_booking_id IS NULL)

-- To be removed when running against all bookings
AND bk_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:01,224 (Thread-1): SQL status: SUCCESS 1 in 1.76 seconds
2019-10-02 13:20:01,226 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 13:20:01,226 (Thread-1): Using snowflake connection "with_fl_acr_booking".
2019-10-02 13:20:01,226 (Thread-1): On with_fl_acr_booking: COMMIT
2019-10-02 13:20:01,312 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 13:20:01,316 (Thread-1): 13:20:01 | 1 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking..... [SUCCESS 1 in 2.14s]
2019-10-02 13:20:01,324 (Thread-1): 13:20:01 | 2 of 5 START incremental model DBT_TEST.with_fl_acr_booking_service.. [RUN]
2019-10-02 13:20:01,324 (Thread-1): Acquiring new snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:01,325 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking).
2019-10-02 13:20:01,325 (Thread-1): Compiling model.dbt_test.with_fl_acr_booking_service
2019-10-02 13:20:01,331 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:20:01,342 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_booking_service"
2019-10-02 13:20:01,346 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:01,347 (Thread-1): On with_fl_acr_booking_service: BEGIN
2019-10-02 13:20:01,473 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:20:01,474 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:01,475 (Thread-1): On with_fl_acr_booking_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_booking_service
      as (

    -- ,unique_key='sk_booking_service_id' -- bk in the target table

SELECT
  bk_ser_1.sk_booking_service_id
  ,bk_ser_1.sk_booking_id
  ,bk_ser_1.sk_service_id
  ,bk_ser_1.service_version
  ,bk_ser_1.booking_version
FROM opa_stg_uk.fl_acr_booking_service bk_ser_1
WHERE bk_ser_1.file_dt = (SELECT MAX(bk_ser_2.file_dt) FROM opa_stg_uk.fl_acr_booking_service bk_ser_2 WHERE bk_ser_1.sk_booking_service_id = bk_ser_2.sk_booking_service_id)
AND bk_ser_1.booking_version = (SELECT MAX(bk_ser_3.booking_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_3 WHERE bk_ser_1.sk_booking_id = bk_ser_3.sk_booking_id)
AND bk_ser_1.service_version = (SELECT MAX(bk_ser_4.service_version) FROM opa_stg_uk.fl_acr_booking_service bk_ser_4 WHERE bk_ser_1.sk_service_id = bk_ser_4.sk_service_id)

-- To be removed when running against all bookings
AND bk_ser_1.sk_booking_id IN ('380402','975528','10016009','10063844','15994298','22568921','25059884','27813713','28536240','30846203','33404409','20348866','31280892','35353771')


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:10,662 (Thread-1): SQL status: SUCCESS 1 in 9.19 seconds
2019-10-02 13:20:10,663 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 13:20:10,663 (Thread-1): Using snowflake connection "with_fl_acr_booking_service".
2019-10-02 13:20:10,663 (Thread-1): On with_fl_acr_booking_service: COMMIT
2019-10-02 13:20:10,753 (Thread-1): SQL status: SUCCESS 1 in 0.09 seconds
2019-10-02 13:20:10,756 (Thread-1): 13:20:10 | 2 of 5 OK created incremental model DBT_TEST.with_fl_acr_booking_service [SUCCESS 1 in 9.43s]
2019-10-02 13:20:10,757 (Thread-1): 13:20:10 | 3 of 5 START incremental model DBT_TEST.with_fl_acr_service.......... [RUN]
2019-10-02 13:20:10,758 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service".
2019-10-02 13:20:10,759 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_booking_service).
2019-10-02 13:20:10,759 (Thread-1): Compiling model.dbt_test.with_fl_acr_service
2019-10-02 13:20:10,765 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:20:10,781 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service"
2019-10-02 13:20:10,787 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:20:10,787 (Thread-1): On with_fl_acr_service: BEGIN
2019-10-02 13:20:10,886 (Thread-1): SQL status: SUCCESS 1 in 0.10 seconds
2019-10-02 13:20:10,887 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:20:10,887 (Thread-1): On with_fl_acr_service: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service
      as (

    -- ,unique_key=concat('sk_service_id', '|', 'service_version') -- bk in the target table

SELECT
  ser_1.sk_service_id
  ,ser_1.atcom_ser_id
  ,ser_1.atcom_dep_point_id
  ,ser_1.service_version
  ,ser_1.service_status
  ,ser_1.direction
  ,ser_1.sell_type
  ,ser_1.service_type
  ,ser_1.flight_type_code
  ,ser_1.service_start_date1
  ,ser_1.service_end_date1
  ,ser_1.departure_flight_number
  ,ser_1.atcom_arr_point_id
  ,ser_1.source_stock_type_code
FROM opa_stg_uk.fl_acr_service ser_1
WHERE ser_1.file_dt = (SELECT MAX(ser_2.file_dt) FROM opa_stg_uk.fl_acr_service ser_2 WHERE ser_1.sk_service_id = ser_2.sk_service_id AND ser_1.service_version = ser_2.service_version)



-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:32,163 (Thread-1): SQL status: SUCCESS 1 in 21.28 seconds
2019-10-02 13:20:32,167 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 13:20:32,168 (Thread-1): Using snowflake connection "with_fl_acr_service".
2019-10-02 13:20:32,168 (Thread-1): On with_fl_acr_service: COMMIT
2019-10-02 13:20:32,291 (Thread-1): SQL status: SUCCESS 1 in 0.12 seconds
2019-10-02 13:20:32,308 (Thread-1): 13:20:32 | 3 of 5 OK created incremental model DBT_TEST.with_fl_acr_service..... [SUCCESS 1 in 21.54s]
2019-10-02 13:20:32,311 (Thread-1): 13:20:32 | 4 of 5 START incremental model DBT_TEST.with_fl_acr_service_element.. [RUN]
2019-10-02 13:20:32,317 (Thread-1): Acquiring new snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:32,318 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service).
2019-10-02 13:20:32,321 (Thread-1): Compiling model.dbt_test.with_fl_acr_service_element
2019-10-02 13:20:32,341 (Thread-1): Writing injected SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:20:32,361 (Thread-1): Writing runtime SQL for node "model.dbt_test.with_fl_acr_service_element"
2019-10-02 13:20:32,368 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:32,368 (Thread-1): On with_fl_acr_service_element: BEGIN
2019-10-02 13:20:32,475 (Thread-1): SQL status: SUCCESS 1 in 0.11 seconds
2019-10-02 13:20:32,475 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:32,475 (Thread-1): On with_fl_acr_service_element: create or replace transient table OPA_DEV.DBT_TEST.with_fl_acr_service_element
      as (

    -- ,unique_key='sk_service_element_id' -- bk in the target table

SELECT
  ser_e_1.sk_service_element_id
  ,ser_e_1.sk_service_id
  ,ser_e_1.service_version
  ,ser_e_1.atcom_sub_ser_id
FROM opa_stg_uk.fl_acr_service_element ser_e_1
WHERE ser_e_1.file_dt = (SELECT MAX(ser_e_2.file_dt) FROM opa_stg_uk.fl_acr_service_element ser_e_2 WHERE ser_e_1.sk_service_element_id = ser_e_2.sk_service_element_id)


-- Incremental filters

-- GROUP BY 1
      );
2019-10-02 13:20:47,557 (Thread-1): SQL status: SUCCESS 1 in 15.08 seconds
2019-10-02 13:20:47,563 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 13:20:47,564 (Thread-1): Using snowflake connection "with_fl_acr_service_element".
2019-10-02 13:20:47,565 (Thread-1): On with_fl_acr_service_element: COMMIT
2019-10-02 13:20:47,851 (Thread-1): SQL status: SUCCESS 1 in 0.29 seconds
2019-10-02 13:20:47,862 (Thread-1): 13:20:47 | 4 of 5 OK created incremental model DBT_TEST.with_fl_acr_service_element [SUCCESS 1 in 15.54s]
2019-10-02 13:20:47,864 (Thread-1): Acquiring new snowflake connection "with_ar_currency".
2019-10-02 13:20:47,864 (Thread-1): Re-using an available connection from the pool (formerly with_fl_acr_service_element).
2019-10-02 13:20:47,869 (Thread-1): Compiling model.dbt_test.with_ar_currency
2019-10-02 13:20:47,880 (Thread-1): Writing injected SQL for node "model.dbt_test.with_ar_currency"
2019-10-02 13:20:47,887 (Thread-1): 13:20:47 | 5 of 5 START table model DBT_TEST.booking_fact_uk.................... [RUN]
2019-10-02 13:20:47,890 (Thread-1): Acquiring new snowflake connection "booking_fact_uk".
2019-10-02 13:20:47,890 (Thread-1): Re-using an available connection from the pool (formerly with_ar_currency).
2019-10-02 13:20:47,891 (Thread-1): Compiling model.dbt_test.booking_fact_uk
2019-10-02 13:20:49,199 (Thread-1): Writing injected SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:20:49,233 (Thread-1): Writing runtime SQL for node "model.dbt_test.booking_fact_uk"
2019-10-02 13:20:49,308 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 13:20:49,308 (Thread-1): On booking_fact_uk: BEGIN
2019-10-02 13:20:49,436 (Thread-1): SQL status: SUCCESS 1 in 0.13 seconds
2019-10-02 13:20:49,437 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 13:20:49,437 (Thread-1): On booking_fact_uk: create or replace transient table OPA_DEV.DBT_TEST.booking_fact_uk
      as (

WITH  __dbt__CTE__with_ar_sellstatic as (


SELECT
  sls_1.sell_stc_id
  ,sls_1.stc_stk_id
FROM opa_stg_uk.ar_sellstatic sls_1
WHERE sls_1.file_dt = (SELECT MAX(sls_2.file_dt) FROM opa_stg_uk.ar_sellstatic sls_2 WHERE sls_1.sell_stc_id = sls_2.sell_stc_id)
),  __dbt__CTE__with_ar_staticstock as (


SELECT
  ss.stc_stk_id
  ,ss.cd
FROM opa_stg_uk.ar_staticstock ss
WHERE ss.file_dt = (SELECT MAX(ss_2.file_dt) FROM opa_stg_uk.ar_staticstock ss_2 WHERE ss.stc_stk_id = ss_2.stc_stk_id)
),  __dbt__CTE__with_ar_sellunit as (


SELECT
  su.sell_unit_id
  ,su.rm_id
  ,su.bb_cd_id
FROM opa_stg_uk.ar_sellunit su
WHERE su.file_dt = (SELECT MAX(su_2.file_dt) FROM opa_stg_uk.ar_sellunit su_2 WHERE su.sell_unit_id = su_2.sell_unit_id)
),  __dbt__CTE__with_ar_staticroom as (


SELECT
  sr.stc_rm_id
  ,sr.stc_stk_id
  ,sr.rm_id
FROM opa_stg_uk.ar_staticroom sr
WHERE sr.file_dt = (SELECT MAX(sr_2.file_dt) FROM opa_stg_uk.ar_staticroom sr_2 WHERE sr.stc_rm_id = sr_2.stc_rm_id)
),  __dbt__CTE__with_ar_usercodes as (


SELECT DISTINCT
  uc_1.user_cd_id
  ,uc_1.cd
  ,uc_1.name
FROM opa_stg_uk.ar_usercodes uc_1
WHERE uc_1.file_dt = (SELECT MAX(uc_2.file_dt) FROM opa_stg_uk.ar_usercodes uc_2 WHERE uc_1.user_cd_id = uc_2.user_cd_id)
),  __dbt__CTE__with_ar_transinvroute as (


SELECT
  tir.trans_inv_route_id
  ,tir.trans_route_id
FROM opa_stg_uk.ar_transinvroute tir
WHERE tir.file_dt = (SELECT MAX(tir_2.file_dt) FROM opa_stg_uk.ar_transinvroute tir_2 WHERE tir.trans_inv_route_id = tir_2.trans_inv_route_id)
),  __dbt__CTE__with_ar_transroute as (


SELECT
	tr.trans_route_id
	,tr.route_cd
FROM opa_stg_uk.ar_transroute tr
WHERE tr.file_dt = (SELECT MAX(tr_2.file_dt) FROM opa_stg_uk.ar_transroute tr_2 WHERE tr.trans_route_id = tr_2.trans_route_id)
),  __dbt__CTE__with_ar_transinvroutesector as (


SELECT
  tirs.trans_inv_route_id
  ,tirs.trans_inv_sec_id
  ,tirs.trans_inv_route_sec_id
FROM opa_stg_uk.ar_transinvroutesector tirs
WHERE tirs.file_dt = (SELECT MAX(tirs_2.file_dt) FROM opa_stg_uk.ar_transinvroutesector tirs_2 WHERE tirs.trans_inv_route_sec_id = tirs_2.trans_inv_route_sec_id)
),  __dbt__CTE__with_ar_transinvsector as (


SELECT
  tis.trans_inv_sec_id
  ,tis.dep_dt_tm
FROM opa_stg_uk.ar_transinvsector tis
WHERE tis.file_dt = (SELECT MAX(tis_2.file_dt) FROM opa_stg_uk.ar_transinvsector tis_2 WHERE tis.trans_inv_sec_id = tis_2.trans_inv_sec_id)
),  __dbt__CTE__with_ar_point as (


SELECT
  p.pt_id
  ,p.pt_cd
FROM opa_stg_uk.ar_point p
WHERE p.file_dt = (SELECT MAX(p_2.file_dt) FROM opa_stg_uk.ar_point p_2 WHERE p.pt_id = p_2.pt_id)
),  __dbt__CTE__with_dates as (



SELECT
	dd.bk_date
	,dd.group_season_code
FROM opa_stg_all.date_dim dd
),  __dbt__CTE__with_ar_agent as (


SELECT DISTINCT
  ag_1.agt_id
  ,ag_1.def_mkt_id
  ,ag_1.agt_tp_id
FROM opa_stg_uk.ar_agent ag_1
WHERE ag_1.file_dt = (SELECT MAX(ag_2.file_dt) FROM opa_stg_uk.ar_agent ag_2 WHERE ag_1.agt_id = ag_2.agt_id)
),  __dbt__CTE__with_ar_market as (


SELECT DISTINCT
  mk_1.mkt_id
  ,mk_1.off_id
FROM opa_stg_uk.ar_market mk_1
WHERE mk_1.file_dt = (SELECT MAX(mk_2.file_dt) FROM opa_stg_uk.ar_market mk_2 WHERE mk_1.mkt_id = mk_2.mkt_id)
),  __dbt__CTE__with_ar_officename as (


SELECT DISTINCT
  ofn_1.off_name_id
  ,ofn_1.cd
  ,ofn_1.name
  -- ,sm.source_market_code
FROM opa_stg_uk.ar_officename ofn_1
-- LEFT OUTER JOIN opa_stg_all.source_market sm ON 'UKATCOM|' || ofn_1.cd = bk_source_market
WHERE ofn_1.file_dt = (SELECT MAX(ofn_2.file_dt) FROM opa_stg_uk.ar_officename ofn_2 WHERE ofn_1.off_name_id = ofn_2.off_name_id)
),  __dbt__CTE__with_booking_fact_margin as (


SELECT
  bff_1.bk_booking
  ,bff_1.ffd_flag
  ,bff_1.sm_currency
  ,bff_1.sm_revenue
  ,bff_1.sm_cnx_and_amend_revenue
  ,bff_1.sm_accommodation_costs
  ,bff_1.sm_early_booking_discounts
  ,bff_1.sm_late_booking_discounts
  ,bff_1.sm_flying_costs
  ,bff_1.sm_other_costs
  ,bff_1.sm_distribution_costs
  ,bff_1.sm_non_margin_items
  ,bff_1.sm_margin
  ,bff_1.smg_currency
  ,bff_1.smg_revenue
  ,bff_1.smg_cnx_and_amend_revenue
  ,bff_1.smg_accommodation_costs
  ,bff_1.smg_early_booking_discounts
  ,bff_1.smg_late_booking_discounts
  ,bff_1.smg_flying_costs
  ,bff_1.smg_other_costs
  ,bff_1.smg_distribution_costs
  ,bff_1.smg_non_margin_items
  ,bff_1.smg_margin
  ,bff_1.rep_currency
  ,bff_1.rep_revenue
  ,bff_1.rep_cnx_and_amend_revenue
  ,bff_1.rep_accommodation_costs
  ,bff_1.rep_early_booking_discounts
  ,bff_1.rep_late_booking_discounts
  ,bff_1.rep_flying_costs
  ,bff_1.rep_other_costs
  ,bff_1.rep_distribution_costs
  ,bff_1.rep_non_margin_items
  ,bff_1.rep_margin
FROM opa_fl_uk.v_booking_fact_margin_uk bff_1
),booking_service AS (
	SELECT
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,bk_ser.sk_service_id
		,bk_ser.service_version
		,bk_ser.sk_booking_service_id
		,ser.service_type
		,ser.source_stock_type_code
		,ser.sell_type
		,ser.service_status
		,ser.flight_type_code
		,ser.service_start_date1
		,ser.service_end_date1
		,tis.dep_dt_tm
		,ser.departure_flight_number
		,ser.direction
		,tr.route_cd
		,dpt.pt_cd
		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN apt.pt_cd
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				AND ser.service_status = 'CON'
				THEN apt.pt_cd
				ELSE NULL
			END
		END AS min_flight_gateway

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MIN(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END	AS min_flight_id

		,CASE WHEN
			-- All flight cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		ELSE
			CASE WHEN
				ser.service_start_date1 =
					MAX(CASE WHEN
							(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
							OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
						THEN ser.service_start_date1
						ELSE NULL
						END
					) OVER (PARTITION BY bk_ser.sk_booking_id)
					AND ser.service_status = 'CON'
				THEN
					CASE WHEN tr.route_cd IS NULL
						THEN
							ser.departure_flight_number|| '|' || dpt.pt_cd || '|' || apt.pt_cd|| '|' || CAST(SUBSTR(ser.service_start_date1,1,4)||SUBSTR(ser.service_start_date1,6,2)||SUBSTR(ser.service_start_date1,9,2) AS VARCHAR)
						ELSE
							tr.route_cd || '|' || SUBSTRING(tis.dep_dt_tm, 1, 4) || SUBSTRING(tis.dep_dt_tm, 6, 2) || SUBSTRING(tis.dep_dt_tm, 9, 2)
						END
				ELSE NULL
			END
		END AS max_flight_id


		-- MULTICENTRE
		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS min_multi_center_date

		,CASE WHEN
			-- All multicentre services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'MC' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_multi_center_date


		-- ACCOM
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_accom_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU'))
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'ACCM' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS max_accom_date


		-- CRUISE
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_cruise_date
		,CASE WHEN
			-- All accom services cancelled
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'CRU' AND ser.service_status = 'CON')
				THEN ser.service_end_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END max_cruise_date


		-- FLIGHT
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MIN(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END AS min_flight_date
		,CASE WHEN
			-- All flight services cancelled
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			=
			SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
		THEN
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		ELSE
			MAX(CASE WHEN
					(ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
					OR (ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.service_status = 'CON')
				--THEN tis.dep_dt_tm END)
				THEN ser.service_start_date1 END)
			OVER (PARTITION BY bk_ser.sk_booking_id)
		END	AS max_flight_date

		,sts.cd AS accom
		,su.bb_cd_id AS board_cd
		,uc_3.name AS board_name
		,str.stc_rm_id AS room

		-- Booking type derivation part 1
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_out_count
		,CASE WHEN
				-- No outbound flight services on the booking are third party
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
		THEN 0
		ELSE
			CASE WHEN
				-- All outbound flight services are 3PF
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
					+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				=
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

			OR
				SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
			THEN 1
			ELSE 0
			END
		END AS tpf_in_count
		,CASE WHEN
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
			+
				CASE WHEN
						-- No outbound flight services on the booking are third party
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) = 0
				THEN 0
				ELSE
					CASE WHEN
						-- All outbound flight services are 3PF
						SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
							+ SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
						=
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)

					OR
						SUM(CASE WHEN ser.flight_type_code = 'T' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id) > 1
					THEN 1
					ELSE 0
					END
				END
		> 0
			THEN 'Y'
			ELSE 'N'
		END AS tpf_indicator
		,CASE WHEN
				-- All accom cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code NOT IN ('MC', 'CRU') AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS accom_count
		,CASE WHEN
				-- All cruise cancelled
				SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'ACC' AND ser.source_stock_type_code = 'CRU' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS cruise_count
		,CASE WHEN
				-- All flight out cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_out_count
		,CASE WHEN
				-- All flight in cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS flight_ret_count
		,CASE WHEN
				-- All ahoc services cancelled
				SUM(CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'AHOC' THEN 1 ELSE 0 END
			ELSE CASE WHEN ser.service_type = 'AHOC' AND ser.service_status = 'CON' THEN 1 ELSE 0 END
		END AS thirdparty_count

		,CASE WHEN
				-- All flight out first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'OUT' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_out_first_date
		,CASE WHEN
				-- All flight in first date cancelled
				SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
				= SUM(CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bk_ser.sk_booking_id)
			THEN CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' THEN ser.service_start_date1 ELSE NULL END
			ELSE CASE WHEN ser.service_type = 'TRS' AND ser.sell_type = 'FLT' AND ser.direction = 'IN' AND ser.service_status = 'CON' THEN ser.service_start_date1 ELSE NULL END
		END AS flight_ret_first_date

	-- Service and subservice
	FROM OPA_DEV.DBT_TEST.with_fl_acr_booking_service bk_ser
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service ser ON bk_ser.sk_service_id = ser.sk_service_id AND bk_ser.service_version = ser.service_version
	LEFT OUTER JOIN OPA_DEV.DBT_TEST.with_fl_acr_service_element ser_e ON ser.sk_service_id = ser_e.sk_service_id AND ser.service_version = ser_e.service_version

	-- Accom
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellstatic sls ON ser.atcom_ser_id = sls.sell_stc_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticstock sts ON sls.stc_stk_id = sts.stc_stk_id

	-- Room
	LEFT OUTER JOIN __dbt__CTE__with_ar_sellunit su ON ser_e.atcom_sub_ser_id = su.sell_unit_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_staticroom str ON sts.stc_stk_id = str.stc_stk_id AND su.rm_id = str.rm_id

	-- Board
	LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc_3 ON su.bb_cd_id = uc_3.user_cd_id

	-- Flight
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroute tir ON ser.atcom_ser_id = tir.trans_inv_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transroute tr ON tir.trans_route_id = tr.trans_route_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_transinvroutesector tirs ON tir.trans_inv_route_id = tirs.trans_inv_route_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_transinvsector tis ON tirs.trans_inv_sec_id = tis.trans_inv_sec_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point dpt ON ser.atcom_dep_point_id = dpt.pt_id
	LEFT OUTER JOIN __dbt__CTE__with_ar_point apt ON ser.atcom_arr_point_id = apt.pt_id

	ORDER BY
		bk_ser.sk_booking_id
		,bk_ser.booking_version
		,ser.source_stock_type_code

)
,booking_fact_1 AS (
  SELECT DISTINCT
    CASE WHEN bk.atcom_res_id IS NULL THEN NULL ELSE 'UKATCOM|' || bk.atcom_res_id || '|' || bk.booking_version END AS bk_booking
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_accom
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN 'U'
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.room ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS bk_primary_room
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) > 1
          THEN 'MULTI'
      WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
        AND COUNT(DISTINCT bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = 1
          THEN 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      WHEN SUM(bs.flight_out_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_first_flight
    ,COALESCE(
      CASE WHEN
        MIN(bs.min_flight_id) OVER (PARTITION BY bk.atcom_res_id) = MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
          THEN NULL
      WHEN SUM(bs.flight_ret_count) OVER (PARTITION BY bk.atcom_res_id) > 1
        THEN 'MULTI'
        ELSE 'UKATCOM|' || MIN(bs.max_flight_id) OVER (PARTITION BY bk.atcom_res_id)
      END
    , 'U') AS bk_last_flight
    ,CASE WHEN ofn.cd IS NULL
      THEN 'UKATCOM|U'
      ELSE 'UKATCOM|' || ofn.cd
    END AS bk_source_market
    ,'UKATCOM' AS bk_originating_system
    ,CASE WHEN
        -- Third party flight
        SUM(CASE WHEN bs.tpf_indicator = 'Y' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|3PF'

      WHEN
        -- Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGAF'

      WHEN
        -- Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCF'

      WHEN
        -- Cruise and Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGCAF'

      WHEN
        -- Multi Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAF'

      WHEN
        -- Multi Cruise and Flight Package
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCF'

      WHEN
        -- Multi Accommodation and One Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMACF'

      WHEN
        -- Multi Cruise and One Accommodation and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMCAF'

      WHEN
        -- Multi Accommodation and Multi Cruise and Flight Package
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
          THEN 'UKATCOM|PKG' -- Granular code = 'PKGMAMCF'

      WHEN
        -- Single Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCA'

      WHEN
        -- Multi Accommodation Only
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCMA'

      WHEN
        -- Accommodation and Flight Other
        SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 1
          THEN 'UKATCOM|ACC' -- Granular code = 'ACCOTH'

      WHEN
        -- Flight Only Return Outbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTROF'

      WHEN
        -- Flight Only Return Inbound First
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) < MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTRIF'

      WHEN
        -- Flight only same day return
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND MIN(bs.flight_ret_first_date) OVER (PARTITION BY bs.sk_booking_id) = MIN(bs.flight_out_first_date) OVER (PARTITION BY bs.sk_booking_id)
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTSDR'

      WHEN
        -- Flight Only One Way Outbound
        SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTOBO'

      WHEN
        -- Flight Only One Way Inbound
        SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|FLT' -- Granular code = 'FLTIBO'

      WHEN
        -- Single Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) = 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUSGL'

      WHEN
        -- Multi Cruise Only
        SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id) > 1
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|CRU' -- Granular code = 'CRUMLT'

      WHEN
        -- Third party
        SUM(bs.thirdparty_count) OVER (PARTITION BY bs.sk_booking_id) > 0
        AND (SUM(bs.flight_out_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.flight_ret_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
        AND (SUM(bs.accom_count) OVER (PARTITION BY bs.sk_booking_id) + SUM(bs.cruise_count) OVER (PARTITION BY bs.sk_booking_id)) = 0
          THEN 'UKATCOM|TPB' -- Granular code = 'TPB'

      ELSE 'UKATCOM|OTH'
    END AS bk_booking_type
    ,CASE WHEN bk.booking_status IS NULL
      THEN 'U'
      ELSE 'UKATCOM|' || bk.booking_status
    END AS bk_booking_status
    ,bk.atcom_res_id AS source_booking_id
    --,bk.atcom_res_version AS source_booking_version
    ,bk.booking_version AS source_booking_version -- swapped to FL version not Atcom version PiT
    ,COALESCE(CAST(bk.source_created_on AS TIMESTAMP), CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_created_datetime
    ,COALESCE(bk.confirmed_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_confirmed_datetime
    ,COALESCE(bk.cancelled_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS booking_cancelled_datetime
    ,gs.group_season_code AS group_season
    ,CASE WHEN bk.sk_season_id IS NULL OR bk.sk_season_id = -1 OR bk.sk_season_id = -2
      THEN NULL
      ELSE
        CASE WHEN SUBSTRING(bk.sk_season_id, 5, 2) = 01
          THEN 'S' || SUBSTRING(bk.sk_season_id, 3, 2)
          ELSE 'W' || SUBSTRING(bk.sk_season_id, 3, 2)
        END
    END AS sm_season
    ,CASE WHEN uc.cd IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.cd
    END AS channel_code
    ,CASE WHEN uc.name IS NULL
      THEN NULL
      ELSE 'UKATCOM|' || uc.name
    END AS channel_desc
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_code
    ,CASE WHEN
        -- All accom services cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        =
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
          + SUM(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
      ELSE
        CASE WHEN
            COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
            = 0
          THEN NULL
          ELSE
            CASE WHEN
              COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              + COUNT(DISTINCT CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_cd ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              > 1
            THEN 'MULTI'

            ELSE 'UKATCOM|' || COALESCE(
                MIN(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
                ,MIN(CASE WHEN bs.service_type = 'AHOC' AND bs.sell_type = 'ACCM' AND bs.service_status = 'CON' THEN bs.board_name ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id)
              )
            END
        END
    END AS booked_board_name
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_room_booking
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      ELSE
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
    END AS number_of_booked_rooms
    ,CASE WHEN
        -- All accom services are cancelled
        SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
        = SUM(CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CNX' THEN 1 ELSE 0 END) OVER (PARTITION BY bs.sk_booking_id)
      THEN
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
      ELSE
        CASE WHEN COUNT(DISTINCT CASE WHEN bs.service_type = 'ACC' AND bs.source_stock_type_code NOT IN ('MC') AND bs.service_status = 'CON' THEN bs.accom ELSE NULL END) OVER (PARTITION BY bs.sk_booking_id) > 1
          THEN 'Y'
          ELSE 'N'
        END
    END AS multi_centre_booking
    ,COALESCE(bk.season_date,CAST('2999-12-31 23:59:59.0' AS DATE)) AS departure_date
    ,COALESCE(
      bs.max_multi_center_date,
      bs.max_accom_date,
      bs.max_cruise_date,
      bs.max_flight_date,
      CAST('2999-12-31 23:59:59.0' AS DATE)
    ) AS return_date
    ,CASE WHEN
      COALESCE(bk.season_date, CAST('2999-12-31 23:59:59.0' AS DATE)) = CAST('2999-12-31 23:59:59.0' AS DATE)
    OR
      COALESCE(
        bs.max_multi_center_date,
        bs.max_accom_date,
        bs.max_cruise_date,
        bs.max_flight_date,
        CAST('2999-12-31 23:59:59.0' AS DATE)
      ) = CAST('2999-12-31 23:59:59.0' AS DATE)
    THEN 0
    ELSE
      DATEDIFF('DAY',
        bk.season_date
      ,
        COALESCE(
          bs.max_multi_center_date,
          bs.max_accom_date,
          bs.max_cruise_date,
          bs.max_flight_date)
      )
    END	AS DURATION
    ,COALESCE(bk.number_of_adults, 0) AS std_number_of_booking_adult_pax
    ,COALESCE(bk.number_of_children, 0) AS std_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS std_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS std_number_of_booking_pax
    ,COALESCE(bk.number_of_adults, 0) AS sm_number_of_booking_adult_pax
    ,0 AS sm_number_of_booking_teenager_pax
    ,COALESCE(bk.number_of_children, 0) AS sm_number_of_booking_child_pax
    ,COALESCE(bk.number_of_infants, 0) AS sm_number_of_booking_infant_pax
    ,COALESCE(bk.number_of_passengers, 0) AS sm_number_of_booking_pax
    ,CASE WHEN COUNT(DISTINCT bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id) > 1
      THEN 'MULTI'
      ELSE MIN(bs.min_flight_gateway) OVER (PARTITION BY bk.atcom_res_id)
    END AS primary_gateway
    -- ,cur.name AS currency
    ,'Insert' AS record_type
    ,COALESCE(bk.effective_from, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS effective_from
    ,COALESCE(
      bk.lead_effective_from
      ,bk.effective_to
      ,CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)
    ) AS effective_to
    ,COALESCE(bk.dwh_created_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_created_datetime
    ,COALESCE(bk.dwh_modified_on, CAST('2999-12-31 23:59:59.0' AS TIMESTAMP)) AS sm_updated_datetime
    ,CAST(CONVERT_TIMEZONE('Europe/London',CURRENT_TIMESTAMP()) AS TIMESTAMP_NTZ) AS dm_created_datetime

  FROM OPA_DEV.DBT_TEST.with_fl_acr_booking bk
  LEFT OUTER JOIN booking_service bs ON bk.sk_booking_id = bs.sk_booking_id AND bk.booking_version = bs.booking_version

  -- Group Season
  LEFT OUTER JOIN __dbt__CTE__with_dates gs ON CAST(COALESCE(SUBSTRING(bk.season_date, 1, 4) || SUBSTRING(bk.season_date, 6, 2) || SUBSTRING(bk.season_date, 9, 2), 20991231) AS INTEGER) = gs.bk_date

  -- Market source
  LEFT OUTER JOIN __dbt__CTE__with_ar_agent ag ON bk.atcom_agent_id = ag.agt_id

  -- V1.06 Version of source market joins
  LEFT OUTER JOIN __dbt__CTE__with_ar_market m ON bk.atcom_market_id = m.mkt_id
  LEFT OUTER JOIN __dbt__CTE__with_ar_officename ofn ON m.off_id = ofn.off_name_id

  -- Channel
  LEFT OUTER JOIN __dbt__CTE__with_ar_usercodes uc ON ag.agt_tp_id = uc.user_cd_id

  -- Currency
  -- LEFT OUTER JOIN ar_currency cur ON bk.atcom_sell_currency_id = cur.cur_id

  WHERE bk_booking IS NOT NULL
)

SELECT
  bf_1.bk_booking,
  bf_1.bk_primary_accom,
  bf_1.bk_primary_room,
  bf_1.bk_first_flight,
  bf_1.bk_last_flight,
  bf_1.bk_source_market,
  bf_1.bk_originating_system,
  bf_1.bk_booking_type,
  bf_1.bk_booking_status,
  bf_1.source_booking_id,
  bf_1.source_booking_version,
  bf_1.booking_created_datetime,
  bf_1.booking_confirmed_datetime,
  bf_1.booking_cancelled_datetime,
  bf_1.group_season,
  bf_1.sm_season,
  bf_1.channel_code,
  bf_1.channel_desc,
  bf_1.booked_board_code,
  bf_1.booked_board_name,
  bf_1.multi_room_booking,
  bf_1.number_of_booked_rooms,
  bf_1.multi_centre_booking,
  bf_1.departure_date,
  bf_1.return_date,
  bf_1.duration,
  bf_1.std_number_of_booking_adult_pax,
  bf_1.std_number_of_booking_child_pax,
  bf_1.std_number_of_booking_infant_pax,
  bf_1.std_number_of_booking_pax,
  bf_1.sm_number_of_booking_adult_pax,
  bf_1.sm_number_of_booking_teenager_pax,
  bf_1.sm_number_of_booking_child_pax,
  bf_1.sm_number_of_booking_infant_pax,
  bf_1.sm_number_of_booking_pax,
  bf_1.primary_gateway,
  COALESCE(bfm.sm_currency, fx.bk_sm_ccy, 'U') AS sm_currency,
  COALESCE(bfm.sm_revenue, 0) AS sm_revenue,
  COALESCE(bfm.sm_cnx_and_amend_revenue, 0) AS sm_cnx_and_amend_revenue,
  COALESCE(bfm.sm_accommodation_costs, 0) AS sm_accommodation_costs,
  COALESCE(bfm.sm_early_booking_discounts, 0) AS sm_early_booking_discounts,
  COALESCE(bfm.sm_late_booking_discounts, 0) AS sm_late_booking_discounts,
  COALESCE(bfm.sm_flying_costs, 0) AS sm_flying_costs,
  COALESCE(bfm.sm_other_costs, 0) AS sm_other_costs,
  COALESCE(bfm.sm_distribution_costs, 0) AS sm_distribution_costs,
  COALESCE(bfm.sm_non_margin_items, 0) AS sm_non_margin_items,
  COALESCE(bfm.sm_margin, 0) AS sm_margin,
  COALESCE(bfm.smg_currency, fx.bk_smg_ccy, 'U') AS smg_currency,
  COALESCE(bfm.smg_revenue, 0) AS smg_revenue,
  COALESCE(bfm.smg_cnx_and_amend_revenue, 0) AS smg_cnx_and_amend_revenue,
  COALESCE(bfm.smg_accommodation_costs, 0) AS smg_accommodation_costs,
  COALESCE(bfm.smg_early_booking_discounts, 0) AS smg_early_booking_discounts,
  COALESCE(bfm.smg_late_booking_discounts, 0) AS smg_late_booking_discounts,
  COALESCE(bfm.smg_flying_costs, 0) AS smg_flying_costs,
  COALESCE(bfm.smg_other_costs, 0) AS smg_other_costs,
  COALESCE(bfm.smg_distribution_costs, 0) AS smg_distribution_costs,
  COALESCE(bfm.smg_non_margin_items, 0) AS smg_non_margin_items,
  COALESCE(bfm.smg_margin, 0) AS smg_margin,
  COALESCE(bfm.rep_currency, fx.bk_rep_ccy, 'U') AS rep_currency,
  COALESCE(bfm.rep_revenue, 0) AS rep_revenue,
  COALESCE(bfm.rep_cnx_and_amend_revenue, 0) AS rep_cnx_and_amend_revenue,
  COALESCE(bfm.rep_accommodation_costs, 0) AS rep_accommodation_costs,
  COALESCE(bfm.rep_early_booking_discounts, 0) AS rep_early_booking_discounts,
  COALESCE(bfm.rep_late_booking_discounts, 0) AS rep_late_booking_discounts,
  COALESCE(bfm.rep_flying_costs, 0) AS rep_flying_costs,
  COALESCE(bfm.rep_other_costs, 0) AS rep_other_costs,
  COALESCE(bfm.rep_distribution_costs, 0) AS rep_distribution_costs,
  COALESCE(bfm.rep_non_margin_items, 0) AS rep_non_margin_items,
  COALESCE(bfm.rep_margin, 0) AS rep_margin,
  COALESCE(bfm.ffd_flag, 'N') AS ffd_flag,
  bf_1.record_type,
  bf_1.effective_from,
  bf_1.effective_to,
  bf_1.sm_created_datetime,
  bf_1.sm_updated_datetime,
  bf_1.dm_created_datetime,
  CASE WHEN bf_1.source_booking_version = MAX(bf_1.source_booking_version) OVER (PARTITION BY LEFT(bf_1.bk_booking, LENGTH(bf_1.bk_booking) - REGEXP_INSTR(bf_1.bk_booking, '|', 2)))
    THEN 'Y'
    ELSE 'N'
  END AS latest_record_indicator
FROM booking_fact_1 bf_1
LEFT OUTER JOIN __dbt__CTE__with_booking_fact_margin bfm ON bf_1.bk_booking = bfm.bk_booking
LEFT OUTER JOIN opa_fl_all.source_market sm ON bf_1.bk_source_market = sm.bk_source_market
LEFT OUTER JOIN opa_fl_uk.fx_rates_dim_uk fx
  ON bf_1.sm_season = fx.bk_season
  AND sm.source_market_code = fx.source_market_code
ORDER BY
  bk_booking
  ,source_booking_version
  ,record_type DESC
      );
2019-10-02 13:21:37,208 (Thread-1): SQL status: SUCCESS 1 in 47.77 seconds
2019-10-02 13:21:37,211 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 13:21:37,212 (Thread-1): Using snowflake connection "booking_fact_uk".
2019-10-02 13:21:37,212 (Thread-1): On booking_fact_uk: COMMIT
2019-10-02 13:21:37,297 (Thread-1): SQL status: SUCCESS 1 in 0.08 seconds
2019-10-02 13:21:37,319 (Thread-1): 13:21:37 | 5 of 5 OK created table model DBT_TEST.booking_fact_uk............... [SUCCESS 1 in 49.42s]
2019-10-02 13:21:37,430 (MainThread): Using snowflake connection "master".
2019-10-02 13:21:37,432 (MainThread): On master: BEGIN
2019-10-02 13:21:37,629 (MainThread): SQL status: SUCCESS 1 in 0.20 seconds
2019-10-02 13:21:37,632 (MainThread): On master: COMMIT
2019-10-02 13:21:37,632 (MainThread): Using snowflake connection "master".
2019-10-02 13:21:37,633 (MainThread): On master: COMMIT
2019-10-02 13:21:37,786 (MainThread): SQL status: SUCCESS 1 in 0.15 seconds
2019-10-02 13:21:37,787 (MainThread): 13:21:37 | 
2019-10-02 13:21:37,787 (MainThread): 13:21:37 | Finished running 4 incremental models, 1 table model in 102.29s.
2019-10-02 13:21:37,788 (MainThread): Connection 'master' was left open.
2019-10-02 13:21:37,789 (MainThread): On master: Close
2019-10-02 13:21:37,917 (MainThread): Connection 'booking_fact_uk' was left open.
2019-10-02 13:21:37,920 (MainThread): On booking_fact_uk: Close
2019-10-02 13:21:38,140 (MainThread): 
2019-10-02 13:21:38,140 (MainThread): Completed successfully
2019-10-02 13:21:38,142 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2019-10-02 13:21:38,142 (MainThread): Flushing usage events
